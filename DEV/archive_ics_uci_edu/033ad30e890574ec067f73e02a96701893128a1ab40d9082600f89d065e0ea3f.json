{"url": "http://archive.ics.uci.edu/ml/datasets/Heterogeneity+Activity+Recognition", "content": "\n\n\n\n<!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 4.01 Transitional//EN\\\">\n<html>\n<head>\n<title>UCI Machine Learning Repository: Heterogeneity Activity Recognition Data Set</title>\n\n<!-- Stylesheet link -->\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../assets/ml.css\" />\n\n<script language=\"JavaScript\" type=\"text/javascript\">\n<!--\nfunction checkform ( form )\n{\n  // see http://www.thesitewizard.com/archive/validation.shtml\n  // for an explanation of this script and how to use it on your\n  // own website\n\n  // ** START **\n  if (form.q.value == \"\")\n  {\n    alert( \"Please enter search terms.\" );\n    form.q.focus();\n    return false ;\n  }\n\n  if (getCheckedValue(form.sitesearch) == \"ics.uci.edu\" && form.q.value.indexOf(\"site:archive.ics.uci.edu/ml\") == -1)\n  {\n    form.q.value = form.q.value + \" site:archive.ics.uci.edu/ml\";\n  }\n\n  // ** END **\n  return true ;\n}\n\n// return the value of the radio button that is checked\n// return an empty string if none are checked, or\n// there are no radio buttons\nfunction getCheckedValue(radioObj) {\n\tif(!radioObj)\n\t\treturn \"\";\n\tvar radioLength = radioObj.length;\n\tif(radioLength == undefined)\n\t\tif(radioObj.checked)\n\t\t\treturn radioObj.value;\n\t\telse\n\t\t\treturn \"\";\n\tfor(var i = 0; i < radioLength; i++) {\n\t\tif(radioObj[i].checked) {\n\t\t\treturn radioObj[i].value;\n\t\t}\n\t}\n\treturn \"\";\n}\n//-->\n</script>\n\n</head>\n\n<body>\n\n\n<!-- SITE HEADER (INCLUDES LOGO AND SEARCH BOX) -->\n\n<table width=100% bgcolor=\"#003366\">\n<tr>\n\t<td>\n\t\t<span class=\"normal\"><a href=\"../index.html\" alt=\"Home\"><img src=\"../assets/logo.gif\"\nborder=0></img></a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"http://cml.ics.uci.edu\"><font color=\"FFDD33\">Center for Machine Learning and Intelligent Systems</font></a></span>\n\t</td>\n\t<td width=100% valign=top align=\"right\">\n\t\t<span class=\"whitetext\">\n\t\t<a href=\"../about.html\">About</a>&nbsp;\n\t\t<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;\n\t\t<a href=\"../donation_policy.html\">Donate a Data Set</a>&nbsp;\n\t\t<a href=\"../contact.html\">Contact</a>\n\t\t</span>\n\n\t\t<br>\n\t\t<br>\n\t\t<!-- Search Google -->\n\n\t\t<FORM method=GET action=http://www.google.com/custom onsubmit=\"return checkform(this);\">\n\t\t<INPUT TYPE=text name=q size=30 maxlength=255 value=\"\">\n\t\t<INPUT type=submit name=sa VALUE=\"Search\">\n\t\t<INPUT type=hidden name=cof VALUE=\"AH:center;LH:130;L:http://archive.ics.uci.edu/assets/logo.gif;LW:384;AWFID:869c0b2eaa8d518e;\">\n\t\t<input type=hidden name=domains value=\"ics.uci.edu\">\n\t\t<br>\n\t\t<input type=radio name=sitesearch value=\"ics.uci.edu\" checked> <span class=\"whitetext\"><font size=\"1\">Repository</font></span>\n\t\t<input type=radio name=sitesearch value=\"\"> <span class=\"whitetext\"><font size=\"1\">Web</font></span>\n\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n\t\t<A HREF=http://www.google.com/search><IMG SRC=http://www.google.com/logos/Logo_25blk.gif border=0 ALT=Google align=middle height=27></A>\n\t\t<br>\n\t\t</FORM>\n\t\t<!-- Search Google -->\n\n\n\t\t<span class=\"whitetext\"><a href=\"../datasets.php\"><font size=\"3\" color=\"#FFDD33\"><b>View\nALL Data Sets</b></font></a></span>\n\t\t<br>\n\t</td>\n</tr>\n</table>\n\n\n<br />\n<table width=100% border=0 cellpadding=2><tr><td>\n\n   <table><tr>\n     <td valign=top>\n\t<p>\n\t<span class=\"heading\"><b>Heterogeneity Activity Recognition Data Set</b></span>\n\t<br><span class=\"normal\"><i><font size=4 >Download</font></i>: <a href=\"../machine-learning-databases/00344/\"><font\nstyle=\"BACKGROUND-COLOR: #FFFFAA\" size=4>Data Folder</font></a>, <a href=\"#\"><font\nstyle=\"BACKGROUND-COLOR: #FFFFAA\" size=4>Data Set Description</font></a></span></p>\n\n\t<p class=\"normal\"><b>Abstract</b>: The Heterogeneity Human Activity Recognition (HHAR) dataset from Smartphones and Smartwatches is a dataset devised to benchmark human activity recognition algorithms (classification, automatic data segmentation, sensor fusion, feature extraction, etc.) in real-world contexts; specifically, the dataset is gathered with a variety of different device models and use-scenarios, in order to reflect sensing heterogeneities to be expected in real deployments.</p>\n     </td>\n     <td> </td>\n   </tr></table>\n\n<table border=1 cellpadding=6>\n\t<tr>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n\t\t<td><p class=\"normal\">Multivariate, Time-Series</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n\t\t<td><p class=\"normal\">43930257</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n\t\t<td><p class=\"normal\">Computer</p></td>\n\t</tr>\n\n\t<tr>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n\t\t<td><p class=\"normal\">Real</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n\t\t<td><p class=\"normal\">16</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n\t\t<td><p class=\"normal\">2015-10-26</p></td>\n\t</tr>\n\t<tr>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n\t\t<td><p class=\"normal\">Classification, Clustering</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n\t\t<td><p class=\"normal\">Yes</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n\t\t<td><p class=\"normal\">90212</p></td>\n\t</tr>\n\t<!--\n\t<tr>\n\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Highest Percentage Achieved:&nbsp;&nbsp;</b></p></td>\n\t\t<td><p class=\"normal\">N/A</p></td>\n\t</tr>\n\t-->\n</table>\n\n\n<br />\n\n<p class=\"small-heading\"><b>Source:</b></p>\n<p class=\"normal\">Allan Stisen, allans, '@' cs.au.dk, Aarhus University, Denmark <br>Henrik Blunck, blunck '@' cs.au.dk, Aarhus University, Denmark <br>Sourav Bhattacharya, sourav.bhattacharya '@' bell-labs.com, Bell Laboratories, Dublin, Ireland <br>Thor Siiger Prentow, prentow '@' cs.au.dk, Aarhus University, Denmark <br>Mikkel Baun Kj\u00e6rgaard, mikkelbk '@' cs.au.dk, Aarhus University, Denmark <br>Anind Dey, anind '@' cs.cmu.edu, Carnegie Mellon University, USA <br>Tobias Sonne,tsonne '@' cs.au.dk, Aarhus University, Denmark <br>Mads M\u00f8ller Jensen, mmjensen '@' cs.au.dk , Aarhus University, Denmark</p>\n\n<br />\n\n<p class=\"small-heading\"><b>Data Set Information:</b></p>\n<p class=\"normal\">The Heterogeneity Dataset for Human Activity Recognition from Smartphone and Smartwatch sensors consists of two datasets devised to investigate sensor heterogeneities' impacts on human activity recognition algorithms (classification, automatic data segmentation, sensor fusion, feature extraction, etc). The datasets were used for the results and analyses produced in [1]. <br>Activity recognition data set<br><br>The dataset contains the readings of two motion sensors commonly found in smartphones. Reading were recorded while users executed activities scripted in no specific order carrying smartwatches and smartphones.<br>Activities: \u2018Biking\u2019, \u2018Sitting\u2019, \u2018Standing\u2019, \u2018Walking\u2019, \u2018Stair Up\u2019 and \u2018Stair down\u2019.<br>Sensors: Sensors: Two embedded sensors, i.e., Accelerometer and Gyroscope, sampled at the highest frequency the respective device allows.<br>Devices: 4 smartwatches (2 LG watches, 2 Samsung Galaxy Gears)<br>8 smartphones (2 Samsung Galaxy S3 mini, 2 Samsung Galaxy S3, 2 LG Nexus 4, 2 Samsung Galaxy S+)<br>Recordings: 9 users <br><br> Recording scenario<br>===============<br><br>The activity recognition environment and scenario has been designed to generate many activity primitives, yet in a realistic manner. Users took 2 different routes for the biking and walking, and 2 different set of stairs were used for the stairs up and down.<br><br> Still experiment data set<br>===================<br><br>Accelerometer recordings as above but with devices lying still, in 6 different orientations. Devices used comprise 31 smartphones, 4 smartwatches and 1 tablet, representing 13 different models from 4 manufacturers, running variants of Android and iOS.</p>\n\n<br />\n\n<p class=\"small-heading\"><b>Attribute Information:</b></p>\n<p class=\"normal\">Activity recognition data set <br>accelerometer Samples ------------ <br>The Phones_accelerometer.csv contains all smartphone accelerometer samples from all devices and users. <br>The csv file consist of the following columns: <br>'Index', 'Arrival_Time', 'Creation_Time', 'x', 'y', 'z', 'User', 'Model', 'Device', 'gt' <br><br>All samples from all the experiments is a row in the file containing each column value. <br><br>------------- Groundtruths -------------------- <br><br>The null class is defined as null in the gt (groundtruth) column, whereas the rest of the classes can be seen in the column. <br><br><br>------------- Devices -------------------------- <br>the phones from the still experiment which has been used for activity recognition is the following: <br>\u00e2\u20ac\u02dcit-116', 'it-133', 'it-108', 'it-103','it-123','3Renault-AH', 'no-name/LG-Nexus4','G-Watch' <br><br>The device numbering used in the data set is: <br>LG-Nexus 4 <br>'nexus4_1' <br>'nexus4_2' <br>Saumsung Galaxy S3 <br>'s3_1' <br>'s3_2\u00e2\u20ac\u2122 <br>Samsung Galaxy S3 min: <br>'s3mini_1' <br>'s3mini_2' <br>Samsung Galaxy S+: <br>'samsungold_1' <br>'samsungold_2' <br><br>Still experiment data set <br>This is the Heterogeneity Dataset for Human Activity Recognition, and contains all the samples <br>from the static still experiment. Where the phones where place in the 6 different possible orientation. <br>The data set is structured in the following way: <br><br>------------- Static Accelerometer Samples ------------ <br>Each specific device is located in the following way: Orientation/[Web Link] <br>Where the 6 different orientations can be either one of the following: <br>Phoneonback,Phoneonbottom,Phoneonfront,Phoneonleft,Phoneonright,Phoneontop <br><br>For example to get the samples from the device named 3Renault-AH of the model Samsung-Galaxy-S3 Mini when laying static on the back we get the following structure: <br>Phoneonback/3Renault-AH/Samsung-Galaxy-S3 Mini.csv. <br><br>Each CSV file consist of 6 columns creation time, sensor time,arrival time,x,y,z. <br>The six axes from the accelerometer is the x,y,z columns. </p>\n\n<br />\n\n<p class=\"small-heading\"><b>Relevant Papers:</b></p>\n<p class=\"normal\">[1] Allan Stisen, Henrik Blunck, Sourav Bhattacharya, Thor Siiger Prentow, Mikkel Baun Kj\u00e6rgaard, Anind Dey, Tobias Sonne, and Mads M\u00f8ller Jensen \"Smart Devices are Different: Assessing and Mitigating Mobile Sensing Heterogeneities for Activity Recognition\" In Proc. 13th ACM Conference on Embedded Networked Sensor Systems (SenSys 2015), Seoul, Korea, 2015. <a href=\"http://dx.doi.org/10.1145/2809695.2809718\">[Web Link]</a></p>\n\n<br />\n\n\n<!-- OLD CODE:\n\n<p class=\"small-heading\"><b>Papers That Cite This Data Set<sup>1</sup>:</b></p>\n<img src=\"../assets/rexa.jpg\" />\n<p class=\"normal\">N/A</p>\n\n-->\n\n\n\n<br />\n\n<p class=\"small-heading\"><b>Citation Request:</b></p>\n<p class=\"normal\">Use of this dataset in publications should be acknowledged by referencing publication [1]. <br>We recommend to refer to this dataset as the \"Heterogeneity Human Activity Recognition Dataset\" or HHAR for short in publications. <br>We also appreciate if you drop us an email (allans '@' cs.au.dk or blunck \u2018@\u2019 cs.au.dk) to inform us of any publication using this dataset or if you have further question about the dataset and how to make use of it. <br>Reference [1] details the dataset, recording scenarios, multimodality and sensor aspects of the setup as well as quality metrics for evaluating heterogeneities and their impact on HAR.</p>\n\n</td></tr></table>\n\n\n<hr>\n\n<!-- OLD CODE:\n<p class=\"normal\"><font size=1>[1] Papers were automatically harvested and associated with this data set, in collaboration with <a href=\"http://rexa.info\"><font size=1>Rexa.info</font></a></font></p>\n-->\n\n\n\n<table cellpadding=5 align=center><tr valign=center>\n\t\t<td><p class=\"normal\">Supported By:</p></td>\n        <td><img src=\"../assets/nsfe.gif\" height=60 /> </td>\n        <td><p class=\"normal\">&nbsp;In Collaboration With:</p></td>\n        <td><img src=\"../assets/rexaSmall.jpg\" /></td>\n</tr></table>\n\n<center>\n<span class=\"normal\">\n<a href=\"../about.html\">About</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../donation_policy.html\">Donation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../contact.html\">Contact</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"http://cml.ics.uci.edu\">CML</a>\n</span>\n</center>\n\n\n\n\n</body>\n</html>\n", "encoding": "utf-8"}