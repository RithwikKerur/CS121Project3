{"url": "http://archive.ics.uci.edu/ml/datasets/Pioneer-1+Mobile+Robot+Data", "content": "\n\n\n\n<!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 4.01 Transitional//EN\\\">\n<html>\n<head>\n<title>UCI Machine Learning Repository: Pioneer-1 Mobile Robot Data Data Set</title>\n\n<!-- Stylesheet link -->\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../assets/ml.css\" />\n\n<script language=\"JavaScript\" type=\"text/javascript\">\n<!--\nfunction checkform ( form )\n{\n  // see http://www.thesitewizard.com/archive/validation.shtml\n  // for an explanation of this script and how to use it on your\n  // own website\n\n  // ** START **\n  if (form.q.value == \"\")\n  {\n    alert( \"Please enter search terms.\" );\n    form.q.focus();\n    return false ;\n  }\n\n  if (getCheckedValue(form.sitesearch) == \"ics.uci.edu\" && form.q.value.indexOf(\"site:archive.ics.uci.edu/ml\") == -1)\n  {\n    form.q.value = form.q.value + \" site:archive.ics.uci.edu/ml\";\n  }\n\n  // ** END **\n  return true ;\n}\n\n// return the value of the radio button that is checked\n// return an empty string if none are checked, or\n// there are no radio buttons\nfunction getCheckedValue(radioObj) {\n\tif(!radioObj)\n\t\treturn \"\";\n\tvar radioLength = radioObj.length;\n\tif(radioLength == undefined)\n\t\tif(radioObj.checked)\n\t\t\treturn radioObj.value;\n\t\telse\n\t\t\treturn \"\";\n\tfor(var i = 0; i < radioLength; i++) {\n\t\tif(radioObj[i].checked) {\n\t\t\treturn radioObj[i].value;\n\t\t}\n\t}\n\treturn \"\";\n}\n//-->\n</script>\n\n</head>\n\n<body>\n\n\n<!-- SITE HEADER (INCLUDES LOGO AND SEARCH BOX) -->\n\n<table width=100% bgcolor=\"#003366\">\n<tr>\n\t<td>\n\t\t<span class=\"normal\"><a href=\"../index.html\" alt=\"Home\"><img src=\"../assets/logo.gif\"\nborder=0></img></a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"http://cml.ics.uci.edu\"><font color=\"FFDD33\">Center for Machine Learning and Intelligent Systems</font></a></span>\n\t</td>\n\t<td width=100% valign=top align=\"right\">\n\t\t<span class=\"whitetext\">\n\t\t<a href=\"../about.html\">About</a>&nbsp;\n\t\t<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;\n\t\t<a href=\"../donation_policy.html\">Donate a Data Set</a>&nbsp;\n\t\t<a href=\"../contact.html\">Contact</a>\n\t\t</span>\n\n\t\t<br>\n\t\t<br>\n\t\t<!-- Search Google -->\n\n\t\t<FORM method=GET action=http://www.google.com/custom onsubmit=\"return checkform(this);\">\n\t\t<INPUT TYPE=text name=q size=30 maxlength=255 value=\"\">\n\t\t<INPUT type=submit name=sa VALUE=\"Search\">\n\t\t<INPUT type=hidden name=cof VALUE=\"AH:center;LH:130;L:http://archive.ics.uci.edu/assets/logo.gif;LW:384;AWFID:869c0b2eaa8d518e;\">\n\t\t<input type=hidden name=domains value=\"ics.uci.edu\">\n\t\t<br>\n\t\t<input type=radio name=sitesearch value=\"ics.uci.edu\" checked> <span class=\"whitetext\"><font size=\"1\">Repository</font></span>\n\t\t<input type=radio name=sitesearch value=\"\"> <span class=\"whitetext\"><font size=\"1\">Web</font></span>\n\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n\t\t<A HREF=http://www.google.com/search><IMG SRC=http://www.google.com/logos/Logo_25blk.gif border=0 ALT=Google align=middle height=27></A>\n\t\t<br>\n\t\t</FORM>\n\t\t<!-- Search Google -->\n\n\n\t\t<span class=\"whitetext\"><a href=\"../datasets.php\"><font size=\"3\" color=\"#FFDD33\"><b>View\nALL Data Sets</b></font></a></span>\n\t\t<br>\n\t</td>\n</tr>\n</table>\n\n\n<br />\n<table width=100% border=0 cellpadding=2><tr><td>\n\n   <table><tr>\n     <td valign=top>\n\t<p>\n\t<span class=\"heading\"><b>Pioneer-1 Mobile Robot Data Data Set</b></span>\n\t<br><span class=\"normal\"><i><font size=4 >Download</font></i>: <a href=\"../machine-learning-databases/pioneer-mld/\"><font\nstyle=\"BACKGROUND-COLOR: #FFFFAA\" size=4>Data Folder</font></a>, <a href=\"../machine-learning-databases/pioneer-mld/pioneer.data.html\"><font\nstyle=\"BACKGROUND-COLOR: #FFFFAA\" size=4>Data Set Description</font></a></span></p>\n\n\t<p class=\"normal\"><b>Abstract</b>: This dataset contains time series sensor readings of the Pioneer-1 mobile robot. The data is broken into \"experiences\" in which the robot takes action for some period of time and experiences a control</p>\n     </td>\n     <td> </td>\n   </tr></table>\n\n<table border=1 cellpadding=6>\n\t<tr>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n\t\t<td><p class=\"normal\">Multivariate, Time-Series</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n\t\t<td><p class=\"normal\">N/A</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n\t\t<td><p class=\"normal\">Computer</p></td>\n\t</tr>\n\n\t<tr>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n\t\t<td><p class=\"normal\">Categorical, Real</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n\t\t<td><p class=\"normal\">N/A</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n\t\t<td><p class=\"normal\">1999-01-28</p></td>\n\t</tr>\n\t<tr>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n\t\t<td><p class=\"normal\">N/A</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n\t\t<td><p class=\"normal\">N/A</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n\t\t<td><p class=\"normal\">36429</p></td>\n\t</tr>\n\t<!--\n\t<tr>\n\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Highest Percentage Achieved:&nbsp;&nbsp;</b></p></td>\n\t\t<td><p class=\"normal\">N/A</p></td>\n\t</tr>\n\t-->\n</table>\n\n\n<br />\n\n<p class=\"small-heading\"><b>Source:</b></p>\n<p class=\"normal\">Matthew D. Schmill, Paul R. Cohen\r<br>Experimental Knowledge Systems Laboratory \r<br>Department of Computer Science \r<br>Box 34610 \r<br>University of Massachusetts, Amherst \r<br>Amherst, MA 01003-4610 \r<br><u>schmill <b>'@'</b> cs.umass.edu</u>, <u>cohen <b>'@'</b> cs.umass.edu</u></p>\n\n<br />\n\n<p class=\"small-heading\"><b>Data Set Information:</b></p>\n<p class=\"normal\">The data were collected over a series of specifically designed trials. Our hope was to cover most of the types of sensory interactions that a Pioneer might be reasonably expected to encounter: things like passing by visible objects, pushing visible objects, crashing into walls, etc. Many of these interactions are repeated throughout the dataset.\r<br>\r<br>This data was collected to serve as the basis for work in learning and conceptual development. Our first goal was to be able to have the robot cluster these experiences by their dynamics on their own into clusters of experiences with a common outcome.\r<br>\r<br>Each data file contains time series data in which each row of data corresponds to a single observation of the sensor array. Included in each row are two additional variables, 'id' and 'description', which indicate the experience number that the observation belongs to, and a description of that experience, respectively. Observations within an experience are taken every 100ms. \r<br>\r<br>The data is stored in three text files: one file for experiences in which the Pioneer was moving in a straight line, one in which it was turning in place, and one in which it was raising or lowering its gripper.\r<br>\r<br>The description variable is a string of symbols. The string breaks down as follows:\r<br>\r<br>\"u\" or \"o\" -  unobstructed or obstructed\r<br>\"x.xs\"     -  activity lasted x.x seconds\r<br>activity   -  the activity and speed, if applicable, i.e. move100 = move forward at 100mm/sec\r<br>visual     -  objects in the visual array are listed in sequence. \"cAHEAD\" indicates an object visible to channel c directly AHEAD of the Pioneer.\r<br>[visual.X] -  visual descriptions followed by a '.' and one character indicate that something special happens with the visible object. .V means the object Vanishes from sight during the activity. .D indicates that the object is Discovered (becomes visible) during the activity. .P indicates that the object is pushed. \r<br>\r<br>An example: \"u-3.5s-retr-100-aRIGHT.D\"  An unobstructed retreat (move) at -100 mm/sec for 3.5 seconds with an object being discovered in channel A.\r<br>\r<br>It should be noted that, particularly with respect to the visual channels, the description may not be 100% accurate. Since the visual channels respond to colors that they are trained on (visual a=red, visual b=yellow, visual c=blue), it was possible, but infrequent, for some extraneous object in the environment generated a response in visual channels that were not supposed to show activity in a particular trial.\r<br>\r<br>Rows are seperated by carriage returns, columns by commas. </p>\n\n<br />\n\n<p class=\"small-heading\"><b>Attribute Information:</b></p>\n<p class=\"normal\">TRIAL-ID\t: categorical, the trial id of the experience that the observation belongs to\r<br>DESCRIPTION\t: a symbolic description of the experience design\r<br>TIME-SECS\t: a reading of the Pioneer's internal clock, in seconds\r<br>BATTERY-LEVEL\t: a reading of battery level, in volts\r<br>SONAR-0\t\t: sonar depth reading, in mm, of the left (90) pointing sonar\r<br>SONAR-1\t\t: sonar depth reading, in mm, of a (15) pointing sonar\r<br>SONAR-2 \t: sonar depth reading, in mm, of a (7.5) pointing sonar\r<br>SONAR-3 \t: sonar depth reading, in mm, of a forward (0) pointing sonar\r<br>SONAR-4 \t: sonar depth reading, in mm, of a (-7.5) pointing sonar\r<br>SONAR-5 \t: sonar depth reading, in mm, of a (-15) pointing sonar\r<br>SONAR-6 \t: sonar depth reading, in mm, of a right (-90) pointing sonar\r<br>HEADING\t\t: heading reading, in degrees, from the robot's \"true north\"\r<br>R-WHEEL-VEL\t: right wheel velocity, in mm/sec\r<br>L-WHEEL-VEL\t: left wheel velocity, in mm/sec\r<br>TRANS-VEL\t: translational velocity, mm/sec\r<br>ROT-VEL\t\t: rotational velocity, mm/sec\r<br>R-STALL\t\t: right wheel stall sensor, binary (0/1)\r<br>L-STALL\t\t: left wheel stall sensor, binary (0/1)\r<br>ROBOT-STATUS\t: robot status, 2.0 = stationary, 3.0 = moving\r<br>GRIP-STATE\t: gripper state\r<br>GRIP-FRONT-BEAM : gripper break beam, binary, 1.0 = broken\r<br>GRIP-REAR-BEAM\t: gripper break beam, binary, 1.0 = broken\r<br>GRIP-BUMPER\t: gripper bumper, binary, 1.0 = in contact\r<br>VIS-A-AREA\t: area of dominant visible object for channel A, in pixels\r<br>VIS-A-X\t\t: X location of object in channel A on image plane, -140 ... 140\r<br>VIS-A-Y\t\t: Y location of channel A on image plane\r<br>VIS-A-H\t\t: height of object in channel A on plane, in pixels\r<br>VIS-A-W\t\t: width of object in A on image plane, in pixels\r<br>VIS-A-DIST\t: distance to object in channel A, in mm\r<br>VIS-B-AREA\t: area of dominant visible object for channel B, in pixels\r<br>VIS-B-X\t\t: X location of object in channel B on image plane, -140 ... 140\r<br>VIS-B-Y\t\t: Y location of channel B on image plane\r<br>VIS-B-H\t\t: height of object in channel B on plane, in pixels\r<br>VIS-B-W\t\t: width of object in B on image plane, in pixels\r<br>VIS-B-DIST\t: distance to object in channel B, in mm\r<br>VIS-C-AREA\t: area of dominant visible object for channel C, in pixels\r<br>VIS-C-X\t\t: X location of object in channel C on image plane, -140 ... 140\r<br>VIS-C-Y\t\t: Y location of channel C on image plane\r<br>VIS-C-H\t\t: height of object in C on image plane, in pixels\r<br>VIS-C-W\t\t: width of object in C on image plane, in pixels\r<br>VIS-C-DIST\t: distance to object in channel C, in mm\r<br>\r<br>For the visual variables, when there is no visible object, width = 0, height = 0, area = 0, distance = 10000.0, Y = 0, X = 140.0. The sonars report 5201.0 as their maximum distance. </p>\n\n<br />\n\n<p class=\"small-heading\"><b>Relevant Papers:</b></p>\n<p class=\"normal\">Oates, Tim; Schmill, Matthew D. and Cohen, Paul R. Identifying Qualitatively Different Experiences: Experiments with a Mobile Robot.\r<br><a href=\"http://rexa.info/paper/604cf86186813a56fb42b25a3065e0a6ecd14711\">[Web Link]</a>\r<br>\r<br>Schmill, Matthew D.; Oates, Tim; and Cohen, Paul R. Learned Models for Continuous Planning. Seventh International Workshop on Artificial Intelligence and Statistics. \r<br><a href=\"http://rexa.info/paper/b655463ad6c49f9a37468db4aa77683efb5f8fc0\">[Web Link]</a></p>\n\n<br />\n\n\n<!-- OLD CODE:\n\n<p class=\"small-heading\"><b>Papers That Cite This Data Set<sup>1</sup>:</b></p>\n<img src=\"../assets/rexa.jpg\" />\n<p class=\"normal\">N/A</p>\n\n-->\n\n\n\n<br />\n\n<p class=\"small-heading\"><b>Citation Request:</b></p>\n<p class=\"normal\">The work represented here was funded by DARPA contracts F49620-97-1-0485 and N66001-96-C-8504.\r<br>\r<br>For research use only. </p>\n\n</td></tr></table>\n\n\n<hr>\n\n<!-- OLD CODE:\n<p class=\"normal\"><font size=1>[1] Papers were automatically harvested and associated with this data set, in collaboration with <a href=\"http://rexa.info\"><font size=1>Rexa.info</font></a></font></p>\n-->\n\n\n\n<table cellpadding=5 align=center><tr valign=center>\n\t\t<td><p class=\"normal\">Supported By:</p></td>\n        <td><img src=\"../assets/nsfe.gif\" height=60 /> </td>\n        <td><p class=\"normal\">&nbsp;In Collaboration With:</p></td>\n        <td><img src=\"../assets/rexaSmall.jpg\" /></td>\n</tr></table>\n\n<center>\n<span class=\"normal\">\n<a href=\"../about.html\">About</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../donation_policy.html\">Donation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../contact.html\">Contact</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"http://cml.ics.uci.edu\">CML</a>\n</span>\n</center>\n\n\n\n\n</body>\n</html>\n", "encoding": "ascii"}