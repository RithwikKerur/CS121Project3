{"url": "http://archive.ics.uci.edu/ml/support/Statlog+Project#b88612f75e6cd1cee2efb08360bfb0ebf5295a97", "content": "\n\n\n\n<!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 4.01 Transitional//EN\\\">\n<html>\n<head>\n<title>UCI Machine Learning Repository: Statlog Project Data Set: Support</title>\n\n<!-- Stylesheet link -->\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../assets/ml.css\" />\n\n<script language=\"JavaScript\" type=\"text/javascript\">\n<!--\nfunction checkform ( form )\n{\n  // see http://www.thesitewizard.com/archive/validation.shtml\n  // for an explanation of this script and how to use it on your\n  // own website\n\n  // ** START **\n  if (form.q.value == \"\")\n  {\n    alert( \"Please enter search terms.\" );\n    form.q.focus();\n    return false ;\n  }\n\n  if (getCheckedValue(form.sitesearch) == \"ics.uci.edu\" && form.q.value.indexOf(\"site:archive.ics.uci.edu/ml\") == -1)\n  {\n    form.q.value = form.q.value + \" site:archive.ics.uci.edu/ml\";\n  }\n\n  // ** END **\n  return true ;\n}\n\n// return the value of the radio button that is checked\n// return an empty string if none are checked, or\n// there are no radio buttons\nfunction getCheckedValue(radioObj) {\n\tif(!radioObj)\n\t\treturn \"\";\n\tvar radioLength = radioObj.length;\n\tif(radioLength == undefined)\n\t\tif(radioObj.checked)\n\t\t\treturn radioObj.value;\n\t\telse\n\t\t\treturn \"\";\n\tfor(var i = 0; i < radioLength; i++) {\n\t\tif(radioObj[i].checked) {\n\t\t\treturn radioObj[i].value;\n\t\t}\n\t}\n\treturn \"\";\n}\n//-->\n</script>\n\n</head>\n\n<body>\n\n\n<!-- SITE HEADER (INCLUDES LOGO AND SEARCH BOX) -->\n\n<table width=100% bgcolor=\"#003366\">\n<tr>\n\t<td>\n\t\t<span class=\"normal\"><a href=\"../index.html\" \nalt=\"Home\"><img src=\"../assets/logo.gif\" \nborder=0></img></a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"http://cml.ics.uci.edu\"><font color=\"FFDD33\">Center for Machine Learning and Intelligent Systems</font></a></span>\n\t</td>\n\t<td width=100% valign=top align=\"right\">\n\t\t<span class=\"whitetext\">\n\t\t<a href=\"../about.html\">About</a>&nbsp;\n\t\t<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;\n\t\t<a href=\"../donation_policy.html\">Donate a Data Set</a>&nbsp;\n\t\t<a href=\"../contact.html\">Contact</a>\n\t\t</span>\n\n\t\t<br>\n\t\t<br>\n\t\t<!-- Search Google -->\n\n\t\t<FORM method=GET action=http://www.google.com/custom onsubmit=\"return checkform(this);\">\n\t\t<INPUT TYPE=text name=q size=30 maxlength=255 value=\"\">\n\t\t<INPUT type=submit name=sa VALUE=\"Search\">\n\t\t<INPUT type=hidden name=cof VALUE=\"AH:center;LH:130;L:http://archive.ics.uci.edu/assets/logo.gif;LW:384;AWFID:869c0b2eaa8d518e;\">\n\t\t<input type=hidden name=domains value=\"ics.uci.edu\">\n\t\t<br>\n\t\t<input type=radio name=sitesearch value=\"ics.uci.edu\" checked> <span class=\"whitetext\"><font size=\"1\">Repository</font></span>\n\t\t<input type=radio name=sitesearch value=\"\"> <span class=\"whitetext\"><font size=\"1\">Web</font></span>\n\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n\t\t<A HREF=http://www.google.com/search><IMG SRC=http://www.google.com/logos/Logo_25blk.gif border=0 ALT=Google align=middle height=27></A>\n\t\t<br>\n\t\t</FORM>\n\t\t<!-- Search Google -->\n\n\n\t\t<span class=\"whitetext\"><a href=\"../datasets.php\"><font size=\"3\" color=\"#FFDD33\"><b>View ALL Data Sets</b></font></a></span>\n\t\t<br>\n\t</td>\n</tr>\n</table>\n\n<br />\n<table width=100% border=0 cellpadding=2><tr><td>\n\n\n   <table><tr>\n     <td valign=top>\n\t<p>\n\t<span class=\"heading\"><b>Statlog Project Data Set</b></span>\n\n\t\t\n\t\t\t\t<p class=\"normal\">Below are papers that cite this data set, with context shown.\n\t\tPapers were automatically harvested and associated with this data set, in collaboration with <a href=\"http://rexa.info\">Rexa.info</a>.</p>\n\t\t<img src=\"../assets/rexa.jpg\" />\n\t\t<p class=\"normal\"><a href=\"/ml/datasets/Statlog+Project\">Return to Statlog Project data set page</a>.\n\t\t<hr><p class=\"normal\"><a name=\"dd4500e327a5f555d2f594711dc50b0f9faccd30\"></a><i>Gavin Brown. <a href=\"http://rexa.info/paper/dd4500e327a5f555d2f594711dc50b0f9faccd30\">Diversity in Neural Network Ensembles</a>. The University of Birmingham. 2004. </i><br><br>from the UCI repository (699 patterns), and the Heart disease dataset from <b>Statlog</b> (270 patterns). An ensemble consisting of two networks, each with five hidden nodes, was trained using NC. We use 5-fold cross-validation, and 40 trials from uniform random weights in<br></p><hr><p class=\"normal\"><a name=\"d64d2705cabed449e8cb2ecc3c3c77c54ee71051\"></a><i>Jeroen Eggermont and Joost N. Kok and Walter A. Kosters. <a href=\"http://rexa.info/paper/d64d2705cabed449e8cb2ecc3c3c77c54ee71051\">Genetic Programming for data classification: partitioning the search space</a>. SAC. 2004. </i><br><br>records attributes classes Australian credit  <b>statlog</b>  690 14 2 German credit (statlog) 1000 23 2 Pima Indians diabetes 768 8 2 Heart disease (statlog) 270 13 2 Ionosphere 351 34 2 total data set is divided into n parts. Each part is chosen once as the test set while the other ncross-validation. We will mention the results of C4.5 as reported by Freund and Shapire [4], in order to compare<br></p><hr><p class=\"normal\"><a name=\"1383360e8bb2cfd7a98219f867869a9f6d7e0db0\"></a><i>Wei-Chun Kao and Kai-Min Chung and Lucas Assun and Chih-Jen Lin. <a href=\"http://rexa.info/paper/1383360e8bb2cfd7a98219f867869a9f6d7e0db0\">Decomposition Methods for Linear Support Vector Machines</a>. Neural Computation, 16. 2004. </i><br><br>D. J. Spiegelhalter, and C. C. Taylor (1994). Machine Learning, Neural and Statistical Classification. Englewood Cli\u00aes, N.J.: Prentice Hall. Data available at http://www.ncc.up.pt/liacc/ML <b>statlog</b> datasets.html. Osuna, E., R. Freund, and F. Girosi (1997). Training support vector machines: An application to face detection. In Proceedings of CVPR'97, New York, NY, pp. 130--136. IEEE. Platt, J. C.<br></p><hr><p class=\"normal\"><a name=\"426e712ef75473927e172cd8d75299a5c9037bd6\"></a><i>Xiaoli Z. Fern and Carla Brodley. <a href=\"http://rexa.info/paper/426e712ef75473927e172cd8d75299a5c9037bd6\">Cluster Ensembles for High Dimensional Clustering: An Empirical Study</a>. Journal of Machine Learning Research n, a. 2004. </i><br><br>(6 letters only) UCI ML archive mfeat Handwritten digits represented by Fourier coefficients (Blake and Merz, 1998) satimage <b>StatLog</b> Satellite image data set (training set) segmentation Image segmentation data In contrast, HBGF allows the similarity of instances and the similarity of clusters to be considered simultaneously in producing the final<br></p><hr><p class=\"normal\"><a name=\"30ef69908e0a0792007e4a8b95c7c422b7e0ff99\"></a><i>Zoubin Ghahramani and Hyun-Chul Kim. <a href=\"http://rexa.info/paper/30ef69908e0a0792007e4a8b95c7c422b7e0ff99\">Bayesian Classifier Combination</a>. Gatsby Computational Neuroscience Unit University College London. 2003. </i><br><br>and using different component classifiers. We used Satellite and DNA data sets from the <b>Statlog</b> project([8]) and the UCI digit data set ([1]) 3 . Our goal was not to obtain the best classifier performance---for this we would have paid very careful attention to the component<br></p><hr><p class=\"normal\"><a name=\"74b68cad54c62b62b7ad64911291e2e0b0620dd8\"></a><i>Bart Hamers and J. A. K Suykens. <a href=\"http://rexa.info/paper/74b68cad54c62b62b7ad64911291e2e0b0620dd8\">Coupled Transductive Ensemble Learning of Kernel Models</a>. Bart De Moor. 2003. </i><br><br>donated by Quinlan and is one of the Credit Approval Databases which were used in the <b>Statlog</b> project. There 690 observations in this data set with six numerical and eight attributes. The optimal hyperparameters for the Gaussian RBF kernel are \u00a1 \u00b0, \u00be 2 \u00a2 = (9.03e2, 12.15) . All the ensembles were based on 10 submodels. Similar to all the<br></p><hr><p class=\"normal\"><a name=\"81ff15994633ecdb2b9fd5a6d11d985c2b215442\"></a><i>Ramesh Natarajan and Edwin P D Pednault. <a href=\"http://rexa.info/paper/81ff15994633ecdb2b9fd5a6d11d985c2b215442\">Segmented Regression Estimators for Massive Data Sets</a>. SDM. 2002. </i><br><br>Problems, SIAM, Philadelphia (1996). [4] C. Blake, E. Keogh and C. Merz, UCI repository of machine learning databases. (http://www.ics.uci.edu/ mlearn). [5] P. Brazdil and J. Gama, <b>statlog</b> project datasets, http://www.nccp.up.pt/liacc/ML/statlog. [6] L. Breiman, J. Friedman, R. Olshen and C. Stone, Classification and Regression Trees, Wadsworth, Belmont CA (1984). [7] G. H. Golub and C. F. Van Loan,<br></p><hr><p class=\"normal\"><a name=\"a8a26052ead9d54b217e18b4e159137da340946f\"></a><i>Jun Wang and Bin Yu and Les Gasser. <a href=\"http://rexa.info/paper/a8a26052ead9d54b217e18b4e159137da340946f\">Concept Tree Based Clustering Visualization with Shaded Similarity Matrices</a>. ICDM. 2002. </i><br><br>similarity. has a scalability limitation. One solution is to use sampling and ensemble approaches. Using small sample sizes such as 100 or 200, we have tested the sampling approach on some <b>Statlog</b> datasets, including the Shuttle dataset which contains 43, 500 instances[6]. The results are promising. 6. Summary This paper proposes a new approach for getting better interpretations for clustering<br></p><hr><p class=\"normal\"><a name=\"64b5cc377a38b3f27da4b5ec9de3391f634beb4b\"></a><i>Avelino J. Gonzalez and Lawrence B. Holder and Diane J. Cook. <a href=\"http://rexa.info/paper/64b5cc377a38b3f27da4b5ec9de3391f634beb4b\">Graph-Based Concept Learning</a>. FLAIRS Conference. 2001. </i><br><br>Voting Records Database available from the UCI machine learning repository (Keogh et. al 1998). The diabetes domain is the Pima Indians Diabetes Database, and the credit domain is the German Credit Dataset from the <b>Statlog</b> Project Databases (Keogh et. Al 1998). The Tic-Tac-Toe domain consists of 958 exhaustively generated examples. Positive examples are those where \"X\" starts moving and wins the game<br></p><hr><p class=\"normal\"><a name=\"4018f616747e1e9c96771daa20bca34c484b966a\"></a><i>Jochen Garcke and Michael Griebel and Michael Thess. <a href=\"http://rexa.info/paper/4018f616747e1e9c96771daa20bca34c484b966a\">Data Mining with Sparse Grids</a>. Computing, 67. 2001. </i><br><br>for B l is su\u00c6ciently limited. The operations of the matrices C l and G l on the vectors are then computed on the fly when needed in the conjugate gradient iteration. 3.4.1 Shuttle Data The shuttle data set comes from the <b>StatLog</b> Project [52]. It consists of 43 500 observations in the training set and 14 500 data in the testing set and has 9 attributes and 7 classes in 22 the original version. To<br></p><hr><p class=\"normal\"><a name=\"4dac55f2daa66b00a555405664b6f275370782ac\"></a><i>Haixun Wang and Carlo Zaniolo. <a href=\"http://rexa.info/paper/4dac55f2daa66b00a555405664b6f275370782ac\">CMP: A Fast Decision Tree Classifier Using Multivariate Predictions</a>. ICDE. 2000. </i><br><br>(Letter, Satimage, Segment and Shuttle) in the table are from the <b>STATLOG</b> project[6], and the two large datasets (Function 2 and Function 7) are synthetic datasets described in [5]. In these test cases there were at most N = 2 alive intervals: i) the one whose left boundary (or right boundary, depending on<br></p><hr><p class=\"normal\"><a name=\"32cb39d6ec7d1af5c8f8ad0fff8300527cf9f188\"></a><i>Edgar Acuna and Alex Rojas. <a href=\"http://rexa.info/paper/32cb39d6ec7d1af5c8f8ad0fff8300527cf9f188\">Ensembles of classifiers based on Kernel density estimators</a>. Department of Mathematics University of Puerto Rico. 2000. </i><br><br>All of them have been analyzed already in a combining setup and nine of these datasets were analyzed in the <b>Statlog</b> Project (Michie, et. al. 1994). B) To make an analysis of the bias-variance decomposition for the misclassification error when classifiers based in kernel density<br></p><hr><p class=\"normal\"><a name=\"6c5be33e1f8da0388cb66c628ccad3a0b00eab57\"></a><i>Guido Lindner and Rudi Studer. <a href=\"http://rexa.info/paper/6c5be33e1f8da0388cb66c628ccad3a0b00eab57\">AST: Support for Algorithm Selection with a CBR Approach</a>. PKDD. 1999. </i><br><br>the MLT project with its Consultant system [Consortium, 1993] as well as the <b>Statlog</b> project [Michie et al., 1994]), aiming at comparing the performance of a fixed set of algorithms on several data sets. In the Statlog project 23 algorithms were evaluated on 21 data sets. A similar perspective on model selection can be found in [Kohavi et al., 1997], where these ideas form the background<br></p><hr><p class=\"normal\"><a name=\"5eeec5743b3bcc32f80f4f6ee849c0a777f73480\"></a><i>Ljupco Todorovski and Saso Dzeroski. <a href=\"http://rexa.info/paper/5eeec5743b3bcc32f80f4f6ee849c0a777f73480\">Experiments in Meta-level Learning with ILP</a>. PKDD. 1999. </i><br><br>used in the experiments are public domain and the experiments can be repeated. This was not the case with the <b>StatLog</b> dataset repository where more then half of the datasets used are not publicly available. Another improvement is the use of a unified methodology for measuring the error rate of different classification<br></p><hr><p class=\"normal\"><a name=\"319529c0338699404ff7d7f9d7e5c900e5294959\"></a><i>Art B. Owen. <a href=\"http://rexa.info/paper/319529c0338699404ff7d7f9d7e5c900e5294959\">Tubular neighbors for regression and classification</a>. Stanford University. 1999. </i><br><br>neighbors and slightly worse (three more errors) than global logistic regression. Cross-validation did not identify the best performing method on the test cases. This diabetes data is one of the data sets in the <b>statlog</b> study (Michie et al. 1995). In the statlog study, the best method was global logistic regression, for which they report an accuracy of 77:73%. This differs from the logistic<br></p><hr><p class=\"normal\"><a name=\"6f9e5db8e117763c59d6ffabcb511900b9f62159\"></a><i>Cesar Guerra-Salcedo and L. Darrell Whitley. <a href=\"http://rexa.info/paper/6f9e5db8e117763c59d6ffabcb511900b9f62159\">Genetic Approach to Feature Selection for Ensemble Creation</a>. GECCO. 1999. </i><br><br>Features Classes Train Size Test Size LandSat 36 6 4435 2000 DNA 180 39 2000 1186 Segment 19 7 210 2100 3 EXPERIMENTAL SETUP A series of experiments were carried out using publicly available datasets provided by the Project <b>Statlog</b> 1 and by UCI machine learning repository [C. Blake and Merz, 1998]. Table 1 shows the datasets employed for this research. 3.1 ENSEMBLE RELATED SETUPS Our main<br></p><hr><p class=\"normal\"><a name=\"44326d77510f1b8976c3d73c224e9a1cb80ecc3c\"></a><i>Khaled A. Alsabti and Sanjay Ranka and Vineet Singh. <a href=\"http://rexa.info/paper/44326d77510f1b8976c3d73c224e9a1cb80ecc3c\">CLOUDS: A Decision Tree Classifier for Large Datasets</a>. KDD. 1998. </i><br><br>The first four datasets are taken from the <b>STATLOG</b> project, which has been a widely used benchmark in classification. 3 The Abalone,\" Waveform,\" and Isolet\" datasets can be found in [13]. The Synth1\" and Synth2\"<br></p><hr><p class=\"normal\"><a name=\"ca1479cb43feeda16386d2e50460bd2c1230bc8b\"></a><i>Robert E. Schapire and Yoav Freund and Peter Bartlett and Wee Sun Lee. <a href=\"http://rexa.info/paper/ca1479cb43feeda16386d2e50460bd2c1230bc8b\">The Annals of Statistics, to appear. Boosting the Margin: A New Explanation for the Effectiveness of Voting Methods</a>. AT&T Labs. 1998. </i><br><br>Each stimulus was converted into 16 primitive numerical attributes (statistical moments and edge counts) which were then scaled to fit into a range of integer values from 0 through 15.\" The satimage dataset is the <b>statlog</b> version of a satellite image dataset. According to the documentation, \"This database consists of the multi-spectral values of pixels in 3 # 3 neighborhoods in a satellite image, and<br></p><hr><p class=\"normal\"><a name=\"632fe4095475bee152843a02969ade56a290db39\"></a><i>Igor Kononenko and Edvard Simec and Marko Robnik-Sikonja. <a href=\"http://rexa.info/paper/632fe4095475bee152843a02969ade56a290db39\">Overcoming the Myopia of Inductive Learning Algorithms with RELIEFF</a>. Appl. Intell, 7. 1997. </i><br><br>(LYMP), and diagnosis in rheumatology (RHEU). ffl HEPA: prognostics of survival for patients suffering from hepatitis. The data was provided by Gail Gong from Carnegie-Mellon University. ffl Data sets obtained from the <b>StatLog</b> database[18]: diagnosis of diabetes (DIAB) and diagnosis of heart diseases (HEART). For the DIAB data set, Ragavan & Rendell [27]report 78.8% classification accuracy with<br></p><hr><p class=\"normal\"><a name=\"82d533c91dcbffe00f026dfeb08fdee463030c72\"></a><i>Oya Ekin and Peter L. Hammer and Alexander Kogan and Pawel Winter. <a href=\"http://rexa.info/paper/82d533c91dcbffe00f026dfeb08fdee463030c72\">Distance-Based Classification Methods</a>. e p o r t RUTCOR ffl Rutgers Center for Operations Research ffl Rutgers University. 1996. </i><br><br>653 instances with 15 attributes each. Carter and Catlett [3] reported an 85.5% correct prediction rate, when using 71% of all 690 instances as the training set. 4.6 German Credit  <b>Statlog</b>  This data set contains data used to evaluate credit applications in Germany. It has 1000 instances. We used a version of this data set that was produced by Strathclyde University. In this version each case is<br></p><hr><p class=\"normal\"><a name=\"dd3f32548422fd3db3846c2fba689a4406d9cf0c\"></a><i>Ron Kohavi. <a href=\"http://rexa.info/paper/dd3f32548422fd3db3846c2fba689a4406d9cf0c\">The Power of Decision Tables</a>. ECML. 1995. </i><br><br>with continuous features, we chose the rest of the <b>StatLog</b> datasets except shuttle, which was too big, and all the datasets used by Holte (1993). 4.1 Methodology We now define the exact settings used in the algorithms. The estimated accuracy for each node was<br></p><hr><p class=\"normal\"><a name=\"81865e4bd3f3a7a8b86c73c6144db99274e5bbaf\"></a><i>Georgios Paliouras and David S. Br\u00e9e. <a href=\"http://rexa.info/paper/81865e4bd3f3a7a8b86c73c6144db99274e5bbaf\">The Effect of Numeric Features on the Scalability of Inductive Learning Programs</a>. ECML. 1995. </i><br><br>was acquired from the UCI Repository [13] and its original donor was D.J. Slate. Its author has used it as an application domain for Holland-style genetic classifier systems [7]. More recently the data set has also been used in the <b>StatLog</b> project [11]. The data set contains 20; 000 instances, of which roughly 16; 000 have been used for learning in this experiment. Each instance corresponds to an<br></p><hr><p class=\"normal\"><a name=\"3f9e71cd1f71f5f65b712d5cc5c29045d0193711\"></a><i>Ron Kohavi and George H. John and Richard Long and David Manley and Karl Pfleger. <a href=\"http://rexa.info/paper/3f9e71cd1f71f5f65b712d5cc5c29045d0193711\">MLC++: A Machine Learning Library in C</a>. ICTAI. 1994. </i><br><br>but they are not an integrated environment, and are not very efficient. <b>StatLog</b> [14] is an ESPRIT project studying the behavior of over twenty algorithms (mostly in the MLToolbox), on over twenty datasets. StatLog is an instance of a good experimental study, but does not provide the tools to aid researchers in performing similar studies. Wray Buntine has recently suggested a unified approach to some<br></p><hr><p class=\"normal\"><a name=\"53ac23f963b3607aae9580b356e6b236d2955314\"></a><i>Wl/odzisl/aw Duch and Rafal/ Adamczak Email:duchraad@phys. uni. torun. pl. <a href=\"http://rexa.info/paper/53ac23f963b3607aae9580b356e6b236d2955314\">Statistical methods for construction of neural networks</a>. Department of Computer Methods, Nicholas Copernicus University. </i><br><br>cases give results that are comparable or better than those found by neural networks. A review of different approaches to classification and comparison of performance of 20 methods on 22 real world datasets has been done within the <b>StatLog</b> European Community project [3]. The algorithms that appeared most frequently as the top five were all of statistical nature, including four discriminant approaches:<br></p><hr><p class=\"normal\"><a name=\"f624e93bd6b670bc3dc31925c1c885b538131534\"></a><i>Chih-Wei Hsu and Cheng-Ru Lin. <a href=\"http://rexa.info/paper/f624e93bd6b670bc3dc31925c1c885b538131534\">A Comparison of Methods for Multi-class Support Vector Machines</a>. Department of Computer Science and Information Engineering National Taiwan University. </i><br><br>iris, wine, glass, and vowel. Those problems had already been tested in [27]. From <b>Statlog</b> collection we choose all multi-class datasets: vehicle, segment, dna, satimage, letter, and shuttle. Note that except problem dna we scale all training data to be in [-1, 1]. Then test data are adjusted using the same linear transformation.<br></p><hr><p class=\"normal\"><a name=\"e2b2b723df700c90e69a31a4403b740c2d2a7b2f\"></a><i>Alexander K. Seewald. <a href=\"http://rexa.info/paper/e2b2b723df700c90e69a31a4403b740c2d2a7b2f\">Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften</a>. </i><br><br>features which uniquely characterize the dataset. These were inspired by the <b>StatLOG</b> project (Brazdil, Gama & Henry, 1994). Space restrictions prevent us from giving exact formulas for each case, but a reference implementation is available from<br></p><hr><p class=\"normal\"><a name=\"b4f5fa80a6f5e06084e3e518c67de340a8a6aead\"></a><i>Wl/odzisl/aw Duch. <a href=\"http://rexa.info/paper/b4f5fa80a6f5e06084e3e518c67de340a8a6aead\">Support Vector Neural Training</a>. Index Terms--. </i><br><br>has been re-analyzed with a number of methods available in the Ghostminer package [11]. Many other results for this dataset may be found in the <b>Statlog</b> book [13]. Best results (Table I) were achieved with the k-Nearest Neighbors classifier with small k (automatic selection using crossvalidation tests found optimal k=3),<br></p><hr><p class=\"normal\"><a name=\"944b9d70eb0a01d18c91109dfeb566936461a194\"></a><i>Alexander K. Seewald. <a href=\"http://rexa.info/paper/944b9d70eb0a01d18c91109dfeb566936461a194\">Meta-Learning for Stacked Classification</a>. Austrian Research Institute for Artificial Intelligence. </i><br><br>features which uniquely characterize the dataset. These were inspired by the <b>StatLOG</b> project (Brazdil, Gama & Henery, 1994) and reimplemented in WEKA. # Inst, the number of examples. # log(Inst) which is the natural logarithm of Inst. # Classes,<br></p><hr><p class=\"normal\"><a name=\"e100b0bcc229ac20bf69c9a7a6bcc360ea16a720\"></a><i>Wl/odzisl/aw Duch and Karol Grudzinski. <a href=\"http://rexa.info/paper/e100b0bcc229ac20bf69c9a7a6bcc360ea16a720\">Meta-learning: searching in the model space</a>. Department of Computer Methods, Nicholas Copernicus University. </i><br><br>on which they work well. A review of many approaches to classification and comparison of performance of 20 methods on 20 real world datasets has been done within the <b>StatLog</b> European Community project [2]. The accuracy of 24 neural-based, pattern recognition and statistical classification systems has been compared on 11 large datasets<br></p><hr><p class=\"normal\"><a name=\"ce160518d6a429585aeeb3f7a784c5dfb124b669\"></a><i>Kuan-ming Lin and Chih-Jen Lin. <a href=\"http://rexa.info/paper/ce160518d6a429585aeeb3f7a784c5dfb124b669\">A Study on Reduced Support Vector Machines</a>. Department of Computer Science and Information Engineering National Taiwan University. </i><br><br>votes. The implementation of all methods mentioned above is available upon request. V. EXPERIMENTS In this section we conduct experiments on some commonly used problems. We choose large multiclass datasets from the <b>Statlog</b> collection: dna, satimage, letter, and shuttle [16]. We also consider mnist [9], an important benchmark for handwritten digit recognition. The problem ijcnn1 is from the first<br></p><hr><p class=\"normal\"><a name=\"d8a0c5fd34dede91f5241e9b9dca0626f6969c0d\"></a><i>Je Scott and Mahesan Niranjan and Richard W. Prager. <a href=\"http://rexa.info/paper/d8a0c5fd34dede91f5241e9b9dca0626f6969c0d\">Realisable Classifiers: Improving Operating Performance on Variable Cost Problems</a>. Cambridge University Department of Engineering. </i><br><br>the convex hull over the Test data ROC curves. The ROC curves for System 1 and System 2 using the Unseen data are plotted for comparison with the MRROC. 3.3 LandSat data A LandSat image segmentation dataset, originally used in the <b>Statlog</b> project, was obtained from the UCI repository [13, 12]. The data consisted of multi-spectral values of pixels in 3 # 3 neighbourhoods in a satellite image. A<br></p><hr><p class=\"normal\"><a name=\"b88612f75e6cd1cee2efb08360bfb0ebf5295a97\"></a><i>Yishay Mansour. <a href=\"http://rexa.info/paper/b88612f75e6cd1cee2efb08360bfb0ebf5295a97\">Pessimistic decision tree pruning based on tree size</a>. Computer Science Dept. Tel-Aviv University. </i><br><br><b>statlog</b>  Comparative testing and evaluation of statistical and logical learning algorithms for large-scale applications in classification, prediction and control. ftp:ftp.ncc.up.pt/pub/statlog /datasets, (See also: Machine Learning, Neural and Statistical Classification, ed. Michie, Spiegelhalter and Taylor). [VC71] V. N. Vapnik and A. Ya. Chervonenkis. On the uniform convergence of relative<br></p><hr><p class=\"normal\"><a name=\"3df4cdc6ac34e8ad8f2800107ccd6373c7e3505e\"></a><i>Guido Lindner and Rudi Studer. <a href=\"http://rexa.info/paper/3df4cdc6ac34e8ad8f2800107ccd6373c7e3505e\">Algorithm Selection Support for Classification</a>. DaimlerChrysler AG, Research & Technology FT3/KL. </i><br><br>[Sleeman et al., 1995]. Such an approach is very di\u00c6cult to maintain: each time a new algorithm has to be included one has to recompute all the rules. The <b>Statlog</b> project tried to describe data sets for a meta learning step to generate rules that specify in which case which algorithm is (possibly) applicable. The generated rules use hard boundaries within their condition part. However, instead<br></p><hr><p class=\"normal\"><a name=\"c15fec7384ce8461549ba1fc09fb2d87024cf037\"></a><i>Ron Kohavi and George H. John. <a href=\"http://rexa.info/paper/c15fec7384ce8461549ba1fc09fb2d87024cf037\">Automatic Parameter Selection by Minimizing Estimated Error</a>. Computer Science Dept. Stanford University. </i><br><br>being studied. We report experiments with this method on 33 datasets selected from the UCI and <b>StatLog</b> collections using C4.5 as the basic induction algorithm. At a 90% confidence level, our method improves the performance of C4.5 on nine domains, degrades<br></p><hr><p class=\"normal\"><a name=\"b9b24d88e45ac7034e22363aac1347ca65caffc6\"></a><i>I\u00f1aki Inza and Pedro Larraaga and Ramon Etxeberria and Basilio Sierra. <a href=\"http://rexa.info/paper/b9b24d88e45ac7034e22363aac1347ca65caffc6\">Feature Subset Selection by Bayesian networks based optimization</a>. Dept. of Computer Science and Artificial Intelligence. University of the Basque Country. </i><br><br>come from the UCI repository [66]. Image dataset comes from the <b>Statlog</b> project [83]. LED24 (Breiman et al. [15]) is a well known artificial dataset with 7 equally relevant and 17 irrelevant binary features. We designed another artificial domain,<br></p><hr><p class=\"normal\"><a name=\"f894a06c44cd7ad6cf65caefba1dbe69d29763ec\"></a><i>Ron Kohavi and George John and Richard Long and David Manley and Karl Pfleger. <a href=\"http://rexa.info/paper/f894a06c44cd7ad6cf65caefba1dbe69d29763ec\">Appears in Tools with AI '94</a>. Computer Science Department Stanford University. </i><br><br>but they are not an integrated environment, and are not very efficient. <b>StatLog</b> [19] is an ESPRIT project studying the behavior of over twenty algorithms (mostly in the MLToolbox), on over twenty datasets. StatLog is an instance of a good experimental study, but does not provide the tools to aid researchers in performing similar studies. Wray Buntine has recently suggested a unified approach to some<br></p><hr><p class=\"normal\"><a name=\"193231e78c226995eee9f66bf9a4177b8416daf4\"></a><i>H. -T Lin and C. -J Lin. <a href=\"http://rexa.info/paper/193231e78c226995eee9f66bf9a4177b8416daf4\">A Study on Sigmoid Kernels for SVM and the Training of non-PSD Kernels by SMO-type Methods</a>. Department of Computer Science and Information Engineering National Taiwan University. </i><br><br>D. J. Spiegelhalter, and C. C. Taylor (1994). Machine Learning, Neural and Statistical Classification. Englewood Cliffs, N.J.: Prentice Hall. Data available at http://www.ncc.up.pt/liacc/ML <b>statlog</b> datasets.html. Nash, S. G. and A. Sofer (1996). Linear and Nonlinear Programming. McGraw-Hill. Osuna, E., R. Freund, and F. Girosi (1997). Training support vector machines: An application to face detection.<br></p><hr><p class=\"normal\"><a name=\"28734e2b9b072c9ef055eefa88999a60f6a3dc81\"></a><i>Jun Wang. <a href=\"http://rexa.info/paper/28734e2b9b072c9ef055eefa88999a60f6a3dc81\">Classification Visualization with Shaded Similarity Matrix</a>. Bei Yu Les Gasser Graduate School of Library and Information Science University of Illinois at Urbana-Champaign. </i><br><br>explored in the future. The purpose of this section is to see if it is effective to use simple random sampling with very small sample size. To this end, we test the ensemble classifier on 5 <b>Statlog</b> data sets: Satimage, Segment, Shuttle, Australian, and DNA. For data description, please see Table 3. The reason to use these 5 Statlog data sets is because Ankerst used them as benchmark in his PBC system<br></p><hr><p class=\"normal\"><a name=\"da329267bf8880c2becb15eae121a5b002347349\"></a><i>Rong-En Fan and P. -H Chen and C. -J Lin. <a href=\"http://rexa.info/paper/da329267bf8880c2becb15eae121a5b002347349\">Working Set Selection Using the Second Order Information for Training SVM</a>. Department of Computer Science and Information Engineering National Taiwan University. </i><br><br>D. J. Spiegelhalter, and C. C. Taylor. Machine Learning, Neural and Statistical Classification. Prentice Hall, Englewood Cliffs, N.J., 1994. Data available at http://www.ncc.up.pt/liacc/ML <b>statlog</b> datasets.html. E. Osuna, R. Freund, and F. Girosi. Training support vector machines: An application to face detection. In Proceedings of CVPR'97, pages 130--136, New York, NY, 1997. IEEE. Laura Palagi and<br></p><hr><p class=\"normal\"><a name=\"0fe919006360334c17c021088209b2a45eadb84d\"></a><i>Wl odzisl/aw Duch and Karol Grudzinski. <a href=\"http://rexa.info/paper/0fe919006360334c17c021088209b2a45eadb84d\">Search and global minimization in similarity-based methods</a>. Department of Computer Methods, Nicholas Copernicus University. </i><br><br>significant improvements of results obtained with reduced feature set or with weighted features are obtained. Other tests that we have performed indicate that for more than half of the <b>Statlog</b> datasets [1] feature selection and weighting makes k-NN results better than that of any other classifiers used in this project. The same feature selection and weighting methods may be used to improve<br></p><hr><p class=\"normal\"><a name=\"c7147f5e08903c837fbc854a1979dd207bd90350\"></a><i>Wl odzisl and aw Duch. <a href=\"http://rexa.info/paper/c7147f5e08903c837fbc854a1979dd207bd90350\">Committees of Undemocratic Competent Models</a>. School of Computer Engineering Nanyang Technological University. </i><br><br>k=7, Euclidean 94.9 95.3 best single CUC model Dipol92 98.3 95.2 <b>STATLOG</b> Alloc80 93.7 94.3 Statlog Quadratic DA 100 94.1 Statlog LDA 96.6 94.1 Statlog TABLE II COMPARISON OF RESULTS ON THE LETTER DATASET. RESULTS ARE FROM THE STATLOG BOOK OR OUR OWN CALCULATIONS . System Train % Test % Remarks CUC committee 98.5 96.5 Majority committee 95.8 95.4 kNN, k=5, Euclidean 94.8 95.4 best single CUC model<br></p><hr><p class=\"normal\"><a name=\"2b9850dda87431cc9117f2a0a63d79863723e4b0\"></a><i>Krzysztof Grabczewski and Wl/odzisl/aw Duch. <a href=\"http://rexa.info/paper/2b9850dda87431cc9117f2a0a63d79863723e4b0\">THE SEPARABILITY OF SPLIT VALUE CRITERION</a>. Department of Computer Methods, Nicolaus Copernicus University. </i><br><br>analyzed in the Stalog project [6]. Results of the C4.5 decision tree are already significantly worse. 5.4 <b>Statlog</b> Australian credit data This dataset contains 690 cases classified in 2 classes (+ and -). Data vectors are described by 14 attributes (6 continuous and 8 discrete). In the Table 4 a comparison of 10 fold crossvalidation results for<br></p><hr><p class=\"normal\"><a name=\"f91a9d851efd2169d5f16f8bfd5c7b9d2b81655c\"></a><i>C. esar and Cesar Guerra-Salcedo and Darrell Whitley. <a href=\"http://rexa.info/paper/f91a9d851efd2169d5f16f8bfd5c7b9d2b81655c\">Feature Selection Mechanisms for Ensemble Creation : A Genetic Search Perspective</a>. Department of Computer Science Colorado State University. </i><br><br>1993) and a table-based classifier called Euclidean Decision Tables (EDT) (Guerra-Salcedo & Whitley 1998). Setups and Results A series of experiments were carried out using publicly available datasets provided by the Project <b>Statlog</b> 1 the UCI machine learning repository (C. Blake & Merz 1998) and by Richard Bankert of the Naval Research Laboratory. Table 1 shows the datasets employed for this<br></p><hr><p class=\"normal\"><a name=\"e5d994d772cfe5ec4d0f3e6d669f0bc28180a3ae\"></a><i>Elena Smirnova and Ida G. Sprinkhuizen-Kuyper and I. Nalbantis and b. ERIM and Universiteit Rotterdam. <a href=\"http://rexa.info/paper/e5d994d772cfe5ec4d0f3e6d669f0bc28180a3ae\">Unanimous Voting using Support Vector Machines</a>. IKAT, Universiteit Maastricht. </i><br><br>the hypothesis space H contains the target hyperplane, the hyperplane is consistent with the training data; i.e., it belongs to the version space [7, 11]. Thus, the unanimous-voting classification Data Set Parameters Cvssvm Avssvm Asvm I Heart <b>Statlog</b> P, E=2.0, C=1730 56.3% 100% 73.0% 0.42 Heart-Statlog RBF, G=0.2 , C=2182 40.7% 100% 73.7 % 0.24 Hepatitis P, E=1.4, C=11.7 80.0% 100% 80.0 % 0.72<br></p><hr><p class=\"normal\"><a name=\"4c8e8cf6857f1f1bc9b43679d241b096513ee6f2\"></a><i>Ron Kohavi and Barry G. Becker and Dan Sommerfield. <a href=\"http://rexa.info/paper/4c8e8cf6857f1f1bc9b43679d241b096513ee6f2\">Improving Simple Bayes</a>. Data Mining and Visualization Group Silicon Graphics, Inc. </i><br><br>was large or artificial, indicating that a single test set would yield accurate estimates, we used a training-set/test-set as defined in the source for the dataset (e.g., <b>Statlog</b> defined the splits for DNA, letter, satimage; CART defined the training size for waveform and led24) or a 2/3, 1/3 split, and ran the inducer once; otherwise, we performed 10-fold<br></p><hr><p class=\"normal\"><a name=\"5fb9f4bc7a3d1365076eca93c3ffae6e628a8926\"></a><i>Wl odzisl and aw Duch. <a href=\"http://rexa.info/paper/5fb9f4bc7a3d1365076eca93c3ffae6e628a8926\">Control and Cybernetics</a>. Department of Computer Methods, Nicholas Copernicus University. </i><br><br>and thus also belong to the SBM. All of these methods may be useful in control problems. A review of many approaches to classification and comparison of performance of 20 methods on 20 real world datasets has been done within the <b>StatLog</b> European Community project (Michie et al. 1994). More recently the accuracy of 24 neuralbased, pattern recognition and statistical classification systems has been<br></p><hr><p class=\"normal\"><a name=\"8afa6796645ce4b0642db26c822cf6bfa8cc4d0d\"></a><i>Wl odzisl/aw Duch and Rudy Setiono and Jacek M. Zurada. <a href=\"http://rexa.info/paper/8afa6796645ce4b0642db26c822cf6bfa8cc4d0d\">Computational intelligence methods for rule-based data understanding</a>. </i><br><br>diabetes. Eight attributes describe age, number of times pregnant, body mass index, plasma glucose concentration, diastolic blood pressure, diabetes pedigree function, and other medical tests. This dataset was used in the <b>Statlog</b> project [89], with the best 10-fold cross-validation accuracy around 77.7% obtained by logistic discriminant analysis. Our estimation of variance on cross-validation<br></p>\n\n\n\t</td></tr></table>\n\n\n\n<hr>\n\n<p class=\"normal\"><a href=\"/datasets/Statlog+Project\">Return to Statlog Project data set page</a>.\n\n\n<table cellpadding=5 align=center><tr valign=center>\n\t\t<td><p class=\"normal\">Supported By:</p></td>\n        <td><img src=\"../assets/nsfe.gif\" height=60 /> </td>\n        <td><p class=\"normal\">&nbsp;In Collaboration With:</p></td>\n        <td><img src=\"../assets/rexaSmall.jpg\" /></td>\n</tr></table>\n\n<center>\n<span class=\"normal\">\n<a href=\"../about.html\">About</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../donation_policy.html\">Donation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../contact.html\">Contact</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"http://cml.ics.uci.edu\">CML</a>\n</span>\n</center>\n\n\n\n\n</body>\n</html>\n", "encoding": "ISO-8859-1"}