{"url": "http://archive.ics.uci.edu/ml/datasets/MEx", "content": "\n\n\n\n<!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 4.01 Transitional//EN\\\">\n<html>\n<head>\n<title>UCI Machine Learning Repository: MEx Data Set</title>\n\n<!-- Stylesheet link -->\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../assets/ml.css\" />\n\n<script language=\"JavaScript\" type=\"text/javascript\">\n<!--\nfunction checkform ( form )\n{\n  // see http://www.thesitewizard.com/archive/validation.shtml\n  // for an explanation of this script and how to use it on your\n  // own website\n\n  // ** START **\n  if (form.q.value == \"\")\n  {\n    alert( \"Please enter search terms.\" );\n    form.q.focus();\n    return false ;\n  }\n\n  if (getCheckedValue(form.sitesearch) == \"ics.uci.edu\" && form.q.value.indexOf(\"site:archive.ics.uci.edu/ml\") == -1)\n  {\n    form.q.value = form.q.value + \" site:archive.ics.uci.edu/ml\";\n  }\n\n  // ** END **\n  return true ;\n}\n\n// return the value of the radio button that is checked\n// return an empty string if none are checked, or\n// there are no radio buttons\nfunction getCheckedValue(radioObj) {\n\tif(!radioObj)\n\t\treturn \"\";\n\tvar radioLength = radioObj.length;\n\tif(radioLength == undefined)\n\t\tif(radioObj.checked)\n\t\t\treturn radioObj.value;\n\t\telse\n\t\t\treturn \"\";\n\tfor(var i = 0; i < radioLength; i++) {\n\t\tif(radioObj[i].checked) {\n\t\t\treturn radioObj[i].value;\n\t\t}\n\t}\n\treturn \"\";\n}\n//-->\n</script>\n\n</head>\n\n<body>\n\n\n<!-- SITE HEADER (INCLUDES LOGO AND SEARCH BOX) -->\n\n<table width=100% bgcolor=\"#003366\">\n<tr>\n\t<td>\n\t\t<span class=\"normal\"><a href=\"../index.html\" alt=\"Home\"><img src=\"../assets/logo.gif\"\nborder=0></img></a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"http://cml.ics.uci.edu\"><font color=\"FFDD33\">Center for Machine Learning and Intelligent Systems</font></a></span>\n\t</td>\n\t<td width=100% valign=top align=\"right\">\n\t\t<span class=\"whitetext\">\n\t\t<a href=\"../about.html\">About</a>&nbsp;\n\t\t<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;\n\t\t<a href=\"../donation_policy.html\">Donate a Data Set</a>&nbsp;\n\t\t<a href=\"../contact.html\">Contact</a>\n\t\t</span>\n\n\t\t<br>\n\t\t<br>\n\t\t<!-- Search Google -->\n\n\t\t<FORM method=GET action=http://www.google.com/custom onsubmit=\"return checkform(this);\">\n\t\t<INPUT TYPE=text name=q size=30 maxlength=255 value=\"\">\n\t\t<INPUT type=submit name=sa VALUE=\"Search\">\n\t\t<INPUT type=hidden name=cof VALUE=\"AH:center;LH:130;L:http://archive.ics.uci.edu/assets/logo.gif;LW:384;AWFID:869c0b2eaa8d518e;\">\n\t\t<input type=hidden name=domains value=\"ics.uci.edu\">\n\t\t<br>\n\t\t<input type=radio name=sitesearch value=\"ics.uci.edu\" checked> <span class=\"whitetext\"><font size=\"1\">Repository</font></span>\n\t\t<input type=radio name=sitesearch value=\"\"> <span class=\"whitetext\"><font size=\"1\">Web</font></span>\n\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n\t\t<A HREF=http://www.google.com/search><IMG SRC=http://www.google.com/logos/Logo_25blk.gif border=0 ALT=Google align=middle height=27></A>\n\t\t<br>\n\t\t</FORM>\n\t\t<!-- Search Google -->\n\n\n\t\t<span class=\"whitetext\"><a href=\"../datasets.php\"><font size=\"3\" color=\"#FFDD33\"><b>View\nALL Data Sets</b></font></a></span>\n\t\t<br>\n\t</td>\n</tr>\n</table>\n\n\n<br />\n<table width=100% border=0 cellpadding=2><tr><td>\n\n   <table><tr>\n     <td valign=top>\n\t<p>\n\t<span class=\"heading\"><b>MEx Data Set</b></span>\n\t<br><span class=\"normal\"><i><font size=4 >Download</font></i>: <a href=\"../machine-learning-databases/00500/\"><font\nstyle=\"BACKGROUND-COLOR: #FFFFAA\" size=4>Data Folder</font></a>, <a href=\"#\"><font\nstyle=\"BACKGROUND-COLOR: #FFFFAA\" size=4>Data Set Description</font></a></span></p>\n\n\t<p class=\"normal\"><b>Abstract</b>: The MEx Multi-modal Exercise dataset contains data of 7 different\r\nphysiotherapy exercises, performed by 30 subjects recorded with 2 accelerometers,\r\na pressure mat and a depth camera.</p>\n     </td>\n     <td> </td>\n   </tr></table>\n\n<table border=1 cellpadding=6>\n\t<tr>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n\t\t<td><p class=\"normal\">Time-Series</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n\t\t<td><p class=\"normal\">6262</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n\t\t<td><p class=\"normal\">Computer</p></td>\n\t</tr>\n\n\t<tr>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n\t\t<td><p class=\"normal\">Real</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n\t\t<td><p class=\"normal\">710</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n\t\t<td><p class=\"normal\">2019-09-20</p></td>\n\t</tr>\n\t<tr>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n\t\t<td><p class=\"normal\">Classification, Clustering</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n\t\t<td><p class=\"normal\">N/A</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n\t\t<td><p class=\"normal\">1516</p></td>\n\t</tr>\n\t<!--\n\t<tr>\n\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Highest Percentage Achieved:&nbsp;&nbsp;</b></p></td>\n\t\t<td><p class=\"normal\">N/A</p></td>\n\t</tr>\n\t-->\n</table>\n\n\n<br />\n\n<p class=\"small-heading\"><b>Source:</b></p>\n<p class=\"normal\">Anjana Wijekoon, Nirmalie Wiratunga, Kay Cooper\r<br>Robert Gordon University\r<br>Aberdeen, UK</p>\n\n<br />\n\n<p class=\"small-heading\"><b>Data Set Information:</b></p>\n<p class=\"normal\">The MEx Multi-modal Exercise dataset contains data of 7 different physiotherapy\r<br>exercises, performed by 30 subjects recorded four sensor modalities.\r<br>**Application**\r<br>The dataset can be used for exercise recognition, exercise quality assessment and\r<br>exercise counting, by developing algorithms for pre-processing, feature extraction,\r<br>multi-modal sensor fusion, segmentation and classification.\r<br>\r<br>** Data collection method **\r<br>Each subject was given a sheet of 7 exercises with instructions to perform the\r<br>exercise at the beginning of the session. At the beginning of each exercise the\r<br>researcher demonstrated the exercise to the subject, then the subject performed the\r<br>exercise for maximum 60 seconds while being recorded with four sensors. During\r<br>the recording, the researcher did not give any advice or kept count or time to enforce\r<br>a rhythm.\r<br>** Sensors**\r<br>Obbrec Astra Depth Camera\r<br>- sampling frequency - 15Hz\u00a0\r<br>- frame size - 240x320\r<br>Sensing Tex Pressure Mat\r<br>- sampling frequency - 15Hz\r<br>- frame size - 32*16\r<br>Axivity AX3 3-Axis Logging Accelerometer\r<br>- sampling frequency - 100Hz\r<br>- range - 8g\r<br>\r<br>** Sensor Placement**\r<br>All the exercises were performed lying down on the mat while the subject wearing\r<br>two accelerometers on the wrist and the thigh. The depth camera was placed above\r<br>the subject facing down-words recording an aerial view. Top of the depth camera\r<br>frame was aligned with the top of the pressure mat frame and the subject\u00e2\u20ac\u2122s\r<br>shoulders such that the face will not be included in the depth camera video.\r<br>** Data folder **\r<br>MEx folder has four folders, one for each sensor. Inside each sensor folder,\r<br>30 folders can be found, one for each subject. In each subject folder, 8 files can be\r<br>found for each exercise with 2 files for exercise 4 as it is performed on two sides.\r<br>(The user 22 will only have 7 files as they performed the exercise 4 on only one\r<br>side.) One line in the data files correspond to one timestamped and sensory data.</p>\n\n<br />\n\n<p class=\"small-heading\"><b>Attribute Information:</b></p>\n<p class=\"normal\">The 4 columns in the act and acw files is organized as follows:\r<br>1 - timestamp\r<br>2 - x value\r<br>3 - y value\r<br>4 - z value\r<br>Min value = -8\r<br>Max value = +8\r<br>The 513 columns in the pm file is organized as follows:\r<br>1 - timestamp\r<br>2-513 pressure mat data frame (32x16)\r<br>Min value - 0\r<br>Max value - 1\r<br>The 193 columns in the dc file is organized as follows:\r<br>1 - timestamp\r<br>2-193 depth camera data frame (12x16)\r<br>dc data frame is scaled down from 240x320 to 12x16 using the OpenCV resize\r<br>algorithm\r<br>Min value - 0\r<br>Max value - 1</p>\n\n<br />\n\n<p class=\"small-heading\"><b>Relevant Papers:</b></p>\n<p class=\"normal\">Wijekoon, Anjana, Nirmalie Wiratunga, and Kay Cooper. 'MEx: Multi-modal Exercises Dataset for Human Activity Recognition.' arXiv preprint <a href=\"arXiv:1908.08992\">[Web Link]</a> (2019).</p>\n\n<br />\n\n\n<!-- OLD CODE:\n\n<p class=\"small-heading\"><b>Papers That Cite This Data Set<sup>1</sup>:</b></p>\n<img src=\"../assets/rexa.jpg\" />\n<p class=\"normal\">N/A</p>\n\n-->\n\n\n\n<br />\n\n<p class=\"small-heading\"><b>Citation Request:</b></p>\n<p class=\"normal\">@article{wijekoon2019mex,\r<br>  title={MEx: Multi-modal Exercises Dataset for Human Activity Recognition},\r<br>  author={Wijekoon, Anjana and Wiratunga, Nirmalie and Cooper, Kay},\r<br>  journal={arXiv preprint <a href=\"arXiv:1908.08992\">[Web Link]</a>},\r<br>  year={2019}\r<br>}</p>\n\n</td></tr></table>\n\n\n<hr>\n\n<!-- OLD CODE:\n<p class=\"normal\"><font size=1>[1] Papers were automatically harvested and associated with this data set, in collaboration with <a href=\"http://rexa.info\"><font size=1>Rexa.info</font></a></font></p>\n-->\n\n\n\n<table cellpadding=5 align=center><tr valign=center>\n\t\t<td><p class=\"normal\">Supported By:</p></td>\n        <td><img src=\"../assets/nsfe.gif\" height=60 /> </td>\n        <td><p class=\"normal\">&nbsp;In Collaboration With:</p></td>\n        <td><img src=\"../assets/rexaSmall.jpg\" /></td>\n</tr></table>\n\n<center>\n<span class=\"normal\">\n<a href=\"../about.html\">About</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../donation_policy.html\">Donation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../contact.html\">Contact</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"http://cml.ics.uci.edu\">CML</a>\n</span>\n</center>\n\n\n\n\n</body>\n</html>\n", "encoding": "utf-8"}