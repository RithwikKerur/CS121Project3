{"url": "http://archive.ics.uci.edu/ml/datasets/BAUM-2", "content": "\n\n\n\n<!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 4.01 Transitional//EN\\\">\n<html>\n<head>\n<title>UCI Machine Learning Repository: BAUM-2 Data Set</title>\n\n<!-- Stylesheet link -->\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../assets/ml.css\" />\n\n<script language=\"JavaScript\" type=\"text/javascript\">\n<!--\nfunction checkform ( form )\n{\n  // see http://www.thesitewizard.com/archive/validation.shtml\n  // for an explanation of this script and how to use it on your\n  // own website\n\n  // ** START **\n  if (form.q.value == \"\")\n  {\n    alert( \"Please enter search terms.\" );\n    form.q.focus();\n    return false ;\n  }\n\n  if (getCheckedValue(form.sitesearch) == \"ics.uci.edu\" && form.q.value.indexOf(\"site:archive.ics.uci.edu/ml\") == -1)\n  {\n    form.q.value = form.q.value + \" site:archive.ics.uci.edu/ml\";\n  }\n\n  // ** END **\n  return true ;\n}\n\n// return the value of the radio button that is checked\n// return an empty string if none are checked, or\n// there are no radio buttons\nfunction getCheckedValue(radioObj) {\n\tif(!radioObj)\n\t\treturn \"\";\n\tvar radioLength = radioObj.length;\n\tif(radioLength == undefined)\n\t\tif(radioObj.checked)\n\t\t\treturn radioObj.value;\n\t\telse\n\t\t\treturn \"\";\n\tfor(var i = 0; i < radioLength; i++) {\n\t\tif(radioObj[i].checked) {\n\t\t\treturn radioObj[i].value;\n\t\t}\n\t}\n\treturn \"\";\n}\n//-->\n</script>\n\n</head>\n\n<body>\n\n\n<!-- SITE HEADER (INCLUDES LOGO AND SEARCH BOX) -->\n\n<table width=100% bgcolor=\"#003366\">\n<tr>\n\t<td>\n\t\t<span class=\"normal\"><a href=\"../index.html\" alt=\"Home\"><img src=\"../assets/logo.gif\"\nborder=0></img></a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"http://cml.ics.uci.edu\"><font color=\"FFDD33\">Center for Machine Learning and Intelligent Systems</font></a></span>\n\t</td>\n\t<td width=100% valign=top align=\"right\">\n\t\t<span class=\"whitetext\">\n\t\t<a href=\"../about.html\">About</a>&nbsp;\n\t\t<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;\n\t\t<a href=\"../donation_policy.html\">Donate a Data Set</a>&nbsp;\n\t\t<a href=\"../contact.html\">Contact</a>\n\t\t</span>\n\n\t\t<br>\n\t\t<br>\n\t\t<!-- Search Google -->\n\n\t\t<FORM method=GET action=http://www.google.com/custom onsubmit=\"return checkform(this);\">\n\t\t<INPUT TYPE=text name=q size=30 maxlength=255 value=\"\">\n\t\t<INPUT type=submit name=sa VALUE=\"Search\">\n\t\t<INPUT type=hidden name=cof VALUE=\"AH:center;LH:130;L:http://archive.ics.uci.edu/assets/logo.gif;LW:384;AWFID:869c0b2eaa8d518e;\">\n\t\t<input type=hidden name=domains value=\"ics.uci.edu\">\n\t\t<br>\n\t\t<input type=radio name=sitesearch value=\"ics.uci.edu\" checked> <span class=\"whitetext\"><font size=\"1\">Repository</font></span>\n\t\t<input type=radio name=sitesearch value=\"\"> <span class=\"whitetext\"><font size=\"1\">Web</font></span>\n\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n\t\t<A HREF=http://www.google.com/search><IMG SRC=http://www.google.com/logos/Logo_25blk.gif border=0 ALT=Google align=middle height=27></A>\n\t\t<br>\n\t\t</FORM>\n\t\t<!-- Search Google -->\n\n\n\t\t<span class=\"whitetext\"><a href=\"../datasets.php\"><font size=\"3\" color=\"#FFDD33\"><b>View\nALL Data Sets</b></font></a></span>\n\t\t<br>\n\t</td>\n</tr>\n</table>\n\n\n<br />\n<table width=100% border=0 cellpadding=2><tr><td>\n\n   <table><tr>\n     <td valign=top>\n\t<p>\n\t<span class=\"heading\"><b>BAUM-2 Data Set</b></span>\n\t<br><span class=\"normal\"><i><font size=4 >Download</font></i>: <a href=\"../machine-learning-databases/00474/\"><font\nstyle=\"BACKGROUND-COLOR: #FFFFAA\" size=4>Data Folder</font></a>, <a href=\"#\"><font\nstyle=\"BACKGROUND-COLOR: #FFFFAA\" size=4>Data Set Description</font></a></span></p>\n\n\t<p class=\"normal\"><b>Abstract</b>: A multilingual audio-visual affective face database consisting of 1047 video clips of 286 subjects. </p>\n     </td>\n     <td> </td>\n   </tr></table>\n\n<table border=1 cellpadding=6>\n\t<tr>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Data Set Characteristics:&nbsp;&nbsp;</b></p></td>\n\t\t<td><p class=\"normal\">Time-Series</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Instances:</b></p></td>\n\t\t<td><p class=\"normal\">1047</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Area:</b></p></td>\n\t\t<td><p class=\"normal\">Computer</p></td>\n\t</tr>\n\n\t<tr>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Attribute Characteristics:</b></p></td>\n\t\t<td><p class=\"normal\">N/A</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Attributes:</b></p></td>\n\t\t<td><p class=\"normal\">N/A</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Date Donated</b></p></td>\n\t\t<td><p class=\"normal\">2018-11-09</p></td>\n\t</tr>\n\t<tr>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Associated Tasks:</b></p></td>\n\t\t<td><p class=\"normal\">Classification</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Missing Values?</b></p></td>\n\t\t<td><p class=\"normal\">N/A</p></td>\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Number of Web Hits:</b></p></td>\n\t\t<td><p class=\"normal\">8295</p></td>\n\t</tr>\n\t<!--\n\t<tr>\n\n\t\t<td bgcolor=\"#DDEEFF\"><p class=\"normal\"><b>Highest Percentage Achieved:&nbsp;&nbsp;</b></p></td>\n\t\t<td><p class=\"normal\">N/A</p></td>\n\t</tr>\n\t-->\n</table>\n\n\n<br />\n\n<p class=\"small-heading\"><b>Source:</b></p>\n<p class=\"normal\">C. E. Erdem, C. Turan, Z. Ayd\u00c4\u00b1n, 'BAUM-2: a multilingual audio-visual affecive face database', Multimedia Tools and Applications, vol.74, pp. 7429-7459, 2015. \r<br>DOI 10.1007/s11042-014-1986-2\r<br>\r<br>\r<br>\r<br></p>\n\n<br />\n\n<p class=\"small-heading\"><b>Data Set Information:</b></p>\n<p class=\"normal\">A multilingual audio-visual affective face database consisting of 1047 video clips of 286 subjects. The collected clips simulate real-world conditions by containing various head poses, illumination conditions, accessories, temporary occlusions and subjects with a wide range of ages.\r<br>\r<br>In order to download the database please send an e-mail to <u>cigdem.turan <b>'@'</b> connect.polyu.hk</u> or <u>cigdem.erogluerdem <b>'@'</b> gmail.com</u></p>\n\n<br />\n\n<p class=\"small-heading\"><b>Attribute Information:</b></p>\n<p class=\"normal\">The readme file contains more information about the format of the database. </p>\n\n<br />\n\n<p class=\"small-heading\"><b>Relevant Papers:</b></p>\n<p class=\"normal\">\r<br>Histogram-based local descriptors for facial expression recognition (FER): A comprehensive study\r<br>By: Turan, Cigdem; Lam, Kin-Man\r<br>JOURNAL OF VISUAL COMMUNICATION AND IMAGE REPRESENTATION  Volume: 55   Pages: 331-341   Published: AUG 2018\r<br>\r<br>\r<br>BAUM-1: A Spontaneous Audio-Visual Face Database of Affective and Mental States\r<br>By: Zhalehpour, Sara; Onder, Onur; Akhtar, Zahid; et al.\r<br>IEEE TRANSACTIONS ON AFFECTIVE COMPUTING  Volume: 8   Issue: 3   Pages: 300-313   Published: JUL-SEP 2017\r<br>\r<br>\r<br>Affect Recognition using Key Frame Selection based on Minimum Sparse Reconstruction\r<br>By: Kayaoglu, Mehmet; Erdem, Cigdem Eroglu\r<br>Conference: 2015 ACM International Conference on Multimodal Interaction Location: Seattle, WA Date: NOV 09-13, 2015\r<br>Sponsor(s): ACM SIGCHI\r<br>ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION  Pages: 519-524   Published: 2015</p>\n\n<br />\n\n\n<!-- OLD CODE:\n\n<p class=\"small-heading\"><b>Papers That Cite This Data Set<sup>1</sup>:</b></p>\n<img src=\"../assets/rexa.jpg\" />\n<p class=\"normal\">N/A</p>\n\n-->\n\n\n\n<br />\n\n<p class=\"small-heading\"><b>Citation Request:</b></p>\n<p class=\"normal\">C. E. Erdem, C. Turan, Z. Ayd\u00c4\u00b1n, 'BAUM-2: a multilingual audio-visual affective face database', Multimedia Tools and Applications, vol.74, pp. 7429-7459, 2015. \r<br>DOI 10.1007/s11042-014-1986-2</p>\n\n</td></tr></table>\n\n\n<hr>\n\n<!-- OLD CODE:\n<p class=\"normal\"><font size=1>[1] Papers were automatically harvested and associated with this data set, in collaboration with <a href=\"http://rexa.info\"><font size=1>Rexa.info</font></a></font></p>\n-->\n\n\n\n<table cellpadding=5 align=center><tr valign=center>\n\t\t<td><p class=\"normal\">Supported By:</p></td>\n        <td><img src=\"../assets/nsfe.gif\" height=60 /> </td>\n        <td><p class=\"normal\">&nbsp;In Collaboration With:</p></td>\n        <td><img src=\"../assets/rexaSmall.jpg\" /></td>\n</tr></table>\n\n<center>\n<span class=\"normal\">\n<a href=\"../about.html\">About</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../donation_policy.html\">Donation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../contact.html\">Contact</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"http://cml.ics.uci.edu\">CML</a>\n</span>\n</center>\n\n\n\n\n</body>\n</html>\n", "encoding": "utf-8"}