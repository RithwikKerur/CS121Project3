{"url": "http://archive.ics.uci.edu/ml/support/MONK's+Problems#4695569c53cd581fcc193415a8a94a1f92abf607", "content": "\n\n\n\n<!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 4.01 Transitional//EN\\\">\n<html>\n<head>\n<title>UCI Machine Learning Repository: MONK's Problems Data Set: Support</title>\n\n<!-- Stylesheet link -->\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../assets/ml.css\" />\n\n<script language=\"JavaScript\" type=\"text/javascript\">\n<!--\nfunction checkform ( form )\n{\n  // see http://www.thesitewizard.com/archive/validation.shtml\n  // for an explanation of this script and how to use it on your\n  // own website\n\n  // ** START **\n  if (form.q.value == \"\")\n  {\n    alert( \"Please enter search terms.\" );\n    form.q.focus();\n    return false ;\n  }\n\n  if (getCheckedValue(form.sitesearch) == \"ics.uci.edu\" && form.q.value.indexOf(\"site:archive.ics.uci.edu/ml\") == -1)\n  {\n    form.q.value = form.q.value + \" site:archive.ics.uci.edu/ml\";\n  }\n\n  // ** END **\n  return true ;\n}\n\n// return the value of the radio button that is checked\n// return an empty string if none are checked, or\n// there are no radio buttons\nfunction getCheckedValue(radioObj) {\n\tif(!radioObj)\n\t\treturn \"\";\n\tvar radioLength = radioObj.length;\n\tif(radioLength == undefined)\n\t\tif(radioObj.checked)\n\t\t\treturn radioObj.value;\n\t\telse\n\t\t\treturn \"\";\n\tfor(var i = 0; i < radioLength; i++) {\n\t\tif(radioObj[i].checked) {\n\t\t\treturn radioObj[i].value;\n\t\t}\n\t}\n\treturn \"\";\n}\n//-->\n</script>\n\n</head>\n\n<body>\n\n\n<!-- SITE HEADER (INCLUDES LOGO AND SEARCH BOX) -->\n\n<table width=100% bgcolor=\"#003366\">\n<tr>\n\t<td>\n\t\t<span class=\"normal\"><a href=\"../index.html\" \nalt=\"Home\"><img src=\"../assets/logo.gif\" \nborder=0></img></a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"http://cml.ics.uci.edu\"><font color=\"FFDD33\">Center for Machine Learning and Intelligent Systems</font></a></span>\n\t</td>\n\t<td width=100% valign=top align=\"right\">\n\t\t<span class=\"whitetext\">\n\t\t<a href=\"../about.html\">About</a>&nbsp;\n\t\t<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;\n\t\t<a href=\"../donation_policy.html\">Donate a Data Set</a>&nbsp;\n\t\t<a href=\"../contact.html\">Contact</a>\n\t\t</span>\n\n\t\t<br>\n\t\t<br>\n\t\t<!-- Search Google -->\n\n\t\t<FORM method=GET action=http://www.google.com/custom onsubmit=\"return checkform(this);\">\n\t\t<INPUT TYPE=text name=q size=30 maxlength=255 value=\"\">\n\t\t<INPUT type=submit name=sa VALUE=\"Search\">\n\t\t<INPUT type=hidden name=cof VALUE=\"AH:center;LH:130;L:http://archive.ics.uci.edu/assets/logo.gif;LW:384;AWFID:869c0b2eaa8d518e;\">\n\t\t<input type=hidden name=domains value=\"ics.uci.edu\">\n\t\t<br>\n\t\t<input type=radio name=sitesearch value=\"ics.uci.edu\" checked> <span class=\"whitetext\"><font size=\"1\">Repository</font></span>\n\t\t<input type=radio name=sitesearch value=\"\"> <span class=\"whitetext\"><font size=\"1\">Web</font></span>\n\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n\t\t<A HREF=http://www.google.com/search><IMG SRC=http://www.google.com/logos/Logo_25blk.gif border=0 ALT=Google align=middle height=27></A>\n\t\t<br>\n\t\t</FORM>\n\t\t<!-- Search Google -->\n\n\n\t\t<span class=\"whitetext\"><a href=\"../datasets.php\"><font size=\"3\" color=\"#FFDD33\"><b>View ALL Data Sets</b></font></a></span>\n\t\t<br>\n\t</td>\n</tr>\n</table>\n\n<br />\n<table width=100% border=0 cellpadding=2><tr><td>\n\n\n   <table><tr>\n     <td valign=top>\n\t<p>\n\t<span class=\"heading\"><b>MONK's Problems Data Set</b></span>\n\n\t\t\n\t\t\t\t<p class=\"normal\">Below are papers that cite this data set, with context shown.\n\t\tPapers were automatically harvested and associated with this data set, in collaboration with <a href=\"http://rexa.info\">Rexa.info</a>.</p>\n\t\t<img src=\"../assets/rexa.jpg\" />\n\t\t<p class=\"normal\"><a href=\"/ml/datasets/MONK's+Problems\">Return to MONK's Problems data set page</a>.\n\t\t<hr><p class=\"normal\"><a name=\"14f025e969e3a0418fd852ee46e54039ab3f216a\"></a><i>Jianbin Tan and David L. Dowe. <a href=\"http://rexa.info/paper/14f025e969e3a0418fd852ee46e54039ab3f216a\">MML Inference of Decision Graphs with Multi-way Joins and Dynamic Attributes</a>. Australian Conference on Artificial Intelligence. 2003. </i><br><br>Each 10-fold cross-validation consists of 10 tests. In each test, we trained on nine-tenths of the data and tested on the remaining one-tenth. This amounted to 10x10=100 tests. 1st <b>monk</b> s data set: The 1st monk's data set is in the UCI machine learning repository [10, 1], and constructed from the noiseless function ( Jacket Color = Red ) V ( Head Shape = body Shape ) 10 independent tests were<br></p><hr><p class=\"normal\"><a name=\"7372c1c34417795a4d0752a07c77b3595dba16c4\"></a><i>Wl/odzisl/aw Duch and Karol Grudzinski. <a href=\"http://rexa.info/paper/7372c1c34417795a4d0752a07c77b3595dba16c4\">Ensembles of Similarity-based Models</a>. Intelligent Information Systems. 2001. </i><br><br>range. A single weight corresponding to a highly-ranked feature is fixed at 1 to establish an absolute scale for distances. First the ensemble selection method has been used with two artificial datasets, <b>Monk</b> 1 and Monk-3 [13]. These problems are designed for rule-based symbolic machine learning algorithms and the nearest neighbor algorithms usually do not work well in such cases. 6 symbolic<br></p><hr><p class=\"normal\"><a name=\"0b84bc02dcedbeae5f76f03a2226874e828db0ea\"></a><i>Alexey Tsymbal and Seppo Puuronen and Vagan Y. Terziyan. <a href=\"http://rexa.info/paper/0b84bc02dcedbeae5f76f03a2226874e828db0ea\">Arbiter Meta-Learning with Dynamic Selection of Classifiers and Its Experimental Investigation</a>. ADBIS. 1999. </i><br><br>from the UCI machine learning repository: three <b>MONK</b> s problem datasets donated by Sebastian Thrun and the Tic-Tac-Toe Endgame dataset donated by David W. Aha [8]. The MONK's problems are a collection of three artificial binary classification problems over the same<br></p><hr><p class=\"normal\"><a name=\"cd11168bb19fd462bc59beefbe670bc4eb31e3eb\"></a><i>Mark A. Hall. <a href=\"http://rexa.info/paper/cd11168bb19fd462bc59beefbe670bc4eb31e3eb\">Department of Computer Science Hamilton, NewZealand Correlation-based Feature Selection for Machine Learning</a>. Doctor of Philosophy at The University of Waikato. 1999. </i><br><br>a one-third/two-thirds split on credit and one-eighth of the instances were used for training on mushroom (the largest 80 dataset). In the case of the <b>Monk</b> s problems, testing is performed on the full dataset (as was done originally by Thrun et al. [TBB + 91]). Various different train and test set sizes are used with the<br></p><hr><p class=\"normal\"><a name=\"a3483a19000e691a9fbd69f2b008445f3acd3124\"></a><i>Blai Bonet and Hector Geffner. <a href=\"http://rexa.info/paper/a3483a19000e691a9fbd69f2b008445f3acd3124\">Learning Sorting and Decision Trees with POMDPs</a>. ICML. 1998. </i><br><br>figures for ID3 and C4.5 were taken from (Friedman, Kohavi, & Yun 1996). The column named `Test' in the table indicates how the generalization performance of the algorithms was measured. The <b>Monk</b> n datasets come with separate training and test data; on the other two problems the test data was generated by 5-fold cross validation: the data were partitioned into five segments, and fives runs were<br></p><hr><p class=\"normal\"><a name=\"08bad2c42799dc0f04d6729f069239fba413cb8f\"></a><i>Jan C. Bioch and D. Meer and Rob Potharst. <a href=\"http://rexa.info/paper/08bad2c42799dc0f04d6729f069239fba413cb8f\">Bivariate Decision Trees</a>. PKDD. 1997. </i><br><br>in which interactions between two variables occur. We will test our method on two artificial data sets. The first is the <b>monk</b> 1 data set [Thr91]. This data set contains 6 attributes and two classes. The rule that generates the data is: if (x 1 = x 2 or x 5 = 1) then yes else no. Note that x 5 takes<br></p><hr><p class=\"normal\"><a name=\"dd3f32548422fd3db3846c2fba689a4406d9cf0c\"></a><i>Ron Kohavi. <a href=\"http://rexa.info/paper/dd3f32548422fd3db3846c2fba689a4406d9cf0c\">The Power of Decision Tables</a>. ECML. 1995. </i><br><br>Breiman et al. (1984), Devijver & Kittler (1982)). The results demonstrate that IDTM can achieve high accuracy in discrete domains using the simple hypothesis space of DTMs. In corral, dna, the <b>Monk</b> Dataset Features sizes Accuracy Accuracy Accuracy Accuracy australian 14 690 CV 55.5Sigma2.3 85.4Sigma1.1 84.9Sigma 1.7 89.4Sigma1.3 breast 10 699 CV 65.5Sigma1.7 95.4Sigma0.7 90.6Sigma 0.9<br></p><hr><p class=\"normal\"><a name=\"81a75649d5acc1cc428ca756dac221bac3c8fe01\"></a><i>Geoffrey I. Webb. <a href=\"http://rexa.info/paper/81a75649d5acc1cc428ca756dac221bac3c8fe01\">OPUS: An Efficient Admissible Algorithm for Unordered Search</a>. J. Artif. Intell. Res. (JAIR, 3. 1995. </i><br><br>with respect to minimizing the number of nodes expanded under depth-first search. 458 An Efficient Admissible Algorithm for Unordered Search Nonetheless, for only one search task, the <b>Monk</b> 2 data set, does OPUS o explore more nodes under depth-first search (16,345) than an alternative (both no optimistic reordering and fixed-order search that explore 12,879 and 12,791 nodes respectively). These<br></p><hr><p class=\"normal\"><a name=\"e100b0bcc229ac20bf69c9a7a6bcc360ea16a720\"></a><i>Wl/odzisl/aw Duch and Karol Grudzinski. <a href=\"http://rexa.info/paper/e100b0bcc229ac20bf69c9a7a6bcc360ea16a720\">Meta-learning: searching in the model space</a>. Department of Computer Methods, Nicholas Copernicus University. </i><br><br>The goal of further search for the best model should therefore include not only accuracy but also reduction of variance, i.e. stabilization of the classifier. 4.1 <b>Monk</b> problems The artificial dataset Monk-1 [11] is designed for rule-based symbolic machine learning algorithms (the data was taken from the UCI repository [12]). The nearest neighbor algorithms usually do not work well in such cases.<br></p><hr><p class=\"normal\"><a name=\"d4664ad584fcc55802b2bffeb0d57f8e62eca0e2\"></a><i>Ron Kohavi and Brian Frasca. <a href=\"http://rexa.info/paper/d4664ad584fcc55802b2bffeb0d57f8e62eca0e2\">Useful Feature Subsets and Rough Set Reducts</a>. the Third International Workshop on Rough Sets and Soft Computing. </i><br><br>tic-tac-toe, breast-cancer, chess, mushroom, vote, and vote1, Holte-II has an average accuracy of 93.6%, much better than C4.5's average accuracy of 82.2%. If we ignore <b>Monk</b> 1, Monk 2, and parity---datasets that C4.5 does very badly on---the average accuracy for Holte-II is 91.2% and 88.5% for C4.5. Holte's 1R program (Holte 1993) built one-rules, that is, rules that test a single attribute, and was<br></p><hr><p class=\"normal\"><a name=\"4695569c53cd581fcc193415a8a94a1f92abf607\"></a><i>Chotirat Ann and Dimitrios Gunopulos. <a href=\"http://rexa.info/paper/4695569c53cd581fcc193415a8a94a1f92abf607\">Scaling up the Naive Bayesian Classifier: Using Decision Trees for Feature Selection</a>. Computer Science Department University of California. </i><br><br>3,198 instances, 37 attributes, 2classes. Attributes selected by SBC = 4. <b>Monk</b> 85 88 91 94 97 100 10203040506070809099 Training Data NBC SBC C4.5 Figure 5. Monk dataset (prob.3). 554 instances, 6 attributes, 2 classes. Attributes selected by SBC = 4. Mushroom 90 92 94 96 98 100 10 20 30 40 50 60 70 80 90 99 Training Data (%) Accuracy (%) NBC SBC C4.5 Figure 6.<br></p><hr><p class=\"normal\"><a name=\"95e24786ffc779c3b7d5a2d838391b5d0252a15c\"></a><i>Wl odzisl/aw Duch and Rafal Adamczak and Krzysztof Grabczewski and Norbert Jankowski. <a href=\"http://rexa.info/paper/95e24786ffc779c3b7d5a2d838391b5d0252a15c\">Control and Cybernetics</a>. Department of Computer Methods, Nicholas Copernicus University. </i><br><br>classifiers used in such problems, but they have an opinion of being opaque black boxes. Several neural methods have been compared experimentally on the mushroom and the 3 <b>Monk</b> problems benchmark datasets (Andrews et al. 1995), and recently comparison with some machine learning methods has been given (Duch et al. 2000). There is no reason why a simple classification model based on logical rules<br></p><hr><p class=\"normal\"><a name=\"16ecc3d56b302443c748705dd289fcdcb7f2bba0\"></a><i>Ron Kohavi and Dan Sommerfield. <a href=\"http://rexa.info/paper/16ecc3d56b302443c748705dd289fcdcb7f2bba0\">To Appear in KDD-98 Targeting Business Users with Decision Table Classifiers</a>. Data Mining and Visualization Silicon Graphics, Inc. </i><br><br>available, mostly natural but also a few artificial ones (m-of-n and the <b>monk</b> problems). The artificial datasets were tested on the given training and test sets. The natural datasets were evaluated using 10fold cross-validation if the file size was less than 3,000 records (to ensure a small standard deviation<br></p><hr><p class=\"normal\"><a name=\"c3f9c3303aa080beec901b74703cef88ee2b2f24\"></a><i>Wl odzisl and Rafal Adamczak and Krzysztof Grabczewski and Grzegorz Zal. <a href=\"http://rexa.info/paper/c3f9c3303aa080beec901b74703cef88ee2b2f24\">A hybrid method for extraction of logical rules from data</a>. Department of Computer Methods, Nicholas Copernicus University. </i><br><br>this hybrid method the simplest logical description for several benchmark problems (Iris, mushroom) has been found. Very good solutions were obtained for the three <b>monk</b> problems. For many medical datasets (only 3 were shown here) very simple and highly accurate results were obtained. It is not quite clear why logical rules work so well, for example in the hypothyroidor the Wisconsin breast cancer<br></p><hr><p class=\"normal\"><a name=\"68b230977077ba67eb9e5c9a9111d3ccb3672150\"></a><i>Karol Grudzi nski and Wl/odzisl/aw Duch. <a href=\"http://rexa.info/paper/68b230977077ba67eb9e5c9a9111d3ccb3672150\">SBL-PM: A Simple Algorithm for Selection of Reference Instances in Similarity Based Methods</a>. Department of Computer Methods, Nicholas Copernicus University. </i><br><br>by other classification systems. Due to the noisy character of the data the limit in the leave-one-out or crossvalidation tests is about 98% [10]. Another set of experiments was done on the 3 <b>Monk</b> datasets [11]. On this artificial data SBM gives good results (100% of correct answers on the first problem, 85% on problem 2, and over 97% on problem 3) only if feature selection and/or weighting is<br></p>\n\n\n\t</td></tr></table>\n\n\n\n<hr>\n\n<p class=\"normal\"><a href=\"/datasets/MONK's+Problems\">Return to MONK's Problems data set page</a>.\n\n\n<table cellpadding=5 align=center><tr valign=center>\n\t\t<td><p class=\"normal\">Supported By:</p></td>\n        <td><img src=\"../assets/nsfe.gif\" height=60 /> </td>\n        <td><p class=\"normal\">&nbsp;In Collaboration With:</p></td>\n        <td><img src=\"../assets/rexaSmall.jpg\" /></td>\n</tr></table>\n\n<center>\n<span class=\"normal\">\n<a href=\"../about.html\">About</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../donation_policy.html\">Donation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../contact.html\">Contact</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"http://cml.ics.uci.edu\">CML</a>\n</span>\n</center>\n\n\n\n\n</body>\n</html>\n", "encoding": "ascii"}