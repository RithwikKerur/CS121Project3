{"url": "http://archive.ics.uci.edu/ml/support/Glass+Identification#10cb2e0135796333fda81f2d65da6be1e1ed9e06", "content": "\n\n\n\n<!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 4.01 Transitional//EN\\\">\n<html>\n<head>\n<title>UCI Machine Learning Repository: Glass Identification Data Set: Support</title>\n\n<!-- Stylesheet link -->\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../assets/ml.css\" />\n\n<script language=\"JavaScript\" type=\"text/javascript\">\n<!--\nfunction checkform ( form )\n{\n  // see http://www.thesitewizard.com/archive/validation.shtml\n  // for an explanation of this script and how to use it on your\n  // own website\n\n  // ** START **\n  if (form.q.value == \"\")\n  {\n    alert( \"Please enter search terms.\" );\n    form.q.focus();\n    return false ;\n  }\n\n  if (getCheckedValue(form.sitesearch) == \"ics.uci.edu\" && form.q.value.indexOf(\"site:archive.ics.uci.edu/ml\") == -1)\n  {\n    form.q.value = form.q.value + \" site:archive.ics.uci.edu/ml\";\n  }\n\n  // ** END **\n  return true ;\n}\n\n// return the value of the radio button that is checked\n// return an empty string if none are checked, or\n// there are no radio buttons\nfunction getCheckedValue(radioObj) {\n\tif(!radioObj)\n\t\treturn \"\";\n\tvar radioLength = radioObj.length;\n\tif(radioLength == undefined)\n\t\tif(radioObj.checked)\n\t\t\treturn radioObj.value;\n\t\telse\n\t\t\treturn \"\";\n\tfor(var i = 0; i < radioLength; i++) {\n\t\tif(radioObj[i].checked) {\n\t\t\treturn radioObj[i].value;\n\t\t}\n\t}\n\treturn \"\";\n}\n//-->\n</script>\n\n</head>\n\n<body>\n\n\n<!-- SITE HEADER (INCLUDES LOGO AND SEARCH BOX) -->\n\n<table width=100% bgcolor=\"#003366\">\n<tr>\n\t<td>\n\t\t<span class=\"normal\"><a href=\"../index.html\" \nalt=\"Home\"><img src=\"../assets/logo.gif\" \nborder=0></img></a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"http://cml.ics.uci.edu\"><font color=\"FFDD33\">Center for Machine Learning and Intelligent Systems</font></a></span>\n\t</td>\n\t<td width=100% valign=top align=\"right\">\n\t\t<span class=\"whitetext\">\n\t\t<a href=\"../about.html\">About</a>&nbsp;\n\t\t<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;\n\t\t<a href=\"../donation_policy.html\">Donate a Data Set</a>&nbsp;\n\t\t<a href=\"../contact.html\">Contact</a>\n\t\t</span>\n\n\t\t<br>\n\t\t<br>\n\t\t<!-- Search Google -->\n\n\t\t<FORM method=GET action=http://www.google.com/custom onsubmit=\"return checkform(this);\">\n\t\t<INPUT TYPE=text name=q size=30 maxlength=255 value=\"\">\n\t\t<INPUT type=submit name=sa VALUE=\"Search\">\n\t\t<INPUT type=hidden name=cof VALUE=\"AH:center;LH:130;L:http://archive.ics.uci.edu/assets/logo.gif;LW:384;AWFID:869c0b2eaa8d518e;\">\n\t\t<input type=hidden name=domains value=\"ics.uci.edu\">\n\t\t<br>\n\t\t<input type=radio name=sitesearch value=\"ics.uci.edu\" checked> <span class=\"whitetext\"><font size=\"1\">Repository</font></span>\n\t\t<input type=radio name=sitesearch value=\"\"> <span class=\"whitetext\"><font size=\"1\">Web</font></span>\n\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n\t\t<A HREF=http://www.google.com/search><IMG SRC=http://www.google.com/logos/Logo_25blk.gif border=0 ALT=Google align=middle height=27></A>\n\t\t<br>\n\t\t</FORM>\n\t\t<!-- Search Google -->\n\n\n\t\t<span class=\"whitetext\"><a href=\"../datasets.php\"><font size=\"3\" color=\"#FFDD33\"><b>View ALL Data Sets</b></font></a></span>\n\t\t<br>\n\t</td>\n</tr>\n</table>\n\n<br />\n<table width=100% border=0 cellpadding=2><tr><td>\n\n\n   <table><tr>\n     <td valign=top>\n\t<p>\n\t<span class=\"heading\"><b>Glass Identification Data Set</b></span>\n\n\t\t\n\t\t<img src=\"../assets/MLimages/Large42.jpg\" hspace=20 vspace=10 align=right />\t\t<p class=\"normal\">Below are papers that cite this data set, with context shown.\n\t\tPapers were automatically harvested and associated with this data set, in collaboration with <a href=\"http://rexa.info\">Rexa.info</a>.</p>\n\t\t<img src=\"../assets/rexa.jpg\" />\n\t\t<p class=\"normal\"><a href=\"/ml/datasets/Glass+Identification\">Return to Glass Identification data set page</a>.\n\t\t<hr><p class=\"normal\"><a name=\"81ad8e5b8306aee758f09fd5c1caa8a23c63c2d6\"></a><i>Ping Zhong and Masao Fukushima. <a href=\"http://rexa.info/paper/81ad8e5b8306aee758f09fd5c1caa8a23c63c2d6\">A Regularized Nonsmooth Newton Method for Multi-class Support Vector Machines</a>. 2005. </i><br><br>the starting point of the next (k + 1)th iteration. The parameters \u00ba 1 and \u00ba 2 in (3) are both set 0.01. In Algorithm 3.1, we replaced the standard Armijo-rule in (S.3) by 10 Table 1: Six benchmark datasets from UCI name iris wine <b>glass</b> vowel vehicle segment #pts 150 178 214 528 846 2310 {fiats|flats} 4 13 9 10 18 19 #cls 3 3 6 11 4 7 #pts: the number of training data; {fiats|flats}: the number of<br></p><hr><p class=\"normal\"><a name=\"692880d7b3356df64bfa0f06a683f89e4ce6955b\"></a><i>Vassilis Athitsos and Stan Sclaroff. <a href=\"http://rexa.info/paper/692880d7b3356df64bfa0f06a683f89e4ce6955b\">Boosting Nearest Neighbor Classifiers for Multiclass Recognition</a>. Boston University Computer Science Tech. Report No, 2004-006. 2004. </i><br><br>used in the experiments, largely copied from (Allwein et al., 2000). Dataset Train Test Attributes Classes <b>glass</b> 214 - 9 6 isolet 6238 1559 617 26 letter 16000 4000 16 26 pendigits 7494 3498 16 10 satimage 4435 2000 36 6 segmentation 2310 - 19 7 vowel 528 462 10 11 yeast<br></p><hr><p class=\"normal\"><a name=\"5ef9c5c8a24b6e0df983284f0caa3fb337c1a77a\"></a><i>Yuan Jiang and Zhi-Hua Zhou. <a href=\"http://rexa.info/paper/5ef9c5c8a24b6e0df983284f0caa3fb337c1a77a\">Editing Training Data for kNN Classifiers with Neural Network Ensemble</a>. ISNN (1). 2004. </i><br><br>i.e. annealing, credit, liver, pima, soybean, wine and zoo. RemoveOnly obtains the best performance on three data sets, i.e. <b>glass</b>  hayes-roth and wine. It is surprising that Depuration obtains the best performance on only one data set, i.e. iris, as RelabelOnly does. These observations indicate that NNEE is a<br></p><hr><p class=\"normal\"><a name=\"63460ee5afd1e104ba91e654e9aee9b977433c4c\"></a><i>S. Augustine Su and Jennifer G. Dy. <a href=\"http://rexa.info/paper/63460ee5afd1e104ba91e654e9aee9b977433c4c\">Automated hierarchical mixtures of probabilistic principal component analyzers</a>. ICML. 2004. </i><br><br>5 wine -3-8 .478 .627 8 2 .623 .722 4 Interestingly, the mixture of PPCA approach is not always better than PCA+EM. Mixtures of PPCA performed better than PCA+EM in terms of NMI and FM on most small datasets (toy, oil, and <b>glass</b> , which are well modeled by mixtures of Gaussians. PPCA with fewer clusters has a comparable performance with EM + PCA on the large data sets (optical digits, satellite image,<br></p><hr><p class=\"normal\"><a name=\"ba94d46c3f1c8a8ccb1dc3fcbeb6afdd963d3f87\"></a><i>Xiaoli Z. Fern and Carla Brodley. <a href=\"http://rexa.info/paper/ba94d46c3f1c8a8ccb1dc3fcbeb6afdd963d3f87\">Solving cluster ensemble problems by bipartite graph partitioning</a>. ICML. 2004. </i><br><br>a fair comparison. 7. Experimental Results The goal of the experiments is to evaluate the three graph formulations - IBGF, CBGF and HBGF - given different cluster ensembles. Table 1. Summary of the data sets data set eos <b>glass</b> hrct isolet6 modis #inst. 2398 214 1545 1440 4975 #class 8 6 8 6 10 org. dim. 20 9 183 617 112 rp dim. 5 5 10 10 6 pca dim. --- --- 30 60 6 7.1. Data Sets and Parameter Settings<br></p><hr><p class=\"normal\"><a name=\"78b94c51025c63bb39ea776347fe151e203eaa24\"></a><i>Francesco Masulli. <a href=\"http://rexa.info/paper/78b94c51025c63bb39ea776347fe151e203eaa24\">An experimental analysis of the dependence among codeword bit errors in ECOC learning machines</a>. and Giorgio Valentini b,c. 2003. </i><br><br>machine, varying the number of hidden units between 5 to 50, yielding to 11\u00d720 = 220 evaluations of I E , I SE , \u00a9R and \u00a9 S both for ECOC monolithic and ECOC PND learning machines. For the UCI data sets <b>glass</b>  letter and optdigits we used only 2 di\u00aeerent structures, using, respectively, 5 and 9, 120 and 140, 60 and 70 hidden units, yielding to 2 \u00d7 20 = 40 evaluations of the mutual information<br></p><hr><p class=\"normal\"><a name=\"7ca6f3f2b00e225b5b648c2998c727d0b7d6cde8\"></a><i>Krzysztof Krawiec. <a href=\"http://rexa.info/paper/7ca6f3f2b00e225b5b648c2998c727d0b7d6cde8\">Genetic Programming-based Construction of Features for Machine Learning and Knowledge Discovery Tasks</a>. Institute of Computing Science, Poznan University of Technology. 2002. </i><br><br>in favor of feature construction is usually statistically relevant. Note also that positive results have been obtained for both real-world problems (Crx, Diabetes and <b>Glass</b>  as well as artificial datasets, which were intentionally designed to test the usefulness of feature construction methods [34]. Although the increases in accuracy of classification are not always impressive, the feature<br></p><hr><p class=\"normal\"><a name=\"df4390b4164d70e186a080009bf9b23fb367478c\"></a><i>Michail Vlachos and Carlotta Domeniconi and Dimitrios Gunopulos and George Kollios and Nick Koudas. <a href=\"http://rexa.info/paper/df4390b4164d70e186a080009bf9b23fb367478c\">Non-linear dimensionality reduction techniques for classification and visualization</a>. KDD. 2002. </i><br><br>The average error rates for the smaller data sets (i.e., Iris, Sonar, <b>Glass</b>  Liver, and Lung) were based on leave-oneout cross-validation, and the error rates for Image and Vowel were based on ten two-fold-cross-validation, as summarized in Table<br></p><hr><p class=\"normal\"><a name=\"abe4b819b1c9858440502f14d418706d2446c387\"></a><i>Giorgio Valentini and Francesco Masulli. <a href=\"http://rexa.info/paper/abe4b819b1c9858440502f14d418706d2446c387\">NEURObjects: an object-oriented library for neural network development</a>. Neurocomputing, 48. 2002. </i><br><br>validation [35]. The folds can be prepared using the program dofold in a simple way: dofold <b>glass</b> data -nf 10 -na 9 -name glass This command build the folds for a ten fold cross validation test. The data set is glass from the UCI Machine Learning repository [29]. Ten folds from the data file glass.data (named glass.#.train and glass.#.test varying i from 1 to 10) are extracted (the option -na specifies<br></p><hr><p class=\"normal\"><a name=\"932cec9f3183bf03e366c0b093984ca256a4c3e4\"></a><i>D. I. S I and Francesco Masulli and Giorgio Valentini and D. I. S. <a href=\"http://rexa.info/paper/932cec9f3183bf03e366c0b093984ca256a4c3e4\">Universit#a di Genova</a>. Dipartimento di Informatica e Scienze dell' Informazione. 2001. </i><br><br>machine, varying the number of hidden units between 5 to 50, yielding to 11 # 20 = 220 evaluations of I E ; I SE ; #R and # S both for ECOC monolithic and ECOC PND learning machines. On the UCI data sets <b>glass</b>  letter and 18 optdigits we have used only 2 different structures, using, respectively, 5 and 9, 120 and 140, 60 and 70 hidden units, yielding to 2 # 20 = 40 evaluations of the mutual<br></p><hr><p class=\"normal\"><a name=\"d18b9cca12173a8ca3d5a781cadcf847442930f4\"></a><i>Carlotta Domeniconi and Jing Peng and Dimitrios Gunopulos. <a href=\"http://rexa.info/paper/d18b9cca12173a8ca3d5a781cadcf847442930f4\">An Adaptive Metric Machine for Pattern Classification</a>. NIPS. 2000. </i><br><br>N = 208 data of J = 2 classes (``mines'' and ``rocks''); 3. Vowel data. This example has q = 10 measurements and 11 classes. There are total of N = 528 samples in this example; 4. <b>Glass</b> data. This data set consists of q = 9 chemical attributes measured for each of N = 214 data of J = 6 classes; 5. Image data. This data set consists of 40 texture images that are manually classified into 15 classes. The<br></p><hr><p class=\"normal\"><a name=\"69aaccfb9601e579827a9940738bb255a8cec3b5\"></a><i>Mark A. Hall. <a href=\"http://rexa.info/paper/69aaccfb9601e579827a9940738bb255a8cec3b5\">Correlation-based Feature Selection for Discrete and Numeric Class Machine Learning</a>. ICML. 2000. </i><br><br>In the case of CFS, a discretized copy of each training split was made for it to operate on. The same folds were used for each feature selector{learning scheme combination. Table 1. Discrete class data sets. Data Set Instances Num. Nom. Classes 1 <b>glass</b> 2 163 9 0 2 2 anneal 898 6 32 5 3 breast-c 286 0 9 2 4 credit-g 1000 7 13 2 5 diabetes 768 8 0 2 6 horse colic 368 7 15 2 7 heart-c 303 6 7 2 8<br></p><hr><p class=\"normal\"><a name=\"084aa2a0b1ffd67537222e2c439d2fadce6090ca\"></a><i>Petri Kontkanen and Petri Myllym and Tomi Silander and Henry Tirri and Peter Gr. <a href=\"http://rexa.info/paper/084aa2a0b1ffd67537222e2c439d2fadce6090ca\">On predictive distributions and Bayesian networks</a>. Department of Computer Science, Stanford University. 2000. </i><br><br>used show very similar behavior. As an illustrative example, in Figure 4 the average log-scores obtained are plotted in the Hepatitis and <b>Glass</b> dataset cases. Again, the EVU and EVJ approaches are quite robust in the sense that they predict quite well even with small training sets. This shows that the data sets used here are quite redundant, and<br></p><hr><p class=\"normal\"><a name=\"f51be2f205fbe38436ed150a6627139668eb002a\"></a><i>Thierry Denoeux. <a href=\"http://rexa.info/paper/f51be2f205fbe38436ed150a6627139668eb002a\">A neural network classifier based on Dempster-Shafer theory</a>. IEEE Transactions on Systems, Man, and Cybernetics, Part A, 30. 2000. </i><br><br>analysis techniques [13]. As shown in Table I, our approach with at least three prototypes per class dominates the other techniques for this classification task. 2) Forensic <b>Glass</b> Data: This data set contains the description of 214 fragments of glass [17] originally collected for a study in the context of criminal investigation. Each fragment has a measured reflectivity index and chemical<br></p><hr><p class=\"normal\"><a name=\"9e2e49a81a0cec7e7872787b2b52ec128f5ebb0d\"></a><i>Francesco Masulli and Giorgio Valentini. <a href=\"http://rexa.info/paper/9e2e49a81a0cec7e7872787b2b52ec128f5ebb0d\">Effectiveness of Error Correcting Output Codes in Multiclass Learning Problems</a>. Multiple Classifier Systems. 2000. </i><br><br>effective for PND classi#ers rather than monolithic MLP classifiers. Hypothesis 2 In PLD error recovering induced by ECOC is counter-balanced by the higher error rate of the dichotomizers. Table 1. Data sets general features. The data sets <b>glass</b>  letter and optdigits data sets are from the UCI repository [16]. Data set Number of Number of Number of Number of attributes classes training samples testing<br></p><hr><p class=\"normal\"><a name=\"72d5bd2d46a0dc05c20340f71ac9c9e0eb6e0abf\"></a><i>Nir Friedman and Iftach Nachman. <a href=\"http://rexa.info/paper/72d5bd2d46a0dc05c20340f71ac9c9e0eb6e0abf\">Gaussian Process Networks</a>. UAI. 2000. </i><br><br>contains 4177 samples with 9 attributes. 300 samples were used as a test set. # <b>Glass</b> identification data set - a data describing the material concentrations in glasses, with a class attribute denoting the type of the glass. The data set contains 214 samples with 10 attributes. 64 samples were used as a<br></p><hr><p class=\"normal\"><a name=\"70172e511a3bc27c7927119a3b2a3405fbad99e0\"></a><i>Kai Ming Ting and Ian H. Witten. <a href=\"http://rexa.info/paper/70172e511a3bc27c7927119a3b2a3405fbad99e0\">Issues in Stacked Generalization</a>. J. Artif. Intell. Res. (JAIR, 10. 1999. </i><br><br>Note that stacking performs very poorly on <b>Glass</b> and Ionosphere, two small real-world datasets. This is not surprising, because cross-validation inevitably produces poor estimates for small datasets. 4.2 Discussion Like bagging, stacking is ideal for parallel computation. The construction of<br></p><hr><p class=\"normal\"><a name=\"ae82a44ada49c66439b67eae7ff10392ff209df9\"></a><i>Christopher J. Merz. <a href=\"http://rexa.info/paper/ae82a44ada49c66439b67eae7ff10392ff209df9\">Using Correspondence Analysis to Combine Classifiers</a>. Machine Learning, 36. 1999. </i><br><br>The resulting weighting schemes reversed this effect by counting a vote for one of the confused classes as a vote for the other, and vice versa. PV performs well on the <b>glass</b>  lymph and wave data sets where the errors of the learned models are measured (using the statistic) to be fairly uncorrelated. Here, SCANN performs similarly to PV, but S-BP and S-Bayes (except for wave) appear to be<br></p><hr><p class=\"normal\"><a name=\"27e33344198975ea1b20e02c8f0fce01cd29f6e5\"></a><i>Eibe Frank and Ian H. Witten. <a href=\"http://rexa.info/paper/27e33344198975ea1b20e02c8f0fce01cd29f6e5\">Generating Accurate Rule Sets Without Global Optimization</a>. ICML. 1998. </i><br><br>listed in Table 2. They give the percentage of correct classifications, averaged over ten ten-fold cross-validation runs, and standard 3 Following Holte (Holte, 1993), the G2 variant of the <b>glass</b> dataset has classes 1 and 3 combined and classes 4 to 7 deleted, and the horse-colic dataset has attributes 3, 25, 26, 27, 28 deleted with attribute 24 being used as the class. We also deleted all<br></p><hr><p class=\"normal\"><a name=\"08bad2c42799dc0f04d6729f069239fba413cb8f\"></a><i>Jan C. Bioch and D. Meer and Rob Potharst. <a href=\"http://rexa.info/paper/08bad2c42799dc0f04d6729f069239fba413cb8f\">Bivariate Decision Trees</a>. PKDD. 1997. </i><br><br>with the standard error. From these table we can conclude 10 name cases attr classes <b>glass</b> 214 9 6 diabetes(pima) 768 8 2 breast cancer 699 9 2 heart 270 13 2 wave 300 21 3 Table 1: Summary of the Datasets method glass diabetes cancer heart wave BIT1 65.3Sigma1:1 74.3Sigma0:7 95.4Sigma0:3 78.5Sigma0:3 76.1Sigma1:3 6.2Sigma2:1 5.2Sigma2:5 2.8Sigma0:2 4.1Sigma0:5 5.0Sigma1:6 BIT2<br></p><hr><p class=\"normal\"><a name=\"d688186b7174c0a53391d92f70d64a41209d3358\"></a><i>D. Greig and Hava T. Siegelmann and Michael Zibulevsky. <a href=\"http://rexa.info/paper/d688186b7174c0a53391d92f70d64a41209d3358\">A New Class of Sigmoid Activation Functions That Don't Saturate</a>. 1997. </i><br><br>(3 hidden nodes) the \u00f8 values (0:5; 1:5; 2:5) were used, for the <b>glass</b> data set (6 hidden nodes), the values (0:5; 1:0; 1:5; 2:0; 2:5; 3:0) were used, and for the bodyfat data set (7 hidden nodes) the values (0:5; 1:0; 1:5; 2:0; 2:5; 3:0; 3:5) were used. The results for these<br></p><hr><p class=\"normal\"><a name=\"500f7245b01ee7978bef7ad022c0cbe7eec8eace\"></a><i>Christopher J. Merz. <a href=\"http://rexa.info/paper/500f7245b01ee7978bef7ad022c0cbe7eec8eace\">Combining Classifiers Using Correspondence Analysis</a>. NIPS. 1997. </i><br><br>with error rates around 80 percent. This empirically demonstrates PV's known sensitivity to learned models with highly correlated errors. On the other hand, PV performs well on the <b>glass</b> and wave data sets where the errors of the learned models are measured to be fairly uncorrelated. Here, SCANN performs similarly to PV, but S-BP and S-Bayes appear to be overfitting by making erroneous predictions<br></p><hr><p class=\"normal\"><a name=\"b0009a0081cc5fbfbae758def55cfd5b3256623b\"></a><i><a href=\"http://rexa.info/paper/b0009a0081cc5fbfbae758def55cfd5b3256623b\">Prototype Selection for Composite Nearest Neighbor Classifiers</a>. Department of Computer Science University of Massachusetts. 1997. </i><br><br>there is no sense of positive and negative examples. For example, in the <b>Glass</b> Recognition data set, there are six classes and therefore six prototypes will be selected. There, the classes correspond to the source and manufacturing process of glass fragments for crime scene analysis: building<br></p><hr><p class=\"normal\"><a name=\"0244677960291674fa0816f5d724ca20eef22bf7\"></a><i>Georg Thimm and E. Fiesler. <a href=\"http://rexa.info/paper/0244677960291674fa0816f5d724ca20eef22bf7\">Optimal Setting of Weights, Learning Rate, and Gain</a>. E S E A R C H R E P R O R T I D I A P. 1997. </i><br><br>Multilayer perceptrons behave similarly, as shown in figure 4, as confirmed by experiments performed with the Solar, Wine, <b>Glass</b> and Servo data sets. The most important difference with high order perceptrons is that the networks do not or only very slowly converge for weight variances close to zero. Such variances should therefore not be used<br></p><hr><p class=\"normal\"><a name=\"482c2024eea88014e9cff136b42fc98cccf6dad4\"></a><i>Richard Maclin and David W. Opitz. <a href=\"http://rexa.info/paper/482c2024eea88014e9cff136b42fc98cccf6dad4\">An Empirical Evaluation of Bagging and Boosting</a>. AAAI/IAAI. 1997. </i><br><br>that can be drawn from the results is that both the Simple Ensemble and Bagging approaches almost always produces better performance than just training a single classifier. For some of these data sets (e.g., <b>glass</b>  kr-vs-kp, letter, segmentation, soybean, and vehicle) the gains in performance are quite significant. One aspect many of these data sets share is that they involve predictions for<br></p><hr><p class=\"normal\"><a name=\"6f2537b9354cfbd865cc2057f04a6216cbafd89c\"></a><i>Ethem Alpaydin. <a href=\"http://rexa.info/paper/6f2537b9354cfbd865cc2057f04a6216cbafd89c\">Voting over Multiple Condensed Nearest Neighbors</a>. Artif. Intell. Rev, 11. 1997. </i><br><br>do not contribute much. Whether an additional subset pays off the additional complexity and memory is a trade-off that needs to be resolved depending on the particular application at hand. In three datasets, VOWEL, THYROID, and <b>GLASS</b>  we do not seem to gain anything by voting. The VOWEL database defines a quite difficult problem and is very noisy; the optimal k is 7. The result with 7-NN is the<br></p><hr><p class=\"normal\"><a name=\"b9cc48070522b3c3f7b5d7bc3b49a06213978f8e\"></a><i>Ron Kohavi and Mehran Sahami. <a href=\"http://rexa.info/paper/b9cc48070522b3c3f7b5d7bc3b49a06213978f8e\">Error-Based and Entropy-Based Discretization of Continuous Features</a>. KDD. 1996. </i><br><br>to discretize using Ent-MDL were Sick-euthyroid and Hypothyroid, which each took about 31 seconds per fold on an SGI Challenge. The longest running time for ErrorMin was encountered with the <b>Glass</b> dataset which took 153 seconds per fold to discretize, although this was much longer than any other of the datasets examined. The ErrorMin method could not be run on the Letter domain with 300MB of main<br></p><hr><p class=\"normal\"><a name=\"10cb2e0135796333fda81f2d65da6be1e1ed9e06\"></a><i>Aynur Akkus and H. Altay G\u00fcvenir. <a href=\"http://rexa.info/paper/10cb2e0135796333fda81f2d65da6be1e1ed9e06\">K Nearest Neighbor Classification on Feature Projections</a>. ICML. 1996. </i><br><br>Many Irrelevant Features, Proceedings of the Ninth National Conference on Artificial Intelligence, 547-552. Dasarathy, B. V., (1990). Nearest Neighbor (NN) Table 2: Comparison on some real-world datasets. Data Set: bcancerw cleveland <b>glass</b> hungarian ionosphere iris musk wine No. of Instances 273 303 214 294 351 150 476 178 No. of Features 9 13 9 13 34 4 166 13 No. of Classes 2 2 6 2 2 3 2 3 No. of<br></p><hr><p class=\"normal\"><a name=\"b154b00ca44ffdbc56ab144aa90deab78e1f0de3\"></a><i>Jitender S. Deogun and Vijay V. Raghavan and Hayri Sever. <a href=\"http://rexa.info/paper/b154b00ca44ffdbc56ab144aa90deab78e1f0de3\">Exploiting Upper Approximation in the Rough Set Methodology</a>. KDD. 1995. </i><br><br>does not match to known concepts we use 5NNR classification scheme with Euclidean distance function to determine the closest known concept. The difference between two values of an attribute are data set Size Attr. Training Test 1. <b>Glass</b> 9 66 148 2. Breast cancer 9 211 488 3. Parity 5+10 15 226 524 4. Iris 4 45 105 5. Monk 1 6 124 432 6. Monk 2 6 169 432 7. Monk 3 6 122 432 8. Vote 16 132 303 9.<br></p><hr><p class=\"normal\"><a name=\"019c2f2e77588b6e654cc5c4c27ae643d3bd0f62\"></a><i>Thomas G. Dietterich and Ghulum Bakiri. <a href=\"http://rexa.info/paper/019c2f2e77588b6e654cc5c4c27ae643d3bd0f62\">Solving Multiclass Learning Problems via Error-Correcting Output Codes</a>. CoRR, csAI/9501101. 1995. </i><br><br>Table 4 summarizes the data sets employed in the study. The <b>glass</b>  vowel, soybean, audiologyS, ISOLET, letter, and NETtalk data sets are available from the Irvine Repository of machine learning databases (Murphy & Aha, 1994). 1<br></p><hr><p class=\"normal\"><a name=\"8be22c7cb4b6b5d2147c5376492279b13ba12e07\"></a><i><a href=\"http://rexa.info/paper/8be22c7cb4b6b5d2147c5376492279b13ba12e07\">Eectiveness of Error Correcting Output Coding methods in ensemble and monolithic learning machines</a>. Dipartimento di Informatica, Universitdi Pisa. </i><br><br>and composed by normal distributed clusters of data. The set p6 contains 6 classes with no overlapping regions, while the regions of the 9 classes of p9 hardly overlap. <b>Glass</b>  letter and optdigits data sets are from the UCI repository [42]. In the experimentation we have used exhaustive [17] and BCH ECOC generation algorithms [8]. ECOC exhaustive algorithms select among all possible 2 K dichotomies<br></p><hr><p class=\"normal\"><a name=\"c042581c25e66281bb5ce382f70738b0233e5f5a\"></a><i>Zhi-Hua Zhou and Xu-Ying Liu. <a href=\"http://rexa.info/paper/c042581c25e66281bb5ce382f70738b0233e5f5a\">Training Cost-Sensitive Neural Networks with Methods Addressing the Class Imbalance Problem</a>. </i><br><br>effect on soybean which is with the biggest number of classes and suffering from serious class imbalance. It is noteworthy that the sampling methods and SMOTE cause negative effect on several data sets suffering from class imbalance, that is, <b>glass</b>  soybean and annealing. IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING 9 TABLE IX EXPERIMENTAL RESULTS ON MULTI-CLASS UCI DATA SETS WITH TYPE (A)<br></p><hr><p class=\"normal\"><a name=\"945d8ba4c7eacfaed696aaf0bd72fd576efa78d5\"></a><i>Aynur Akku and H. Altay Guvenir. <a href=\"http://rexa.info/paper/945d8ba4c7eacfaed696aaf0bd72fd576efa78d5\">Weighting Features in k Nearest Neighbor Classification on Feature Projections</a>. Department of Computer Engineering and Information Science Bilkent University. </i><br><br>weight to features by this method on realworld taken from the UCI repository (Murphy, 1995). The results of this experiments will be presented in Section 4. 5 Table 1: Comparison on some real-world datasets. Data Set: bcancerw cleveland <b>glass</b> hungarian ionosphere iris liver wine No. of Instances 273 303 214 294 351 150 345 178 No. of Features 9 13 9 13 34 4 6 13 No. of Classes 2 2 6 2 2 3 2 3 No. of<br></p><hr><p class=\"normal\"><a name=\"8e36921ac4908ffda6ec3eeef41d8c840c9fd884\"></a><i>Francesco Masulli and Giorgio Valentini. <a href=\"http://rexa.info/paper/8e36921ac4908ffda6ec3eeef41d8c840c9fd884\">Quantitative Evaluation of Dependence among Outputs in ECOC Classifiers Using Mutual Information Based Measures</a>. Universitdi Genova DISI - Dipartimento di Informatica e Scienze dell'Informazione INFM - Istituto Nazionale per la Fisica della Materia. </i><br><br>the dependence among codeword bits errors [12, 8]. In our experimentation we evaluate this dependence in ECOC monolithic and ECOC PND learning machines. 3.2 The data In our experiments we have used data sets from the UCI repository of Irvine  <b>glass</b>  letter, optdigits) [11] and a synthetic data set (d5) made up by five threedimensional classes, each composed by two normal distributed disjoint clusters<br></p><hr><p class=\"normal\"><a name=\"da329267bf8880c2becb15eae121a5b002347349\"></a><i>Rong-En Fan and P. -H Chen and C. -J Lin. <a href=\"http://rexa.info/paper/da329267bf8880c2becb15eae121a5b002347349\">Working Set Selection Using the Second Order Information for Training SVM</a>. Department of Computer Science and Information Engineering National Taiwan University. </i><br><br>was originally used in (Bailey et al., 1993). The problem mg is a Mackey <b>Glass</b> time series. The data sets cpusmall and splice are from the Delve archive (http://www.cs.toronto.edu/~delve). Problem fourclass is from (Ho and Kleinberg, 1996) and we further transform it to a two-class set. The problem<br></p><hr><p class=\"normal\"><a name=\"8432b52f06e00a68cb8a7a49e3938190338231de\"></a><i>Yin Zhang and W. Nick Street. <a href=\"http://rexa.info/paper/8432b52f06e00a68cb8a7a49e3938190338231de\">Bagging with Adaptive Costs</a>. Management Sciences Department University of Iowa Iowa City. </i><br><br>and the out-of-bag margin estimation will result in better generalization as it does in stacking. 3. Computational Experiments Bacing was implemented using MATLAB and tested on 14 UCI repository data sets [2]: Autompg, Bupa, <b>Glass</b>  Haberman, Housing, Cleveland-heart-disease, Hepatitis, Ion, Pima, Sonar, Vehicle, WDBC, Wine and WPBC. Some of the data sets do not originally depict two-class problems<br></p><hr><p class=\"normal\"><a name=\"17b1afb4bd706435fa92313e1e85a5d6009a42f4\"></a><i>Ping Zhong and Masao Fukushima. <a href=\"http://rexa.info/paper/17b1afb4bd706435fa92313e1e85a5d6009a42f4\">Second Order Cone Programming Formulations for Robust Multi-class Classification</a>. </i><br><br>problem as follows: max \u00ae,\u00be,\u00bf e T \u00ae- (\u00be + \u00bf) s.t. \u00af E T \u00ae = 0, \u00ae \u00b7 (1 - \u00ba)e, (38) \u00be - \u00bf = \u00ba, \u00b0 \u00b0 \u00b0 \u00b0 \u00b0 \u00b0 2 4 - 1 p 2(K+1) ~ A T \u00ae \u00bf 3 5 \u00b0 \u00b0 \u00b0 \u00b0 \u00b0 \u00b0 \u00b7 \u00be. Table 1: Description of Iris, Wine and <b>Glass</b> datasets. name dimension (N) #classes (K) #examples (L) Iris 4 3 150 Wine 13 3 178 Glass 9 6 214 14 Table 2: Results for Iris, Wine and Glass datasets with noise (\u00bd = 0.3, \u00b7 = 2, \u00ba = 0.05). R a Robust (I)<br></p><hr><p class=\"normal\"><a name=\"e4ce48114dcd770134f22df787d55e8daf02ac4a\"></a><i>Karthik Ramakrishnan. <a href=\"http://rexa.info/paper/e4ce48114dcd770134f22df787d55e8daf02ac4a\">UNIVERSITY OF MINNESOTA</a>. </i><br><br>classifier is shown as a straight line across the x-axis for comparison purposes. . . . . . . . . . . . . . . . . . 37 11 Bagging, Boosting, and Distance-Weighted test set error rates for the <b>glass</b> data set as the number of classifiers in the ensemble increases. The test set error rate for a single decision tree classifier is shown as a straight line across the x-axis for comparison purposes. . . . . .<br></p><hr><p class=\"normal\"><a name=\"77faaac3f85d52abea60e7152460894b085b63ec\"></a><i>Pramod Viswanath and M. Narasimha Murty and Shalabh Bhatnagar. <a href=\"http://rexa.info/paper/77faaac3f85d52abea60e7152460894b085b63ec\">A pattern synthesis technique to reduce the curse of dimensionality effect</a>. E-mail. </i><br><br>We performed experiments with five different datasets, viz., OCR, WINE, THYROID, <b>GLASS</b> and PENDIGITS, respectively. Except the OCR dataset, all others are from the UCI Repository [16]. OCR dataset is also used in [17, 18]. The properties of the<br></p><hr><p class=\"normal\"><a name=\"469be567c6e8bb0955c395472ef2fefc4fe43f77\"></a><i>Erin J. Bredensteiner and Kristin P. Bennett. <a href=\"http://rexa.info/paper/469be567c6e8bb0955c395472ef2fefc4fe43f77\">Multicategory Classification by Support Vector Machines</a>. Department of Mathematics University of Evansville. </i><br><br>protocol (ftp) from the UCI Repository of Machine Learning Databases and Domain Theories [16] at ftp://ftp.ics.uci.edu/pub/machine-learning-databases. <b>Glass</b> Identification Database The Glass dataset [11] is used to identify the origin of a sample of glass through chemical analysis. This dataset is comprised of six classes of 214 points with 9 features. The distribution of points by class is as<br></p><hr><p class=\"normal\"><a name=\"a9190b213f00d51e490ba40125b46f31d04d77ca\"></a><i>Pramod Viswanath and M. Narasimha Murty and Shalabh Bhatnagar. <a href=\"http://rexa.info/paper/a9190b213f00d51e490ba40125b46f31d04d77ca\">Partition Based Pattern Synthesis Technique with Efficient Algorithms for Nearest Neighbor Classification</a>. Department of Computer Science and Automation, Indian Institute of Science. </i><br><br>We performed experiments with five different datasets, viz., OCR, WINE, VOWEL, THYROID, <b>GLASS</b> and PENDIGITS, respectively. Except the OCR dataset, all others are from the UCI Repository [19]. OCR dataset is also used in [20,18]. The properties of the<br></p><hr><p class=\"normal\"><a name=\"954de642cab661d060a2dbc68d3023ba3a9763e1\"></a><i>Federico Divina and Elena Marchiori. <a href=\"http://rexa.info/paper/954de642cab661d060a2dbc68d3023ba3a9763e1\">Handling Continuous Attributes in an Evolutionary Inductive Learner</a>. Department of Computer Science Vrije Universiteit. </i><br><br>and ECL-LSDc (together with ECL-GSD) becomes significantly better than ECL-LSDf and ECL-LUD on the German dataset. The other datasets (Echocardiogram, <b>Glass</b> 2, Heart, and Hepatitis) are small, and the results of the experiments are not normally distributed, so the t-test cannot be applied. Dataset ECL-LSDc<br></p><hr><p class=\"normal\"><a name=\"0a882383e36d72c5890e2d191326433e23e53c9b\"></a><i>James J. Liu and James Tin and Yau Kwok. <a href=\"http://rexa.info/paper/0a882383e36d72c5890e2d191326433e23e53c9b\">An Extended Genetic Rule Induction Algorithm</a>. Department of Computer Science Wuhan University. </i><br><br>With ESIA and other GA-based rule induction algorithms, this can easily be done by incorporating various \"interestingness\" measures [8] into 5 Following [6, 14], the glass2 variant of the <b>glass</b> dataset has classes 1 and 3 combined and classes 4 to 7 deleted, and the horse-colic dataset has attributes 3, 25, 26, 27, 28 deleted and with attribute 24 being used as the class label. We also deleted all<br></p><hr><p class=\"normal\"><a name=\"50339570de3deefebea8a48dc4100e6fe883a16f\"></a><i>Francesco Masulli and Giorgio Valentini. <a href=\"http://rexa.info/paper/50339570de3deefebea8a48dc4100e6fe883a16f\">Comparing Decomposition Methods for Classification</a>. Istituto Nazionale per la Fisica della Materia DISI - Dipartimento di Informatica e Scienze dell'Informazione. </i><br><br>OPC bold driver CC grad. desc. CC bold driver ECOC BCH grad. desc. ECOC BCH bold driver (a) (b) Figure 1: Comparison of performances of different decomposition methods on <b>glass</b> (a) and optdigits (b) data sets of the UCI. Table 4: Standard PWC (left) and CC (right) decomposition matrices. 0 B B B B B @ +1 1 0 0 +1 0 1 0 +1 0 0 1 0 +1 1 0 0 +1 0 1 0 0 +1 1 1 C C C C C A 0 B B B B B @ +1 +1 1 1 +1 1 +1 1<br></p><hr><p class=\"normal\"><a name=\"e2b2b723df700c90e69a31a4403b740c2d2a7b2f\"></a><i>Alexander K. Seewald. <a href=\"http://rexa.info/paper/e2b2b723df700c90e69a31a4403b740c2d2a7b2f\">Dissertation Towards Understanding Stacking Studies of a General Ensemble Learning Scheme ausgefuhrt zum Zwecke der Erlangung des akademischen Grades eines Doktors der technischen Naturwissenschaften</a>. </i><br><br>#10 Training set (8-9=CV, 7=75%, 6=62%,.. 1=25%) Hold-out accuracy Figure 6.2: Learning curves for dataset balance-scale to <b>glass</b>  56 0 1 2 3 4 5 6 7 8 9 0.65 0.7 0.75 0.8 0.85 0.9 Learncurve for Dataset #11 Training set (8-9=CV, 7=75%, 6=62%,.. 1=25%) Hold-out accuracy 0 1 2 3 4 5 6 7 8 9 0.65 0.7 0.75<br></p><hr><p class=\"normal\"><a name=\"cf334aad055b27faaeece97ee1630e146388cd10\"></a><i>H. Altay G uvenir and Aynur Akkus. <a href=\"http://rexa.info/paper/cf334aad055b27faaeece97ee1630e146388cd10\">WEIGHTED K NEAREST NEIGHBOR CLASSIFICATION ON FEATURE PROJECTIONS</a>. Department of Computer Engineering and Information Science Bilkent University. </i><br><br>row of each k value presents the accuracy of the WkNNFP algorithm with equal feature weigths, while the second row shows the accuracy obtained by WkNNFP using Table 1: Comparison on some real-world datasets. Data Set: cleveland <b>glass</b> horse hungarian iris liver sonar wine No. of Instances 303 214 368 294 150 345 208 178 No. of Features 13 9 22 13 4 6 60 13 No. of Classes 2 6 2 2 3 2 2 3 No. of Missing<br></p><hr><p class=\"normal\"><a name=\"d4664ad584fcc55802b2bffeb0d57f8e62eca0e2\"></a><i>Ron Kohavi and Brian Frasca. <a href=\"http://rexa.info/paper/d4664ad584fcc55802b2bffeb0d57f8e62eca0e2\">Useful Feature Subsets and Rough Set Reducts</a>. the Third International Workshop on Rough Sets and Soft Computing. </i><br><br>taken from Holte's paper, C4.5 has a 3.5% higher accuracy. The average accuracy for Holte-II is 82.7%, and 86.2% for C4.5. If we ignore the two <b>glass</b> datasets on which Holte-II does poorly, the difference shrinks to 1.3%. Thus even on data with continuous features that have not been discretized, Holte-II does reasonably close to C4.5. Moreover, the<br></p><hr><p class=\"normal\"><a name=\"8eb7bb53b63501db4eb1c49eab30d76f7febba8d\"></a><i>H. Altay Guvenir. <a href=\"http://rexa.info/paper/8eb7bb53b63501db4eb1c49eab30d76f7febba8d\">A Classification Learning Algorithm Robust to Irrelevant Features</a>. Bilkent University, Department of Computer Engineering and Information Science. </i><br><br>VFI5 1NN 3NN 5NN 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Number of irrelevant features added 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 Classification accuracy <b>Glass</b> data set VFI5 1NN 3NN 5NN 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Number of irrelevant features added 0.5 0.6 0.7 0.8 0.9 1.0 Classification accuracy Iris data set VFI5 1NN 3NN 5NN 0 1 2 3 4 5 6<br></p><hr><p class=\"normal\"><a name=\"341c37581773a2a38cecc290e6272ca752b9df84\"></a><i>Suresh K. Choubey and Jitender S. Deogun and Vijay V. Raghavan and Hayri Sever. <a href=\"http://rexa.info/paper/341c37581773a2a38cecc290e6272ca752b9df84\">A comparison of feature selection algorithms in the context of rough classifiers</a>. </i><br><br>different and zero otherwise, and the difference between two quantitative values is normalized into the interval [0,1]. We first consider results from Table 2. Except for <b>Glass</b>  Monks, and Hepatitis data sets, the performance obtained in Predictive Experiments approach those in the case of Upperbound Experiments. This suggests that for Glass, Monks, and Hepatitis data data set Size No. of Attributes<br></p><hr><p class=\"normal\"><a name=\"6858832ba8e9e4ac002900af151a8ffcc1796f8f\"></a><i>Stefan Aeberhard and Danny Coomans and De Vel. <a href=\"http://rexa.info/paper/6858832ba8e9e4ac002900af151a8ffcc1796f8f\">THE PERFORMANCE OF STATISTICAL PATTERN RECOGNITION METHODS IN HIGH DIMENSIONAL SETTINGS</a>. James Cook University. </i><br><br>resonant frequency easily obtainable using NMR, constituting the 19 variables measured. With 19 dimensions and 13 training samples per class, this problem is ill-posed. <b>Glass</b> Types Data This data set is from [15]. It summarises a chemical analysis done on two types (classes) of glass. Glass which was float-processed and such which was not. The data is ten dimensional and well-posed, with 87<br></p><hr><p class=\"normal\"><a name=\"f624e93bd6b670bc3dc31925c1c885b538131534\"></a><i>Chih-Wei Hsu and Cheng-Ru Lin. <a href=\"http://rexa.info/paper/f624e93bd6b670bc3dc31925c1c885b538131534\">A Comparison of Methods for Multi-class Support Vector Machines</a>. Department of Computer Science and Information Engineering National Taiwan University. </i><br><br>section we present experimental results on several problems from the Statlog collection [20] and the UCI Repository of machine learning databases [1]. From UCI Repository we choose the following datasets: iris, wine, <b>glass</b>  and vowel. Those problems had already been tested in [27]. From Statlog collection we choose all multi-class datasets: vehicle, segment, dna, satimage, letter, and shuttle. Note<br></p><hr><p class=\"normal\"><a name=\"48d6beec2a36a87d9d88b6de85dd85a75e5ed24d\"></a><i>C. Titus Brown and Harry W. Bullen and Sean P. Kelly and Robert K. Xiao and Steven G. Satterfield and John G. Hagedorn and Judith E. Devaney. <a href=\"http://rexa.info/paper/48d6beec2a36a87d9d88b6de85dd85a75e5ed24d\">Visualization and Data Mining in an 3D Immersive Environment: Summer Project 2003</a>. </i><br><br>whole museum from abovelack of support for numeric targets by InfoGain. 50 4.14 <b>glass</b> The glass data set was analysed by Sean Kelly. This is a purely numeric dataset containing roughly 200 glass samples with information on amounts of various chemical elements in the samples and what purpose the glass<br></p>\n\n\n\t</td></tr></table>\n\n\n\n<hr>\n\n<p class=\"normal\"><a href=\"/datasets/Glass+Identification\">Return to Glass Identification data set page</a>.\n\n\n<table cellpadding=5 align=center><tr valign=center>\n\t\t<td><p class=\"normal\">Supported By:</p></td>\n        <td><img src=\"../assets/nsfe.gif\" height=60 /> </td>\n        <td><p class=\"normal\">&nbsp;In Collaboration With:</p></td>\n        <td><img src=\"../assets/rexaSmall.jpg\" /></td>\n</tr></table>\n\n<center>\n<span class=\"normal\">\n<a href=\"../about.html\">About</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../donation_policy.html\">Donation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../contact.html\">Contact</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"http://cml.ics.uci.edu\">CML</a>\n</span>\n</center>\n\n\n\n\n</body>\n</html>\n", "encoding": "ISO-8859-1"}