{"url": "http://archive.ics.uci.edu/ml/support/Breast+Cancer+Wisconsin+(Prognostic)#3c3eb7beca3f6ab6fcebe2863131fa3dbae6cb7f", "content": "\n\n\n\n<!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 4.01 Transitional//EN\\\">\n<html>\n<head>\n<title>UCI Machine Learning Repository: Breast Cancer Wisconsin (Prognostic) Data Set: Support</title>\n\n<!-- Stylesheet link -->\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../assets/ml.css\" />\n\n<script language=\"JavaScript\" type=\"text/javascript\">\n<!--\nfunction checkform ( form )\n{\n  // see http://www.thesitewizard.com/archive/validation.shtml\n  // for an explanation of this script and how to use it on your\n  // own website\n\n  // ** START **\n  if (form.q.value == \"\")\n  {\n    alert( \"Please enter search terms.\" );\n    form.q.focus();\n    return false ;\n  }\n\n  if (getCheckedValue(form.sitesearch) == \"ics.uci.edu\" && form.q.value.indexOf(\"site:archive.ics.uci.edu/ml\") == -1)\n  {\n    form.q.value = form.q.value + \" site:archive.ics.uci.edu/ml\";\n  }\n\n  // ** END **\n  return true ;\n}\n\n// return the value of the radio button that is checked\n// return an empty string if none are checked, or\n// there are no radio buttons\nfunction getCheckedValue(radioObj) {\n\tif(!radioObj)\n\t\treturn \"\";\n\tvar radioLength = radioObj.length;\n\tif(radioLength == undefined)\n\t\tif(radioObj.checked)\n\t\t\treturn radioObj.value;\n\t\telse\n\t\t\treturn \"\";\n\tfor(var i = 0; i < radioLength; i++) {\n\t\tif(radioObj[i].checked) {\n\t\t\treturn radioObj[i].value;\n\t\t}\n\t}\n\treturn \"\";\n}\n//-->\n</script>\n\n</head>\n\n<body>\n\n\n<!-- SITE HEADER (INCLUDES LOGO AND SEARCH BOX) -->\n\n<table width=100% bgcolor=\"#003366\">\n<tr>\n\t<td>\n\t\t<span class=\"normal\"><a href=\"../index.html\" \nalt=\"Home\"><img src=\"../assets/logo.gif\" \nborder=0></img></a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"http://cml.ics.uci.edu\"><font color=\"FFDD33\">Center for Machine Learning and Intelligent Systems</font></a></span>\n\t</td>\n\t<td width=100% valign=top align=\"right\">\n\t\t<span class=\"whitetext\">\n\t\t<a href=\"../about.html\">About</a>&nbsp;\n\t\t<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;\n\t\t<a href=\"../donation_policy.html\">Donate a Data Set</a>&nbsp;\n\t\t<a href=\"../contact.html\">Contact</a>\n\t\t</span>\n\n\t\t<br>\n\t\t<br>\n\t\t<!-- Search Google -->\n\n\t\t<FORM method=GET action=http://www.google.com/custom onsubmit=\"return checkform(this);\">\n\t\t<INPUT TYPE=text name=q size=30 maxlength=255 value=\"\">\n\t\t<INPUT type=submit name=sa VALUE=\"Search\">\n\t\t<INPUT type=hidden name=cof VALUE=\"AH:center;LH:130;L:http://archive.ics.uci.edu/assets/logo.gif;LW:384;AWFID:869c0b2eaa8d518e;\">\n\t\t<input type=hidden name=domains value=\"ics.uci.edu\">\n\t\t<br>\n\t\t<input type=radio name=sitesearch value=\"ics.uci.edu\" checked> <span class=\"whitetext\"><font size=\"1\">Repository</font></span>\n\t\t<input type=radio name=sitesearch value=\"\"> <span class=\"whitetext\"><font size=\"1\">Web</font></span>\n\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n\t\t<A HREF=http://www.google.com/search><IMG SRC=http://www.google.com/logos/Logo_25blk.gif border=0 ALT=Google align=middle height=27></A>\n\t\t<br>\n\t\t</FORM>\n\t\t<!-- Search Google -->\n\n\n\t\t<span class=\"whitetext\"><a href=\"../datasets.php\"><font size=\"3\" color=\"#FFDD33\"><b>View ALL Data Sets</b></font></a></span>\n\t\t<br>\n\t</td>\n</tr>\n</table>\n\n<br />\n<table width=100% border=0 cellpadding=2><tr><td>\n\n\n   <table><tr>\n     <td valign=top>\n\t<p>\n\t<span class=\"heading\"><b>Breast Cancer Wisconsin (Prognostic) Data Set</b></span>\n\n\t\t\n\t\t<img src=\"../assets/MLimages/Large14.jpg\" hspace=20 vspace=10 align=right />\t\t<p class=\"normal\">Below are papers that cite this data set, with context shown.\n\t\tPapers were automatically harvested and associated with this data set, in collaboration with <a href=\"http://rexa.info\">Rexa.info</a>.</p>\n\t\t<img src=\"../assets/rexa.jpg\" />\n\t\t<p class=\"normal\"><a href=\"/ml/datasets/Breast+Cancer+Wisconsin+(Prognostic)\">Return to Breast Cancer Wisconsin (Prognostic) data set page</a>.\n\t\t<hr><p class=\"normal\"><a name=\"dd4500e327a5f555d2f594711dc50b0f9faccd30\"></a><i>Gavin Brown. <a href=\"http://rexa.info/paper/dd4500e327a5f555d2f594711dc50b0f9faccd30\">Diversity in Neural Network Ensembles</a>. The University of Birmingham. 2004. </i><br><br>critical to consider values for the strength parameter outside the originally specified range. Table 5.3 shows the classification error rates of two empirical tests, on the <b>Wisconsin</b> <b>breast</b> <b>cancer</b> dataset from the UCI repository (699 patterns), and the Heart disease dataset from Statlog (270 patterns). An ensemble consisting of two networks, each with five hidden nodes, was trained using NC. We use<br></p><hr><p class=\"normal\"><a name=\"b19579eae108f0efb0d9adf97e480280f8e4f7a8\"></a><i>Krzysztof Grabczewski and Wl/odzisl/aw Duch. <a href=\"http://rexa.info/paper/b19579eae108f0efb0d9adf97e480280f8e4f7a8\">Heterogeneous Forests of Decision Trees</a>. ICANN. 2002. </i><br><br>< 1.10531) then primary hypothyroid 2. if TSH } 6.05 # FTI } 64.72 # on_thyroxine = 0 # thyroid_surgery = 0 # TT4 < 150.5 then compensated hypothyroid 3. else healthy. The <b>Wisconsin</b> <b>breast</b> <b>cancer</b> dataset contains 699 instances, with 458 benign (65.5%) and 241 (34.5%) malignant cases. Each instance is described by 9 attributes with integer value in the range 1-10 and a binary class label. For 16<br></p><hr><p class=\"normal\"><a name=\"3ecc983417b61977b8f998e8a843948dad8fa21c\"></a><i>Andr\u00e1s Antos and Bal\u00e1zs K\u00e9gl and Tam\u00e1s Linder and G\u00e1bor Lugosi. <a href=\"http://rexa.info/paper/3ecc983417b61977b8f998e8a843948dad8fa21c\">Data-dependent margin-based generalization bounds for classification</a>. Journal of Machine Learning Research, 3. 2002. </i><br><br>attributes were binary coded in a 1-out-of-n fashion. Data points with missing attributes were removed. Each attribute was normalized to have zero mean and 1= p d standard deviation. The four data sets were the <b>Wisconsin</b> <b>breast</b> <b>cancer</b> (n = 683, d = 9), the ionosphere (n = 351, d = 34), the Japanese credit screening (n = 653, d = 42), and the tic-tac-toe endgame (n = 958, d = 27) database. 84<br></p><hr><p class=\"normal\"><a name=\"ca3e1e0bf335a97cedb76be7b64610181e0f6684\"></a><i>Kristin P. Bennett and Ayhan Demiriz and Richard Maclin. <a href=\"http://rexa.info/paper/ca3e1e0bf335a97cedb76be7b64610181e0f6684\">Exploiting unlabeled data in ensemble methods</a>. KDD. 2002. </i><br><br>experiments we used simple multilayer perceptrons with a single layer of hidden units. The networks were trained using backpropagation with a learning rate of 0.15 and a momentum value of 0.90. The datasets for the experiments are <b>breast</b> <b>cancer</b> <b>wisconsin</b>  pima-indians diabetes, and letter-recognition drawn from the UCI Machine Learning repository [3]. The number of units in the hidden layer for the<br></p><hr><p class=\"normal\"><a name=\"3a500f9d0b3bfdadc810cde1043178b2d127888e\"></a><i>Hussein A. Abbass. <a href=\"http://rexa.info/paper/3a500f9d0b3bfdadc810cde1043178b2d127888e\">An evolutionary artificial neural networks approach for breast cancer diagnosis</a>. Artificial Intelligence in Medicine, 25. 2002. </i><br><br>well, compared to the previous studies. In another study, Setiono [26] used his rule extraction from ANNs algorithm [28, 29] to extract useful rules that can predict <b>breast</b> <b>cancer</b> from the <b>Wisconsin</b> dataset. He needed first to train an ANN using BP and achieved an accuracy level on the test data of approximately 94%. After applying his rule extraction technique, the accuracy of the extracted rule set<br></p><hr><p class=\"normal\"><a name=\"4ce4c96181e2836dd80a71c2efebc7fb030c55d8\"></a><i>Baback Moghaddam and Gregory Shakhnarovich. <a href=\"http://rexa.info/paper/4ce4c96181e2836dd80a71c2efebc7fb030c55d8\">Boosted Dyadic Kernel Discriminants</a>. NIPS. 2002. </i><br><br>the number of support vectors for the SVM, and #k.ev. the number of kernel evaluations required by a boosted hypercuts classifier. Means and standard deviations in 30 trials are reported for each data set. WBC,WPBC,WDBC are <b>Wisconsin</b> <b>Breast</b> <b>Cancer</b>  Prognosis and Diagnosis data sets, respectively. In each experiment, the data set was randomly partitioned into training, validation and test sets of<br></p><hr><p class=\"normal\"><a name=\"5193dfc0a9d39b5f86fe360d6beff81aa9b7390e\"></a><i>Nikunj C. Oza and Stuart J. Russell. <a href=\"http://rexa.info/paper/5193dfc0a9d39b5f86fe360d6beff81aa9b7390e\">Experimental comparisons of online and batch versions of bagging and boosting</a>. KDD. 2001. </i><br><br>learning and its effect on ensemble performance. 6. ACKNOWLEDGEMENTS The <b>Wisconsin</b> <b>Breast</b> <b>Cancer</b> dataset was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg. The Forest Covertype is Copyrighted 1998 by Jock A. Blackard and Colorado State University. 7.<br></p><hr><p class=\"normal\"><a name=\"c185d513badef2336ca48f64098d4b5df17bf5a4\"></a><i>Robert Burbidge and Matthew Trotter and Bernard F. Buxton and Sean B. Holden. <a href=\"http://rexa.info/paper/c185d513badef2336ca48f64098d4b5df17bf5a4\">STAR - Sparsity through Automated Rejection</a>. IWANN (1). 2001. </i><br><br>available from the UCI Machine Learning Data Repository [11], are as follows. The <b>breast</b> <b>cancer</b> <b>Wisconsin</b> data set has 699 examples in nine dimensions and is `noise-free', one feature has 16 missing values which are replaced with the feature mean. The ionosphere data set has 351 examples in 33 dimensions and is<br></p><hr><p class=\"normal\"><a name=\"63e63c88edc486c3b1b2aeebb790f88a119536c9\"></a><i>Lorne Mason and Peter L. Bartlett and Jonathan Baxter. <a href=\"http://rexa.info/paper/63e63c88edc486c3b1b2aeebb790f88a119536c9\">Improved Generalization Through Explicit Optimization of Margins</a>. Machine Learning, 38. 2000. </i><br><br>chosen as the final solution. In some cases the training sets were reduced in size to makeoverfitting more likely (so that complexity regularization with DOOM could have an effect). In three of the datasets (Credit Application, <b>Wisconsin</b> <b>Breast</b> <b>Cancer</b> and Pima Indians Diabetes), AdaBoost gained no advantage from using more than a single classifier. In these datasets, the number of classifiers was<br></p><hr><p class=\"normal\"><a name=\"d254374dd5eab5d871c8010dcbe4ac84ec86ea8c\"></a><i>P. S and Bradley K. P and Bennett A. Demiriz. <a href=\"http://rexa.info/paper/d254374dd5eab5d871c8010dcbe4ac84ec86ea8c\">Constrained K-Means Clustering</a>. Microsoft Research Dept. of Mathematical Sciences One Microsoft Way Dept. of Decision Sciences and Eng. Sys. 2000. </i><br><br>the Johns Hopkins Ionosphere dataset and the <b>Wisconsin</b> Diagnostic <b>Breast</b> <b>Cancer</b> dataset (WDBC) [7]. The Ionosphere dataset contains 351 data points in R 33 and values along each dimension Contrained K-Means Clustering 6 0 5 10 15 20 25<br></p><hr><p class=\"normal\"><a name=\"7265efd898e4c045ff078fcb63fec9fbde4b1249\"></a><i>Endre Boros and Peter Hammer and Toshihide Ibaraki and Alexander Kogan and Eddy Mayoraz and Ilya B. Muchnik. <a href=\"http://rexa.info/paper/7265efd898e4c045ff078fcb63fec9fbde4b1249\">An Implementation of Logical Analysis of Data</a>. IEEE Trans. Knowl. Data Eng, 12. 2000. </i><br><br>the housing value is above or below the median. Using training sets of 80% of the observations, [16] reports correct prediction rates ranging from 82% to 83.2%. <b>Breast</b> <b>Cancer</b>  <b>Wisconsin</b> . The dataset, compiled by O. Mangasarian and K.P. Bennett, is widely used in the machine learning community for comparing learning algorithms. It is, however, difficult to use it for rigorous comparisons since<br></p><hr><p class=\"normal\"><a name=\"3c3eb7beca3f6ab6fcebe2863131fa3dbae6cb7f\"></a><i>Yuh-Jeng Lee. <a href=\"http://rexa.info/paper/3c3eb7beca3f6ab6fcebe2863131fa3dbae6cb7f\">Smooth Support Vector Machines</a>. Preliminary Thesis Proposal Computer Sciences Department University of Wisconsin. 2000. </i><br><br>[37]. To evaluate the efficacy of SSVM, we compared computational times of SSVM with those of RLP and SV M k\u00b7k1 . We ran all tests on six publicly available datasets: the <b>Wisconsin</b> Prognostic <b>Breast</b> <b>Cancer</b> Database [34] and five datasets from the Irvine Machine Learning Database Repository [36]. It turned out that tenfold testing correctness of the SSVM is the<br></p><hr><p class=\"normal\"><a name=\"93e4d326f6a322d66e034c1b88773f3a7f621526\"></a><i>Justin Bradley and Kristin P. Bennett and Bennett A. Demiriz. <a href=\"http://rexa.info/paper/93e4d326f6a322d66e034c1b88773f3a7f621526\">Constrained K-Means Clustering</a>. Microsoft Research Dept. of Mathematical Sciences One Microsoft Way Dept. of Decision Sciences and Eng. Sys. 2000. </i><br><br>the Johns Hopkins Ionosphere dataset and the <b>Wisconsin</b> Diagnostic <b>Breast</b> <b>Cancer</b> dataset (WDBC) [7]. The Ionosphere dataset contains 351 data points in R 33 and values along each dimension Contrained K-Means Clustering 6 0 5 10 15 20 25<br></p><hr><p class=\"normal\"><a name=\"283e535d8f512eedabbd803c72a86b891eed8474\"></a><i>Chun-Nan Hsu and Hilmar Schuschel and Ya-Ting Yang. <a href=\"http://rexa.info/paper/283e535d8f512eedabbd803c72a86b891eed8474\">The ANNIGMA-Wrapper Approach to Neural Nets Feature Selection for Knowledge Discovery and Data Mining</a>. Institute of Information Science. 1999. </i><br><br>the technique presented in [10], where it is used to enhance the effectiveness of feature. An optimal result is the selection of features ``jacketcolor'', ``holding'', and ``bodyshape''. Real-world Datasets <b>Breast</b> <b>Cancer</b> <b>Wisconsin</b> (Cancer) This dataset has 699 instances of 10 features : one is the ID number and 9 others have values within 1 to 10. Each instance has one of the 2 possible classes:<br></p><hr><p class=\"normal\"><a name=\"79b9012d7063a4c0e98d98ebd63d63044c8da997\"></a><i>W. Nick Street. <a href=\"http://rexa.info/paper/79b9012d7063a4c0e98d98ebd63d63044c8da997\">A Neural Network Model for Prognostic Prediction</a>. ICML. 1998. </i><br><br>of the models to separate cases with favorable and unfavorable prognoses (see Section 3.3). 3 Experimental Results Computational experiments were performed on two very different <b>breast</b> <b>cancer</b> data sets. The first is known as <b>Wisconsin</b> Prognostic Breast Cancer (WPBC) and is characterized by a small number of cases, relatively high dimensionality, very precise values and almost no missing data. The<br></p><hr><p class=\"normal\"><a name=\"ac8fe867e1d16d4d09f9bd759ba46699055c7ca6\"></a><i>Yk Huhtala and Juha K\u00e4rkk\u00e4inen and Pasi Porkka and Hannu Toivonen. <a href=\"http://rexa.info/paper/ac8fe867e1d16d4d09f9bd759ba46699055c7ca6\">Efficient Discovery of Functional and Approximate Dependencies Using Partitions</a>. ICDE. 1998. </i><br><br>and their descriptions are available on the UCI Machine Learning Repository [13]. The number of rows, columns, and minimal dependencies found (N ) in each database are shown in Table 1. The datasets labeled  <b>Wisconsin</b> <b>breast</b> <b>cancer</b> Theta n\" are concatenations of n copies of the Wisconsin breast cancer data. The set of dependencies is the same in all of them. To avoid duplicate rows, all<br></p><hr><p class=\"normal\"><a name=\"73cfbd8185405d37df94492642c9ffdb3b48c37f\"></a><i>Huan Liu and Hiroshi Motoda and Manoranjan Dash. <a href=\"http://rexa.info/paper/73cfbd8185405d37df94492642c9ffdb3b48c37f\">A Monotonic Measure for Optimal Feature Selection</a>. ECML. 1998. </i><br><br>with unknown relevant attributes, consists of WBC - the <b>Wisconsin</b> <b>Breast</b> <b>Cancer</b> data set, LED-7 - data with 7 Boolean attributes and 10 classes, the set of decimal digits (0..9), Letter - the letter image recognition data, LYM - the lymphography data, and Vote - the U.S. House of<br></p><hr><p class=\"normal\"><a name=\"271b9c67f2a11a31962a436a41aaa5ed148dda6e\"></a><i>Lorne Mason and Peter L. Bartlett and Jonathan Baxter. <a href=\"http://rexa.info/paper/271b9c67f2a11a31962a436a41aaa5ed148dda6e\">Direct Optimization of Margins Improves Generalization in Combined Classifiers</a>. NIPS. 1998. </i><br><br>sets were reduced in size to makeoverfitting more likely, so that complexity regularization with DOOM could haveaneffect. (The details are given in the full version [MBB98].) In three of the datasets (Credit Application, <b>Wisconsin</b> <b>Breast</b> <b>Cancer</b> and Pima Indians Diabetes), AdaBoost gained no advantage from using more than a single classifier. In these datasets, the number of classifiers was<br></p><hr><p class=\"normal\"><a name=\"c2525357aa81ca73fb410a5013d47e3c6931342b\"></a><i>Rudy Setiono and Huan Liu. <a href=\"http://rexa.info/paper/c2525357aa81ca73fb410a5013d47e3c6931342b\">NeuroLinear: From neural networks to oblique decision rules</a>. Neurocomputing, 17. 1997. </i><br><br>A. Detailed analysis 1: The University of <b>Wisconsin</b> <b>Breast</b> <b>Cancer</b> Dataset. This data set has been used as the test data for several studies on pattern classification methods using linear programming techniques [1, 13] and statistical techniques [23]. Each pattern is<br></p><hr><p class=\"normal\"><a name=\"b0009a0081cc5fbfbae758def55cfd5b3256623b\"></a><i><a href=\"http://rexa.info/paper/b0009a0081cc5fbfbae758def55cfd5b3256623b\">Prototype Selection for Composite Nearest Neighbor Classifiers</a>. Department of Computer Science University of Massachusetts. 1997. </i><br><br>Selection. : : : : : : : : : : : : : : : : : : : : 117 4.11 Relationships between component accuracy and diversity for the Cleveland Heart Disease, LED-7 Digit, Hepatitis and <b>Breast</b> <b>Cancer</b> <b>Wisconsin</b> data sets for the four boosting algorithms. \"c\" represents the Coarse Reclassification algorithm; \"d\", Deliberate Misclassification; \"f \", Composite Fitness; and \"s\" Composite Fitness--Feature Selection. : :<br></p><hr><p class=\"normal\"><a name=\"63ebbe51c9c4dea76320f7b6a40f2a59f10cc7c0\"></a><i>Kristin P. Bennett and Erin J. Bredensteiner. <a href=\"http://rexa.info/paper/63ebbe51c9c4dea76320f7b6a40f2a59f10cc7c0\">A Parametric Optimization Method for Machine Learning</a>. INFORMS Journal on Computing, 9. 1997. </i><br><br>of the Federal Reserve Bank of Dallas [BS90], has 9 numeric features which range from 0 to 1. The data represent 4311 successful banks and 441 failed banks. <b>Wisconsin</b> <b>Breast</b> <b>Cancer</b> Database This dataset is used to classify a set of 682 patients with breast cancer [WM90]. Each patient is represented by nine integral attributes ranging in value from 1 to 10. The two classes represented are benign and<br></p><hr><p class=\"normal\"><a name=\"7d8a7f4c9a24d1127a5ded21969c82ed63037c42\"></a><i>Erin J. Bredensteiner and Kristin P. Bennett. <a href=\"http://rexa.info/paper/7d8a7f4c9a24d1127a5ded21969c82ed63037c42\">Feature Minimization within Decision Trees</a>. National Science Foundation. 1996. </i><br><br>attributes. Each patient is classified as to whether there is presence or absence of heart disease. There are 137 patients who have a presence of heart disease. <b>Wisconsin</b> <b>breast</b> <b>Cancer</b> Database This data set is used to classify 682 patients 18 with breast cancer. Each patient is represented by nine integral attributes ranging in value from 1 to 10. The two classes represented are benign and malignant:<br></p><hr><p class=\"normal\"><a name=\"9f9df113476ffbf356892bb497bd2714e6f56d99\"></a><i>Ismail Taha and Joydeep Ghosh. <a href=\"http://rexa.info/paper/9f9df113476ffbf356892bb497bd2714e6f56d99\">Characterization of the Wisconsin Breast cancer Database Using a Hybrid Symbolic-Connectionist System</a>. Proceedings of ANNIE. 1996. </i><br><br>rule extraction techniques, the BIO-RE, Partial-RE, and Full-RE, on the <b>breast</b> <b>cancer</b> problem. The extracted rules are presented in order based on the rule ordering algorithm. 5.1 Breast-Cancer Data Set: The <b>Wisconsin</b> breast cancer data set has nine inputs and two output classes [26, 31]. The input features are: X 1 = Clump Thickness; X 2 = Uniformity of Cell Size; X 3 = Uniformity of Cell Shape; X<br></p><hr><p class=\"normal\"><a name=\"19e1b6e0932bbe665a2c4a069a0636d8d5cf0c6f\"></a><i>Jennifer A. Blue and Kristin P. Bennett. <a href=\"http://rexa.info/paper/19e1b6e0932bbe665a2c4a069a0636d8d5cf0c6f\">Hybrid Extreme Point Tabu Search</a>. Department of Mathematical Sciences Rensselaer Polytechnic Institute. 1996. </i><br><br>(Liver); the PIMA Indians Diabetes dataset (Diabetes), the <b>Wisconsin</b> <b>Breast</b> <b>Cancer</b> Database (Cancer) [23], and the Cleveland Heart Disease Database (Heart) [9]. We used 5-fold cross validation. Each dataset was divided into 5 parts. The<br></p><hr><p class=\"normal\"><a name=\"81a75649d5acc1cc428ca756dac221bac3c8fe01\"></a><i>Geoffrey I. Webb. <a href=\"http://rexa.info/paper/81a75649d5acc1cc428ca756dac221bac3c8fe01\">OPUS: An Efficient Admissible Algorithm for Unordered Search</a>. J. Artif. Intell. Res. (JAIR, 3. 1995. </i><br><br>Tic Tac Toe) disabling other pruning had little or no e\u00aeect under best-first or depth-first search. The largest e\u00aeects are 2.5 fold increases for the Soybean Large and <b>Wisconsin</b> <b>Breast</b> <b>Cancer</b> data sets under best-first search and for the Audiology, Soybean Large and Wisconsin Breast Cancer data sets under depth-first search. From these results it is apparent that while there are some data sets<br></p><hr><p class=\"normal\"><a name=\"705b438dbe9ed18fe23005c774d2993019da030f\"></a><i>Jarkko Salojarvi and Samuel Kaski and Janne Sinkkonen. <a href=\"http://rexa.info/paper/705b438dbe9ed18fe23005c774d2993019da030f\">Discriminative clustering in Fisher metrics</a>. Neural Networks Research Centre Helsinki University of Technology. </i><br><br>and secondly through the density function estimate that generates the metric used to define the Fisherian Voronoi regions. IV. EXPERIMENTS Experiments were run with the <b>Wisconsin</b> <b>breast</b> <b>cancer</b> data set from the UCI machine learning repository [9]. The 569 samples consisted of 30 attributes, measured from malignant and benign tumors. We chose the ordinary k-means as the baseline reference method.<br></p><hr><p class=\"normal\"><a name=\"c3f9c3303aa080beec901b74703cef88ee2b2f24\"></a><i>Wl odzisl and Rafal Adamczak and Krzysztof Grabczewski and Grzegorz Zal. <a href=\"http://rexa.info/paper/c3f9c3303aa080beec901b74703cef88ee2b2f24\">A hybrid method for extraction of logical rules from data</a>. Department of Computer Methods, Nicholas Copernicus University. </i><br><br>obtained from the UCI repository [14]. A. <b>Wisconsin</b> <b>breast</b> <b>cancer</b> data. The Wisconsin cancer dataset [17] contains 699 instances, with 458 benign (65.5%) and 241 (34.5%) malignant cases. Each instance is described by the case number, 9 attributes with integer value in the range 1-10 (for example,<br></p><hr><p class=\"normal\"><a name=\"b6e169d69cd67763b95698e8961696fec9ca93bf\"></a><i>Charles Campbell and Nello Cristianini. <a href=\"http://rexa.info/paper/b6e169d69cd67763b95698e8961696fec9ca93bf\">Simple Learning Algorithms for Training Support Vector Machines</a>. Dept. of Engineering Mathematics. </i><br><br>include a sonar classification problem [14], the <b>Wisconsin</b> <b>breast</b> <b>cancer</b> dataset [35] and a database of handwritten digits collected by the US Postal Service [17]. As examples of the improvements with generalisation ability which can be achieved with a soft margin we will also<br></p><hr><p class=\"normal\"><a name=\"4695569c53cd581fcc193415a8a94a1f92abf607\"></a><i>Chotirat Ann and Dimitrios Gunopulos. <a href=\"http://rexa.info/paper/4695569c53cd581fcc193415a8a94a1f92abf607\">Scaling up the Naive Bayesian Classifier: Using Decision Trees for Feature Selection</a>. Computer Science Department University of California. </i><br><br>19 classes. Attributes selected by SBC = 12. <b>Wisconsin</b> <b>Breast</b> <b>Cancer</b> 75 80 85 90 95 100 10203040506070809099 Training Data (%) Accuracy (%) NBC SBC C4.5 Figure 10. Wisconsin Breast Cancer dataset. 699 instances, 9 attributes, 2 classes. Attributes selected by SBC = 4. Congressional Voting Records 80 85 90 95 100 10203040506070809099 Training Data (%) Accuracy (%) NBC SBC C4.5 Figure 11.<br></p><hr><p class=\"normal\"><a name=\"8afa6796645ce4b0642db26c822cf6bfa8cc4d0d\"></a><i>Wl odzisl/aw Duch and Rudy Setiono and Jacek M. Zurada. <a href=\"http://rexa.info/paper/8afa6796645ce4b0642db26c822cf6bfa8cc4d0d\">Computational intelligence methods for rule-based data understanding</a>. </i><br><br>data. Large number of rules will usually lead to poor generalization, and the insight into the knowledge hidden in the data will be lost. C. <b>Wisconsin</b> <b>breast</b> <b>cancer</b> data. The Wisconsin breast cancer dataset [132] is one of the favorite benchmark datasets for testing classifiers (Table V). Properties of cancer cells were collected for 699 cases, with 458 benign (65.5%) and 241 (34.5%) malignant cases of<br></p><hr><p class=\"normal\"><a name=\"899bdb470e48c308144216cc22048c88816ee035\"></a><i>Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. <a href=\"http://rexa.info/paper/899bdb470e48c308144216cc22048c88816ee035\">An Ant Colony Based System for Data Mining: Applications to Medical Data</a>. CEFET-PR, CPGEI Av. Sete de Setembro, 3165. </i><br><br>AntClass 75.13% \u00b1 6.00 5.20 \u00b1 0.87 8.80 \u00b1 1.89 C4.5 73.34% \u00b1 3.21 6.2 \u00b1 4.2 12.8 \u00b1 9.83 <b>Wisconsin</b> <b>Breast</b> <b>Cancer</b> Data Set AntClass 95.47% \u00b1 1.62 5.60 \u00b1 0.80 12.50 \u00b1 2.84 C4.5 95.02% \u00b1 0.31 11.1 \u00b1 1.45 44.1 \u00b1 7.48 Hepatitis Data Set AntClass 88.75% \u00b1 6.73 2.70 \u00b1 0.46 7.50 \u00b1 2.01 C4.5 85.96% \u00b1 1.07 4.4 \u00b1 0.93 8.5 \u00b1 3.04<br></p><hr><p class=\"normal\"><a name=\"53ac23f963b3607aae9580b356e6b236d2955314\"></a><i>Wl/odzisl/aw Duch and Rafal/ Adamczak Email:duchraad@phys. uni. torun. pl. <a href=\"http://rexa.info/paper/53ac23f963b3607aae9580b356e6b236d2955314\">Statistical methods for construction of neural networks</a>. Department of Computer Methods, Nicholas Copernicus University. </i><br><br>p i (x) - p r (x) around x for which the two distributions cross. The simplest network constructed from FDA solution gives classification error which is as good as the original FDA. For such datasets [12] as <b>Wisconsin</b> <b>breast</b> <b>cancer</b>  hepatitis, Cleveland heart disease or diabetes the network obtains better results already before the learning process starts, but for some datasets this is not the<br></p><hr><p class=\"normal\"><a name=\"f4405e32dbb5dea3ece303e2a5b3edb6b413271e\"></a><i>Rafael S. Parpinelli and Heitor S. Lopes and Alex Alves Freitas. <a href=\"http://rexa.info/paper/f4405e32dbb5dea3ece303e2a5b3edb6b413271e\">PART FOUR: ANT COLONY OPTIMIZATION AND IMMUNE SYSTEMS Chapter X An Ant Colony Algorithm for Classification Rule Discovery</a>. CEFET-PR, Curitiba. </i><br><br>2. The numbers after the \"\u00b1\" symbol are the standard deviations of the corresponding accuracy rates. As shown in this table, Ant-Miner discovered rules with a better accuracy rate than C4.5 in four data sets, namely Ljubljana <b>breast</b> <b>cancer</b>  <b>Wisconsin</b> breast cancer, Hepatitis and Heart disease. In two data sets, Ljubljana breast cancer and Heart disease, the difference was quite small. In the other two<br></p><hr><p class=\"normal\"><a name=\"095d7064837557bdfbca12fb9c12dbaaeb3a8b0d\"></a><i>Adam H. Cannon and Lenore J. Cowen and Carey E. Priebe. <a href=\"http://rexa.info/paper/095d7064837557bdfbca12fb9c12dbaaeb3a8b0d\">Approximate Distance Classification</a>. Department of Mathematical Sciences The Johns Hopkins University. </i><br><br>data before implementing the ADC classification algorithm. Here, only the raw data has been analyzed using the same procedure described above. 5 Conclusions Results on the <b>Wisconsin</b> <b>breast</b> <b>cancer</b> data set and the Fisher iris data set compare very well with previous work on these data. The Pima Indian diabetes results are also nearly competitive with previous work. In all three cases it should be<br></p><hr><p class=\"normal\"><a name=\"b0bf518f2c1c4ab72ebac0d17757aa8f52a6badf\"></a><i>Andrew I. Schein and Lyle H. Ungar. <a href=\"http://rexa.info/paper/b0bf518f2c1c4ab72ebac0d17757aa8f52a6badf\">A-Optimality for Active Learning of Logistic Regression Classifiers</a>. Department of Computer and Information Science Levine Hall. </i><br><br>54. The lodgepole pine variety of tree happens to represent about 50% of the observations and so we merge all other tree types into a single category. The <b>Wisconsin</b> Diagnostic <b>Breast</b> <b>Cancer</b> (WDBC) data set consists of evaluation measurements (predictors) and final diagnosis for 569 patients. The goal is to predict the diagnosis using the measurements. The number of predictors is 30. The Thyroid Domain<br></p><hr><p class=\"normal\"><a name=\"dba0c3d458498a4eef66d37b0f3b1cb310086d31\"></a><i>Bart Baesens and Stijn Viaene and Tony Van Gestel and J. A. K Suykens and Guido Dedene and Bart De Moor and Jan Vanthienen and Katholieke Universiteit Leuven. <a href=\"http://rexa.info/paper/dba0c3d458498a4eef66d37b0f3b1cb310086d31\">An Empirical Assessment of Kernel Type Performance for Least Squares Support Vector Machine Classifiers</a>. Dept. Applied Economic Sciences. </i><br><br>Liver Disorders (bld), German Credit (gcr), Heart Disease (hea), Johns Hopkins Ionosphere (ion), Pima Indians Diabetes (pid), Sonar (snr), Tic-Tac-Toe (ttt) and the <b>Wisconsin</b> <b>Breast</b> <b>Cancer</b> (wbc) data set. We start with presenting the empirical setup used to construct the LS-SVM classifier. This is followed by a discussion of the obtained results. 3.1 Constructing the LS-SVM Classifier The<br></p><hr><p class=\"normal\"><a name=\"50b9babac023b426f1531a4265076bea534d121e\"></a><i>Adil M. Bagirov and Alex Rubinov and A. N. Soukhojak and John Yearwood. <a href=\"http://rexa.info/paper/50b9babac023b426f1531a4265076bea534d121e\">Unsupervised and supervised data classification via nonsmooth and global optimization</a>. School of Information Technology and Mathematical Sciences, The University of Ballarat. </i><br><br>The Australian credit dataset, the <b>Wisconsin</b> <b>breast</b> <b>cancer</b> dataset, the diabetes dataset, the heart disease dataset and the liver-disorder dataset have been used in numerical experiments. The description of these datasets can be<br></p><hr><p class=\"normal\"><a name=\"9a75a9a8ce786d6a05ad51afa124cd4f70bfbb36\"></a><i>Rudy Setiono and Huan Liu. <a href=\"http://rexa.info/paper/9a75a9a8ce786d6a05ad51afa124cd4f70bfbb36\">Neural-Network Feature Selector</a>. Department of Information Systems and Computer Science National University of Singapore. </i><br><br>are described below. 1. The University of <b>Wisconsin</b> <b>Breast</b> <b>Cancer</b> Diagnosis Dataset. The Wisconsin Breast Cancer Data (WBCD) is a large data set that consists of 699 patterns of which 458 are benign samples and 241 are malignant samples. Each of these patterns consists of nine<br></p><hr><p class=\"normal\"><a name=\"8f5ae7219e74a85e3f722b58b3fedb30eab7a1d7\"></a><i>Huan Liu. <a href=\"http://rexa.info/paper/8f5ae7219e74a85e3f722b58b3fedb30eab7a1d7\">A Family of Efficient Rule Generators</a>. Department of Information Systems and Computer Science National University of Singapore. </i><br><br>testing set are randomly selected. The rest are used for training. The data has 22 discrete attributes. Each attribute can have 2 to 10 values. ffl <b>Wisconsin</b> <b>Breast</b> <b>Cancer</b> The training and testing datasets contains 350 and 349 instances respectively. 350 instances are randomly selected for training, the other half is for testing. There are 9 discrete attributes. Each attribute has 10 values. The<br></p><hr><p class=\"normal\"><a name=\"42ba5137ab9d88dc1eae5caac18cb6a1818ae700\"></a><i>Rudy Setiono. <a href=\"http://rexa.info/paper/42ba5137ab9d88dc1eae5caac18cb6a1818ae700\">Extracting M-of-N Rules from Trained Neural Networks</a>. School of Computing National University of Singapore. </i><br><br>of the data were converted to 126 binary inputs before training. In order to reduce computation time, only 2000 randomly selected samples were used. 4. The <b>Wisconsin</b> <b>breast</b> <b>cancer</b> classification dataset [17]. Each of the 699 patterns in the 16 TABLE I: The initial network topology (input, hidden and output units) and the average user time required for training and pruning. Figures in parentheses<br></p>\n\n\n\t</td></tr></table>\n\n\n\n<hr>\n\n<p class=\"normal\"><a href=\"/datasets/Breast+Cancer+Wisconsin+(Prognostic)\">Return to Breast Cancer Wisconsin (Prognostic) data set page</a>.\n\n\n<table cellpadding=5 align=center><tr valign=center>\n\t\t<td><p class=\"normal\">Supported By:</p></td>\n        <td><img src=\"../assets/nsfe.gif\" height=60 /> </td>\n        <td><p class=\"normal\">&nbsp;In Collaboration With:</p></td>\n        <td><img src=\"../assets/rexaSmall.jpg\" /></td>\n</tr></table>\n\n<center>\n<span class=\"normal\">\n<a href=\"../about.html\">About</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../donation_policy.html\">Donation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../contact.html\">Contact</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"http://cml.ics.uci.edu\">CML</a>\n</span>\n</center>\n\n\n\n\n</body>\n</html>\n", "encoding": "ISO-8859-1"}