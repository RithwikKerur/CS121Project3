{"url": "http://archive.ics.uci.edu/ml/support/Adult#cefc3da70b90693b8046b574392c86d2db1f196a", "content": "\n\n\n\n<!DOCTYPE HTML PUBLIC \\\"-//W3C//DTD HTML 4.01 Transitional//EN\\\">\n<html>\n<head>\n<title>UCI Machine Learning Repository: Adult Data Set: Support</title>\n\n<!-- Stylesheet link -->\n<link rel=\"stylesheet\" type=\"text/css\" href=\"../assets/ml.css\" />\n\n<script language=\"JavaScript\" type=\"text/javascript\">\n<!--\nfunction checkform ( form )\n{\n  // see http://www.thesitewizard.com/archive/validation.shtml\n  // for an explanation of this script and how to use it on your\n  // own website\n\n  // ** START **\n  if (form.q.value == \"\")\n  {\n    alert( \"Please enter search terms.\" );\n    form.q.focus();\n    return false ;\n  }\n\n  if (getCheckedValue(form.sitesearch) == \"ics.uci.edu\" && form.q.value.indexOf(\"site:archive.ics.uci.edu/ml\") == -1)\n  {\n    form.q.value = form.q.value + \" site:archive.ics.uci.edu/ml\";\n  }\n\n  // ** END **\n  return true ;\n}\n\n// return the value of the radio button that is checked\n// return an empty string if none are checked, or\n// there are no radio buttons\nfunction getCheckedValue(radioObj) {\n\tif(!radioObj)\n\t\treturn \"\";\n\tvar radioLength = radioObj.length;\n\tif(radioLength == undefined)\n\t\tif(radioObj.checked)\n\t\t\treturn radioObj.value;\n\t\telse\n\t\t\treturn \"\";\n\tfor(var i = 0; i < radioLength; i++) {\n\t\tif(radioObj[i].checked) {\n\t\t\treturn radioObj[i].value;\n\t\t}\n\t}\n\treturn \"\";\n}\n//-->\n</script>\n\n</head>\n\n<body>\n\n\n<!-- SITE HEADER (INCLUDES LOGO AND SEARCH BOX) -->\n\n<table width=100% bgcolor=\"#003366\">\n<tr>\n\t<td>\n\t\t<span class=\"normal\"><a href=\"../index.html\" \nalt=\"Home\"><img src=\"../assets/logo.gif\" \nborder=0></img></a><br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href=\"http://cml.ics.uci.edu\"><font color=\"FFDD33\">Center for Machine Learning and Intelligent Systems</font></a></span>\n\t</td>\n\t<td width=100% valign=top align=\"right\">\n\t\t<span class=\"whitetext\">\n\t\t<a href=\"../about.html\">About</a>&nbsp;\n\t\t<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;\n\t\t<a href=\"../donation_policy.html\">Donate a Data Set</a>&nbsp;\n\t\t<a href=\"../contact.html\">Contact</a>\n\t\t</span>\n\n\t\t<br>\n\t\t<br>\n\t\t<!-- Search Google -->\n\n\t\t<FORM method=GET action=http://www.google.com/custom onsubmit=\"return checkform(this);\">\n\t\t<INPUT TYPE=text name=q size=30 maxlength=255 value=\"\">\n\t\t<INPUT type=submit name=sa VALUE=\"Search\">\n\t\t<INPUT type=hidden name=cof VALUE=\"AH:center;LH:130;L:http://archive.ics.uci.edu/assets/logo.gif;LW:384;AWFID:869c0b2eaa8d518e;\">\n\t\t<input type=hidden name=domains value=\"ics.uci.edu\">\n\t\t<br>\n\t\t<input type=radio name=sitesearch value=\"ics.uci.edu\" checked> <span class=\"whitetext\"><font size=\"1\">Repository</font></span>\n\t\t<input type=radio name=sitesearch value=\"\"> <span class=\"whitetext\"><font size=\"1\">Web</font></span>\n\t\t&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n\t\t<A HREF=http://www.google.com/search><IMG SRC=http://www.google.com/logos/Logo_25blk.gif border=0 ALT=Google align=middle height=27></A>\n\t\t<br>\n\t\t</FORM>\n\t\t<!-- Search Google -->\n\n\n\t\t<span class=\"whitetext\"><a href=\"../datasets.php\"><font size=\"3\" color=\"#FFDD33\"><b>View ALL Data Sets</b></font></a></span>\n\t\t<br>\n\t</td>\n</tr>\n</table>\n\n<br />\n<table width=100% border=0 cellpadding=2><tr><td>\n\n\n   <table><tr>\n     <td valign=top>\n\t<p>\n\t<span class=\"heading\"><b>Adult Data Set</b></span>\n\n\t\t\n\t\t<img src=\"../assets/MLimages/Large2.jpg\" hspace=20 vspace=10 align=right />\t\t<p class=\"normal\">Below are papers that cite this data set, with context shown.\n\t\tPapers were automatically harvested and associated with this data set, in collaboration with <a href=\"http://rexa.info\">Rexa.info</a>.</p>\n\t\t<img src=\"../assets/rexa.jpg\" />\n\t\t<p class=\"normal\"><a href=\"/ml/datasets/Adult\">Return to Adult data set page</a>.\n\t\t<hr><p class=\"normal\"><a name=\"686ccd571de3e92d89394f207348bd5a669558d2\"></a><i>Rakesh Agrawal and Ramakrishnan ikant and Dilys Thomas. <a href=\"http://rexa.info/paper/686ccd571de3e92d89394f207348bd5a669558d2\">Privacy Preserving OLAP</a>. SIGMOD Conference. 2005. </i><br><br>present among the original set of queried columns. 7. EXPERIMENTS We next present an empirical evaluation of our algorithms on real as well as synthetic data. For real data, we used the <b>Adult</b> dataset, from the UCI Machine Learning Repository [5], which has census information. The Adult dataset contains about 32,000 rows with 4 numerical columns. The columns and their ranges are: age[17 - 90],<br></p><hr><p class=\"normal\"><a name=\"1383360e8bb2cfd7a98219f867869a9f6d7e0db0\"></a><i>Wei-Chun Kao and Kai-Min Chung and Lucas Assun and Chih-Jen Lin. <a href=\"http://rexa.info/paper/1383360e8bb2cfd7a98219f867869a9f6d7e0db0\">Decomposition Methods for Linear Support Vector Machines</a>. Neural Computation, 16. 2004. </i><br><br>used are in Table 3.2. The four small problems are from the statlog collection (Michie, Spiegelhalter, and Taylor 1994). The problem <b>adult</b> is compiled by Platt (1998) from the UCI \"adult\" data set (Blake and Merz 1998). Problem web is also from Platt. Problem ijcnn is from the first problem of IJCNN challenge 2001 (Prokhorov 2001). Note that we use the winner's transformation of the raw data<br></p><hr><p class=\"normal\"><a name=\"92270daca0b7d369e25eb444e918bcb74b18d682\"></a><i>Saharon Rosset. <a href=\"http://rexa.info/paper/92270daca0b7d369e25eb444e918bcb74b18d682\">Model selection via the AUC</a>. ICML. 2004. </i><br><br>to prefer the K-NN model most of the time. This illustrates the \"bias\" in using AUC to select classi#cation models, which we discuss in section 3.2 Finally, we performed experiments on a real-life data set. We used the  <b>Adult</b>  data-set available from the UCI repository (Blake & Merz, 1998). We used only the first ten variables in this data-set, to make a largescale experiment feasible, and compared<br></p><hr><p class=\"normal\"><a name=\"97c489fe4c5d81f7fde00a62d3a5d043ec9ddcb6\"></a><i>Rich Caruana and Alexandru Niculescu-Mizil. <a href=\"http://rexa.info/paper/97c489fe4c5d81f7fde00a62d3a5d043ec9ddcb6\">An Empirical Evaluation of Supervised Learning for ROC Area</a>. ROCAI. 2004. </i><br><br>selection is done using the 1k validation sets, SVMs move slightly ahead of the neural nets.) Boosted stumps and plain decision trees are not competitive, though boosted stumps are best on the <b>Adult</b> data set. It is interesting to note that boosting weaker stump models is clearly inferior to boosting full decision trees on most of the test problems: boosting full decision trees yields better performance<br></p><hr><p class=\"normal\"><a name=\"b2c60bdf066b03909792bd5d64891f3607b948c8\"></a><i>Rich Caruana and Alexandru Niculescu-Mizil and Geoff Crew and Alex Ksikes. <a href=\"http://rexa.info/paper/b2c60bdf066b03909792bd5d64891f3607b948c8\">Ensemble selection from libraries of models</a>. ICML. 2004. </i><br><br>but each ensemble is just a weighted average of models, so the average of a set of ensembles also is a simple weighted average of the base-level models. Bagging is discussed in Section 5.3. 3. Data Sets We experiment with seven problems: <b>ADULT</b>  COVER TYPE, LETTER.p1, and LETTER.p2 from the UCI Repository (Blake & Merz, 1998), MEDIS, a pneumonia data set, SLAC, data from collaborators at the<br></p><hr><p class=\"normal\"><a name=\"1d416aa15df505a2052d91f04ce93d8e3f2bfa7e\"></a><i>Bianca Zadrozny. <a href=\"http://rexa.info/paper/1d416aa15df505a2052d91f04ce93d8e3f2bfa7e\">Learning and evaluating classifiers under sample selection bias</a>. ICML. 2004. </i><br><br>3.5. Experimental results To verify the effects of sample selection bias experimentally, we apply Naive Bayes, logistic regression, C4.5 and SVMLight (soft margin) (Joachims, 2000b) to the <b>Adult</b> dataset, available from the UCI Machine Learning repository (Blake & Merz, 1998). We assume that the original dataset is not biased and artificially simulate biasedness by generating a value for s for each<br></p><hr><p class=\"normal\"><a name=\"74b68cad54c62b62b7ad64911291e2e0b0620dd8\"></a><i>Bart Hamers and J. A. K Suykens. <a href=\"http://rexa.info/paper/74b68cad54c62b62b7ad64911291e2e0b0620dd8\">Coupled Transductive Ensemble Learning of Kernel Models</a>. Bart De Moor. 2003. </i><br><br>0.16 5.08e-4 0.27 0.28 7.92e-4 0.21 0.21 8.37e-4 0.15 0.14 5.08e-4 0.24 0.24 8.34e-4 1 0 1 9.8e-5 1 2.7e-3 Table 2: Misclassification rates on a test set (Tic-Tac-Toe (TTT), Australian Credit Card Data Set (ACR) and the <b>ADULT</b> Data Set (ADULT)). The number of models is indicated by the second number in Table 1, example TTT11 is an ensemble model based on 11 individual models on, the TTT prediction. We<br></p><hr><p class=\"normal\"><a name=\"13c8e4e9474a8fbd7bd8a66695b62f218189ac6f\"></a><i>Andrew W. Moore and Weng-Keen Wong. <a href=\"http://rexa.info/paper/13c8e4e9474a8fbd7bd8a66695b62f218189ac6f\">Optimal Reinsertion: A New Search Operator for Accelerated and More Accurate Bayesian Network Structure Learning</a>. ICML. 2003. </i><br><br>if and only if an odd number of parents have value \"True\". The nodes are thus noisy exclusive-ors and so it is hard to learn a set of parents incrementally. Synth2 Synth3 Synth4 Figure 3. Synthetic datasets described in Section 3.1. R m AA <b>adult</b> 49K 15 7.7 Contributed to UCI by Ron Kohavi alarm 20K 37 2.8 Data generated from a standard Bayes Net benchmark (Beinlich et al., 1989). biosurv 150K 24 3.5<br></p><hr><p class=\"normal\"><a name=\"0767f0171b0f74f96978a41f3e947ea91cc9dbd3\"></a><i>Alexander J. Smola and Vishy Vishwanathan and Eleazar Eskin. <a href=\"http://rexa.info/paper/0767f0171b0f74f96978a41f3e947ea91cc9dbd3\">Laplace Propagation</a>. NIPS. 2003. </i><br><br># \u00c4 # # # ##\u00c7 # (15) with the joint minimizer being the average of the individual solutions. 5 Experiments To test our ideas we performed a set of experiments with the widely available Web and <b>Adult</b> datasets from the UCI repository [1]. All experiments were performed on a 2.4 MHz 2 Note that we had to replace the equality with set inclusion due to the fact that \u00dc is not everywhere differentiable, hence<br></p><hr><p class=\"normal\"><a name=\"df1dc2bd013ef17735eb85d2de85701f833db3ff\"></a><i>I. Yoncaci. <a href=\"http://rexa.info/paper/df1dc2bd013ef17735eb85d2de85701f833db3ff\">Maximum a Posteriori Tree Augmented Naive Bayes Classifiers</a>. O EN INTEL.LIG ` ENCIA ARTIFICIAL CSIC. 2003. </i><br><br>In the rest of the section we discuss and justify these assertions into more detail. 14 Dataset MAPTAN MAPTAN+BMA sTAN sTAN+BMA <b>adult</b> 17.18 \u00b1 0.68 17.19 \u00b1 0.71 17.60 \u00b1 0.82 17.60 \u00b1 0.80 australian 19.91 \u00b1 1.14 19.62 \u00b1 1.13 25.39 \u00b1 1.18 24.96 \u00b1 1.13 breast 17.23 \u00b1 1.21 16.89 \u00b1 1.28 8.73 \u00b1 0.87<br></p><hr><p class=\"normal\"><a name=\"5e9e56b4525a16e039d75d04d32477b118e36b0d\"></a><i>Christopher R. Palmer and Christos Faloutsos. <a href=\"http://rexa.info/paper/5e9e56b4525a16e039d75d04d32477b118e36b0d\">Electricity Based External Similarity of Categorical Attributes</a>. PAKDD. 2003. </i><br><br>than the distance functions computed by D fr;P . Since D fr;P has been previously evaluated using single link hierarchical clustering, that is the algorithm that we will use here [3]. The three data sets weevaluated are: 1. <b>Adult</b> - a selection of fields from the 1994 census data collected in the United States. There are 32,561 training examples and 16,281 test examples with 6 numeric fields and 8<br></p><hr><p class=\"normal\"><a name=\"679efdb662f70091c573c74a40aadab38fc0d868\"></a><i>S. Sathiya Keerthi and Chih-Jen Lin. <a href=\"http://rexa.info/paper/679efdb662f70091c573c74a40aadab38fc0d868\">Asymptotic Behaviors of Support Vector Machines with Gaussian Kernel</a>. Neural Computation, 15. 2003. </i><br><br>into (training set, test set) partitions. We consider only the first of those realizations. In addition, the problem <b>adult</b>  from the UCI adult\" data set (Blake and Merz 1998) and the problem web, both as compiled by Platt (1998), are also included. For each of these two datasets also, there are several realizations. For our study here, we only<br></p><hr><p class=\"normal\"><a name=\"a702c0617d7187cfc988819d79f0eb2a42ba3f19\"></a><i>Thomas Serafini and G. Zanghirati and Del Zanna and T. Serafini and Gaetano Zanghirati and Luca Zanni. <a href=\"http://rexa.info/paper/a702c0617d7187cfc988819d79f0eb2a42ba3f19\">DIPARTIMENTO DI MATEMATICA</a>. Gradient Projection Methods for. 2003. </i><br><br>the MNIST database of handwritten digits [24] and the UCI <b>Adult</b> data set [27]. These experiments are carried out on a Compaq XP1000 workstation at 667MHz with 1GB of RAM, with standard C codes. All the considered methods compute the projection on the special feasible<br></p><hr><p class=\"normal\"><a name=\"6a6b4ca13137132e00185012fd7c4667ff964769\"></a><i>S. Sathiya Keerthi and Kaibo Duan and Shirish Krishnaj Shevade and Aun Neow Poo. <a href=\"http://rexa.info/paper/6a6b4ca13137132e00185012fd7c4667ff964769\">A Fast Dual Algorithm for Kernel Logistic Regression</a>. ICML. 2002. </i><br><br>much faster than the BFGS algorithm. The difference is much higher for large values of C. To see how the cost of the SMO algorithm scales with data size, an experiment was done on the UCI  <b>Adult</b>  dataset (Merz and Murphy, 1998) by gradually increasing the training set size from 1605 to 22696 in eight steps and observing the training time. A line was then fitted to the plot of the log of the training<br></p><hr><p class=\"normal\"><a name=\"81ff15994633ecdb2b9fd5a6d11d985c2b215442\"></a><i>Ramesh Natarajan and Edwin P D Pednault. <a href=\"http://rexa.info/paper/81ff15994633ecdb2b9fd5a6d11d985c2b215442\">Segmented Regression Estimators for Massive Data Sets</a>. SDM. 2002. </i><br><br>Figure 1. A comparison of the lift on the Fingerhut data for the \"Consolidated Payout Model\"using the LRT methodology (left), and for the \"Response Model\"using the NBT methodology (right). 6.3 <b>Adult</b> data set This is a standard data set from [4] with the 32561 training and 16281 test data and about 7% missing value records in the training data. The data has 6 continuous and 8 nominal features and the<br></p><hr><p class=\"normal\"><a name=\"4284c9cb6236847cd246f69cfb8e4209c107d18f\"></a><i>Bianca Zadrozny and Charles Elkan. <a href=\"http://rexa.info/paper/4284c9cb6236847cd246f69cfb8e4209c107d18f\">Transforming classifier scores into accurate multiclass probability estimates</a>. KDD. 2002. </i><br><br># x### s # : the number of examples with score s that belong to class c divided by the total number of examples 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 <b>Adult</b> Dataset NB Score Empirical class membership probability 8941 790 610 450 480 532 477 620 672 2710 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 The Insurance Company<br></p><hr><p class=\"normal\"><a name=\"4dbb0e14d9556fd1099e129462d0bedcf35bd82b\"></a><i>Nitesh V. Chawla and Kevin W. Bowyer and Lawrence O. Hall and W. Philip Kegelmeyer. <a href=\"http://rexa.info/paper/4dbb0e14d9556fd1099e129462d0bedcf35bd82b\">SMOTE: Synthetic Minority Over-sampling Technique</a>. J. Artif. Intell. Res. (JAIR, 16. 2002. </i><br><br>is to distinguish between nasal (class 0) and oral sounds (class 1). There are 5 features. The class distribution is 3,818 samples in class 0 and 1,586 samples in class 1. 3. The <b>Adult</b> dataset (Blake & Merz, 1998) has 48,842 samples with 11,687 samples belonging to the minority class. This dataset has 6 continuous features and 8 nominal features. SMOTE and SMOTE-NC (see Section 6.1)<br></p><hr><p class=\"normal\"><a name=\"510872c81d0a05f14c583cf3e8245b6c88d43db6\"></a><i>Bernhard Pfahringer and Geoffrey Holmes and Richard Kirkby. <a href=\"http://rexa.info/paper/510872c81d0a05f14c583cf3e8245b6c88d43db6\">Optimizing the Induction of Alternating Decision Trees</a>. PAKDD. 2001. </i><br><br>kr-vs-kp 3196 0.0 0 36 labor 57 33.6 8 8 mushroom 8124 1.3 0 22 promoters 106 0.0 0 57 sick-euthyroid 3163 6.5 7 18 sonar 208 0.0 60 0 splice 3190 0.0 0 61 vote 435 5.3 0 16 vote1 3 435 5.5 0 15 KDD Datasets coil 5822/4000 0.0 85 0 <b>adult</b> 32561/16281 0.2 6 8 art1 50000/50000 0.0 0 50 art2 50000/50000 0.0 25 25 art3 50000/50000 0.0 50 0 This section compares the performance of the original optimized<br></p><hr><p class=\"normal\"><a name=\"8931d2a4a8256ea88abea3ea3ac820fd421ce0b1\"></a><i>Stephen D. Bay and Michael J. Pazzani. <a href=\"http://rexa.info/paper/8931d2a4a8256ea88abea3ea3ac820fd421ce0b1\">Detecting Group Differences: Mining Contrast Sets</a>. Data Min. Knowl. Discov, 5. 2001. </i><br><br>3 This program is available from http://fuzzy.cs.Uni-Magdeburg.de/#borgelt/.Version 1.8 of his program is incorporated in the data mining tool Clementine. 18 issues. We used the following datasets which are summarized in Table 2. <b>Adult</b>  The Adult Census data contains information extracted from the 1994 CurrentPopulation Survey. There are variables such as age, working class, education, sex,<br></p><hr><p class=\"normal\"><a name=\"beeb203c082359f4e141e1767a14f09449a5a717\"></a><i>Jie Cheng and Russell Greiner. <a href=\"http://rexa.info/paper/beeb203c082359f4e141e1767a14f09449a5a717\">Learning Bayesian Belief Network Classifiers: Algorithms and System</a>. Canadian Conference on AI. 2001. </i><br><br>used in the experiments. Dataset Attributes. Classes Instances Train Test <b>Adult</b> 13 2 32561 16281 Nursery 8 5 8640 4320 Mushroom 22 2 5416 2708 Chess 36 2 2130 1066 DNA 60 3 2000 1186 The experiments were carried out using our<br></p><hr><p class=\"normal\"><a name=\"6bacbb21f7a1d6dee581f756cf326e0932446698\"></a><i>Zhiyuan Chen and Johannes Gehrke and Flip Korn. <a href=\"http://rexa.info/paper/6bacbb21f7a1d6dee581f756cf326e0932446698\">Query Optimization In Compressed Database Systems</a>. SIGMOD Conference. 2001. </i><br><br>are not compressed. TPC-H data contains 8 tables and 61 attributes, 23 of which are string-valued. The string attributes account for about 60% of the total database size. We also used a 4MB of dataset with US census data, the <b>adult</b> data set [5] for experiments on compression strategies. The adult dataset contains a single table with 14 attributes, 8 of them string-valued, accounting for about 80%<br></p><hr><p class=\"normal\"><a name=\"0527f760f533e2a7a827710a924d6987bfc9a06e\"></a><i>Stephen D. Bay. <a href=\"http://rexa.info/paper/0527f760f533e2a7a827710a924d6987bfc9a06e\">Multivariate Discretization for Set Mining</a>. Knowl. Inf. Syst, 3. 2001. </i><br><br>Data Set #Features # Continuous # Examples <b>Adult</b> 14 5 48812 Census-Income 5 41 7 199523 SatImage 37 36 6435 Shuttle 10 9 48480 UCI Admissions 19 8 123028 Table 3. Discretization Time in CPU seconds Data Set<br></p><hr><p class=\"normal\"><a name=\"94cf84d5a454c97d326efdb24b2b96e0eac25c33\"></a><i>Kristin P. Bennett and Ayhan Demiriz and John Shawe-Taylor. <a href=\"http://rexa.info/paper/94cf84d5a454c97d326efdb24b2b96e0eac25c33\">A Column Generation Algorithm For Boosting</a>. ICML. 2000. </i><br><br>all points and # i measures the additional margin obtained by each point. AdaBoost also minimizes a margin cost function based on the margin obtained by each point. We ran experiments on two larger datasets: Forest and <b>Adult</b>  from UCI(Murphy & Aha, 1992). Forest is a 54-dimension dataset with 7 possible classes. The data are divided into 11340 training, 3780 validation and 565892 testing instances.<br></p><hr><p class=\"normal\"><a name=\"d6a42d10713c10dbc3efa4b7de53fb7f807caa0b\"></a><i>Dmitry Pavlov and Jianchang Mao and Byron Dom. <a href=\"http://rexa.info/paper/d6a42d10713c10dbc3efa4b7de53fb7f807caa0b\">Scaling-Up Support Vector Machines Using Boosting Algorithm</a>. ICPR. 2000. </i><br><br>one week of February 1998. The classification task, as we pose it, is to predict whether a user will visit the most popular site S based on his/her visiting pattern of all other sites. The <b>Adult</b> data set is available at UCI machine learning repository [1]. The task is to predict if the income of a person is greater than 50K based on several census parameters, such as age, education, marital status<br></p><hr><p class=\"normal\"><a name=\"55a7f45a6b42ceb9097c7260032694bcbd8a2fd2\"></a><i>Gary M. Weiss and Haym Hirsh. <a href=\"http://rexa.info/paper/55a7f45a6b42ceb9097c7260032694bcbd8a2fd2\">A Quantitative Study of Small Disjuncts: Experiments and Results</a>. Department of Computer Science Rutgers University. 2000. </i><br><br>were compared as the training set size was varied. Because disjuncts of a specific size for most concepts cover very few examples, statistically valid comparison were possible for only 4 of the 30 datasets (Coding, Move, <b>Adult</b>  and Market2); with the other datasets the number of examples covered by disjuncts of a given size is too small. The results for the Coding dataset are shown in Figure 8.<br></p><hr><p class=\"normal\"><a name=\"5300c71ae945611a1d091404fc0461a48738e151\"></a><i>Dmitry Pavlov and Darya Chudova and Padhraic Smyth. <a href=\"http://rexa.info/paper/5300c71ae945611a1d091404fc0461a48738e151\">Towards scalable support vector machines using squashing</a>. KDD. 2000. </i><br><br>were ``The Microsoft Anonymous Web'' and the ''Forest Cover Type'' datasets available at UCI KDD archive [Bay99] and <b>Adult</b> dataset available at UCI machine learning repository [BM98]. Web data reflects the Web pages of www.microsoft.com that each user visited during one<br></p><hr><p class=\"normal\"><a name=\"819bb37e80fcb500fd159702e1dc2c0fe98f38ac\"></a><i>Petri Kontkanen and Jussi Lahtinen and Petri Myllymaki and Tomi Silander and Henry Tirri. <a href=\"http://rexa.info/paper/819bb37e80fcb500fd159702e1dc2c0fe98f38ac\">Proceedings of Pre- and Post-processing in Machine Learning and Data Mining: Theoretical Aspects and Applications, a workshop within Machine Learning and Applications</a>. Complex Systems Computation Group (CoSCo). 1999. </i><br><br>via the CoSCo group home page. 42 Australian Credit Balance Scale Connect-4 German Credit Thyroid Disease Vehicle Silhouettes Figure 1: Examples of the two-dimensional visualizations obtained. 43 dataset size #attrs. #classes <b>Adult</b> 32561 15 2 Australian Credit 690 15 2 Balance Scale 625 5 3 Breast Cancer (Wisconsin) 699 11 2 Breast Cancer 286 10 2 Connect-4 67557 43 3 Credit Screening 690 16 2 Pima<br></p><hr><p class=\"normal\"><a name=\"47354ca48da5014e0a8f5e4da7f3a7e9aaa6e9e5\"></a><i>Jie Cheng and Russell Greiner. <a href=\"http://rexa.info/paper/47354ca48da5014e0a8f5e4da7f3a7e9aaa6e9e5\">Comparing Bayesian Network Classifiers</a>. UAI. 1999. </i><br><br>used in the experiments. Instances Dataset Attributes. Classes Train Test <b>Adult</b> 13 2 32561 16281 Nursery 8 5 8640 4320 Mushroom 22 2 5416 2708 Chess 36 2 2130 1066 Car 6 4 1728 CV5 Flare 10 3 1066 CV5 Vote 16 2 435 CV5 Brief descriptions of<br></p><hr><p class=\"normal\"><a name=\"ac8fe867e1d16d4d09f9bd759ba46699055c7ca6\"></a><i>Yk Huhtala and Juha K\u00e4rkk\u00e4inen and Pasi Porkka and Hannu Toivonen. <a href=\"http://rexa.info/paper/ac8fe867e1d16d4d09f9bd759ba46699055c7ca6\">Efficient Discovery of Functional and Approximate Dependencies Using Partitions</a>. ICDE. 1998. </i><br><br>(shown only in the table). Approximate dependencies could not be discovered in the <b>Adult</b> data set with TANE/MEM due to the lack of main memory. To find out how the number of rows affects the algorithms, we ran a series of experiments with increasing number of rows. The relations were formed by<br></p><hr><p class=\"normal\"><a name=\"46a760d333f90e12eb326d2b17c90aa70c01d1df\"></a><i>John C. Platt. <a href=\"http://rexa.info/paper/46a760d333f90e12eb326d2b17c90aa70c01d1df\">Using Analytic QP and Sparseness to Speed Training of Support Vector Machines</a>. NIPS. 1998. </i><br><br>can be found in [8, 7]. The first test set is the UCI <b>Adult</b> data set [5]. The SVM is given 14 attributes of a census form of a household and asked to predict whether that household has an income greater than $50,000. Out of the 14 attributes, eight are categorical<br></p><hr><p class=\"normal\"><a name=\"bf6cec50b7f7d48d105c8c649210cc3a42d3d71e\"></a><i>Ron Kohavi. <a href=\"http://rexa.info/paper/bf6cec50b7f7d48d105c8c649210cc3a42d3d71e\">Scaling Up the Accuracy of Naive-Bayes Classifiers: A Decision-Tree Hybrid</a>. KDD. 1996. </i><br><br>the algorithm, and 20 intervals were used. The error bars show 95% confidence intervals on the accuracy, based on the leftout sample. In most cases it is clear that even with much more 1 The <b>Adult</b> dataset is from the Census bureau and the task is to predict whether a given adult makes more than $50,000 a year based attributes such as education, hours of work per week, etc.. 74 76 78 80 82 84 86 88 90<br></p><hr><p class=\"normal\"><a name=\"0e6263639bcf297001939fd27576b20c6b78f68b\"></a><i>Luca Zanni. <a href=\"http://rexa.info/paper/0e6263639bcf297001939fd27576b20c6b78f68b\">An Improved Gradient Projection-based Decomposition Technique for Support Vector Machines</a>. Dipartimento di Matematica, Universitdi Modena e Reggio Emilia. </i><br><br>in [8]. In order to analyze the behaviour of the two solvers within GPDT2 we consider three large test problems of the form (1) derived by training Gaussian SVMs on the well known UCI <b>Adult</b> data set [22], WEB data set [26] and MNIST data set [18]. A detailed description of the test problems generation is reported in the Appendix. All the experiments are carried out with standard C code running<br></p><hr><p class=\"normal\"><a name=\"8ea9716e5199404825766638c2cc07ec93be5236\"></a><i>Jeff G. Schneider and Andrew W. Moore. <a href=\"http://rexa.info/paper/8ea9716e5199404825766638c2cc07ec93be5236\">Active Learning in Discrete Input Spaces</a>. School of Computer Science Carnegie Mellon University. </i><br><br>regression, confidence intervals can be obtained using the usual t distributions for the mean response of a linear fit. 3 Experimental Results We test our active learning algorithms using the <b>adult</b> data set from the UCI Irvine machine learning repository [2]. We use the age as a continuous output and all other attributes as inputs. The other continuous attributes were discretized to three levels for<br></p><hr><p class=\"normal\"><a name=\"03a71aaf988c71c8022be08734da8e376f7fe037\"></a><i>Omid Madani and David M. Pennock and Gary William Flake. <a href=\"http://rexa.info/paper/03a71aaf988c71c8022be08734da8e376f7fe037\">Co-Validation: Using Model Disagreement to Validate Classification Algorithms</a>. Yahoo! Research Labs. </i><br><br>unlabeled data does not tend to wildly underestimate error, even though it's theoretically possible. 3 Experiments We conducted experiments on the 20 Newsgroups and Reuters-21578 test categorization datasets 1 , and the Votes, Chess, <b>Adult</b>  and Optics datasets from the UCI collection [BKM98]. We chose 1 Available from http://www.ics.uci.edu/ and http://www.daviddlewis.com/resources/testcollections/ two<br></p><hr><p class=\"normal\"><a name=\"4c8e8cf6857f1f1bc9b43679d241b096513ee6f2\"></a><i>Ron Kohavi and Barry G. Becker and Dan Sommerfield. <a href=\"http://rexa.info/paper/4c8e8cf6857f1f1bc9b43679d241b096513ee6f2\">Improving Simple Bayes</a>. Data Mining and Visualization Group Silicon Graphics, Inc. </i><br><br>especially larger ones, such as segment, mushroom, letter, and <b>adult</b> for a total of 37. The specific datasets are shown below in Table 2. Our main concern with estimating accuracy is that the estimate should be precise. Therefore, we ran different inducers on these datasets in two forms. If the dataset was<br></p><hr><p class=\"normal\"><a name=\"e2e72927eb590e2b7daf9095e42d6ed43ce21e68\"></a><i>Shi Zhong and Weiyu Tang and Taghi M. Khoshgoftaar. <a href=\"http://rexa.info/paper/e2e72927eb590e2b7daf9095e42d6ed43ce21e68\">Boosted Noise Filters for Identifying Mislabeled Data</a>. Department of Computer Science and Engineering Florida Atlantic University. </i><br><br>in Table 1. Overall, BBF-I significantly outperforms BBF-II, except for low ( 20%) noise levels for the <b>adult</b>  car, and nursery datasets. The reason BBF-II performs poorly may be that too many clean instances are weighted low. The noise filter constructed in the next round loses strong support from clean data instances, which are<br></p><hr><p class=\"normal\"><a name=\"f1395e1da4a724219d6cc414e48969140355bebb\"></a><i>David R. Musicant. <a href=\"http://rexa.info/paper/f1395e1da4a724219d6cc414e48969140355bebb\">DATA MINING VIA MATHEMATICAL PROGRAMMING AND MACHINE LEARNING</a>. Doctor of Philosophy (Computer Sciences) UNIVERSITY. </i><br><br>separability on SOR performance . . . . . . . . . . . . . 34 3.2 SOR, SMO, and SVM light comparison on the <b>Adult</b> dataset in R 123 . . . 36 3.3 SOR and LPC comparison on 1 million point dataset in R 32 . . . . . . . 38 3.4 SOR applied to 10 million point dataset in R 32 . . . . . . . . . . . . . . . 38 4.1 SOR training<br></p><hr><p class=\"normal\"><a name=\"0ded09c3d904c9f8eeef9ed0bc3445c2b44a6008\"></a><i>William W. Cohen and Yoram Singer. <a href=\"http://rexa.info/paper/0ded09c3d904c9f8eeef9ed0bc3445c2b44a6008\">A Simple, Fast, and Effective Rule Learner</a>. AT&T Labs--Research Shannon Laboratory. </i><br><br>average ranks among these three are 1.8, 2.3, and 1.9. The largest ruleset produced by SLIPPER is 49 rules (for coding). Finally, we evaluated the scalability of the rule learners on several large datasets. We used <b>adult</b>  blackjack, with the addition of 20 irrelevant noise variables; and market3, for which many examples were available. C4rules was not run, since it is known to have scalability<br></p><hr><p class=\"normal\"><a name=\"c7d3013a5143009f65d4303e65d8ecfcc892fa2e\"></a><i>Haixun Wang and Philip S. Yu. <a href=\"http://rexa.info/paper/c7d3013a5143009f65d4303e65d8ecfcc892fa2e\">SSDT-NN: A Subspace-Splitting Decision Tree Classifier with Application to Target Selection</a>. IBM T. J. Watson Research Center. </i><br><br>that have biased data distribution. We use 25% of the cases for training and the rest 75% for testing. The results in shown in Table 3. 19 Datasets Dataset Size Bias SPRINT SSDT-NN <b>Adult</b> 32561 0.24 68 72.1 Anneal 5 798 0.08 100 100 Anneal U 798 0.04 100 100 breast-cancer 466 0.37 76.9 89.2 Vehicle bus 846 0.23 43.3 68.2 Sick 3770 0.06 72.3<br></p><hr><p class=\"normal\"><a name=\"cefc3da70b90693b8046b574392c86d2db1f196a\"></a><i>S. V. N Vishwanathan and Alexander J. Smola and M. Narasimha Murty. <a href=\"http://rexa.info/paper/cefc3da70b90693b8046b574392c86d2db1f196a\">considerably faster than competing methods such as Sequential Minimal Optimization or the Nearest Point Algorithm</a>. Machine Learning Program, National ICT for Australia. </i><br><br>was proposed by Alexis Wieland of MITRE Corporation and it is available from the CMU Artificial Intelligence repository. Both WSPBC and the <b>Adult</b> datasets are available from the UCI Machine Learning repository (Blake & Merz, 1998). We used the same values of # 2 as in Keerthi 3 It is a common misperception that different SV optimization algorithms<br></p><hr><p class=\"normal\"><a name=\"7de1dca96d7e6789dadc875a7f1b070f9d65fff5\"></a><i>Grigorios Tsoumakas and Ioannis P. Vlahavas. <a href=\"http://rexa.info/paper/7de1dca96d7e6789dadc875a7f1b070f9d65fff5\">Fuzzy Meta-Learning: Preliminary Results</a>. Greek Secretariat for Research and Technology. </i><br><br>from the Machine Learning Repository at the University of Irvine, California (Blake & Merz, 1998). These were the <b>adult</b> and chess data sets, large enough (} 1000 examples) to simulate distributed environment. Only two domains were selected at this stage of our research to investigate the performance of the suggested methodology. The<br></p><hr><p class=\"normal\"><a name=\"59e7c62dd41ce2ed1741bafac723745eb7b80b65\"></a><i>Josep Roure Alcobe. <a href=\"http://rexa.info/paper/59e7c62dd41ce2ed1741bafac723745eb7b80b65\">Incremental Hill-Climbing Search Applied to Bayesian Network Structure Learning</a>. Escola Universitria Politcnica de Mataro. </i><br><br>by means of a parameter nRSS. 3.2 Experimental Results In this section we compare the performance of repeatedly using the batch algorithms against the corresponding incremental approach. We used the datasets <b>Adult</b> 48.842 instances and 13 variables), Mushroom (8.124 inst. and 23 var.) and Nursery (12.960 inst. and 9 var.) from the UCI machine learning repository [9], the Alarm dataset (20.000 inst. and<br></p><hr><p class=\"normal\"><a name=\"fc0a66d3a7336b6eabad919a7389c68cc37f2564\"></a><i>Ayhan Demiriz and Kristin P. Bennett and John Shawe and I. Nouretdinov V.. <a href=\"http://rexa.info/paper/fc0a66d3a7336b6eabad919a7389c68cc37f2564\">Linear Programming Boosting via Column Generation</a>. Dept. of Decision Sciences and Eng. Systems, Rensselaer Polytechnic Institute. </i><br><br>of the final set of weak hypotheses. This is just a very simple method of boosting multiclass problems. Further investigation of LP multiclass approaches is needed. We ran experiments on larger datasets: Forest, <b>Adult</b>  USPS, and Optdigits from UCI(Murphy & Aha, 1992). Forest is a 54-dimension dataset with seven possible classes. The data are divided into 11340 training, 3780 validation, and 565892<br></p><hr><p class=\"normal\"><a name=\"48dc427a3536d7bef34e910efc1f34171bf98729\"></a><i>Chris Giannella and Bassem Sayrafi. <a href=\"http://rexa.info/paper/48dc427a3536d7bef34e910efc1f34171bf98729\">An Information Theoretic Histogram for Single Dimensional Selectivity Estimation</a>. Department of Computer Science, Indiana University Bloomington. </i><br><br>was obtained from the UCI machine learning archive [1] (called the  <b>adult</b>  dataset there). We use the age column of the training dataset. The dataset was extracted from 1994 US census data. The shuttle2 dataset was downloaded from the \"Esprit Project 5170 StatLog\" archive<br></p><hr><p class=\"normal\"><a name=\"da329267bf8880c2becb15eae121a5b002347349\"></a><i>Rong-En Fan and P. -H Chen and C. -J Lin. <a href=\"http://rexa.info/paper/da329267bf8880c2becb15eae121a5b002347349\">Working Set Selection Using the Second Order Information for Training SVM</a>. Department of Computer Science and Information Engineering National Taiwan University. </i><br><br>image, diabetes, covtype, breast-cancer, and abalone are from the UCI machine learning repository (Blake and Merz, 1998). Problems a1a and a9a are compiled in (Platt, 1998) from the UCI  <b>adult</b>  data set. Problems w1a and w8a are also from (Platt, 1998). The tree data set was originally used in (Bailey et al., 1993). The problem mg is a Mackey-Glass time series. The data sets cpusmall and splice are<br></p><hr><p class=\"normal\"><a name=\"da53589d7ad993c65a1857401ea6f7b0b025f41a\"></a><i>Petri Kontkanen and Jussi Lahtinen and Petri Myllymaki and Tomi Silander and Henry Tirri. <a href=\"http://rexa.info/paper/da53589d7ad993c65a1857401ea6f7b0b025f41a\">USING BAYESIAN NETWORKS FOR VISUALIZING HIGH-DIMENSIONAL DATA</a>. Complex Systems Computation Group (CoSCo). </i><br><br>via the CoSCo group home page. 5 Australian Credit Balance Scale Connect-4 German Credit Thyroid Disease Vehicle Silhouettes Figure 1: Examples of the two-dimensional visualizations obtained. 6 dataset size #attrs. #classes <b>Adult</b> 32561 15 2 Australian Credit 690 15 2 Balance Scale 625 5 3 Breast Cancer (Wisconsin) 699 11 2 Breast Cancer 286 10 2 Connect-4 67557 43 3 Credit Screening 690 16 2 Pima<br></p><hr><p class=\"normal\"><a name=\"ef65a20ee05551cc411c8acd0c5af4796dc1a39e\"></a><i>Ahmed Hussain Khan and Intensive Care. <a href=\"http://rexa.info/paper/ef65a20ee05551cc411c8acd0c5af4796dc1a39e\">Multiplier-Free Feedforward Networks</a>. 174. </i><br><br>network configuration, and many hundreds for promising ones. Test data results reported here represent the best performance of the optimal configurations. A. Forecasting the Onset of Diabetes This data set 5 is related to a group of <b>adult</b> women belonging to the Pima Indian tribe and was collected by the US National Institute of Diabetes and Digestive and Kidney Diseases [1]. The learning task is to<br></p><hr><p class=\"normal\"><a name=\"e3cb1b3c129bc2be18036ad91073724543894185\"></a><i>Luc Hoegaerts and J. A. K Suykens and J. Vandewalle and Bart De Moor. <a href=\"http://rexa.info/paper/e3cb1b3c129bc2be18036ad91073724543894185\">Subset Based Least Squares Subspace Regression in RKHS</a>. Katholieke Universiteit Leuven Department of Electrical Engineering, ESAT-SCD-SISTA. </i><br><br>side our approach achieves overall a much smaller O(nm) memory cost, compared to the typical O(n 2 ) and a computational complexity of O(nm 3 ) compared to the typical O(n 2 ). The <b>ADULT</b> UCI data set [33] consists of 45222 cases having 14 input variables. The aim is to classify if the income of a person is greater than 50K based on several census parameters, such as age, education, marital<br></p><hr><p class=\"normal\"><a name=\"8e003bfae7c07cdeeb0ae5f251d545873364dd1e\"></a><i>David R. Musicant and Alexander Feinberg. <a href=\"http://rexa.info/paper/8e003bfae7c07cdeeb0ae5f251d545873364dd1e\">Active Set Support Vector Regression</a>. </i><br><br>Census 30k, is a version of the US Census Bureau  <b>Adult</b>  dataset, which is publicly available from Silicon Graphics' website [39]. This \"Adult\" dataset contains nearly 300,000 data points with 11 numeric attributes, and is used for predicting income levels based<br></p><hr><p class=\"normal\"><a name=\"c26b03be3bf94e423d30b545d09efd83310e97bd\"></a><i>Luc Hoegaerts and J. A. K Suykens and J. Vandewalle and Bart De Moor. <a href=\"http://rexa.info/paper/c26b03be3bf94e423d30b545d09efd83310e97bd\">Primal Space Sparse Kernel Partial Least Squares Regression for Large Scale Problems Special Session paper </a>. Katholieke Universiteit Leuven Department of Electrical Engineering, ESAT-SCD-SISTA. </i><br><br>sample with added noise (dots). The subset consists of 5 points, marked with a full dot on the figure. The <b>ADULT</b> UCI data set [24] consists of 45222 cases having 14 input variables. The aim is to classify if the income of a person is greater than 50K based on several census parameters, such as age, education, marital<br></p><hr><p class=\"normal\"><a name=\"ce160518d6a429585aeeb3f7a784c5dfb124b669\"></a><i>Kuan-ming Lin and Chih-Jen Lin. <a href=\"http://rexa.info/paper/ce160518d6a429585aeeb3f7a784c5dfb124b669\">A Study on Reduced Support Vector Machines</a>. Department of Computer Science and Information Engineering National Taiwan University. </i><br><br>for protein secondary structure prediction [26]. Finally, the problem <b>adult</b>  from the UCI \"adult\" data set [1] and compiled by Platt [20], is also included. For the adult dataset, there are several realizations. Here, we only consider the realization with the smallest training set; the full dataset with<br></p>\n\n\n\t</td></tr></table>\n\n\n\n<hr>\n\n<p class=\"normal\"><a href=\"/datasets/Adult\">Return to Adult data set page</a>.\n\n\n<table cellpadding=5 align=center><tr valign=center>\n\t\t<td><p class=\"normal\">Supported By:</p></td>\n        <td><img src=\"../assets/nsfe.gif\" height=60 /> </td>\n        <td><p class=\"normal\">&nbsp;In Collaboration With:</p></td>\n        <td><img src=\"../assets/rexaSmall.jpg\" /></td>\n</tr></table>\n\n<center>\n<span class=\"normal\">\n<a href=\"../about.html\">About</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../citation_policy.html\">Citation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../donation_policy.html\">Donation Policy</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"../contact.html\">Contact</a>&nbsp;&nbsp;||&nbsp;\n<a href=\"http://cml.ics.uci.edu\">CML</a>\n</span>\n</center>\n\n\n\n\n</body>\n</html>\n", "encoding": "ISO-8859-1"}