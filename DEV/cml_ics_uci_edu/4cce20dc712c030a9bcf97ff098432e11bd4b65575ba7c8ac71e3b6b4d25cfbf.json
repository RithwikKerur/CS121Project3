{"url": "https://cml.ics.uci.edu/2015/09/fall-2015/", "content": "<!DOCTYPE html>\n<html lang=\"en-US\">\n<head>\n<meta charset=\"UTF-8\" />\n<meta name=\"viewport\" content=\"width=device-width\" />\n<title>Fall 2015 | Center for Machine Learning and Intelligent Systems</title>\n<link rel=\"profile\" href=\"http://gmpg.org/xfn/11\" />\n<link rel=\"pingback\" href=\"https://cml.ics.uci.edu/xmlrpc.php\" />\n<!--[if lt IE 9]>\n<script src=\"https://cml.ics.uci.edu/wp-content/cml/themes/bonpress-wpcom/js/html5.js\" type=\"text/javascript\"></script>\n<![endif]-->\n\n<link rel='dns-prefetch' href='//s.w.org' />\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Center for Machine Learning and Intelligent Systems &raquo; Feed\" href=\"https://cml.ics.uci.edu/feed/\" />\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Center for Machine Learning and Intelligent Systems &raquo; Comments Feed\" href=\"https://cml.ics.uci.edu/comments/feed/\" />\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Center for Machine Learning and Intelligent Systems &raquo; Fall 2015 Comments Feed\" href=\"https://cml.ics.uci.edu/2015/09/fall-2015/feed/\" />\n\t\t<script type=\"text/javascript\">\n\t\t\twindow._wpemojiSettings = {\"baseUrl\":\"https:\\/\\/s.w.org\\/images\\/core\\/emoji\\/12.0.0-1\\/72x72\\/\",\"ext\":\".png\",\"svgUrl\":\"https:\\/\\/s.w.org\\/images\\/core\\/emoji\\/12.0.0-1\\/svg\\/\",\"svgExt\":\".svg\",\"source\":{\"concatemoji\":\"https:\\/\\/cml.ics.uci.edu\\/wp-includes\\/js\\/wp-emoji-release.min.js?ver=5.2.3\"}};\n\t\t\t!function(a,b,c){function d(a,b){var c=String.fromCharCode;l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,a),0,0);var d=k.toDataURL();l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,b),0,0);var e=k.toDataURL();return d===e}function e(a){var b;if(!l||!l.fillText)return!1;switch(l.textBaseline=\"top\",l.font=\"600 32px Arial\",a){case\"flag\":return!(b=d([55356,56826,55356,56819],[55356,56826,8203,55356,56819]))&&(b=d([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]),!b);case\"emoji\":return b=d([55357,56424,55356,57342,8205,55358,56605,8205,55357,56424,55356,57340],[55357,56424,55356,57342,8203,55358,56605,8203,55357,56424,55356,57340]),!b}return!1}function f(a){var c=b.createElement(\"script\");c.src=a,c.defer=c.type=\"text/javascript\",b.getElementsByTagName(\"head\")[0].appendChild(c)}var g,h,i,j,k=b.createElement(\"canvas\"),l=k.getContext&&k.getContext(\"2d\");for(j=Array(\"flag\",\"emoji\"),c.supports={everything:!0,everythingExceptFlag:!0},i=0;i<j.length;i++)c.supports[j[i]]=e(j[i]),c.supports.everything=c.supports.everything&&c.supports[j[i]],\"flag\"!==j[i]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[j[i]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(h=function(){c.readyCallback()},b.addEventListener?(b.addEventListener(\"DOMContentLoaded\",h,!1),a.addEventListener(\"load\",h,!1)):(a.attachEvent(\"onload\",h),b.attachEvent(\"onreadystatechange\",function(){\"complete\"===b.readyState&&c.readyCallback()})),g=c.source||{},g.concatemoji?f(g.concatemoji):g.wpemoji&&g.twemoji&&(f(g.twemoji),f(g.wpemoji)))}(window,document,window._wpemojiSettings);\n\t\t</script>\n\t\t<style type=\"text/css\">\nimg.wp-smiley,\nimg.emoji {\n\tdisplay: inline !important;\n\tborder: none !important;\n\tbox-shadow: none !important;\n\theight: 1em !important;\n\twidth: 1em !important;\n\tmargin: 0 .07em !important;\n\tvertical-align: -0.1em !important;\n\tbackground: none !important;\n\tpadding: 0 !important;\n}\n</style>\n\t<link rel='stylesheet' id='wp-block-library-css'  href='https://cml.ics.uci.edu/wp-includes/css/dist/block-library/style.min.css?ver=5.2.3' type='text/css' media='all' />\n<link rel='stylesheet' id='bonpress-style-css'  href='https://cml.ics.uci.edu/wp-content/cml/themes/bonpress-cml/style.css?ver=5.2.3' type='text/css' media='all' />\n<link rel='stylesheet' id='tipsy-css'  href='https://cml.ics.uci.edu/wp-content/cml/plugins/wp-shortcode/css/tipsy.css?ver=5.2.3' type='text/css' media='all' />\n<link rel='stylesheet' id='mts_wpshortcodes-css'  href='https://cml.ics.uci.edu/wp-content/cml/plugins/wp-shortcode/css/wp-shortcode.css?ver=5.2.3' type='text/css' media='all' />\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-includes/js/jquery/jquery.js?ver=1.12.4-wp'></script>\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.4.1'></script>\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-content/cml/plugins/wp-shortcode/js/jquery.tipsy.js?ver=5.2.3'></script>\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-content/cml/plugins/wp-shortcode/js/wp-shortcode.js?ver=5.2.3'></script>\n<link rel='https://api.w.org/' href='https://cml.ics.uci.edu/wp-json/' />\n<link rel=\"EditURI\" type=\"application/rsd+xml\" title=\"RSD\" href=\"https://cml.ics.uci.edu/xmlrpc.php?rsd\" />\n<link rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\" href=\"https://cml.ics.uci.edu/wp-includes/wlwmanifest.xml\" /> \n<link rel='prev' title='Stern to help lead national effort to improve criminal evidence analysis, cut wrongful convictions' href='https://cml.ics.uci.edu/2015/05/center-member-and-ics-dean-hal-stern-to-help-lead-national-effort-to-improve-criminal-evidence-analysis-cut-wrongful-convictions/' />\n<link rel='next' title='Winter 2016' href='https://cml.ics.uci.edu/2016/01/winter-2016/' />\n<meta name=\"generator\" content=\"WordPress 5.2.3\" />\n<link rel=\"canonical\" href=\"https://cml.ics.uci.edu/2015/09/fall-2015/\" />\n<link rel='shortlink' href='https://cml.ics.uci.edu/?p=542' />\n<link rel=\"alternate\" type=\"application/json+oembed\" href=\"https://cml.ics.uci.edu/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fcml.ics.uci.edu%2F2015%2F09%2Ffall-2015%2F\" />\n<link rel=\"alternate\" type=\"text/xml+oembed\" href=\"https://cml.ics.uci.edu/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fcml.ics.uci.edu%2F2015%2F09%2Ffall-2015%2F&#038;format=xml\" />\n</head>\n\n<body class=\"post-template-default single single-post postid-542 single-format-standard group-blog\">\n<div id=\"page\" class=\"hfeed site\">\n\t\t<header id=\"masthead\" class=\"all-header\" role=\"banner\">\n\t\t<hgroup class=\"hgroup-wide\">\n                        <a href=\"https://cml.ics.uci.edu/\" title=\"Center for Machine Learning and Intelligent Systems\" rel=\"home\"><img src='/wp-content/cml/uploads/cml-curve.jpg'></a>\n<!--\t\t\t<h1 class=\"site-title\"><a href=\"https://cml.ics.uci.edu/\" title=\"Center for Machine Learning and Intelligent Systems\" rel=\"home\">Center for Machine Learning and Intelligent Systems</a></h1>\n\t\t\t<h2 class=\"site-description\">University of California, Irvine</h2> -->\n\t\t\t<h1 class=\"site-title\"><a href=\"https://cml.ics.uci.edu/\" title=\"Center for Machine Learning and Intelligent Systems\" rel=\"home\">Center for Machine Learning and Intelligent Systems</a></h1>\n\t\t\t<h2 class=\"site-description\">Bren School of Information and Computer Science</h2>\t\t\t\n\t\t\t<h2 class=\"site-description\">University of California, Irvine</h2>\n\t\t\t<div style=\"clear:both\"></div>\n\t\t</hgroup>\n\t</header>\n\t<header id=\"masthead\" class=\"site-header\" role=\"banner\">\n\t\t<hgroup class=\"hgroup-img\">\n                        <a href=\"https://cml.ics.uci.edu/\" title=\"Center for Machine Learning and Intelligent Systems\" rel=\"home\"><img src='/wp-content/cml/uploads/cml-curve.jpg'></a>\n\t\t\t<h1 class=\"site-title\"><a href=\"https://cml.ics.uci.edu/\" title=\"Center for Machine Learning and Intelligent Systems\" rel=\"home\">Center for Machine Learning and Intelligent Systems</a></h1>\n\t\t\t<h2 class=\"site-description\">University of California, Irvine</h2>\n\t\t</hgroup>\n\n\t\t<nav id=\"site-navigation\" class=\"navigation-main\" role=\"navigation\">\n\t\t\t<h1 class=\"menu-toggle\">Menu</h1>\n\t\t\t<div class=\"screen-reader-text skip-link\"><a href=\"#content\" title=\"Skip to content\">Skip to content</a></div>\n\n\t\t\t<div class=\"menu-navigation-container\"><ul id=\"menu-navigation\" class=\"menu\"><li id=\"menu-item-234\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-234\"><a href=\"https://cml.ics.uci.edu/\">Home</a></li>\n<li id=\"menu-item-79\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-79\"><a href=\"https://cml.ics.uci.edu/home/about-us/\">About CML</a>\n<ul class=\"sub-menu\">\n\t<li id=\"menu-item-78\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-78\"><a href=\"https://cml.ics.uci.edu/home/about-us/\">About us</a></li>\n\t<li id=\"menu-item-429\" class=\"menu-item menu-item-type-taxonomy menu-item-object-category menu-item-429\"><a href=\"https://cml.ics.uci.edu/category/news/\">News</a></li>\n\t<li id=\"menu-item-76\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-76\"><a href=\"https://cml.ics.uci.edu/home/contact-us/\">Contact Us</a></li>\n</ul>\n</li>\n<li id=\"menu-item-539\" class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children menu-item-539\"><a>People</a>\n<ul class=\"sub-menu\">\n\t<li id=\"menu-item-55\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-55\"><a href=\"https://cml.ics.uci.edu/faculty/\">Faculty</a></li>\n\t<li id=\"menu-item-220\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-220\"><a href=\"https://cml.ics.uci.edu/alumni/\">Alumni</a></li>\n</ul>\n</li>\n<li id=\"menu-item-75\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-75\"><a href=\"https://cml.ics.uci.edu/aiml/\">Events &#038; Seminars</a>\n<ul class=\"sub-menu\">\n\t<li id=\"menu-item-74\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-74\"><a href=\"https://cml.ics.uci.edu/aiml/\">AI/ML Seminar Series</a></li>\n\t<li id=\"menu-item-914\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-914\"><a href=\"https://cml.ics.uci.edu/aiml/ml-distinguished-speakers/\">ML Distinguished Speakers</a></li>\n\t<li id=\"menu-item-73\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-73\"><a href=\"https://cml.ics.uci.edu/aiml/ml-reading-group/\">ML Reading Group</a></li>\n</ul>\n</li>\n<li id=\"menu-item-222\" class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children menu-item-222\"><a>Education &#038; Resources</a>\n<ul class=\"sub-menu\">\n\t<li id=\"menu-item-227\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-227\"><a href=\"https://cml.ics.uci.edu/courses/\">Courses</a></li>\n\t<li id=\"menu-item-221\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-221\"><a href=\"https://cml.ics.uci.edu/books/\">Books</a></li>\n</ul>\n</li>\n<li id=\"menu-item-81\" class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-81\"><a href=\"http://www.ics.uci.edu/~mlearn/MLRepository.html\">UCI Machine Learning Archive</a></li>\n<li id=\"menu-item-87\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-87\"><a href=\"https://cml.ics.uci.edu/sponsors-funding/\">Sponsors &#038; Funding</a></li>\n<li id=\"menu-item-86\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-86\"><a href=\"https://cml.ics.uci.edu/subscribe/\">Subscribe to CML List</a></li>\n</ul></div>\t\t</nav><!-- #site-navigation -->\n\t</header><!-- #masthead -->\n\n\r\n\t<div id=\"primary\" class=\"content-area\">\r\n\t\t<div id=\"content\" class=\"site-content\" role=\"main\">\r\n\r\n\t\t\r\n\t\t\t\r\n<article id=\"post-542\" class=\"post-542 post type-post status-publish format-standard hentry category-aiml\">\r\n\t<header class=\"entry-header\">\r\n\t\t<h1 class=\"entry-title\">Fall 2015</h1>\t\t<span class=\"entry-format genericon\">Standard</span>\r\n\t\t<div class=\"entry-meta\">\r\n\t\t\t<a href=\"https://cml.ics.uci.edu/2015/09/fall-2015/\" title=\"1:14 pm\" rel=\"bookmark\"><time class=\"entry-date genericon\" datetime=\"2015-09-15T13:14:09-07:00\">September 15, 2015</time></a>\r\n\t\t\t\r\n\t\t\t<span class=\"cat-links genericon\"><a href=\"https://cml.ics.uci.edu/category/aiml/\" rel=\"category tag\">AIML</a></span>\r\n\t\t\t\t\t</div>\r\n\t</header><!-- .entry-header -->\r\n\r\n\t<div class=\"entry-content\">\r\n\t\t<br />\n<table cellpadding=5 border=1>\n<col width=\"100\">\n<col>\n<p>  <!-- ==== Sep 16 =================================== --></p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Sep 16</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www-scf.usc.edu/~hsedghi/\"><b>Hanie Sedghi</b></a><br />Graduate Student<br />Department of Electrical Engineering<br />University of Southern California</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Taming the Wild: Optimization Approaches to Big Data</b></a></span></div><div class=\"togglec clearfix\">Learning with big data is a challenging task that requires smart and efficient methods to extract useful information from data. Optimization methods, both convex and nonconvex are promising approaches to do this. In this talk I will review two classes of my work on prominent problems in convex and nonconvex optimization.  </p>\n<p>Beating the Perils of Non-Convexity: Guaranteed Training of Neural Networks using Tensor Method: Neural networks provide a versatile tool for approximating functions of various inputs. Despite exciting achievements in application, a theoretical understanding of them is mostly lacking. Training a neural network is a highly nonconvex problem and backpropagation can get stuck in local optima. For the first time, we have a computationally efficient method for training neural networks that also has guaranteed generalization. This is part of our recently proposed general framework based on method-of-moments and tensor decomposition to efficiently learn different models such as neural networks and mixture of classifiers.  </p>\n<p>Breaking Curse of Dimensionality: Stochastic Optimization in high dimensions:  We have designed an efficient stochastic optimization method based on ADMM that is fast and cheap to implement, can be performed in parallel and can be used for any regularized optimization framework with some mild assumptions. We have proved that our algorithm obtains minimax optimal convergence rates for sparse optimization and robust PCA framework. Experiment results show that in the aforementioned scenarios, our method outperforms state-of-the-art, i.e., yields smaller error with equal time.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== Oct  5 =================================== --></p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Oct  5</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.eew.caltech.edu/people/\"><b>Gokcan Karakus</b></a><br />Graduate Student<br />Department of Civil Engineering<br />Caltech</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Using Waveform Envelopes in a Bayesian Framework for Earthquake Early Warning</b></a></span></div><div class=\"togglec clearfix\">We are proposing an algorithm to test the accuracy of the predictions by earthquake early warning systems. Most warning systems predict the location and the magnitude of an ongoing earthquake via the early-arriving seismic wave data. Our algorithm uses logarithm of ratios between observed ground motion envelopes and Virtual Seismologist\u2019s (Cua G. and Heaton T.) predicted envelopes to assess the validity of system predictions. We quantify the uncertainty attached to our parameters using Bayesian probability approach.<br /></div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== Oct 12 =================================== --></p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Oct 12</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.ics.uci.edu/~ihler/\"><b>Alexander Ihler</b></a><br />Associate Professor<br />Department of Computer Science<br />University of California, Irvine</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Discriminance Sampling</b></a></span></div><div class=\"togglec clearfix\">Importance sampling (IS) and its variant, annealed IS (AIS) have been widely used for estimating the partition function in graphical models, such as Markov random fields and deep generative models. However, IS tends to underestimate the partition function and is subject to high variance when the proposal distribution is more peaked than the target distribution. On the other hand, &#8220;reverse&#8221; versions of IS and AIS tend to overestimate the partition function, and degenerate when the target distribution is more peaked than the proposal distribution. We present a simple, general method that gives much more reliable and robust estimates than either IS (AIS) or reverse IS (AIS). Our method works by converting the estimation problem into a simple classification problem that discriminates between the samples drawn from the target and the proposal. We give both theoretical and empirical justification, and show that an annealed version of our method significantly outperforms both AIS and reverse AIS (Burda et al., 2015), which has been the state-of-the-art for likelihood evaluation in deep generative models.  Joint work with Qiang Liu, Jian Peng, and John Fisher.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== Oct 19 =================================== --></p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Oct 19</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://stanford.edu/~zhiyingw/\"><b>Zhiying Wang</b></a><br />Assistant Professor<br />Department of Electrical Engineering<br />University of California, Irvine</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Multi-version Coding for Consistent Distributed Storage</b></a></span></div><div class=\"togglec clearfix\">In this talk, we propose the multi-version coding problem for distributed storage. We consider a setting where there are n servers that aim to store v versions of a message, and there is a total ordering on the versions from the earliest to the latest. We assume that each message version has a given number of bits. Each server can receive any subset of the v versions and stores a function of the message versions it receives. The multi-version code we consider ensures that, a decoder that connects to any c out of the n servers can recover the message corresponding to the latest common version stored among those servers, or a message corresponding to a version that is later than the latest common version. We describe a simple and explicit achievable scheme, as well as an information-theoretic converse. Moreover, we apply the multi-version code to one of the problems in distributed algorithms &#8211; the emulation of atomic shared memory in a message-passing network &#8211; and improve upon previous algorithms up to a half in terms of storage cost.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== Oct 26 =================================== --></p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Oct 26</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.mit.edu/~sfeizi/\"><b>Soheil Feizi</b></a><br />Graduate Student<br />CSAIL<br />MIT</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Learning (from) networks: fundamental limits, algorithms, and applications</b></a></span></div><div class=\"togglec clearfix\">Network models provide a unifying framework for understanding dependencies among variables in medical, biological, and other sciences. Networks can be used to reveal underlying data structures, infer functional modules, and facilitate experiment design. In practice, however, size, uncertainty and complexity of the underlying associations render these applications challenging.  </p>\n<p> In this talk, we illustrate the use of spectral, combinatorial, and statistical inference techniques in several significant network science problems. First, we consider the problem of network alignment where the goal is to find a bijective mapping between nodes of two networks to maximize their overlapping edges while minimizing mismatches. To solve this combinatorial problem, we present a new scalable spectral algorithm, and establish its efficiency theoretically and experimentally over several synthetic and real networks. Next, we introduce network maximal correlation (NMC) as an essential measure to capture nonlinear associations in networks. We characterize NMC using geometric properties of Hilbert spaces and illustrate its application in learning network topology when variables have unknown nonlinear dependencies. Finally, we discuss the problem of learning low dimensional structures (such as clusters) in large networks, where we introduce logistic Random Dot Product Graphs, a new class of networks which includes most stochastic block models as well as other low dimensional structures. Using this model, we propose a spectral network clustering algorithm that possesses robust performance under different clustering setups. In all of these problems, we examine underlying fundamental limits and present efficient algorithms for solving them. We also highlight applications of the proposed algorithms to data-driven problems such as functional and regulatory genomics of human diseases, and cancer.  </p>\n<p> <b>Bio:</b> Soheil Feizi is a PhD candidate at Massachusetts Institute of Technology (MIT), co-supervised by Prof. Muriel M\u00e9dard and Prof. Manolis Kellis. His research interests include analysis of complex networks and the development of inference and learning methods based on Optimization, Information Theory, Machine Learning, Statistics, and Probability, with applications in Computational Biology, and beyond. He completed his B.Sc. at Sharif University of Technology, awarded as the best student of his class. He received the Jacobs Presidential Fellowship and EECS Great Educators Fellowship, both from MIT. He has been a finalist in the Qualcomm Innovation contest. He received an Ernst Guillemin Award for his Master of Science Thesis in the department of Electrical Engineering and Computer Science at MIT.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== Nov  2 =================================== --></p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Nov  2</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://web.stanford.edu/dept/app-physics/cgi-bin/person/surya-gangulijanuary-2012/\"><b>Surya Ganguli</b></a><br />Assistant Professor<br />Department of Applied Physics<br />Stanford University</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>The Statistical Physics of Deep Learning: on the Beneficial Roles of Dynamic Criticality, Random Landscapes, and the Reversal of Time</b></a></span></div><div class=\"togglec clearfix\">Neuronal networks have enjoyed a resurgence both in the worlds of neuroscience, where they yield mathematical frameworks for thinking about complex neural datasets, and in machine learning, where they achieve state of the art results on a variety of tasks, including machine vision, speech recognition, and language translation.   Despite their empirical success, a mathematical theory of how deep neural circuits, with many layers of cascaded nonlinearities, learn and compute remains elusive.  We will discuss three recent vignettes in which ideas from statistical physics can shed light on this issue.  In particular, we show how dynamical criticality can help in neural learning, how the non-intuitive geometry of high dimensional error landscapes can be exploited to speed up learning, and how modern ideas from non-equilibrium statistical physics, like the Jarzynski equality, can be extended to yield powerful algorithms for modeling complex probability distributions.  Time permitting, we will also discuss the relationship between neural network learning dynamics and the developmental time course of semantic concepts in infants.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== Nov  9 =================================== --></p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Nov  9</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.cs.upc.edu/~larrosa/\"><b>Javier Larrosa</b></a><br />Professor<br />Llenguatges i Sistemes Inform\u00e0tics<br />Universitat Polit\u00e8cnica de Catalunya</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>On Max-SAT solving</b></a></span></div><div class=\"togglec clearfix\">Weighted Max-SAT is an extension of SAT in which each clause has an associated cost. The goal is to minimize the cost of falsified clauses. Max-SAT has been successfully applied to a number of domains including Bioinformatics, Telecommunications and Scheduling.</p>\n<p>In this talk I will introduce the Max-SAT framework and discuss the main solving approaches. In particular, I will present Max-resolution and will show how it can be effectively used in the context of Depth-first Branch-and-Bound.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== Nov 16 =================================== --></p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Nov 16</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.ics.uci.edu/~gghiasi/\"><b>Golnaz Ghiasi</b></a><br />Graduate Student<br />Department of Computer Science<br />University of California, Irvine</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Detecting and Localizing Occluded Faces</b></a></span></div><div class=\"togglec clearfix\">Occlusion poses a significant difficulty for detecting and localizing object keypoints and subsequent fine-grained identification. In this talk, I will describe a hierarchical deformable part model for face detection and keypoint localization that explicitly models part occlusion. The proposed model structure makes it possible to augment positive training data with large numbers of synthetically occluded instances. This allows us to easily incorporate the statistics of occlusion patterns in a discriminatively trained model. However, this model does not exploit bottom-up cues such as detection of occluding contours and image segments. I will talk about how to modify the proposed model to utilize bottom-up class-specific segmentation in order to jointly detect and segment out the foreground pixels belonging to the face.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== Nov 23 =================================== --></p>\n<tr>\n<td valign=top class='aiml-none'>\n<div class=\"aiml-date\"><b>Nov 23</b></div>\n</td>\n<td valign=top class='aiml-none'>\n<div class=\"aiml-name\"><b>Thankgiving week</b><br />(no seminar)</div>\n<p>\n  </td>\n</tr>\n<p>  <!-- ==== Nov 30 =================================== --></p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Nov 30</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://dkotzias.com/\"><b>Dimitrios Kotzias</b></a><br />Graduate Student<br />Department of Computer Science<br />University of California, Irvine</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>From Group to Individual Labels using Deep Features</b></a></span></div><div class=\"togglec clearfix\">In many classification problems labels are relatively scarce. One context in which this occurs is where we have labels for groups of instances but not for the instances themselves, as in multi-instance learning. Past work on this problem has typically focused on learning classifiers to make predictions at the group level. In this paper we focus on the problem of learning classifiers to make predictions at the instance level. To achieve this we propose a new objective function that encourages smoothness of inferred instance-level labels based on instance-level similarity, while at the same time respecting group-level label constraints. We apply this approach to the problem of predicting labels for sentences given labels for reviews, using a convolutional neural network to infer sentence similarity. The approach is evaluated using three large review data sets from IMDB, Yelp, and Amazon, and we demonstrate the proposed approach is both accurate and scalable compared to various alternatives.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== Dec  7 =================================== --></p>\n<tr>\n<td valign=top class='aiml-none'>\n<div class=\"aiml-date\"><b>Dec  7</b></div>\n</td>\n<td valign=top class='aiml-none'>\n<div class=\"aiml-name\"><b>Finals week</b><br />(no seminar)</div>\n<p>\n  </td>\n</tr>\n</table>\n\t\t\t</div><!-- .entry-content -->\r\n\r\n\t</article><!-- #post-## -->\r\n\r\n\r\n\t\t\t\t<nav role=\"navigation\" id=\"nav-below\" class=\"navigation-post\">\n\t\t<h1 class=\"screen-reader-text\">Post navigation</h1>\n\n\t\n\t\t<div class=\"nav-previous\"><a href=\"https://cml.ics.uci.edu/2015/05/center-member-and-ics-dean-hal-stern-to-help-lead-national-effort-to-improve-criminal-evidence-analysis-cut-wrongful-convictions/\" rel=\"prev\"><span class=\"meta-nav\">&larr;</span> Stern to help lead national effort to improve criminal evidence analysis, cut wrongful convictions</a></div>\t\t<div class=\"nav-next\"><a href=\"https://cml.ics.uci.edu/2016/01/winter-2016/\" rel=\"next\">Winter 2016 <span class=\"meta-nav\">&rarr;</span></a></div>\n\t\n\t</nav><!-- #nav-below -->\n\t\r\n\t\t\t\r\n\t\t\r\n\t\t</div><!-- #content -->\r\n\t</div><!-- #primary -->\r\n\r\n\t<div id=\"secondary\" class=\"widget-area\" role=\"complementary\">\n\t\t\t\t<aside id=\"search-2\" class=\"widget widget_search\">\t<form method=\"get\" id=\"searchform\" class=\"searchform\" action=\"https://cml.ics.uci.edu/\" role=\"search\">\n\t\t<label for=\"s\" class=\"screen-reader-text\">Search</label>\n\t\t<input type=\"search\" class=\"field\" name=\"s\" value=\"\" id=\"s\" placeholder=\"Search &hellip;\" />\n\t\t<input type=\"submit\" class=\"submit\" id=\"searchsubmit\" value=\"Search\" />\n\t</form>\n</aside>\t</div><!-- #secondary -->\n\r\n</div><!-- #page -->\r\n\r\n<footer id=\"colophon\" class=\"site-footer\" role=\"contentinfo\">\r\n<p style=\"text-align:center;margin:0;\">(c) 2015 <a href=\"http://cml.ics.uci.edu\">Center for Machine Learning and Intelligent Systems</a>\r\n\t<div class=\"site-info\">\r\n\t\t\t\t<a href=\"http://wordpress.org/\" rel=\"generator\">WordPress</a>/<a href=\"http://www.wpzoom.com/\">BonPress</a>\r\n\t</div><!-- .site-info -->\r\n</footer><!-- #colophon -->\r\n\r\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-content/cml/themes/bonpress-wpcom/js/navigation.js?ver=20120206'></script>\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-content/cml/themes/bonpress-wpcom/js/skip-link-focus-fix.js?ver=20130115'></script>\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-includes/js/wp-embed.min.js?ver=5.2.3'></script>\n\r\n</body>\r\n</html>\r\n", "encoding": "utf-8"}