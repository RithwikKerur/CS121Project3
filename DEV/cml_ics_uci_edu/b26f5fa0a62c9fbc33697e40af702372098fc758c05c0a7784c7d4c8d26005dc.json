{"url": "https://cml.ics.uci.edu/aiml/page/8/", "content": "<!DOCTYPE html>\n<html lang=\"en-US\">\n<head>\n<meta charset=\"UTF-8\" />\n<meta name=\"viewport\" content=\"width=device-width\" />\n<title>AI/ML Seminar Series | Center for Machine Learning and Intelligent Systems | Page 8</title>\n<link rel=\"profile\" href=\"http://gmpg.org/xfn/11\" />\n<link rel=\"pingback\" href=\"https://cml.ics.uci.edu/xmlrpc.php\" />\n<!--[if lt IE 9]>\n<script src=\"https://cml.ics.uci.edu/wp-content/cml/themes/bonpress-wpcom/js/html5.js\" type=\"text/javascript\"></script>\n<![endif]-->\n\n<link rel='dns-prefetch' href='//s.w.org' />\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Center for Machine Learning and Intelligent Systems &raquo; Feed\" href=\"https://cml.ics.uci.edu/feed/\" />\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Center for Machine Learning and Intelligent Systems &raquo; Comments Feed\" href=\"https://cml.ics.uci.edu/comments/feed/\" />\n\t\t<script type=\"text/javascript\">\n\t\t\twindow._wpemojiSettings = {\"baseUrl\":\"https:\\/\\/s.w.org\\/images\\/core\\/emoji\\/12.0.0-1\\/72x72\\/\",\"ext\":\".png\",\"svgUrl\":\"https:\\/\\/s.w.org\\/images\\/core\\/emoji\\/12.0.0-1\\/svg\\/\",\"svgExt\":\".svg\",\"source\":{\"concatemoji\":\"https:\\/\\/cml.ics.uci.edu\\/wp-includes\\/js\\/wp-emoji-release.min.js?ver=5.2.3\"}};\n\t\t\t!function(a,b,c){function d(a,b){var c=String.fromCharCode;l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,a),0,0);var d=k.toDataURL();l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,b),0,0);var e=k.toDataURL();return d===e}function e(a){var b;if(!l||!l.fillText)return!1;switch(l.textBaseline=\"top\",l.font=\"600 32px Arial\",a){case\"flag\":return!(b=d([55356,56826,55356,56819],[55356,56826,8203,55356,56819]))&&(b=d([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]),!b);case\"emoji\":return b=d([55357,56424,55356,57342,8205,55358,56605,8205,55357,56424,55356,57340],[55357,56424,55356,57342,8203,55358,56605,8203,55357,56424,55356,57340]),!b}return!1}function f(a){var c=b.createElement(\"script\");c.src=a,c.defer=c.type=\"text/javascript\",b.getElementsByTagName(\"head\")[0].appendChild(c)}var g,h,i,j,k=b.createElement(\"canvas\"),l=k.getContext&&k.getContext(\"2d\");for(j=Array(\"flag\",\"emoji\"),c.supports={everything:!0,everythingExceptFlag:!0},i=0;i<j.length;i++)c.supports[j[i]]=e(j[i]),c.supports.everything=c.supports.everything&&c.supports[j[i]],\"flag\"!==j[i]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[j[i]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(h=function(){c.readyCallback()},b.addEventListener?(b.addEventListener(\"DOMContentLoaded\",h,!1),a.addEventListener(\"load\",h,!1)):(a.attachEvent(\"onload\",h),b.attachEvent(\"onreadystatechange\",function(){\"complete\"===b.readyState&&c.readyCallback()})),g=c.source||{},g.concatemoji?f(g.concatemoji):g.wpemoji&&g.twemoji&&(f(g.twemoji),f(g.wpemoji)))}(window,document,window._wpemojiSettings);\n\t\t</script>\n\t\t<style type=\"text/css\">\nimg.wp-smiley,\nimg.emoji {\n\tdisplay: inline !important;\n\tborder: none !important;\n\tbox-shadow: none !important;\n\theight: 1em !important;\n\twidth: 1em !important;\n\tmargin: 0 .07em !important;\n\tvertical-align: -0.1em !important;\n\tbackground: none !important;\n\tpadding: 0 !important;\n}\n</style>\n\t<link rel='stylesheet' id='wp-block-library-css'  href='https://cml.ics.uci.edu/wp-includes/css/dist/block-library/style.min.css?ver=5.2.3' type='text/css' media='all' />\n<link rel='stylesheet' id='bonpress-style-css'  href='https://cml.ics.uci.edu/wp-content/cml/themes/bonpress-cml/style.css?ver=5.2.3' type='text/css' media='all' />\n<link rel='stylesheet' id='tipsy-css'  href='https://cml.ics.uci.edu/wp-content/cml/plugins/wp-shortcode/css/tipsy.css?ver=5.2.3' type='text/css' media='all' />\n<link rel='stylesheet' id='mts_wpshortcodes-css'  href='https://cml.ics.uci.edu/wp-content/cml/plugins/wp-shortcode/css/wp-shortcode.css?ver=5.2.3' type='text/css' media='all' />\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-includes/js/jquery/jquery.js?ver=1.12.4-wp'></script>\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.4.1'></script>\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-content/cml/plugins/wp-shortcode/js/jquery.tipsy.js?ver=5.2.3'></script>\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-content/cml/plugins/wp-shortcode/js/wp-shortcode.js?ver=5.2.3'></script>\n<link rel='https://api.w.org/' href='https://cml.ics.uci.edu/wp-json/' />\n<link rel=\"EditURI\" type=\"application/rsd+xml\" title=\"RSD\" href=\"https://cml.ics.uci.edu/xmlrpc.php?rsd\" />\n<link rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\" href=\"https://cml.ics.uci.edu/wp-includes/wlwmanifest.xml\" /> \n<meta name=\"generator\" content=\"WordPress 5.2.3\" />\n<link rel=\"canonical\" href=\"https://cml.ics.uci.edu/aiml/\" />\n<link rel='shortlink' href='https://cml.ics.uci.edu/?p=60' />\n<link rel=\"alternate\" type=\"application/json+oembed\" href=\"https://cml.ics.uci.edu/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fcml.ics.uci.edu%2Faiml%2F\" />\n<link rel=\"alternate\" type=\"text/xml+oembed\" href=\"https://cml.ics.uci.edu/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fcml.ics.uci.edu%2Faiml%2F&#038;format=xml\" />\n</head>\n\n<body class=\"paged page-template-default page page-id-60 page-parent paged-8 page-paged-8 group-blog\">\n<div id=\"page\" class=\"hfeed site\">\n\t\t<header id=\"masthead\" class=\"all-header\" role=\"banner\">\n\t\t<hgroup class=\"hgroup-wide\">\n                        <a href=\"https://cml.ics.uci.edu/\" title=\"Center for Machine Learning and Intelligent Systems\" rel=\"home\"><img src='/wp-content/cml/uploads/cml-curve.jpg'></a>\n<!--\t\t\t<h1 class=\"site-title\"><a href=\"https://cml.ics.uci.edu/\" title=\"Center for Machine Learning and Intelligent Systems\" rel=\"home\">Center for Machine Learning and Intelligent Systems</a></h1>\n\t\t\t<h2 class=\"site-description\">University of California, Irvine</h2> -->\n\t\t\t<h1 class=\"site-title\"><a href=\"https://cml.ics.uci.edu/\" title=\"Center for Machine Learning and Intelligent Systems\" rel=\"home\">Center for Machine Learning and Intelligent Systems</a></h1>\n\t\t\t<h2 class=\"site-description\">Bren School of Information and Computer Science</h2>\t\t\t\n\t\t\t<h2 class=\"site-description\">University of California, Irvine</h2>\n\t\t\t<div style=\"clear:both\"></div>\n\t\t</hgroup>\n\t</header>\n\t<header id=\"masthead\" class=\"site-header\" role=\"banner\">\n\t\t<hgroup class=\"hgroup-img\">\n                        <a href=\"https://cml.ics.uci.edu/\" title=\"Center for Machine Learning and Intelligent Systems\" rel=\"home\"><img src='/wp-content/cml/uploads/cml-curve.jpg'></a>\n\t\t\t<h1 class=\"site-title\"><a href=\"https://cml.ics.uci.edu/\" title=\"Center for Machine Learning and Intelligent Systems\" rel=\"home\">Center for Machine Learning and Intelligent Systems</a></h1>\n\t\t\t<h2 class=\"site-description\">University of California, Irvine</h2>\n\t\t</hgroup>\n\n\t\t<nav id=\"site-navigation\" class=\"navigation-main\" role=\"navigation\">\n\t\t\t<h1 class=\"menu-toggle\">Menu</h1>\n\t\t\t<div class=\"screen-reader-text skip-link\"><a href=\"#content\" title=\"Skip to content\">Skip to content</a></div>\n\n\t\t\t<div class=\"menu-navigation-container\"><ul id=\"menu-navigation\" class=\"menu\"><li id=\"menu-item-234\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-234\"><a href=\"https://cml.ics.uci.edu/\">Home</a></li>\n<li id=\"menu-item-79\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-79\"><a href=\"https://cml.ics.uci.edu/home/about-us/\">About CML</a>\n<ul class=\"sub-menu\">\n\t<li id=\"menu-item-78\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-78\"><a href=\"https://cml.ics.uci.edu/home/about-us/\">About us</a></li>\n\t<li id=\"menu-item-429\" class=\"menu-item menu-item-type-taxonomy menu-item-object-category menu-item-429\"><a href=\"https://cml.ics.uci.edu/category/news/\">News</a></li>\n\t<li id=\"menu-item-76\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-76\"><a href=\"https://cml.ics.uci.edu/home/contact-us/\">Contact Us</a></li>\n</ul>\n</li>\n<li id=\"menu-item-539\" class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children menu-item-539\"><a>People</a>\n<ul class=\"sub-menu\">\n\t<li id=\"menu-item-55\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-55\"><a href=\"https://cml.ics.uci.edu/faculty/\">Faculty</a></li>\n\t<li id=\"menu-item-220\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-220\"><a href=\"https://cml.ics.uci.edu/alumni/\">Alumni</a></li>\n</ul>\n</li>\n<li id=\"menu-item-75\" class=\"menu-item menu-item-type-post_type menu-item-object-page current-menu-item page_item page-item-60 current_page_item current-menu-ancestor current-menu-parent current_page_parent current_page_ancestor menu-item-has-children menu-item-75\"><a href=\"https://cml.ics.uci.edu/aiml/\" aria-current=\"page\">Events &#038; Seminars</a>\n<ul class=\"sub-menu\">\n\t<li id=\"menu-item-74\" class=\"menu-item menu-item-type-post_type menu-item-object-page current-menu-item page_item page-item-60 current_page_item menu-item-74\"><a href=\"https://cml.ics.uci.edu/aiml/\" aria-current=\"page\">AI/ML Seminar Series</a></li>\n\t<li id=\"menu-item-914\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-914\"><a href=\"https://cml.ics.uci.edu/aiml/ml-distinguished-speakers/\">ML Distinguished Speakers</a></li>\n\t<li id=\"menu-item-73\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-73\"><a href=\"https://cml.ics.uci.edu/aiml/ml-reading-group/\">ML Reading Group</a></li>\n</ul>\n</li>\n<li id=\"menu-item-222\" class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children menu-item-222\"><a>Education &#038; Resources</a>\n<ul class=\"sub-menu\">\n\t<li id=\"menu-item-227\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-227\"><a href=\"https://cml.ics.uci.edu/courses/\">Courses</a></li>\n\t<li id=\"menu-item-221\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-221\"><a href=\"https://cml.ics.uci.edu/books/\">Books</a></li>\n</ul>\n</li>\n<li id=\"menu-item-81\" class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-81\"><a href=\"http://www.ics.uci.edu/~mlearn/MLRepository.html\">UCI Machine Learning Archive</a></li>\n<li id=\"menu-item-87\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-87\"><a href=\"https://cml.ics.uci.edu/sponsors-funding/\">Sponsors &#038; Funding</a></li>\n<li id=\"menu-item-86\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-86\"><a href=\"https://cml.ics.uci.edu/subscribe/\">Subscribe to CML List</a></li>\n</ul></div>\t\t</nav><!-- #site-navigation -->\n\t</header><!-- #masthead -->\n\n\r\n\t<div id=\"primary\" class=\"content-area\">\r\n\t\t<div id=\"content\" class=\"site-content\" role=\"main\">\r\n\t\t\t<!-- <p style=\"text-align: center;\">\r\n\t\t\tAI/ML Weekly Seminar<br>Sponsored by Yahoo! Research\r\n\t\t\t</p> -->\r\n\t\t\t\t\t\t\t<article style=\"margin-bottom: 0;\" id=\"post-60\" class=\"post-60 page type-page status-publish hentry\">\r\n\t\t\t\t<header class=\"entry-header\">\r\n\t\t\t\t\t<h1 class=\"entry-title\">AI/ML Seminar Series</h1>\t\t\t\t\t<span class=\"entry-format genericon\">Standard</span>\t\t\t\t</header><!-- .entry-header -->\r\n\t\t\t\t<div class=\"entry-content\">\r\n\t\t\t\t\t<p style=\"text-align: center;\">Weekly Seminar in AI &#038; Machine Learning<br />Sponsored by Cylance</p>\n<p><!-- \n\n<p style=\"text-align: center;\">Weekly Seminar in AI & Machine Learning<br />Sponsored by Yahoo! Research</p>\n\n --></p>\n\t\t\t\t\t\t\t\t\t</div><!-- .entry-content -->\r\n\t\t\t\t<php get_template_part( 'content', 'aiml' ); >\r\n\t\t\t\t</article>\r\n\t\t\t\r\n\t\t\t<!-- Ditch old query and run new one getting schedule posts -->\r\n\t\t\t\r\n\t\t\t\t\t\t\t\r\n<article id=\"post-667\" class=\"post-667 post type-post status-publish format-standard hentry category-aiml\">\r\n\t<nav class=\"navigation-paging\" role=\"navigation\">\r\n\t\t<h1 class=\"screen-reader-text\">Navigation</h1>\r\n\t\t<div class=\"nav-links\">\r\n\t\t\t<div class=\"nav-previous\" class=\"inline\"><a href=\"https://cml.ics.uci.edu/aiml/page/9/\" ><span class=\"meta-nav\">&lsaquo;</span><span class=\"screen-reader-text\">Earlier</span></a></div>\r\n\t\t\t\t\t\t\t\t\t<h1 class=\"entry-title\">Winter 2017</h1>\t\t\t<div class=\"nav-next\" class=\"inline\"><a href=\"https://cml.ics.uci.edu/aiml/page/7/\" ><span class=\"screen-reader-text\">Later </span><span class=\"meta-nav\">&rsaquo;</span></a></div>\r\n\t\t\t\t\t\t\t\t</div><!-- .nav-links -->\r\n\t</nav><!-- .navigation -->\r\n\r\n\t<div class=\"entry-content\">\r\n\t\t<br />\n<table cellpadding=5 border=1>\n<col width=\"100\">\n<col>\n<p>  <!-- ==== Jan 16 =================================== --></p>\n<tr>\n<td valign=top class='aiml-none'>\n<div class=\"aiml-date\"><b>Jan 16</b></div>\n</td>\n<td valign=top class='aiml-none'>\n<div class=\"aiml-name\"><b>No Seminar (MLK Day)</b></div>\n<p>\n  </td>\n</tr>\n<p>  <!-- ==== Jan 23 =================================== --></p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Jan 23</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"\"><b>Mohammad Ghavamzadeh</b></a><br />Senior Analytics Researcher<br />Adobe Research</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Learning Safe Policies in Sequential Decision-Making Problems</b></a></span></div><div class=\"togglec clearfix\">In online advertisement as well as many other fields such as health informatics and computational finance, we often have to deal with the situation in which we are given a batch of data generated by the current strategy(ies) of the company (hospital, investor), and we are asked to generate a good or an optimal strategy. Although there are many techniques to find a good policy given a batch of data, there are not much results to guarantee that the obtained policy will perform well in the real system without deploying it. On the other hand, deploying a policy might be risky, and thus, requires convincing the product (hospital, investment) manager that it is not going to harm the business. This is why it is extremely important to devise algorithms that generate policies with performance guarantees. </p>\n<p> In this talk, we discuss four different approaches to this fundamental problem, we call them model-based, model-free, online, and risk-sensitive. In the model-based approach, we first use the batch of data and build a simulator that mimics the behavior of the dynamical system under studies (online advertisement, hospital\u2019s ER, financial market), and then use this simulator to generate data and learn a policy. The main challenge here is to have guarantees on the performance of the learned policy, given the error in the simulator. This line of research is closely related to the area of robust learning and control. In the model-free approach, we learn a policy directly from the batch of data (without building a simulator), and the main question is whether the learned policy is guaranteed to perform at least as well as a baseline strategy. This line of research is related to off-policy evaluation and control. In the online approach, the goal is to control the exploration of the algorithm in a way that never during its execution the loss of using it instead of the baseline strategy is more than a given margin. In the risk-sensitive approach, the goal is to learn a policy that manages risk by minimizing some measure of variability in the performance in addition to maximizing a standard criterion. We present algorithms based on these approaches and demonstrate their usefulness in real-world applications such as personalized ad recommendation, energy arbitrage, traffic signal control, and American option pricing.</p>\n<p><b>Bio:</b>Mohammad Ghavamzadeh received a Ph.D. degree in Computer Science from the University of Massachusetts Amherst in 2005. From 2005 to 2008, he was a postdoctoral fellow at the University of Alberta. He has been a permanent researcher at INRIA in France since November 2008. He was promoted to first-class researcher in 2010, was the recipient of the &#8220;INRIA award for scientific excellence&#8221; in 2011, and obtained his Habilitation in 2014. He is currently (from October 2013) on a leave of absence from INRIA working as a senior analytics researcher at Adobe Research in California, on projects related to digital marketing. He has been an area chair and a senior program committee member at NIPS, IJCAI, and AAAI. He has been on the editorial board of Machine Learning Journal (MLJ), has published over 50 refereed papers in major machine learning, AI, and control journals and conferences, and has organized several tutorials and workshops at NIPS, ICML, and AAAI. His research is mainly focused on sequential decision-making under uncertainty, reinforcement learning, and online learning.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== Jan 27 =================================== --></p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Jan 27</b><br />Bren Hall 6011<br />11:00am</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.cs.cmu.edu/~rsalakhu/\"><b>Ruslan Salakhutdinov</b></a><br />Associate Professor<br />Machine Learning Department<br />Carnegie Mellon University</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Learning Deep Unsupervised and Multimodal Models</b></a></span></div><div class=\"togglec clearfix\">In this talk, I will first introduce a broad class of unsupervised deep learning models and show that they can learn useful hierarchical representations from large volumes of high-dimensional data with applications in information retrieval, object recognition, and speech perception. I will next introduce deep models that are capable of extracting a unified representation that fuses together multiple data modalities and present the Reverse Annealed Importance Sampling Estimator (RAISE) for evaluating these deep generative models. Finally, I will discuss models that can generate natural language descriptions (captions) of images and generate images from captions using attention, as well as introduce multiplicative and fine-grained gating mechanisms with application to reading comprehension.</p>\n<p><p><b>Bio:</b> Ruslan Salakhutdinov received his PhD in computer science from the University of Toronto in 2009. After spending two post-doctoral years at the Massachusetts Institute of Technology Artificial Intelligence Lab, he joined the University of Toronto as an Assistant Professor in the Departments of Statistics and Computer Science. In 2016 he joined the Machine Learning Department at Carnegie Mellon University as an Associate Professor. Ruslan&#8217;s primary interests lie in deep learning, machine learning, and large-scale optimization. He is an action editor of the Journal of Machine Learning Research and served on the senior programme committee of several learning conferences including NIPS and ICML. He is an Alfred P. Sloan Research Fellow, Microsoft Research Faculty Fellow, Canada Research Chair in Statistical Machine Learning, a recipient of the Early Researcher Award, Google Faculty Award, Nvidia&#8217;s Pioneers of AI award, and is a Senior Fellow of the Canadian Institute for Advanced Research.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== Jan 30 =================================== --></p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Jan 30</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.igb.uci.edu/~pfbaldi/\"><b>Pierre Baldi &#038; Peter Sadowski</b></a><br />Chancellor&#8217;s Professor<br />Department of Computer Science<br />University of California, Irvine</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Learning in the Machine: Random Backpropagation and the Learning Channel</b></a></span></div><div class=\"togglec clearfix\">Learning in the Machine is a style of machine learning that takes into account the physical constraints of learning machines, from brains to neuromorphic chips. Taking into account these constraints leads to new insights into the foundations of learning systems, and occasionally leads also to improvements for machine learning performed on digital computers. Learning in the Machine is particularly useful when applied to message passing algorithms such as backpropagation and belief propagation, and leads to the concepts of local learning and learning channel. These concepts in turn will be applied to random backpropagation and several new variants. In addition to simulations corroborating the remarkable robustness of these algorithms, we will present new mathematical results establishing interesting connections between machine learning and Hilbert 16th problem.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== Feb  6 =================================== --></p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Feb  6</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://itensor.org/miles/\"><b>Miles Stoudenmire</b></a><br />Research Scientist<br />Department of Physics<br />University of California, Irvine</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Learning with Tensor Networks</b></a></span></div><div class=\"togglec clearfix\">Tensor networks are a technique for factorizing tensors with hundreds or thousands of indices into a contracted network of low-order tensors. Originally developed at UCI in the 1990&#8217;s, tensor networks have revolutionized major areas of physics are starting to be used in applied math and machine learning. I will show that tensor networks fit naturally into a certain class of non-linear kernel learning models, such that advanced optimization techniques from physics can be applied straightforwardly (arxiv:1605.05775). I will discuss many advantages and future directions of tensor network models, for example adaptive pruning of weights and linear scaling with training set size (compared to at least quadratic scaling when using the kernel trick).</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== Feb 13 =================================== --> </p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Feb 13</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.ics.uci.edu/~qlou/\"><b>Qi Lou</b></a><br />PhD Candidate<br />Department of Computer Science<br />University of California, Irvine</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Anytime Anyspace AND/OR Search for Bounding the Partition Function</b></a></span></div><div class=\"togglec clearfix\">Bounding the partition function is a key inference task in many graphical models.  In this paper, we develop an anytime anyspace search algorithm taking advantage of AND/OR tree structure and optimized variational heuristics to tighten deterministic bounds on the partition function.  We study how our priority-driven best-first search scheme can improve on state-of-the-art variational bounds in an anytime way within limited memory resources, as well as the effect of the AND/OR framework to exploit conditional independence structure within the search process within the context of summation.  We compare our resulting bounds to a number of existing methods, and show that our approach offers a number of advantages on real-world problem instances taken from recent UAI competitions.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== Feb 20 =================================== --></p>\n<tr>\n<td valign=top class='aiml-none'>\n<div class=\"aiml-date\"><b>Feb 20</b></div>\n</td>\n<td valign=top class='aiml-none'>\n<div class=\"aiml-name\"><b>No Seminar (Presidents Day)</b></div>\n<p>\n  </td>\n</tr>\n<p>  <!-- ==== Feb 27 =================================== --></p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Feb 27</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.ics.uci.edu/~enalisni/\"><b>Eric Nalisnick</b></a><br />PhD Candidate<br />Department of Computer Science<br />University of California, Irvine</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Deep Generative Models with Stick-Breaking Priors</b></a></span></div><div class=\"togglec clearfix\">Deep generative models (such as the Variational Autoencoder) efficiently couple the expressiveness of deep neural networks with the robustness to uncertainty of probabilistic latent variables.  This talk will first give an overview of deep generative models, their applications, and approximate inference strategies for them.  Then I\u2019ll discuss our work on placing Bayesian Nonparametric priors on their latent space, which allows the hidden representations to grow as the data necessitates.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== Mar  6 =================================== --></p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>Mar  6</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"https://levyomer.wordpress.com/\"><b>Omer Levy</b></a><br />Postdoctoral Researcher<br />Department of Computer Science &#038; Engineering<br />University of Washington</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Understanding Word Embeddings</b></a></span></div><div class=\"togglec clearfix\">Neural word embeddings, such as word2vec (Mikolov et al., 2013), have become increasingly popular in both academic and industrial NLP. These methods attempt to capture the semantic meanings of words by processing huge unlabeled corpora with methods inspired by neural networks and the recent onset of Deep Learning. The result is a vectorial representation of every word in a low-dimensional continuous space. These word vectors exhibit interesting arithmetic properties (e.g. king &#8211; man + woman = queen) (Mikolov et al., 2013), and seemingly outperform traditional vector-space models of meaning inspired by Harris&#8217;s Distributional Hypothesis (Baroni et al., 2014). Our work attempts to demystify word embeddings, and understand what makes them so much better than traditional methods at capturing semantic properties.</p>\n<p> Our main result shows that state-of-the-art word embeddings are actually &#8220;more of the same&#8221;. In particular, we show that skip-grams with negative sampling, the latest algorithm in word2vec, is implicitly factorizing a word-context PMI matrix, which has been thoroughly used and studied in the NLP community for the past 20 years. We also identify that the root of word2vec&#8217;s perceived superiority can be attributed to a collection of hyperparameter settings. While these hyperparameters were thought to be unique to neural-network inspired embedding methods, we show that they can, in fact, be ported to traditional distributional methods, significantly improving their performance. Among our qualitative results is a method for interpreting these seemingly-opaque word-vectors, and the answer to why king &#8211; man + woman = queen.</p>\n<p> <b>Bio:</b> Omer Levy is a post-doc in the Department of Computer Science &#038; Engineering at the University of Washington, working with Prof. Luke Zettlemoyer. Previously, he completed his BSc and MSc at Technion \u2013 Israel Institute of Technology with the guidance of Prof. Shaul Markovitch, and got his PhD at Bar-Ilan University with the supervision of Prof. Ido Dagan and Dr. Yoav Goldberg. Omer is interested in realizing high-level semantic applications such as question answering and summarization to help people cope with information overload. At the heart of these applications are challenges in textual entailment, semantic similarity, and reading comprehension, which form the core of my current research. He is also interested in the current advances in deep learning and how they can facilitate semantic applications.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n</table>\n\t\t\t</div><!-- .entry-content -->\r\n\r\n\t\t<div class=\"entry-meta\">\r\n\t\t\t<a href=\"https://cml.ics.uci.edu/2017/01/winter-2017/\" title=\"4:41 pm\" rel=\"bookmark\"><time class=\"entry-date genericon\" datetime=\"2017-01-18T16:41:36-07:00\">January 18, 2017</time></a> \r\n\r\n\t\t\t\r\n\t\t\t<span class=\"cat-links genericon\"><a href=\"https://cml.ics.uci.edu/category/aiml/\" rel=\"category tag\">AIML</a></span>\r\n\t\t\t\t\t</div>\r\n\r\n\t</article><!-- #post-## -->\r\n\r\n\t\t\t\t\t\t\t<nav class=\"navigation-paging\" role=\"navigation\">\n\t\t<h1 class=\"screen-reader-text\">Posts navigation</h1>\n\t\t<div class=\"nav-links\">\n\n\t\t\t\t\t\t<div class=\"nav-previous\"><a href=\"https://cml.ics.uci.edu/aiml/page/9/\" ><span class=\"meta-nav\">&lsaquo;</span><span class=\"screen-reader-text\">Older posts</span></a></div>\n\t\t\t\n\t\t\t\t\t\t<div class=\"nav-next\"><a href=\"https://cml.ics.uci.edu/aiml/page/7/\" ><span class=\"screen-reader-text\">Newer posts </span><span class=\"meta-nav\">&rsaquo;</span></a></div>\n\t\t\t\n\t\t</div><!-- .nav-links -->\n\t</nav><!-- .navigation -->\n\t\t\t</div><!-- #content -->\r\n\t</div><!-- #primary -->\r\n\r\n\t<div id=\"secondary\" class=\"widget-area\" role=\"complementary\">\n\t\t\t\t<aside id=\"search-2\" class=\"widget widget_search\">\t<form method=\"get\" id=\"searchform\" class=\"searchform\" action=\"https://cml.ics.uci.edu/\" role=\"search\">\n\t\t<label for=\"s\" class=\"screen-reader-text\">Search</label>\n\t\t<input type=\"search\" class=\"field\" name=\"s\" value=\"\" id=\"s\" placeholder=\"Search &hellip;\" />\n\t\t<input type=\"submit\" class=\"submit\" id=\"searchsubmit\" value=\"Search\" />\n\t</form>\n</aside>\t</div><!-- #secondary -->\n\r\n</div><!-- #page -->\r\n\r\n<footer id=\"colophon\" class=\"site-footer\" role=\"contentinfo\">\r\n<p style=\"text-align:center;margin:0;\">(c) 2015 <a href=\"http://cml.ics.uci.edu\">Center for Machine Learning and Intelligent Systems</a>\r\n\t<div class=\"site-info\">\r\n\t\t\t\t<a href=\"http://wordpress.org/\" rel=\"generator\">WordPress</a>/<a href=\"http://www.wpzoom.com/\">BonPress</a>\r\n\t</div><!-- .site-info -->\r\n</footer><!-- #colophon -->\r\n\r\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-content/cml/themes/bonpress-wpcom/js/navigation.js?ver=20120206'></script>\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-content/cml/themes/bonpress-wpcom/js/skip-link-focus-fix.js?ver=20130115'></script>\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-includes/js/wp-embed.min.js?ver=5.2.3'></script>\n\r\n</body>\r\n</html>\r\n", "encoding": "utf-8"}