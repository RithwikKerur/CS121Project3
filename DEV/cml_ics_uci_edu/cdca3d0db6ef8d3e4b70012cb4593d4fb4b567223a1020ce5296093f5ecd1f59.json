{"url": "https://cml.ics.uci.edu/2012/09/fall-2012/#content", "content": "<!DOCTYPE html>\n<html lang=\"en-US\">\n<head>\n<meta charset=\"UTF-8\" />\n<meta name=\"viewport\" content=\"width=device-width\" />\n<title>Fall 2012 | Center for Machine Learning and Intelligent Systems</title>\n<link rel=\"profile\" href=\"http://gmpg.org/xfn/11\" />\n<link rel=\"pingback\" href=\"https://cml.ics.uci.edu/xmlrpc.php\" />\n<!--[if lt IE 9]>\n<script src=\"https://cml.ics.uci.edu/wp-content/cml/themes/bonpress-wpcom/js/html5.js\" type=\"text/javascript\"></script>\n<![endif]-->\n\n<link rel='dns-prefetch' href='//s.w.org' />\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Center for Machine Learning and Intelligent Systems &raquo; Feed\" href=\"https://cml.ics.uci.edu/feed/\" />\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Center for Machine Learning and Intelligent Systems &raquo; Comments Feed\" href=\"https://cml.ics.uci.edu/comments/feed/\" />\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"Center for Machine Learning and Intelligent Systems &raquo; Fall 2012 Comments Feed\" href=\"https://cml.ics.uci.edu/2012/09/fall-2012/feed/\" />\n\t\t<script type=\"text/javascript\">\n\t\t\twindow._wpemojiSettings = {\"baseUrl\":\"https:\\/\\/s.w.org\\/images\\/core\\/emoji\\/12.0.0-1\\/72x72\\/\",\"ext\":\".png\",\"svgUrl\":\"https:\\/\\/s.w.org\\/images\\/core\\/emoji\\/12.0.0-1\\/svg\\/\",\"svgExt\":\".svg\",\"source\":{\"concatemoji\":\"https:\\/\\/cml.ics.uci.edu\\/wp-includes\\/js\\/wp-emoji-release.min.js?ver=5.2.3\"}};\n\t\t\t!function(a,b,c){function d(a,b){var c=String.fromCharCode;l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,a),0,0);var d=k.toDataURL();l.clearRect(0,0,k.width,k.height),l.fillText(c.apply(this,b),0,0);var e=k.toDataURL();return d===e}function e(a){var b;if(!l||!l.fillText)return!1;switch(l.textBaseline=\"top\",l.font=\"600 32px Arial\",a){case\"flag\":return!(b=d([55356,56826,55356,56819],[55356,56826,8203,55356,56819]))&&(b=d([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]),!b);case\"emoji\":return b=d([55357,56424,55356,57342,8205,55358,56605,8205,55357,56424,55356,57340],[55357,56424,55356,57342,8203,55358,56605,8203,55357,56424,55356,57340]),!b}return!1}function f(a){var c=b.createElement(\"script\");c.src=a,c.defer=c.type=\"text/javascript\",b.getElementsByTagName(\"head\")[0].appendChild(c)}var g,h,i,j,k=b.createElement(\"canvas\"),l=k.getContext&&k.getContext(\"2d\");for(j=Array(\"flag\",\"emoji\"),c.supports={everything:!0,everythingExceptFlag:!0},i=0;i<j.length;i++)c.supports[j[i]]=e(j[i]),c.supports.everything=c.supports.everything&&c.supports[j[i]],\"flag\"!==j[i]&&(c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&c.supports[j[i]]);c.supports.everythingExceptFlag=c.supports.everythingExceptFlag&&!c.supports.flag,c.DOMReady=!1,c.readyCallback=function(){c.DOMReady=!0},c.supports.everything||(h=function(){c.readyCallback()},b.addEventListener?(b.addEventListener(\"DOMContentLoaded\",h,!1),a.addEventListener(\"load\",h,!1)):(a.attachEvent(\"onload\",h),b.attachEvent(\"onreadystatechange\",function(){\"complete\"===b.readyState&&c.readyCallback()})),g=c.source||{},g.concatemoji?f(g.concatemoji):g.wpemoji&&g.twemoji&&(f(g.twemoji),f(g.wpemoji)))}(window,document,window._wpemojiSettings);\n\t\t</script>\n\t\t<style type=\"text/css\">\nimg.wp-smiley,\nimg.emoji {\n\tdisplay: inline !important;\n\tborder: none !important;\n\tbox-shadow: none !important;\n\theight: 1em !important;\n\twidth: 1em !important;\n\tmargin: 0 .07em !important;\n\tvertical-align: -0.1em !important;\n\tbackground: none !important;\n\tpadding: 0 !important;\n}\n</style>\n\t<link rel='stylesheet' id='wp-block-library-css'  href='https://cml.ics.uci.edu/wp-includes/css/dist/block-library/style.min.css?ver=5.2.3' type='text/css' media='all' />\n<link rel='stylesheet' id='bonpress-style-css'  href='https://cml.ics.uci.edu/wp-content/cml/themes/bonpress-cml/style.css?ver=5.2.3' type='text/css' media='all' />\n<link rel='stylesheet' id='tipsy-css'  href='https://cml.ics.uci.edu/wp-content/cml/plugins/wp-shortcode/css/tipsy.css?ver=5.2.3' type='text/css' media='all' />\n<link rel='stylesheet' id='mts_wpshortcodes-css'  href='https://cml.ics.uci.edu/wp-content/cml/plugins/wp-shortcode/css/wp-shortcode.css?ver=5.2.3' type='text/css' media='all' />\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-includes/js/jquery/jquery.js?ver=1.12.4-wp'></script>\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-includes/js/jquery/jquery-migrate.min.js?ver=1.4.1'></script>\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-content/cml/plugins/wp-shortcode/js/jquery.tipsy.js?ver=5.2.3'></script>\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-content/cml/plugins/wp-shortcode/js/wp-shortcode.js?ver=5.2.3'></script>\n<link rel='https://api.w.org/' href='https://cml.ics.uci.edu/wp-json/' />\n<link rel=\"EditURI\" type=\"application/rsd+xml\" title=\"RSD\" href=\"https://cml.ics.uci.edu/xmlrpc.php?rsd\" />\n<link rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\" href=\"https://cml.ics.uci.edu/wp-includes/wlwmanifest.xml\" /> \n<link rel='prev' title='CML members make strong showing at 2012 UAI conference' href='https://cml.ics.uci.edu/2012/08/2012_uaidomination/' />\n<link rel='next' title='Winter 2013' href='https://cml.ics.uci.edu/2013/01/winter-2013/' />\n<meta name=\"generator\" content=\"WordPress 5.2.3\" />\n<link rel=\"canonical\" href=\"https://cml.ics.uci.edu/2012/09/fall-2012/\" />\n<link rel='shortlink' href='https://cml.ics.uci.edu/?p=522' />\n<link rel=\"alternate\" type=\"application/json+oembed\" href=\"https://cml.ics.uci.edu/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fcml.ics.uci.edu%2F2012%2F09%2Ffall-2012%2F\" />\n<link rel=\"alternate\" type=\"text/xml+oembed\" href=\"https://cml.ics.uci.edu/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fcml.ics.uci.edu%2F2012%2F09%2Ffall-2012%2F&#038;format=xml\" />\n</head>\n\n<body class=\"post-template-default single single-post postid-522 single-format-standard group-blog\">\n<div id=\"page\" class=\"hfeed site\">\n\t\t<header id=\"masthead\" class=\"all-header\" role=\"banner\">\n\t\t<hgroup class=\"hgroup-wide\">\n                        <a href=\"https://cml.ics.uci.edu/\" title=\"Center for Machine Learning and Intelligent Systems\" rel=\"home\"><img src='/wp-content/cml/uploads/cml-curve.jpg'></a>\n<!--\t\t\t<h1 class=\"site-title\"><a href=\"https://cml.ics.uci.edu/\" title=\"Center for Machine Learning and Intelligent Systems\" rel=\"home\">Center for Machine Learning and Intelligent Systems</a></h1>\n\t\t\t<h2 class=\"site-description\">University of California, Irvine</h2> -->\n\t\t\t<h1 class=\"site-title\"><a href=\"https://cml.ics.uci.edu/\" title=\"Center for Machine Learning and Intelligent Systems\" rel=\"home\">Center for Machine Learning and Intelligent Systems</a></h1>\n\t\t\t<h2 class=\"site-description\">Bren School of Information and Computer Science</h2>\t\t\t\n\t\t\t<h2 class=\"site-description\">University of California, Irvine</h2>\n\t\t\t<div style=\"clear:both\"></div>\n\t\t</hgroup>\n\t</header>\n\t<header id=\"masthead\" class=\"site-header\" role=\"banner\">\n\t\t<hgroup class=\"hgroup-img\">\n                        <a href=\"https://cml.ics.uci.edu/\" title=\"Center for Machine Learning and Intelligent Systems\" rel=\"home\"><img src='/wp-content/cml/uploads/cml-curve.jpg'></a>\n\t\t\t<h1 class=\"site-title\"><a href=\"https://cml.ics.uci.edu/\" title=\"Center for Machine Learning and Intelligent Systems\" rel=\"home\">Center for Machine Learning and Intelligent Systems</a></h1>\n\t\t\t<h2 class=\"site-description\">University of California, Irvine</h2>\n\t\t</hgroup>\n\n\t\t<nav id=\"site-navigation\" class=\"navigation-main\" role=\"navigation\">\n\t\t\t<h1 class=\"menu-toggle\">Menu</h1>\n\t\t\t<div class=\"screen-reader-text skip-link\"><a href=\"#content\" title=\"Skip to content\">Skip to content</a></div>\n\n\t\t\t<div class=\"menu-navigation-container\"><ul id=\"menu-navigation\" class=\"menu\"><li id=\"menu-item-234\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-home menu-item-234\"><a href=\"https://cml.ics.uci.edu/\">Home</a></li>\n<li id=\"menu-item-79\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-79\"><a href=\"https://cml.ics.uci.edu/home/about-us/\">About CML</a>\n<ul class=\"sub-menu\">\n\t<li id=\"menu-item-78\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-78\"><a href=\"https://cml.ics.uci.edu/home/about-us/\">About us</a></li>\n\t<li id=\"menu-item-429\" class=\"menu-item menu-item-type-taxonomy menu-item-object-category menu-item-429\"><a href=\"https://cml.ics.uci.edu/category/news/\">News</a></li>\n\t<li id=\"menu-item-76\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-76\"><a href=\"https://cml.ics.uci.edu/home/contact-us/\">Contact Us</a></li>\n</ul>\n</li>\n<li id=\"menu-item-539\" class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children menu-item-539\"><a>People</a>\n<ul class=\"sub-menu\">\n\t<li id=\"menu-item-55\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-55\"><a href=\"https://cml.ics.uci.edu/faculty/\">Faculty</a></li>\n\t<li id=\"menu-item-220\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-220\"><a href=\"https://cml.ics.uci.edu/alumni/\">Alumni</a></li>\n</ul>\n</li>\n<li id=\"menu-item-75\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-has-children menu-item-75\"><a href=\"https://cml.ics.uci.edu/aiml/\">Events &#038; Seminars</a>\n<ul class=\"sub-menu\">\n\t<li id=\"menu-item-74\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-74\"><a href=\"https://cml.ics.uci.edu/aiml/\">AI/ML Seminar Series</a></li>\n\t<li id=\"menu-item-914\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-914\"><a href=\"https://cml.ics.uci.edu/aiml/ml-distinguished-speakers/\">ML Distinguished Speakers</a></li>\n\t<li id=\"menu-item-73\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-73\"><a href=\"https://cml.ics.uci.edu/aiml/ml-reading-group/\">ML Reading Group</a></li>\n</ul>\n</li>\n<li id=\"menu-item-222\" class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-has-children menu-item-222\"><a>Education &#038; Resources</a>\n<ul class=\"sub-menu\">\n\t<li id=\"menu-item-227\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-227\"><a href=\"https://cml.ics.uci.edu/courses/\">Courses</a></li>\n\t<li id=\"menu-item-221\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-221\"><a href=\"https://cml.ics.uci.edu/books/\">Books</a></li>\n</ul>\n</li>\n<li id=\"menu-item-81\" class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-81\"><a href=\"http://www.ics.uci.edu/~mlearn/MLRepository.html\">UCI Machine Learning Archive</a></li>\n<li id=\"menu-item-87\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-87\"><a href=\"https://cml.ics.uci.edu/sponsors-funding/\">Sponsors &#038; Funding</a></li>\n<li id=\"menu-item-86\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-86\"><a href=\"https://cml.ics.uci.edu/subscribe/\">Subscribe to CML List</a></li>\n</ul></div>\t\t</nav><!-- #site-navigation -->\n\t</header><!-- #masthead -->\n\n\r\n\t<div id=\"primary\" class=\"content-area\">\r\n\t\t<div id=\"content\" class=\"site-content\" role=\"main\">\r\n\r\n\t\t\r\n\t\t\t\r\n<article id=\"post-522\" class=\"post-522 post type-post status-publish format-standard hentry category-aiml\">\r\n\t<header class=\"entry-header\">\r\n\t\t<h1 class=\"entry-title\">Fall 2012</h1>\t\t<span class=\"entry-format genericon\">Standard</span>\r\n\t\t<div class=\"entry-meta\">\r\n\t\t\t<a href=\"https://cml.ics.uci.edu/2012/09/fall-2012/\" title=\"3:40 pm\" rel=\"bookmark\"><time class=\"entry-date genericon\" datetime=\"2012-09-01T15:40:05-07:00\">September 1, 2012</time></a>\r\n\t\t\t\r\n\t\t\t<span class=\"cat-links genericon\"><a href=\"https://cml.ics.uci.edu/category/aiml/\" rel=\"category tag\">AIML</a></span>\r\n\t\t\t\t\t</div>\r\n\t</header><!-- .entry-header -->\r\n\r\n\t<div class=\"entry-content\">\r\n\t\t<br />\n<table cellpadding=5 border=1>\n<col width=\"100\">\n<col>\n<p>  <!-- ==== October 1 =================================== --> </p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>October 1</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.mohsenhejrati.me\"><b>Mohsen Hejrati</b></a><br />Graduate Student<br />Department of Computer Science<br />University of California, Irvine</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Analyzing 3D Objects in Cluttered Images</b></a></span></div><div class=\"togglec clearfix\">We present an approach to detecting and analyzing the 3D configuration of objects in real-world images with heavy occlusion and clutter. We focus on the application of finding and analyzing cars. We do so with a two-layer model; the first layer reasons about 2D appearance changes due to within-class variation and viewpoint. Rather than using a global view-based model, we describe a compositional representation that models a large number of effective views using a small number of local view-based templates. We use this model to propose candidate detections, which are then refined by our second layer, a 3D statistical model that reasons about 3D shape changes and 3D camera viewpoints. We demonstrate state-of-the-art accuracy on challenging images from the PASCAL VOC 2011 dataset.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== October 8 =================================== --> </p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>October 8</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.stat.purdue.edu/~skirshne\"><b>Sergey Kirshner</b></a><br />Assistant Professor<br />Department of Statistics<br />Purdue University</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Copulas in Machine Learning or How to Make Sense of Multi-Dimensional Non-Gaussian Real-Valued Data</b></a></span></div><div class=\"togglec clearfix\">As number of application domains, including finance, hydrology, and astronomy, produce high-dimensional multivariate data, there is an increasing interest in models which can capture non-linear dependence between the observations.  Enter copulas, a statistical approach which separates the marginal distributions for random variables from their dependence structure. I will go over the recent work on using copulas in two different settings. In the first setting, the graphical models are developed for copulas with the goal of modeling of non-Gaussian multivariate real-valued data.  I will focus on tree-structured copulas in particular as they provide a convenient building block for such models and their applications to modeling of multi-site rainfall. The second setting, copulas are used to construct non-parametric robust estimators of dependence (e.g, information). Among applications of such estimators is a new robust approach to independent component analysis. </p>\n<p> Speaker Bio:</p>\n<p> Sergey Kirshner is an Assistant Professor of Statistics at Purdue University.  Prior to joining Purdue, he was a postdoctoral fellow with Alberta Ingenuity Centre for Machine Learning at the Department of Computing Science at the University of Alberta. Before that, he was a graduate student and then a postdoc at the Donald Bren School of Information and Computer Sciences at the University of California, Irvine in Padhraic Smyth&#8217;s research group.  His research interests lie in the area of statistical machine learning, more specifically, computational methods for learning and inference for sparse models of high-dimensional data, and their applications to scientific problems.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== October 15 =================================== --> </p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>October 15</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.ics.uci.edu/~djp3\"><b>Don Patterson</b></a><br />Associate Professor<br />Department of Informatics<br />University of California, Irvine</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Gesture Recognition with Erlang-Cox Models To Identify Neurological Disorders in Premature Babies</b></a></span></div><div class=\"togglec clearfix\">In this talk I will describe a system that leverages accelerometers to recognize a particular involuntary gesture in babies that have been born preterm. These gestures, known as cramped-synchronized general movements are highly correlated with a diagnosis of Cerebral Palsy. In order to test our system we recorded data from 10 babies admitted to the newborn intensive care unit at the UCI Medical Center. We demonstrate a Markov model based technique for recognizing gestures from accelerometers that explicitly represent duration. We do this by embedding an Erlang-Cox state transition model, which has been shown to accurately represent the first three moments of a general distribution, within a Dynamic Bayesian Network (DBN). The transition probabilities in the DBN can be learned via Expectation-Maximization or by using closed-form solutions. We show that by treating instantaneous machine learning classification values as observations and explicitly modeling duration, we improve the recognition of Cramped Syn- chronized General Movements, a motion highly correlated with an eventual diagnosis of Cerebral Palsy. Validated video observation annotations were utilized as ground truth. Finally, we conducted an analysis to understand the clinical impact of this technique.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== October 22 =================================== --> </p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>October 22</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.ics.uci.edu/~lboyles/\"><b>Levi Boyles</b></a><br />Graduate Student<br />Department of Computer Science<br />University of California, Irvine</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>The Time-Marginalized Coalescent Prior for Hierarchical Clustering</b></a></span></div><div class=\"togglec clearfix\">We introduce a new prior for use in Nonparametric Bayesian Hierarchical Clustering. The prior is constructed by marginalizing out the time information of Kingman\u2019s coalescent, providing a prior over tree structures which we call the Time-Marginalized Coalescent (TMC). This allows for models which factorize the tree structure and times, providing two benefits: more flexible priors may be constructed and more efficient Gibbs type inference can be used. We demonstrate this on an example model for density estimation and show the TMC achieves competitive experimental results.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== October 29 =================================== --> </p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>October 29</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.igb.uci.edu/~pfbaldi\"><b>Pierre Baldi</b></a><br />Chancellor&#8217;s Professor<br />Department of Computer Science<br />University of California, Irvine</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Deep Architectures and Deep Learning</b></a></span></div><div class=\"togglec clearfix\">Deep architectures are important for machine learning, for engineering applications, and for understanding the brain. In this talk we will provide a brief historical overview of deep architectures from their 1950s origins to today. Motivated by this overview, we will study and prove several theorems regarding deep architectures and one of their main ingredients&#8211;autoencoder circuits&#8211;in particular in the unrestricted Boolean and unrestricted probabilistic cases. We will show how these analyses lead to a new general family of learning algorithms for deep architectures&#8211;the deep target (DT) algorithms. The DT approach converts the problem of learning a deep architecture into the problem of learning many shallow architectures by providing learning targets for the deep layers. Finally, we will present simulation results and applications of deep architectures and DT algorithms to protein structure prediction.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== November 5 =================================== --> </p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>November 5</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://amanda.uci.edu/~daniel/index.html\"><b>Daniel Whiteson</b></a><br />Associate Professor<br />Department of Physics and Astronomy<br />University of California, Irvine</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Searching for the Higgs Boson and Beyond with Machine Learning Tools</b></a></span></div><div class=\"togglec clearfix\">High-energy physicists try to decompose matter into its most fundamental pieces by colliding particles at extreme energies. But to extract clues about the structure of matter from these collisions is not a trivial task, due to the incomplete data we can gather regarding the collisions, the subtlety of the signals we seek and the large rate and high dimensionality of the data. These challenges are not unique to high energy physics, and there is the potential for great progress in collaboration between high energy physicists and machine learning experts. I will describe the nature of the physics problem, the challenges we face in analyzing the data, the previous successes and failures of some ML techniques, and the open challenges.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== November 12 (no seminar) =================================== --> </p>\n<tr>\n<td valign=top class='aiml-none'>\n<div class=\"aiml-date\"><b>November 12 (no seminar)</b></div>\n</td>\n<td valign=top class='aiml-none'>\n<div class=\"aiml-name\"><b>Veterans Day</b></div>\n<p>\n  </td>\n</tr>\n<p>  <!-- ==== November 16 =================================== --> </p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>November 16</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://people.csail.mit.edu/fisher/\"><b>John Fisher</b></a><br />Prinicipal Research Scientist<br />CSAIL<br />MIT</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Information Gathering Under Resource Constraints: Greed is Good</b></a></span></div><div class=\"togglec clearfix\">In many distributed sensing problems, resource constraints preclude the utilization of all sensing assets. By way of example, inference in distributed sensor networks presents a fundamental trade-off between the utility in a distributed set of measurements versus the resources expended to acquire them, fuse them into a model of uncertainty, and then transmit the resulting model. Active approaches seek to manage sensing resources so as to maximize a utility function while incorporating constraints on resource expenditures. Such approaches are complicated by several factors. Firstly, the complexity of sensor planning is typically exponential in both the number of sensing actions and the planning time horizon. Consequently, optimal planning methods are intractable excepting for very small scale problems. Secondly, the choice of utility function may vary over time and across users. Approximate approaches (c.f. [Zhao et al., 2002, Kreucher et al., 2005]) have been proposed that treat a subset of these issues; however, the approaches are indirect and do not scale to large problems. In this presentation, I will discuss the use of information measures for resource allocation in distributed sensing systems. Such measures are appealing due to a variety of useful properties. For example, recent results of [Nguyen et al., 2009] link a class of information measures to surrogate risk functions and their associated bounds on excess risk [Bartlett et al., 2003]. Consequently, these measures are suitable proxies for a wide variety of risk functions. I will discuss a method [Williams et al., 2007a] which enables long time-horizon sensor planning in the context of state estimation with a distributed sensor network. The approach integrates the value of information discounted by resource expenditures over a rolling time horizon. Simulation results demonstrate that the resulting algorithm can provide similar estimation performance to that of greedy and myopic methods for a fraction of the resource expenditures. Furthermore, recently developed methods [Fisher III et al., 2009] have been shown to be useful for estimating these quantities in complex signal models. Finally, one consequence of this algorithmic development are new fundamental performance bounds for information gathering systems [Williams et al., 2007b] which show that, under mild assumptions, optimal (though intractable) planning schemes can yield no better than twice the performance of greedy methods for certain choices of information measures. The bound can be shown to be sharp. Additional on-line computable bounds, often tighter in practice, are presented as well.</p>\n<p>This is joint work with Georgios Papachristoudous, Jason L. Williams, &#038; Michael Siracusa.</p>\n<p>Bio</p>\n<p>John Fisher is Principal Research Scientist at the MIT Computer Science and Artificial Intelligence Laboratory. His research focuses on information-theoretic approaches to machine learning, computer vision, and signal processing. Application areas include signal-level approaches to multi-modal data fusion, signal and image processing in sensor networks, distributed inference under resource constraints, resource management in sensor networks, and analysis of seismic and radar images. In collaboration with the Surgical Planning Lab at Brigham and Women&#8217;s Hospital, he is developing nonparametric approaches to image registration and functional imaging.</p>\n<p>He received a BS and MS in Electrical Engineering at the Univsersity of Florida in 1987 and 1989, respectively. He earned a PhD in Electrical and Computer Engineering in 1997.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== November 19 =================================== --> </p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>November 19</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.cs.umd.edu/~getoor\"><b>Lise Getoor</b></a><br />Associate Professor<br />Department of Computer Science<br />University of Maryland, College Park</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Statistical Relational Learning and Graph Identification</b></a></span></div><div class=\"togglec clearfix\">Within the machine learning community, there is a growing interest in learning structured models from input data that is itself structured, an area often referred to as statistical relational learning (SRL). I&#8217;ll begin with a brief overview of SRL, and discuss its relation to network analysis, extraction, and alignment.   I&#8217;ll then describe our recent work on graph identification.   Graph identification is the process of transforming an observed input network into an inferred output graph.  It involves cleaning the data &#8212; inferring missing information and correcting mistakes &#8211; and is an important first step before any further network analysis is performed.   It requires a combination of entity resolution, link prediction, and collective classification techniques.  I will overview two approaches to graph identification: 1) coupled conditional classifiers (C^3), and 2) probabilistic soft logic (PSL).  I will describe their mathematical foundations, learning and inference algorithms, and empirical evaluation, showing their power in terms of both accuracy and scalability.   I will conclude by highlighting connections to privacy in social network data and other current big data challenges. </p>\n<p>Bio</p>\n<p> Lise Getoor is an Associate Professor in the Computer Science Department at the University of Maryland, College Park and University of Maryland Institute for Advanced Computer Studies.  Her research areas include machine learning, and reasoning under uncertainty; in addition she works in data management, visual analytics and social network analysis. She is a board member of the International Machine Learning Society, a former Machine Learning Journal Action Editor, Associate Editor for the ACM Transactions of Knowledge Discovery from Data, JAIR Associate Editor, and she has served on the AAAI Council. She was conference co-chair for ICML 2011, and has served on the PC of many conferences including the senior PC for AAAI, ICML, KDD, UAI and the PC of SIGMOD, VLDB, and WWW. She is a recipient of an NSF Career Award and was awarded a National Physical Sciences Consortium Fellowship. Her work has been funded by ARO, DARPA, IARPA, Google, jIBM, LLNL, Microsoft, NGA, NSF, Yahoo! and others.   She received her PhD from Stanford University, her Master&#8217;s degree from University of California, Berkeley, and her undergraduate degree from University of California, Santa Barbara.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== November 26 =================================== --> </p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>November 26</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"\"><b>Shiwei Lan</b></a><br />Graduate Student<br />Department of Statistics<br />University of California, Irvine</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Lagrangian Dynamical Monte Carlo</b></a></span></div><div class=\"togglec clearfix\">Hamiltonian Monte Carlo (HMC) improves the computational efficiency of the Metropolis algorithm by reducing its random walk behavior. Riemannian Manifold HMC (RMHMC) further improves HMC&#8217;s performance by exploiting the geometric properties of the parameter space. However, the geometric integrator used for RMHMC involves implicit equations that require costly numerical analysis (e.g., fixed-point iteration). In some cases, the computational overhead for solving implicit equations undermines RMHMC&#8217;s benefits. To avoid this problem, we propose an explicit geometric integrator that replaces the momentum variable in RMHMC by velocity. We show that the resulting transformation is equivalent to transforming Riemannian Hamilton dynamics to Lagrangian dynamics. Experimental results show that our method improves RMHMC&#8217;s overall computational efficiency. All computer programs and data sets are available online (<a href=\"http://www.ics.uci.edu/~babaks/Site/Codes.html\">this http URL</a>) in order to allow replications of the results reported in this paper.</p>\n<p>Link to arXiv: <a href=\"http://arxiv.org/abs/1211.3759\">http://arxiv.org/abs/1211.3759</a></div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== November 30 =================================== --> </p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>November 30</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://users.cecs.anu.edu.au/~ssanner/ \"><b>Scott Sanner</b></a><br />Senior Researcher<br />Machine Learning Group<br />NICTA</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Data Structures for Efficient Inference and Optimization in Expressive Continuous Domains</b></a></span></div><div class=\"togglec clearfix\">To date, our ability to perform exact closed-form inference or optimization with continuous variables is largely limited to special well-behaved cases. \u00a0This talk argues that with an appropriate representation and data structure, we can vastly expand the class of models for which we can perform exact, closed-form inference.</p>\n<p>This talk is in two parts. \u00a0In the first part, I introduce an extension of the algebraic decision diagram (ADD) to continuous variables &#8212; termed the extended ADD (XADD) &#8212; to represent arbitrary piecewise functions over discrete and continuous variables and show how to efficiently compute elementary arithmetic operations, integrals, and maximization for these functions. \u00a0In the second part, I briefly cover a wide range of novel applications where the XADD may be applied: (a) exact inference in expressive discrete and continuous variable graphical models, (b) factored, parameterized linear and quadratic optimization, (c) exact solutions to piecewise convex functions that enable a number of novel applications in machine learning, and (d) exact solutions to continuous state, action, and observation sequential decision-making problems &#8212; which includes closed-form exact solutions to previously unsolved problems in operations research.</p>\n<p>Acknowledgments: This is joint work with Zahra Zamani &#038; Ehsan Abbasnejad (Australian National University), Karina Valdivia Delgado &#038; Leliane Nunes de Barros (University of Sao Paulo), and Simon Fang (M.I.T.).</p>\n<p>Quick Speaker Bio: Scott Sanner is a Senior Researcher in the Machine Learning Group at NICTA Canberra and an Adjunct Fellow at the Australian National University, having joined both in 2007. \u00a0Scott earned a PhD from the University of Toronto, an MS degree from Stanford, and a double BS degree from Carnegie Mellon. \u00a0Scott&#8217;s research interests span decision-making applications ranging over AI, Machine Learning, and Information Retrieval. \u00a0For more information, please visit: http://users.cecs.anu.edu.au/~ssanner/</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== December 3 =================================== --> </p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>December 3</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.francescobonchi.com\"><b>Francesco Bonchi</b></a><br />Senior Research Scientist<br />Yahoo! Research Barcelona</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Mining Progagation Data (in Social Networks)</b></a></span></div><div class=\"togglec clearfix\">With the success of online social networks and microblogging platforms such as Facebook, Flickr and Twitter, the phenomenon of influence-driven propagations, has recently attracted the interest of computer scientists, information technologists, and marketing specialists.</p>\n<p>In this talk we take a data mining perspective and we discuss what (and how) can be learned from a social network and a database of traces of past propagations over the social network. Starting from one of the key problems in this area, i.e.  the identification of influential users, by targeting whom certain desirable marketing outcomes can be achieved, we provide an overview of some recent progresses in this area and discuss some open problems.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n<p>  <!-- ==== December 10 =================================== --> </p>\n<tr>\n<td valign=top>\n<div class=\"aiml-date\"><b>December 10</b><br />Bren Hall 4011<br />1 pm</div>\n</td>\n<td valign=top>\n<div class=\"aiml-name\"><a href=\"http://www.stat.ucla.edu/~gpapan/\"><b>George Papandreou</b></a><br />Postdoctoral Research Scholar<br />Department of Statistics<br />University of California, Los Angeles</div>\n<p>\n  <div class=\"toggle clearfix wp_shortcodes_toggle\"><div class=\"wps_togglet\"><span><a><b>Random Sampling and Optimization in Probabilistic Modeling for Computer Vision</b></a></span></div><div class=\"togglec clearfix\">Machine learning plays an increasingly important role in computer vision, allowing us to build complex vision systems that better capture the properties of images. Probabilistic Bayesian methods such as Markov random fields are well suited for describing ambiguous images and videos, providing us with the natural conceptual framework for representing the uncertainty in interpreting them and automatically learning model parameters from training data. However, Bayesian techniques pose significant computational challenges in computer vision applications and alternative deterministic energy minimization techniques are often preferred in practice.</p>\n<p>I will present a new computationally efficient probabilistic random field model, which can be best described as a &#8220;Perturb-and-MAP&#8221; generative process: We obtain a random sample from the whole field at once by first injecting noise into the system&#8217;s energy function, then solving an optimization problem to find the least energy configuration of the perturbed system. With Perturb-and-MAP random fields we thus turn powerful deterministic energy minimization methods into efficient probabilistic random sampling algorithms that bypass costly Markov-chain Monte-Carlo (MCMC) and can generate in a fraction of a second independent random samples from mega-pixel sized images. I will discuss how the Perturb-and-MAP model relates to the standard Gibbs MRF and how it can be used in conjunction with other approximate Bayesian computation techniques. I will illustrate these ideas with applications in image inpainting and deblurring, image segmentation, and scene labeling, showing how the Perturb-and-MAP model makes large-scale Bayesian inference computationally tractable for challenging computer vision problems.</p>\n<p>Speaker Bio:</p>\n<p>George Papandreou holds a Diploma (2003) and a Ph.D. (2009) in electrical and computer engineering from the National Technical University of Athens, Greece.</p>\n<p>Since 2009 he has been a postdoctoral research scholar at the University of California, Los Angeles. His research interests are in probabilistic machine learning, computer vision, and multimodal perception. He approaches these problems with methods from Bayesian statistics, signal processing, and applied mathematics.</div></div><div class=\"clear\"></div>\n  </td>\n</tr>\n</table>\n\t\t\t</div><!-- .entry-content -->\r\n\r\n\t</article><!-- #post-## -->\r\n\r\n\r\n\t\t\t\t<nav role=\"navigation\" id=\"nav-below\" class=\"navigation-post\">\n\t\t<h1 class=\"screen-reader-text\">Post navigation</h1>\n\n\t\n\t\t<div class=\"nav-previous\"><a href=\"https://cml.ics.uci.edu/2012/08/2012_uaidomination/\" rel=\"prev\"><span class=\"meta-nav\">&larr;</span> CML members make strong showing at 2012 UAI conference</a></div>\t\t<div class=\"nav-next\"><a href=\"https://cml.ics.uci.edu/2013/01/winter-2013/\" rel=\"next\">Winter 2013 <span class=\"meta-nav\">&rarr;</span></a></div>\n\t\n\t</nav><!-- #nav-below -->\n\t\r\n\t\t\t\r\n\t\t\r\n\t\t</div><!-- #content -->\r\n\t</div><!-- #primary -->\r\n\r\n\t<div id=\"secondary\" class=\"widget-area\" role=\"complementary\">\n\t\t\t\t<aside id=\"search-2\" class=\"widget widget_search\">\t<form method=\"get\" id=\"searchform\" class=\"searchform\" action=\"https://cml.ics.uci.edu/\" role=\"search\">\n\t\t<label for=\"s\" class=\"screen-reader-text\">Search</label>\n\t\t<input type=\"search\" class=\"field\" name=\"s\" value=\"\" id=\"s\" placeholder=\"Search &hellip;\" />\n\t\t<input type=\"submit\" class=\"submit\" id=\"searchsubmit\" value=\"Search\" />\n\t</form>\n</aside>\t</div><!-- #secondary -->\n\r\n</div><!-- #page -->\r\n\r\n<footer id=\"colophon\" class=\"site-footer\" role=\"contentinfo\">\r\n<p style=\"text-align:center;margin:0;\">(c) 2015 <a href=\"http://cml.ics.uci.edu\">Center for Machine Learning and Intelligent Systems</a>\r\n\t<div class=\"site-info\">\r\n\t\t\t\t<a href=\"http://wordpress.org/\" rel=\"generator\">WordPress</a>/<a href=\"http://www.wpzoom.com/\">BonPress</a>\r\n\t</div><!-- .site-info -->\r\n</footer><!-- #colophon -->\r\n\r\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-content/cml/themes/bonpress-wpcom/js/navigation.js?ver=20120206'></script>\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-content/cml/themes/bonpress-wpcom/js/skip-link-focus-fix.js?ver=20130115'></script>\n<script type='text/javascript' src='https://cml.ics.uci.edu/wp-includes/js/wp-embed.min.js?ver=5.2.3'></script>\n\r\n</body>\r\n</html>\r\n", "encoding": "utf-8"}