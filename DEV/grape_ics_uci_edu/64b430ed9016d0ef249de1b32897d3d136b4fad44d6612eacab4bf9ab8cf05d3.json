{"url": "https://grape.ics.uci.edu/wiki/public/wiki/cs221-2019-spring-project3?version=1&format=txt", "content": "\r\n= CS221: Project 2 - II: Positional index, phrase search, compression =\r\n'''Test Cases Due:     Week 6 Fri. (May 10), Due on Github as Pull Requests'''[[BR]]\r\n'''Review Due:           Week 7 Mon. (May 13),  Due on Github as Pull Requests Comments'''[[BR]]\r\n'''Final Code Due:     Week 8, Wed. (May 22),  Due on Github.'''[[BR]]\r\n\r\n\r\n== Coding Tasks ==\r\n1. Implement LSM-like Positional Index (insertion and merge).\r\n1. Implement Phrase Search.\r\n1. Implement Compression.\r\n\r\n== Testing Tasks ==\r\n1. Write at least 2 test cases for a task (2 points)\r\n1. Review the test cases of two teams (2 points)\r\n\r\nTotal: 19 points \r\n\r\n== Overview ==\r\n\r\nIn this project, you'll be implementing a disk-based positional index and the phrase search operations. Compared to the inverted index in project 2, positional index stores the positions of all occurrences of the keywords in a document. Moreover, positional index also stores the frequency information of the keywords. \r\n\r\nThe \"position\" of a word in the positional index have many different kinds. It could be either character position or token position. Token position might include or exclude stop words. Different kinds of \"position\" also have different meanings on phrase search. For example, \"University of California, Irvine\", if we search the phrase \"University California\", choice on stop words affects the search result.\r\n\r\nIn this project, we stores the '''token''' position. We use the tokens generated from the analyzer - if the analyzer removes the stop words, then the stop words are also excluded from the positional index. For example, the positions of \"cat and dog\" is \"{cat: 1}, {dog: 2}\".\r\n\r\n\r\n== Task 1: Implement LSM-like positional index. ==\r\n\r\nThe on disk index structure of the positional index is similar to the LSM structure in project 2. You need to implement the `addDocument`, `flush`, and `merge` operations similar to project 2.\r\n\r\n{{{\r\npublic void addDocument(Document document)\r\n\r\npublic void flush()\r\n\r\npublic Iterator<Document> documentIterator()\r\n\r\npublic int getNumSegments()\r\n\r\npublic PositionalIndexSegmentForTest getIndexSegment(int segmentNum)\r\n\r\n}}}\r\n\r\n== Task 2: Implement phrase search. ==\r\n\r\nIn this task, you'll implement searching using the inverted index.\r\nYou could assume all documents are flushed to disk segments when doing a search.\r\n\r\nHere we make the same assumption as in the merge case regarding what can be stored in memory.\r\n\r\nFor every query keyword, you need to first analyze it using the provided analyzer before using it to access the inverted index.\r\nYou can assume the analyzer will not convert one keyword to multiple keywords.\r\nIf the keyword is empty, searching should not return any results.\r\n\r\nThe following are specific functions to implement:\r\n\r\n{{{\r\n/**\r\n * Performs a single-keyword search on the inverted index.\r\n * You could assume the analyzer won't convert the keyword into multiple tokens.\r\n * If the keyword is empty, it should not return anything.\r\n *\r\n * @param keyword keyword, cannot be null.\r\n * @return a iterator of documents matching the query\r\n */\r\npublic Iterator<Document> searchQuery(String keyword)\r\n\r\n/**\r\n * Performs an AND boolean search on the inverted index.\r\n *\r\n * @param keywords a list of keywords in the AND query\r\n * @return a iterator of documents matching the query\r\n */\r\npublic Iterator<Document> searchAndQuery(List<String> keywords)\r\n}\r\n\r\n/**\r\n * Performs an OR boolean search on the inverted index.\r\n *\r\n * @param keywords a list of keywords in the OR query\r\n * @return a iterator of documents matching the query\r\n */\r\npublic Iterator<Document> searchOrQuery(List<String> keywords) \r\n}}}\r\n\r\n\r\n== Task 4 (Optional Extra Credit): Implement deletions. ==\r\n\r\nIn the LSM-like index structure, deletion could be implemented by maintaining a list of deleted document IDs per segment.\r\nEach deleted document is not physically deleted in the inverted index nor document store.\r\nWhen reading or searching, each docID is checked to see if it has been logically deleted. \r\nIf so, we will not return it to the user.\r\n\r\nThose deleted documents within a segment should be physically deleted when we merge it with another segment.\r\n\r\nThe following is the specific function to implement:\r\n\r\n{{{\r\n/**\r\n * Deletes all documents in all disk segments of the inverted index that match the keyword.\r\n * @param keyword \r\n */\r\npublic void deleteDocuments(String keyword)\r\n}}}\r\n\r\n\r\n== Test cases ==\r\nPlease follow the similar general guideline and procedure as in project 1. Here is [https://docs.google.com/spreadsheets/d/1_iwJOT-bnYDk9tWNNy61GCyi1kRN7s3VHdn5h_2T1DA/edit#gid=996032174 test task assignment]. There are some guidelines and tips for project 2 test cases:\r\n1. Put the index and document files under your own folder. Specifically, you should use folder `index/YourTestName/`, for example `index/Team0StressTest`.\r\n2. Clean up and delete all files after each test. You should use Junit `@After` to delete all written files.\r\n3. For testing tasks 1 and 2, you could change `default_flush_threshold` or `default_merge_threshold`, or directly call `flush()` and `mergeAllSegments()` to control when to flush or when to merge. If you changed the variables `default_flush_threshold` or `default_merge_threshold`, be sure to change them back to their original value after your tests.\r\n4. For stress test, you should collect or generate a large amount of text data to test the performance and stability. If you rely on external data sets, please don't commit the large data directly in git. Instead, use a source URL to download the data.\r\n5. For all test tasks, you should also check the read/write counter values in the `PageFileChannel` class to make sure the IO number is within a reasonable range.\r\n\r\n", "encoding": "ascii"}