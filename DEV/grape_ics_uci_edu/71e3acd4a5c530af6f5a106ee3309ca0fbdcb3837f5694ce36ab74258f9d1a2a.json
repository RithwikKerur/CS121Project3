{"url": "https://grape.ics.uci.edu/wiki/public/wiki/cs221-2019-spring-project2?version=1&format=txt", "content": "\r\n= CS221: Project 2 - II: Inverted index, boolean search =\r\n'''Test Cases Due:     Week 4 Tu. (Apr 23), Due on Github as Pull Requests'''[[BR]]\r\n'''Review Due:           Week 4, Fri. (Apr 26),  Due on Github as Pull Requests Comments'''[[BR]]\r\n'''Final Code Due:     Week 5, Sun. (May. 5),  Due on Github.'''[[BR]]\r\n\r\n= Overview =\r\n\r\n== Coding Tasks ==\r\n1. Implement LSM-like disk-based inverted index that supports insertions. (7 points)\r\n1. Implement merge of inverted index segments. (4 points)\r\n1. Implement keyword search, boolean AND search, and boolean OR search. (6 points)\r\n1. (Optional) Extra Credit: Implement a dynamic-programming-based Chinese or Japanese tokenizer. (3 points)\r\n\r\n== Testing Tasks ==\r\n1. Write at least 2 test cases for a task (3 points)\r\n1. Review the test cases of two teams (2 points)\r\n\r\nTotal: 17 points  (+ 3 extra credits)\r\n\r\nProject 2: Implement an disk-based inverted index.\r\nIn this project, you'll be implementing a disk-based inverted index and the search operations.\r\n\r\nOn a high level, inverted index stores the mapping from keywords to the documents they appear in.\r\nA simple in-memory structure could be `Map<String, List<Integer>>`, where each key is a keyword token (also called term),\r\nand each value is a list of (often sorted) document IDs (also called postings).\r\n\r\nIn this project, the disk-based index structure is similar to the idea of LSM (Log-Structured Merge tree).\r\nA general idea will be described. The details should follow what Professor says in the lecture.\r\n\r\nThe inverted index consists of multiple index segments, where each segment is only created and then appended.\r\nOnce each segment is written to disk, it becomes immutable and is never changed again.\r\n\r\nEach index segment is a fully searchable inverted index,\r\nit contains the inverted index structure as well the document store (map from documentID to actual document),\r\nthe document ID of each segment is local to the segment itself and it is invisible to the user.\r\n\r\nWhen searching a keyword, all segments are searched, and the result documents from each segment are combined.\r\n\r\nExample:\r\n\r\nAdd documents \"cat dog\" and \"cat elephant\", then flush to write Segment0.\r\nSegment0:\r\n----------\r\nInvertIndex: {\"cat\": [0, 1], \"dog\": [0], \"elephant\": [1]}\r\nDocStore: {0: \"cat dog\", 1: \"cat elephant\"}\r\n----------\r\n\r\nThen add documents \"cat dog\" and \"wolf dog\", and flush to write a new Segment, Segment1.\r\nSegment1:\r\n----------\r\nInvertIndex: {\"cat\": [0], \"dog\": [0, 1], \"wolf\": [1]}\r\nDocStore: {0: \"cat dog\", 1: \"wolf dog\"}\r\n----------\r\n\r\nWhen searching the word \"cat\", first search Segment0 and get [\"cat dog\", \"cat elephant\"],\r\nthen search Segment1 and get [\"cat dog\"], then combine results to get [\"cat dog\", \"cat elephant\", \"cat dog\"]\r\n\r\n\r\nTask 1: Implement LSM-like disk-based inverted index that supports insertions.\r\n\r\nIn this task, you'll implement the disk file structure of an inverted index segment.\r\nWhen a document is added via `addDocument()`, it should be first stored in the in-memory buffer.\r\nWhenever the number of documents reached default_flush_threshold, or function `flush()` is called,\r\nyou should create a new inverted index segment with the documents in the buffer.\r\n\r\nThe specific format of the inverted lists should in general follow what Professor says in lecture.\r\nYou also have freedom to design the format to make it more efficient to store or search.\r\nIn principle, the terms can be loaded into memory, but all the posting lists cannot be entirely loaded into memory.\r\n\r\nFunctions to implement, see each function signature to check the details:\r\n{@link this#addDocument};\r\n{@link this#flush};\r\n{@link this#documentIterator};\r\n{@link this#getNumSegments};\r\n{@link this#getIndexSegment};\r\n\r\n\r\nTask 2: Implement merge of inverted index segments.\r\n\r\nIn this task, you'll implement merging index segments. We cannot let number of segments grow infinitely because it\r\nwould mean searching a keyword needs to go through a lot of documents.\r\n\r\nWhenever the number of segments has reached the default_merge_threshold, or `mergeAllSegments()` is called,\r\nyou need to merge *all* segments in the inverted index pair-wise.\r\nYou could assume merging only happens when you have an even number of segments.\r\n\r\nWhen merging two segments into one, since each segment has its own local document ID, you need to bump up all\r\ndocument IDs in one of the segments.\r\nAs an example, Segment0 contains local docID 1-100, Segment1 contains local docID 1-100,\r\nfirst find the max docID in Segment0, which is 100, then bump up Segment1's docIDs to become 101-200, then do the merge.\r\n\r\nFunctions to implement:\r\n{@link this#mergeAllSegments}\r\n\r\n\r\nTask 3: Implement keyword search, boolean AND search, and boolean OR search.\r\n\r\nIn this task, you'll implement searching on top of the inverted index.\r\nYou could assume all documents are flushed to disk index segments when doing search.\r\n\r\nFor a query keyword, you need to first analyze it using the analyzer.\r\nYou could assume after tokenization and stemming, the result only has 1 token, or is empty (such as the query is a stop ord).\r\nIf the query is empty, searching should not return any results.\r\n\r\nFunctions to implement:\r\n{@link this#searchQuery}\r\n{@link this#searchAndQuery}\r\n{@link this#searchOrQuery}\r\n\r\nTask 4 (Optional Extra Credit): Implement deletions.\r\n\r\nIn our LSM-like index structure, deletion is implemented by maintaining a separate deletion marks per segment.\r\nThe document is not actually deleted in the inverted index nor document store.\r\nWhen reading or searching, the docID is checked with the deletion mark to see if the document is deleted.\r\n\r\nThe document should be deleted when merging two index segments.\r\n\r\nFunctions to implement:\r\n{@link this#deleteDocuments}\r\n\r\nTask 5 (Optional Extra Credit): Implement compression\r\n", "encoding": "ascii"}