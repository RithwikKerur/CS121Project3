{"url": "http://sli.ics.uci.edu/Classes-CS178-Notes/Matlab-Classes", "content": "<!DOCTYPE html \n    PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \n    \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n<html>\n<head>\n  <title>SLI | Classes-CS178-Notes / Matlab-Classes </title>\n  <meta http-equiv='Content-Style-Type' content='text/css' />\n  <link rel='stylesheet' href='http://sli.ics.uci.edu/pmwiki/pub/skins/custom/pmwiki.css' type='text/css' />\n  <!--HTMLHeader--><style type='text/css'><!--\n  ul, ol, pre, dl, p { margin-top:0px; margin-bottom:0px; }\n  code.escaped { white-space: nowrap; }\n  .vspace { margin-top:1.33em; }\n  .indent { margin-left:40px; }\n  .outdent { margin-left:40px; text-indent:-40px; }\n  a.createlinktext { text-decoration:none; border-bottom:1px dotted gray; }\n  a.createlink { text-decoration:none; position:relative; top:-0.5em;\n    font-weight:bold; font-size:smaller; border-bottom:none; }\n  img { border:0px; }\n  .editconflict { color:green; \n  font-style:italic; margin-top:1.33em; margin-bottom:1.33em; }\n\n  table.markup { border:2px dotted #ccf; width:90%; }\n  td.markup1, td.markup2 { padding-left:10px; padding-right:10px; }\n  table.vert td.markup1 { border-bottom:1px solid #ccf; }\n  table.horiz td.markup1 { width:23em; border-right:1px solid #ccf; }\n  table.markup caption { text-align:left; }\n  div.faq p, div.faq pre { margin-left:2em; }\n  div.faq p.question { margin:1em 0 0.75em 0; font-weight:bold; }\n  div.faqtoc div.faq * { display:none; }\n  div.faqtoc div.faq p.question \n    { display:block; font-weight:normal; margin:0.5em 0 0.5em 20px; line-height:normal; }\n  div.faqtoc div.faq p.question * { display:inline; }\n   \n    .frame \n      { border:1px solid #cccccc; padding:4px; background-color:#f9f9f9; }\n    .lfloat { float:left; margin-right:0.5em; }\n    .rfloat { float:right; margin-left:0.5em; }\na.varlink { text-decoration:none;}\n\n--></style>  <meta name='robots' content='index,follow' />\n\n</head>\n<body>\n<!--PageHeaderFmt-->\n  <div id='wikilogo'><a href='http://sli.ics.uci.edu'><img src='/pmwiki/pub/skins/custom/SLI_white.png'\n    alt='SLI' border='0' /></a></div>\n  <div id='wikihead'>\n  <form action='http://sli.ics.uci.edu'>\n    <!-- <span class='headnav'><a href='http://sli.ics.uci.edu/Classes-CS178-Notes/RecentChanges'\n      accesskey='c'>Recent Changes</a> -</span> --> \n    <input type='hidden' name='n' value='Classes-CS178-Notes.Matlab-Classes' />\n    <input type='hidden' name='action' value='search' />\n    <!-- <a href='http://sli.ics.uci.edu/Site/Search'>Search</a>: -->\n    <input type='text' name='q' value='' class='inputbox searchbox' />\n    <input type='submit' class='inputbutton searchbutton'\n      value='Search' />\n    <a href='http://sli.ics.uci.edu/Site/Search'>(?)</a>\n  </form></div>\n<!--/PageHeaderFmt-->\n  <table id='wikimid' width='100%' cellspacing='0' cellpadding='0'><tr>\n<!--PageLeftFmt-->\n      <td id='wikileft' valign='top'>\n        <ul><li><a class='wikilink' href='http://sli.ics.uci.edu/Classes/Classes'>Classes</a>\n</li><li><a class='wikilink' href='http://sli.ics.uci.edu/Group/Group'>Group</a>\n</li><li><a class='wikilink' href='http://sli.ics.uci.edu/Projects/Projects'>Research</a>\n</li><li><a class='urllink' href='http://www.ics.uci.edu/~ihler/pubs.html' rel='nofollow'>Publications</a>\n</li><li><a class='wikilink' href='http://sli.ics.uci.edu/Code/Code'>Code</a>\n</li></ul><div class='vspace'></div><hr />\n<div class='vspace'></div>\n</td>\n<!--/PageLeftFmt-->\n      <td id='wikibody' valign='top'>\n<!--PageActionFmt-->\n        <div id='wikicmds'><ul><li class='browse'><a class='wikilink' href='http://sli.ics.uci.edu/Classes-CS178-Notes/Matlab-Classes?action=login'>login</a>\n</li></ul>\n</div>\n<!--PageTitleFmt-->\n        <div id='wikititle'>\n          <div class='pagegroup'><a href='http://sli.ics.uci.edu/Classes-CS178-Notes'>Classes-CS178-Notes</a> /</div>\n          <h1 class='pagetitle'>Matlab-Classes</h1></div>\n<!--PageText-->\n<div id='wikitext'>\n<h2>Matlab Object-Oriented Programming and Classes</h2>\n<p>Matlab object-oriented programming is a bit awkward and unlike most other\nOO languages, but still has some of the elements that make OO programming\nuseful.  Here I will describe some aspects of Matlab objects, using a class\nto construct a k-nearest neighbor classifier as a working example.\n</p>\n<div class='vspace'></div><h3>Getting started</h3>\n<p>First, download the course code into a directory, say,\n<code>~ihler/Code/cs178/</code>.\nYou should see a number of files and directories created there;\nfor the purposes of this handout, the relevant directory to have is the\n<code>@knnClassify</code> directory, which contains the files for the\nclassifier.\n</p>\n<p class='vspace'>You should make sure you are either in the directory you downloaded the\nfiles to, or add it to your Matlab path.  For example, use\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre> &gt;&gt; addpath ~ihler/Code/cs178\n</pre></div>\n<p>to add that directory to Matlab's path.  Note that you should <em>not</em>\nbe <em>in</em> the <code>@knnClassify</code> directory, nor should you add\nit to the path -- only its parent directory.\n</p>\n<p class='vspace'>We will use \"old style\" Matlab objects, which consist of a directory\n(@-something), which uses one file per member function (private functions\ngo in a further subdirectory called <code>private</code>).  While there are\nsome drawbacks to this type of object (and Matlab has since updated\ntheir object representations to be more flexible and give them\nmore capabilities), this is the type\nthat is also compatible with Octave, which is useful also.\n</p>\n<div class='vspace'></div><h3>Using the class</h3>\n<p>To create an object of the class type, you can simply call the constructor.\nTo find out its usage, use <code>help</code>:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre> &gt;&gt; help knnClassify\n  knnClassify(X,Y,...) : create k-nearest-neighbors classifier\n  takes no arguments, or training data to be used in constructing the classifier\n  alpha: weighted average coefficient (Gaussian weighting); alpha=0 =&gt; simple average\n</pre></div>\n<p>and we can then use it:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre> &gt;&gt; Xtr = rand(5,3),     <span  style='color: green;'> % Create feature matrix of 5 data points with 3 features each </span>\n Xtr =                   <span  style='color: green;'> %  (just in case you want to use the same numbers I do...) </span>\n    0.4898    0.2760    0.4984 \n    0.4456    0.6797    0.9597 \n    0.6463    0.6551    0.3404\n    0.7094    0.1626    0.5853\n    0.7547    0.1190    0.2238\n &gt;&gt; Ytr = [0 0 0 1 1]';  <span  style='color: green;'> % and a corresponding Ytrain of target classes </span>\n &gt;&gt; knn = knnClassify(Xtr,Ytr,3),   <span  style='color: green;'> % Create 3-nearest-nbr classifier with those data</span>\n KNN Classifier, 2 classes, K=3\n</pre></div>\n<p class='vspace'>Now, to find out what methods are available for a given class,\nwe can use the <code>methods</code> command to list them:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre> &gt;&gt; methods knnClassify\n Methods for class knnClassify:\n\n auc          err          predict      setClasses   \n confusion    getClasses   predictSoft  setK         \n display      knnClassify  roc          train        \n</pre></div>\n<p>Our most typical operations will be <code>train</code> and <code>predict</code>, which\ntrain a model on training data, and predict the current model on new data, respectively.\nTypically, when constructor functions accept training data, they simply call the\n<code>train</code> function.\nTo see what parameters <code>train</code> takes, we need to differentiate <em>which</em>\ntrain we mean:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre> &gt;&gt; help knnClassify/train\n   knn=train(knn,Xtrain,Ytrain) : Batch training for knn; just memorize data\n</pre></div>\n<p class='vspace'>Using this calling pattern, we can re-train the model with e.g.,\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre> &gt;&gt; knn = train(knn, Xtr,Ytr);\n</pre></div>\n<p>and predict with\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre> &gt;&gt; Xte = rand(2,3),               <span  style='color: green;'> % Make two test data points (same # of features!)</span>\n Xte =\n    0.7513    0.5060    0.8909\n    0.2551    0.6991    0.9593\n &gt;&gt; Yte = [0 1]';                  <span  style='color: green;'> %   and some test target values for goot measure</span>\n &gt;&gt; Yhat= predict(knn,Xte),        <span  style='color: green;'> % Make prediction for those points:</span>\n Yhat =\n     0\n     0\n</pre></div>\n<p>Two points are worth noting: First, member functions are typically called by\npassing the object as the first argument of the function.  They can also be\ncalled in a more typical format, <code>knn.train(Xtr,Ytr)</code>, but both are\nimplemented in exactly the same way.\n</p>\n<p class='vspace'>Second, functions that modify the class in some way (such as <code>train</code>)\nshould actually return (and set) the object variable.  Matlab cannot generally\nupdate variables by reference (recent object changes relax this point), and\nso the object must be returned in order to modify it.\n</p>\n<p class='vspace'>We can also use accessor functions to get or set object properties, such as:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre> &gt;&gt; knn = setK(knn, 1),            <span  style='color: green;'> % Change to a 1-nearest nbr classifier</span>\n KNN Classifier, 2 classes, K=1\n</pre></div>\n<p>Again, we actually return the modified object variable, and set <code>kdd</code>\nto be equal to the returned value.\n</p>\n<div class='vspace'></div><h3>The object constructor</h3>\n<p>Let's take a closer look at how the constructor function\n<code>knnClassify.m</code> works.  First, here is the file header:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre> function obj = knnClassify(Xtr,Ytr,K)\n <span  style='color: green;'> % knnClassify([X,Y,K]) : create k-nearest-neighbors classifier</span>\n <span  style='color: green;'> % takes no arguments, or training data to be used in constructing the classifier</span>\n</pre></div>\n<p>The first line declares the function itself, and any returned variables.\nThe first set of comments in the file are output for the help\ncommand (<code>help knnClassify</code>), and should contain basic usage information.\n</p>\n<p class='vspace'>Default values are a bit awkward; typically, you can check how many variables\nwere passed in and fill in any missing ones (positional defaults):\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre>   if (nargin &lt; 3) K = 1; end;\n</pre></div>\n<p>Another typical approach is to require that the caller pass an empty matrix,\nwhich can be tested for and filled in with a default value.\n</p>\n<p class='vspace'>The basic form of an object is simply a Matlab structure with a bit of extra\ngloss on top; we declare the member variables as if it were a structure, and\nthen call a function to define it as a class:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre>   obj.K=K; obj.Xtrain=[]; obj.Ytrain=[]; obj.classes=[];\n   obj=class(obj,'knnClassify');\n</pre></div>\n<p>I usually do this immediately with empty values, since the variable fields\nmust always be declared in the same order.  Note also that return values are\nspecified by name, so if <code>obj</code> is listed as the return variable, whatever\nvariable is called <code>obj</code> when the function ends is returned.\n</p>\n<p class='vspace'>I typically also allow <code>train</code> to be called automatically by just passing\nthe data into the constructor:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre>   if (nargin &gt; 0)\n     obj = train(obj,Xtr,Ytr);\n     obj = setK(obj,K);\n   end;\n</pre></div>\n<p>Or, these can be called manually after.\n</p>\n<p class='vspace'>As an aside, Matlab objects can be converted into structures, allowing their\ninternal data to be accessed by anyone:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre> &gt;&gt; s = struct(knn),\n s = \n          K: 1\n     Xtrain: [5x3 double]\n     Ytrain: [5x1 double]\n    classes: [2x1 double]\n</pre></div>\n<p>This can be useful if you're trying to access something in an object while debugging,\nbut is usually non-reversible, i.e., it is difficult to modify <code>s</code> and transform it\nback to an object afterwards.\n</p>\n<div class='vspace'></div><h3>The <code>train</code> function</h3>\n<p>Training for a k-nearest neighbor classifier is trivial; we simply memorize the data:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre> function obj=train(obj, Xtr,Ytr)\n <span  style='color: green;'> % knn=train(knn,Xtrain,Ytrain) : Batch training for knn; just memorize data</span>\n   obj.Xtrain = Xtr;\n   obj.Ytrain = Ytr;\n   obj.classes= unique(Ytr);\n</pre></div>\n<p>One minor point -- I always keep a column vector <code>obj.classes</code> in each classifier.\nThe internal implementation of the classifier predicts a positive integer <img class='TrueLatexImage' style='vertical-align:middle;' border=0 src=\"http://sli.ics.uci.edu/pmwiki/pub/latexcache/3fa649761d69091d3b08de5566039e5e.png\" />,\nand then returns <code>obj.classes(c)</code>.  This way, the class values can be\nnon-consecutive, non-standard, and even of different Matlab types (characters or whatever)\nwithout any difficulty.  Some classifiers are implemented specifically for binary\nclassification problems, in which case we can simply check that the number of classes is only\ntwo.\n</p>\n<div class='vspace'></div><h3>The <code>predict</code> function</h3>\n<p>In order to predict with a k-nearest neighbor classifier, we simply search the stored\ntraining data for the nearest points, in terms of their sum of squared differences.\nThe file header,\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre> function Yte = predict(obj,Xte)\n <span  style='color: green;'> % Yhat = predict(knn, Xtest) : make a nearest-neighbor prediction on test data  </span>\n\n   [Ntr,Mtr] = size(obj.Xtrain);          <span  style='color: green;'> % get size of training, test data</span>\n   [Nte,Mte] = size(Xte);\n   K = min(obj.K, Ntr);                   <span  style='color: green;'> % can't have more than Ntrain neighbors</span>\n   Yte = repmat(obj.Ytrain(1), [Nte,1]);  <span  style='color: green;'> % make Ytest the same data type as Ytrain</span>\n</pre></div>\n<p>gets the number of training and test data, and their dimensions ($M$, which should be the\nsame for both), and makes sure $K$ is valid.  We pre-initialize <code>Yte</code> by\ncopying (<code>repmat</code> = repeat matrix) one of the training data to the correct size;\npre-allocating the correct vector size helps Matlab avoid constantly re-allocating\nmemory for <code>Yte</code>,\nand using <code>repmat</code> ensures it has the right variable type.\n</p>\n<p class='vspace'>Next, for each test data point, we compute the distance from all training data,\nfor example:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre>   for i=1:Nte,                <span  style='color: green;'> % For each test example:</span>\n     dist=zeros(Ntr,1);        <span  style='color: green;'> % pre-allocate a distance vector</span>\n     for j=1:Ntr,              <span  style='color: green;'> % and compute distance from all Ntr training data</span>\n       dist(j)=sum( (obj.Xtrain(j,:)-Xte(i,:)).^2 ); \n     end;\n   end;\n</pre></div>\n<p>However, this turns out to be awfully slow; Matlab is interpreted, and often has\ntrouble performing for-loops quickly.  For better performance, you may\nlearn to ``vectorize'' your calculations, performing them all in one step:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre>   dist = sum( (obj.Xtrain - repmat(Xte(i,:),[Ntr,1]) ).^2 , 2);\n</pre></div>\n<p>This copies the <code>Xte</code> data point to be the same size as <code>Xtrain</code>,\nthen subtracts the two matrices, squares the entries (element-wise), and sums\nthem over their 2nd dimension (the features), leaving a column-vector of distances\nexactly like the for-loop above.  Even harder to read but slightly faster still\nis to use the <code>bsxfun</code> function, which performs operators on differently-sized\nmatrices (so that you don't need to use <code>repmat</code> to copy the data point):\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre>   dist = sum( bsxfun( @minus, obj.Xtrain, Xte(i,:) ).^2 , 2);\n</pre></div>\n<p>All this is useful if you are finding Matlab very slow, but takes a while to get used to.\n</p>\n<p class='vspace'>Finally, we find the $K$ nearest data examples, and find the majority vote among them:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre>   [dst,idx] = sort(dist);       <span  style='color: green;'> % find nearest neighbors over Xtrain</span>\n   idx=idx(1:K);                 <span  style='color: green;'> % keep nearest K data points</span>\n   nClasses=length(obj.classes);\n   count = zeros(1,nClasses);    <span  style='color: green;'> % count up how many in each class</span>\n   for c=1:nClasses, count(c)=sum( obj.Ytrain(idx)==obj.classes(c) ); end;\n   [nil cMax] = max(count);      <span  style='color: green;'> % find the (position of the) largest #</span>\n   Yte(i) = obj.classes(cMax);   <span  style='color: green;'> % and save the prediction</span>\n</pre></div>\n<p>A useful trick here -- both <code>sort</code> and <code>max</code> can return both the\nsorted / maximum value (first return value) <em>and</em> the position of those values\n(as the second return value).  So <code>idx</code> is a list of the training data points\nin order from nearest to farthest, and <code>cMax</code> is the index of the class with\nthe largest <code>count</code> value.\n</p>\n<p class='vspace'>Also, <code>obj.Ytrain(idx)==obj.classes(c)</code> is a binary vector, with \"1\"\nwhen the equality condition is satisified and \"0\" if not.  Then, <code>sum</code>\ncounts up the number of \"1\" entries.\n</p>\n<div class='vspace'></div><h3>Measuring errors</h3>\n<p>A few functions are common to almost all predictors; for example,\nfrequently, we want to evalute the error rate, measuring how often our model makes\nincorrect predictions on a data set (e.g., the training or validation error).\nFunctions like <code>err</code> do this easily:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre> &gt;&gt; J = err(knn, Xte, Yte),       <span  style='color: green;'> % evalute the empirical error rate on these data</span>\n J = \n     0.5000\n</pre></div>\n<p>To get more information, we may want to look at the confusion matrix:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre> &gt;&gt; C = confusion(knn, Xte, Yte), <span  style='color: green;'> % evalute the confusion matrix:</span>\n C =                             \n      1     0                    <span  style='color: green;'> % one true class zero (column), predicted 0 (row)</span>\n      1     0                    <span  style='color: green;'> % one true class zero (column), predicted 1 (row)</span>\n</pre></div>\n<p>Similar functions (<code>mse</code>, etc.) are found in regression classes.\n</p>\n<p class='vspace'>Many classifiers also support <em>soft</em> predictions, which express some level\nof confidence in the possible outcomes.  For example, in kNN, we might return\nthe fraction of the $K$ neighbors in each class (rather than just the decision);\n<code>predictSoft</code> returns a length-<code>nClasses</code> vector of such confidences\nfor each data point:\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre> &gt;&gt; knn = setK(knn, 3);           <span  style='color: green;'> % poinless for k=1...</span>\n &gt;&gt; ySoft = predictSoft(knn,Xte), <span  style='color: green;'> % make soft predictions:</span>\n ySoft =\n     0.6667    0.3333            <span  style='color: green;'> % test point 1 has 66% confidence in class 0</span>\n     1.0000         0            <span  style='color: green;'> % test point 2 has 100% confidence in class 0</span>\n</pre></div>\n<p>These soft scores are useful in computing, for example, ROC curves\n(note that this only works for binary classifications):\n</p><div class='Matlab' style='padding:5px; border:1px solid black; background-color:#dddddd' >\n<pre>  [fpr,tpr,tnr] = roc(knn,Xte,Yte);  <span  style='color: green;'> % find info for ROC curve:</span>\n  plot(fpr,tpr,'-');            <span  style='color: green;'> % (not very interesting for these data, though...)</span>\n</pre></div>\n<p>and the area under the curve can be computed with <code>auc.m</code>.\n</p>\n<div class='vspace'></div>\n</div>\n\n      </td>\n    </tr></table>\n<!--PageFooterFmt-->\n  <div id='wikifoot'>\n    <div class='footnav' style='float:left'> Last modified January 05, 2015, at 12:06 PM</div>\n    <div class='footnav' style='float:right; text-align:right'>\n    <a href=\"http://www.ics.uci.edu\">Bren School of Information and Computer Science</a><br>\n    <a href=\"http://www.uci.edu\">University of California, Irvine</a>\n    </div>\n  </div>\n<!--HTMLFooter--><script type=\"text/javascript\">\n  var _gaq = _gaq || [];\n  _gaq.push([\"_setAccount\", \"UA-24148957-2\"]);\n\t_gaq.push([\"_trackPageview\"]);\n\t(function() {\n\t  var ga = document.createElement(\"script\"); ga.type = \"text/javascript\"; ga.async = true;\n\t  ga.src = (\"https:\" == document.location.protocol ? \"https://ssl\" : \"http://www\") + \".google-analytics.com/ga.js\";\n\t  var s = document.getElementsByTagName(\"script\")[0]; s.parentNode.insertBefore(ga, s);\n\t  })();\n</script>\n</body>\n</html>\n", "encoding": "ascii"}