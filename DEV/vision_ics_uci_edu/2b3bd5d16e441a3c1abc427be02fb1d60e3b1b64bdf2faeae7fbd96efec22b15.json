{"url": "http://vision.ics.uci.edu/papers/ParkR_CVPR_2015/", "content": "\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n<html>\n<head>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n  <title>Computational Vision | ICS | UC Irvine</title>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"/stylesheets/screen.css\" media=\"all\">\n</head>\n\n<body id=\"publications\">\n  <div id=\"outerframe\">\n  <div id=\"header\">\n    <h1>Computational Vision at UC Irvine &nbsp;<img src=\"/images/eye_small.jpg\" alt=\"small eye\"></h1>\n  </div>\n  <div id=\"tabs\">\n    <ul id=\"tabnav\">\n      <li id=\"home_tab\"><a href=\"/index.html\">home</a></li>\n      <li id=\"projects_tab\"><a href=\"/projects.html\">projects</a></li>\n      <li id=\"people_tab\"><a href=\"/people.html\">people</a></li>\n      <li id=\"publications_tab\"><a href=\"/publications.html\">publications</a></li>\n      <li id=\"datasets_tab\"><a href=\"/datasets/index.html\">datasets</a></li>\n      <li id=\"events_tab\"><a href=\"/events.html\">events</a></li>\n      <li id=\"courses_tab\"><a href=\"/courses.html\">courses</a></li>\n      <li id=\"contact_tab\"><a href=\"/contact.html\">contact</a></li>\n      <li id=\"links_tab\"><a href=\"/links.html\">links</a></li>\n    </ul>\n  </div>\n\n  <div id=\"content\">\n    <div id=\"paper_title\">Articulated Pose Estimation With Tiny Synthetic Videos</div>\n    <div id=\"paper_authors\"><a href=\"/people/29.html\">Dennis&nbsp;Park</a>, <a href=\"/people/20.html\">Deva&nbsp;Ramanan</a></div>\n    <div id=\"paper_abstract\">\n      <img src=\"icon_drop.jpg\" alt=\"icon\">\n      We address the task of articulated pose estimation from\nvideo sequences. We consider an interactive setting where\nthe initial pose is annotated in the first frame. Our system\nsynthesizes a large number of hypothetical scenes with\ndifferent poses and camera positions by applying geometric\ndeformations to the first frame. We use these synthetic\nimages to generate a custom labeled training set for the\nvideo in question. This training data is then used to learn\na regressor (for future frames) that predicts joint locations\nfrom image data. Notably, our training set is so accurate\nthat nearest-neighbor (NN) matching on low-resolution\npixel features works well. As such, we name our underlying\nrepresentation \u201ctiny synthetic videos\u201d. We present quantitative\nresults the Friends benchmark dataset that suggests\nour simple approach matches or exceed state-of-the-art.\n\n    </div>\n    <div id=\"bibtext\">\n      <h3>Download: <a href=\"/papers/ParkR_CVPR_2015/ParkR_CVPR_2015.pdf\">pdf</a></h3>\n      <h3>Text Reference</h3>\nDennis Park and Deva Ramanan.\nArticulated pose estimation with tiny synthetic videos.\nIn <em>The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops</em>. 2015.<br>\n<h3>BibTeX Reference</h3>\n@inproceedings{ParkR_CVPR_2015,<br>\n&nbsp;&nbsp;&nbsp;&nbsp;author = \"Park, Dennis and Ramanan, Deva\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;title = \"Articulated Pose Estimation With Tiny Synthetic Videos\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;booktitle = \"The IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;year = \"2015\"<br>\n}<br>\n    </div>\n  </div>\n  <div id=\"footer\">\n    <div>\n      <a href=\"/\">Computational Vision</a> |\n      <a href=\"http://www.ics.uci.edu/\">School of Information and Computer Sciences</a> |\n      <a href=\"http://www.uci.edu/\">UC Irvine</a>\n    </div>\n    <div id=\"updated\">&copy; 2007-2017 UC Irvine</div>\n  </div>\n  </div>\n</body>\n</html>\n\n", "encoding": "utf-8"}