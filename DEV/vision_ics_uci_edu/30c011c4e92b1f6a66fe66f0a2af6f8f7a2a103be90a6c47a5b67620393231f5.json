{"url": "http://vision.ics.uci.edu/papers/RogezSR_CVPR_2015/", "content": "\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n<html>\n<head>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n  <title>Computational Vision | ICS | UC Irvine</title>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"/stylesheets/screen.css\" media=\"all\">\n</head>\n\n<body id=\"publications\">\n  <div id=\"outerframe\">\n  <div id=\"header\">\n    <h1>Computational Vision at UC Irvine &nbsp;<img src=\"/images/eye_small.jpg\" alt=\"small eye\"></h1>\n  </div>\n  <div id=\"tabs\">\n    <ul id=\"tabnav\">\n      <li id=\"home_tab\"><a href=\"/index.html\">home</a></li>\n      <li id=\"projects_tab\"><a href=\"/projects.html\">projects</a></li>\n      <li id=\"people_tab\"><a href=\"/people.html\">people</a></li>\n      <li id=\"publications_tab\"><a href=\"/publications.html\">publications</a></li>\n      <li id=\"datasets_tab\"><a href=\"/datasets/index.html\">datasets</a></li>\n      <li id=\"events_tab\"><a href=\"/events.html\">events</a></li>\n      <li id=\"courses_tab\"><a href=\"/courses.html\">courses</a></li>\n      <li id=\"contact_tab\"><a href=\"/contact.html\">contact</a></li>\n      <li id=\"links_tab\"><a href=\"/links.html\">links</a></li>\n    </ul>\n  </div>\n\n  <div id=\"content\">\n    <div id=\"paper_title\">First-Person Pose Recognition using Egocentric Workspaces</div>\n    <div id=\"paper_authors\"><a href=\"/people/7.html\">Gr\u00e9gory&nbsp;Rogez</a>, <a href=\"/people/10.html\">James&nbsp;Supan\u010di\u010d</a>, <a href=\"/people/20.html\">Deva&nbsp;Ramanan</a></div>\n    <div id=\"paper_abstract\">\n      <img src=\"icon_drop.jpg\" alt=\"icon\">\n      We tackle the problem of estimating the 3D pose of an individual\u2019s\nupper limbs (arms+hands) from a chest mounted\ndepth-camera. Importantly, we consider pose estimation\nduring everyday interactions with objects. Past work shows\nthat strong pose+viewpoint priors and depth-based features\nare crucial for robust performance. In egocentric views,\nhands and arms are observable within a well defined volume\nin front of the camera. We call this volume an egocentric\nworkspace. A notable property is that hand appearance\ncorrelates with workspace location. To exploit this correlation,\nwe classify arm+hand configurations in a global egocentric\ncoordinate frame, rather than a local scanning window.\nThis greatly simplify the architecture and improves\nperformance. We propose an efficient pipeline which 1) generates\nsynthetic workspace exemplars for training using a\nvirtual chest-mounted camera whose intrinsic parameters\nmatch our physical camera, 2) computes perspective-aware\ndepth features on this entire volume and 3) recognizes discrete\narm+hand pose classes through a sparse multi-class\nSVM. We achieve state-of-the-art hand pose recognition\nperformance from egocentric RGB-D images in real-time.\n\n    </div>\n    <div id=\"bibtext\">\n      <h3>Download: <a href=\"/papers/RogezSR_CVPR_2015/RogezSR_CVPR_2015.pdf\">pdf</a></h3>\n      <h3>Text Reference</h3>\nGr\u00e9gory Rogez, James&nbsp;S. Supan\\vc i\\vc &nbsp;III, and Deva Ramanan.\nFirst-person pose recognition using egocentric workspaces.\nIn <em>CVPR</em>. 2015.<br>\n<h3>BibTeX Reference</h3>\n@inproceedings{RogezSR_CVPR_2015,<br>\n&nbsp;&nbsp;&nbsp;&nbsp;AUTHOR = \"Rogez, Gr{\\'e}gory and Supan{\\vc}i{\\vc} III, James S. and Ramanan, Deva\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;TITLE = \"First-Person Pose Recognition using Egocentric Workspaces\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;BOOKTITLE = \"CVPR\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;YEAR = \"2015\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;tag = \"people\"<br>\n}<br>\n    </div>\n  </div>\n  <div id=\"footer\">\n    <div>\n      <a href=\"/\">Computational Vision</a> |\n      <a href=\"http://www.ics.uci.edu/\">School of Information and Computer Sciences</a> |\n      <a href=\"http://www.uci.edu/\">UC Irvine</a>\n    </div>\n    <div id=\"updated\">&copy; 2007-2017 UC Irvine</div>\n  </div>\n  </div>\n</body>\n</html>\n\n", "encoding": "utf-8"}