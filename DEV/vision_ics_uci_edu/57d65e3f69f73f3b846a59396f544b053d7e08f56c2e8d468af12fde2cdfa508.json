{"url": "http://vision.ics.uci.edu/papers/PirsiavashR_CVPR_2012_1/", "content": "\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n<html>\n<head>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n  <title>Computational Vision | ICS | UC Irvine</title>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"/stylesheets/screen.css\" media=\"all\">\n</head>\n\n<body id=\"publications\">\n  <div id=\"outerframe\">\n  <div id=\"header\">\n    <h1>Computational Vision at UC Irvine &nbsp;<img src=\"/images/eye_small.jpg\" alt=\"small eye\"></h1>\n  </div>\n  <div id=\"tabs\">\n    <ul id=\"tabnav\">\n      <li id=\"home_tab\"><a href=\"/index.html\">home</a></li>\n      <li id=\"projects_tab\"><a href=\"/projects.html\">projects</a></li>\n      <li id=\"people_tab\"><a href=\"/people.html\">people</a></li>\n      <li id=\"publications_tab\"><a href=\"/publications.html\">publications</a></li>\n      <li id=\"datasets_tab\"><a href=\"/datasets/index.html\">datasets</a></li>\n      <li id=\"events_tab\"><a href=\"/events.html\">events</a></li>\n      <li id=\"courses_tab\"><a href=\"/courses.html\">courses</a></li>\n      <li id=\"contact_tab\"><a href=\"/contact.html\">contact</a></li>\n      <li id=\"links_tab\"><a href=\"/links.html\">links</a></li>\n    </ul>\n  </div>\n\n  <div id=\"content\">\n    <div id=\"paper_title\">Detecting Activities of Daily Living in First-person Camera Views</div>\n    <div id=\"paper_authors\"><a href=\"/people/28.html\">Hamed&nbsp;Pirsiavash</a>, <a href=\"/people/20.html\">Deva&nbsp;Ramanan</a></div>\n    <div id=\"paper_abstract\">\n      <img src=\"icon_drop.jpg\" alt=\"icon\">\n      We present a novel dataset and novel algorithms for the problem of detecting activities of daily living (ADL) in first-person camera views. We have collected a dataset of 1 million frames of dozens of people performing unscripted, everyday activities. The dataset is annotated with activities, object tracks, hand positions, and interaction events. ADLs differ from typical actions in that they can involve long-scale temporal structure (making tea can take a few minutes) and complex object interactions (a fridge looks different when its door is open). We develop novel representations including (1) temporal pyramids, which generalize the well-known spatial pyramid to approximate temporal correspondence when scoring a model and (2) composite object models that exploit the fact that objects look different when being interacted with. We perform an extensive empirical evaluation and demonstrate that our novel representations produce a two-fold improvement over traditional approaches. Our analysis suggests that real-world ADL recognition is ``all about the objects,'' and in particular, ``all about the objects being interacted with.''\n\n\n    </div>\n    <div id=\"bibtext\">\n      <h3>Download: <a href=\"/papers/PirsiavashR_CVPR_2012_1/PirsiavashR_CVPR_2012_1.pdf\">pdf</a></h3>\n      <h3>Text Reference</h3>\nHamed Pirsiavash and Deva Ramanan.\nDetecting activities of daily living in first-person camera views.\nIn <em>Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on</em>. IEEE, 2012.<br>\n<h3>BibTeX Reference</h3>\n@inproceedings{PirsiavashR_CVPR_2012_1,<br>\n&nbsp;&nbsp;&nbsp;&nbsp;author = \"Pirsiavash, Hamed and Ramanan, Deva\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;title = \"Detecting Activities of Daily Living in First-person Camera Views\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;booktitle = \"Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;year = \"2012\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;organization = \"IEEE\"<br>\n}<br>\n    </div>\n  </div>\n  <div id=\"footer\">\n    <div>\n      <a href=\"/\">Computational Vision</a> |\n      <a href=\"http://www.ics.uci.edu/\">School of Information and Computer Sciences</a> |\n      <a href=\"http://www.uci.edu/\">UC Irvine</a>\n    </div>\n    <div id=\"updated\">&copy; 2007-2017 UC Irvine</div>\n  </div>\n  </div>\n</body>\n</html>\n\n", "encoding": "ascii"}