{"url": "http://vision.ics.uci.edu/papers/YangBKR_CVPR_2012/", "content": "\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n<html>\n<head>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n  <title>Computational Vision | ICS | UC Irvine</title>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"/stylesheets/screen.css\" media=\"all\">\n</head>\n\n<body id=\"publications\">\n  <div id=\"outerframe\">\n  <div id=\"header\">\n    <h1>Computational Vision at UC Irvine &nbsp;<img src=\"/images/eye_small.jpg\" alt=\"small eye\"></h1>\n  </div>\n  <div id=\"tabs\">\n    <ul id=\"tabnav\">\n      <li id=\"home_tab\"><a href=\"/index.html\">home</a></li>\n      <li id=\"projects_tab\"><a href=\"/projects.html\">projects</a></li>\n      <li id=\"people_tab\"><a href=\"/people.html\">people</a></li>\n      <li id=\"publications_tab\"><a href=\"/publications.html\">publications</a></li>\n      <li id=\"datasets_tab\"><a href=\"/datasets/index.html\">datasets</a></li>\n      <li id=\"events_tab\"><a href=\"/events.html\">events</a></li>\n      <li id=\"courses_tab\"><a href=\"/courses.html\">courses</a></li>\n      <li id=\"contact_tab\"><a href=\"/contact.html\">contact</a></li>\n      <li id=\"links_tab\"><a href=\"/links.html\">links</a></li>\n    </ul>\n  </div>\n\n  <div id=\"content\">\n    <div id=\"paper_title\">Recognizing proxemics in personal photos</div>\n    <div id=\"paper_authors\"><a href=\"/people/24.html\">Yi&nbsp;Yang</a>, Simon&nbsp;Baker, Anitha&nbsp;Kannan, <a href=\"/people/20.html\">Deva&nbsp;Ramanan</a></div>\n    <div id=\"paper_abstract\">\n      <img src=\"icon_drop.jpg\" alt=\"icon\">\n      Proxemics is the study of how people interact. We\npresent a computational formulation of visual proxemics by\nattempting to label each pair of people in an image with a\nsubset of physically-based \u201ctouch codes.\u201d A baseline\napproach would be to first perform pose estimation and then\ndetect the touch codes based on the estimated joint locations.\nWe found that this sequential approach does not perform\nwell because pose estimation step is too unreliable for\nimages of interacting people, due to difficulties with\nocclusion and limb ambiguities. Instead, we propose a direct\napproach where we build an articulated model tuned for\neach touch code. Each such model contains two people,\nconnected in an appropriate manner for the touch code in\nquestion. We fit this model to the image and then base\nclassification on the fitting error. Experiments show that this\napproach significantly outperforms the sequential baseline\nas well as other related approaches.\n\n    </div>\n    <div id=\"bibtext\">\n      <h3>Download: <a href=\"/papers/YangBKR_CVPR_2012/YangBKR_CVPR_2012.pdf\">pdf</a></h3>\n      <h3>Text Reference</h3>\nYi&nbsp;Yang, Simon Baker, Anitha Kannan, and Deva Ramanan.\nRecognizing proxemics in personal photos.\nIn <em>CVPR</em>, 3522&ndash;3529. 2012.<br>\n<h3>BibTeX Reference</h3>\n@inproceedings{YangBKR_CVPR_2012,<br>\n&nbsp;&nbsp;&nbsp;&nbsp;author = \"Yang, Yi and Baker, Simon and Kannan, Anitha and Ramanan, Deva\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;title = \"Recognizing proxemics in personal photos\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;booktitle = \"CVPR\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;year = \"2012\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;pages = \"3522-3529\"<br>\n}<br>\n    </div>\n  </div>\n  <div id=\"footer\">\n    <div>\n      <a href=\"/\">Computational Vision</a> |\n      <a href=\"http://www.ics.uci.edu/\">School of Information and Computer Sciences</a> |\n      <a href=\"http://www.uci.edu/\">UC Irvine</a>\n    </div>\n    <div id=\"updated\">&copy; 2007-2017 UC Irvine</div>\n  </div>\n  </div>\n</body>\n</html>\n\n", "encoding": "utf-8"}