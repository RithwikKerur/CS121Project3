{"url": "http://vision.ics.uci.edu/papers/PirsiavashR_CVPR_2014/", "content": "\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n<html>\n<head>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n  <title>Computational Vision | ICS | UC Irvine</title>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"/stylesheets/screen.css\" media=\"all\">\n</head>\n\n<body id=\"publications\">\n  <div id=\"outerframe\">\n  <div id=\"header\">\n    <h1>Computational Vision at UC Irvine &nbsp;<img src=\"/images/eye_small.jpg\" alt=\"small eye\"></h1>\n  </div>\n  <div id=\"tabs\">\n    <ul id=\"tabnav\">\n      <li id=\"home_tab\"><a href=\"/index.html\">home</a></li>\n      <li id=\"projects_tab\"><a href=\"/projects.html\">projects</a></li>\n      <li id=\"people_tab\"><a href=\"/people.html\">people</a></li>\n      <li id=\"publications_tab\"><a href=\"/publications.html\">publications</a></li>\n      <li id=\"datasets_tab\"><a href=\"/datasets/index.html\">datasets</a></li>\n      <li id=\"events_tab\"><a href=\"/events.html\">events</a></li>\n      <li id=\"courses_tab\"><a href=\"/courses.html\">courses</a></li>\n      <li id=\"contact_tab\"><a href=\"/contact.html\">contact</a></li>\n      <li id=\"links_tab\"><a href=\"/links.html\">links</a></li>\n    </ul>\n  </div>\n\n  <div id=\"content\">\n    <div id=\"paper_title\">Parsing videos of actions with segmental grammars</div>\n    <div id=\"paper_authors\"><a href=\"/people/28.html\">Hamed&nbsp;Pirsiavash</a>, <a href=\"/people/20.html\">Deva&nbsp;Ramanan</a></div>\n    <div id=\"paper_abstract\">\n      <img src=\"icon_drop.jpg\" alt=\"icon\">\n      Real-world videos of human activities exhibit temporal\nstructure at various scales; long videos are typically composed\nout of multiple action instances, where each instance\nis itself composed of sub-actions with variable durations\nand orderings. Temporal grammars can presumably model\nsuch hierarchical structure, but are computationally difficult\nto apply for long video streams. We describe simple\ngrammars that capture hierarchical temporal structure\nwhile admitting inference with a finite-state-machine. This\nmakes parsing linear time, constant storage, and naturally\nonline. We train grammar parameters using a latent structural\nSVM, where latent subactions are learned automatically.\nWe illustrate the effectiveness of our approach over\ncommon baselines on a new half-million frame dataset of\ncontinuous YouTube videos.\n\n    </div>\n    <div id=\"bibtext\">\n      <h3>Download: <a href=\"/papers/PirsiavashR_CVPR_2014/PirsiavashR_CVPR_2014.pdf\">pdf</a></h3>\n      <h3>Text Reference</h3>\nHamed Pirsiavash and Deva Ramanan.\nParsing videos of actions with segmental grammars.\nIn <em>Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on</em>, 612\u00e2\u20ac\u201c619. IEEE, 2014.<br>\n<h3>BibTeX Reference</h3>\n@inproceedings{PirsiavashR_CVPR_2014,<br>\n&nbsp;&nbsp;&nbsp;&nbsp;author = \"Pirsiavash, Hamed and Ramanan, Deva\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;title = \"Parsing videos of actions with segmental grammars\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;booktitle = \"Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;pages = \"612--619\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;year = \"2014\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;organization = \"IEEE\"<br>\n}<br>\n    </div>\n  </div>\n  <div id=\"footer\">\n    <div>\n      <a href=\"/\">Computational Vision</a> |\n      <a href=\"http://www.ics.uci.edu/\">School of Information and Computer Sciences</a> |\n      <a href=\"http://www.uci.edu/\">UC Irvine</a>\n    </div>\n    <div id=\"updated\">&copy; 2007-2017 UC Irvine</div>\n  </div>\n  </div>\n</body>\n</html>\n\n", "encoding": "Windows-1252"}