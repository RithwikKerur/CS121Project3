{"url": "http://vision.ics.uci.edu/papers/RogezSR_ICCV_2015/", "content": "\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n<html>\n<head>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n  <title>Computational Vision | ICS | UC Irvine</title>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"/stylesheets/screen.css\" media=\"all\">\n</head>\n\n<body id=\"publications\">\n  <div id=\"outerframe\">\n  <div id=\"header\">\n    <h1>Computational Vision at UC Irvine &nbsp;<img src=\"/images/eye_small.jpg\" alt=\"small eye\"></h1>\n  </div>\n  <div id=\"tabs\">\n    <ul id=\"tabnav\">\n      <li id=\"home_tab\"><a href=\"/index.html\">home</a></li>\n      <li id=\"projects_tab\"><a href=\"/projects.html\">projects</a></li>\n      <li id=\"people_tab\"><a href=\"/people.html\">people</a></li>\n      <li id=\"publications_tab\"><a href=\"/publications.html\">publications</a></li>\n      <li id=\"datasets_tab\"><a href=\"/datasets/index.html\">datasets</a></li>\n      <li id=\"events_tab\"><a href=\"/events.html\">events</a></li>\n      <li id=\"courses_tab\"><a href=\"/courses.html\">courses</a></li>\n      <li id=\"contact_tab\"><a href=\"/contact.html\">contact</a></li>\n      <li id=\"links_tab\"><a href=\"/links.html\">links</a></li>\n    </ul>\n  </div>\n\n  <div id=\"content\">\n    <div id=\"paper_title\">Understanding Everyday Hands in Action from RGB-D Images</div>\n    <div id=\"paper_authors\"><a href=\"/people/7.html\">Gr\u00e9gory&nbsp;Rogez</a>, <a href=\"/people/10.html\">James&nbsp;Supan\u010di\u010d</a>, <a href=\"/people/20.html\">Deva&nbsp;Ramanan</a></div>\n    <div id=\"paper_abstract\">\n      <img src=\"icon_drop.jpg\" alt=\"icon\">\n      We analyze functional manipulations of handheld objects,\nformalizing the problem as one of fine-grained grasp\nclassification. To do so, we make use of a recently developed\nfine-grained taxonomy of human-object grasps. We introduce\na large dataset of 12000 RGB-D images covering 71\neveryday grasps in natural interactions. Our dataset is different\nfrom past work (typically addressed from a robotics\nperspective) in terms of its scale, diversity, and combination\nof RGB and depth data. From a computer-vision perspective,\nour dataset allows for exploration of contact and force\nprediction (crucial concepts in functional grasp analysis)\nfrom perceptual cues. We present extensive experimental\nresults with state-of-the-art baselines, illustrating the role\nof segmentation, object context, and 3D-understanding in\nfunctional grasp analysis. We demonstrate a near 2X improvement\nover prior work and a naive deep baseline, while\npointing out important directions for improvement.\n\n    </div>\n    <div id=\"bibtext\">\n      <h3>Download: <a href=\"/papers/RogezSR_ICCV_2015/RogezSR_ICCV_2015.pdf\">pdf</a></h3>\n      <h3>Text Reference</h3>\nGr\u00e9gory Rogez, James&nbsp;Steven Supan\\vc i\\vc &nbsp;III, and Deva Ramanan.\nUnderstanding everyday hands in action from rgb-d images.\nIn <em>IEEE International Conference on Computer Vision</em>. 2015.<br>\n<h3>BibTeX Reference</h3>\n@INPROCEEDINGS{RogezSR_ICCV_2015,<br>\n&nbsp;&nbsp;&nbsp;&nbsp;author = \"Rogez, Gr{\\'e}gory and Supan{\\vc}i{\\vc} III, James Steven and Ramanan, Deva\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;booktitle = \"IEEE International Conference on Computer Vision\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;title = \"Understanding Everyday Hands in Action from RGB-D Images\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;year = \"2015\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;tag = \"people\"<br>\n}<br>\n    </div>\n  </div>\n  <div id=\"footer\">\n    <div>\n      <a href=\"/\">Computational Vision</a> |\n      <a href=\"http://www.ics.uci.edu/\">School of Information and Computer Sciences</a> |\n      <a href=\"http://www.uci.edu/\">UC Irvine</a>\n    </div>\n    <div id=\"updated\">&copy; 2007-2017 UC Irvine</div>\n  </div>\n  </div>\n</body>\n</html>\n\n", "encoding": "utf-8"}