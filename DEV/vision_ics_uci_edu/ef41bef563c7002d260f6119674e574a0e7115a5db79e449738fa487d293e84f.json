{"url": "http://vision.ics.uci.edu/papers/VondrickR_NIPS_2011/", "content": "\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n<html>\n<head>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n  <title>Computational Vision | ICS | UC Irvine</title>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"/stylesheets/screen.css\" media=\"all\">\n</head>\n\n<body id=\"publications\">\n  <div id=\"outerframe\">\n  <div id=\"header\">\n    <h1>Computational Vision at UC Irvine &nbsp;<img src=\"/images/eye_small.jpg\" alt=\"small eye\"></h1>\n  </div>\n  <div id=\"tabs\">\n    <ul id=\"tabnav\">\n      <li id=\"home_tab\"><a href=\"/index.html\">home</a></li>\n      <li id=\"projects_tab\"><a href=\"/projects.html\">projects</a></li>\n      <li id=\"people_tab\"><a href=\"/people.html\">people</a></li>\n      <li id=\"publications_tab\"><a href=\"/publications.html\">publications</a></li>\n      <li id=\"datasets_tab\"><a href=\"/datasets/index.html\">datasets</a></li>\n      <li id=\"events_tab\"><a href=\"/events.html\">events</a></li>\n      <li id=\"courses_tab\"><a href=\"/courses.html\">courses</a></li>\n      <li id=\"contact_tab\"><a href=\"/contact.html\">contact</a></li>\n      <li id=\"links_tab\"><a href=\"/links.html\">links</a></li>\n    </ul>\n  </div>\n\n  <div id=\"content\">\n    <div id=\"paper_title\">Video Annotation and Tracking with Active Learning</div>\n    <div id=\"paper_authors\"><a href=\"/people/26.html\">Carl&nbsp;Vondrick</a>, <a href=\"/people/20.html\">Deva&nbsp;Ramanan</a></div>\n    <div id=\"paper_abstract\">\n      <img src=\"icon_drop.jpg\" alt=\"icon\">\n      We introduce a novel active learning framework for video annotation. By \njudiciously choosing which frames a user should annotate, we can obtain highly\naccurate tracks with minimal user effort. We cast this problem as one of active\nlearning, and show that we can obtain excellent performance by querying frames\nthat, if annotated, would produce a large expected change in the estimated object\ntrack. We implement a constrained tracker and compute the expected change for\nputative annotations with efficient dynamic programming algorithms. We demonstrate\nour framework on four datasets, including two benchmark datasets constructed with\nkey frame annotations obtained by Amazon Mechanical Turk. Our results indicate\nthat we could obtain equivalent labels for a small fraction of the original cost.\n\n    </div>\n    <div id=\"bibtext\">\n      <h3>Download: <a href=\"/papers/VondrickR_NIPS_2011/VondrickR_NIPS_2011.pdf\">pdf</a></h3>\n      <h3>Text Reference</h3>\nCarl Vondrick and Deva Ramanan.\nVideo annotation and tracking with active learning.\nIn <em>NIPS</em>, 28&ndash;36. 2011.<br>\n<h3>BibTeX Reference</h3>\n@inproceedings{VondrickR_NIPS_2011,<br>\n&nbsp;&nbsp;&nbsp;&nbsp;author = \"Vondrick, Carl and Ramanan, Deva\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;title = \"Video Annotation and Tracking with Active Learning\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;booktitle = \"NIPS\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;year = \"2011\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;pages = \"28-36\"<br>\n}<br>\n    </div>\n  </div>\n  <div id=\"footer\">\n    <div>\n      <a href=\"/\">Computational Vision</a> |\n      <a href=\"http://www.ics.uci.edu/\">School of Information and Computer Sciences</a> |\n      <a href=\"http://www.uci.edu/\">UC Irvine</a>\n    </div>\n    <div id=\"updated\">&copy; 2007-2017 UC Irvine</div>\n  </div>\n  </div>\n</body>\n</html>\n\n", "encoding": "ascii"}