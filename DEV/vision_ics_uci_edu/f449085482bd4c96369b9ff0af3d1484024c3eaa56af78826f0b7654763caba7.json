{"url": "http://vision.ics.uci.edu/papers/DesaiR_ECCV_2012/", "content": "\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" \"http://www.w3.org/TR/html4/strict.dtd\">\n<html>\n<head>\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n  <title>Computational Vision | ICS | UC Irvine</title>\n  <link rel=\"stylesheet\" type=\"text/css\" href=\"/stylesheets/screen.css\" media=\"all\">\n</head>\n\n<body id=\"publications\">\n  <div id=\"outerframe\">\n  <div id=\"header\">\n    <h1>Computational Vision at UC Irvine &nbsp;<img src=\"/images/eye_small.jpg\" alt=\"small eye\"></h1>\n  </div>\n  <div id=\"tabs\">\n    <ul id=\"tabnav\">\n      <li id=\"home_tab\"><a href=\"/index.html\">home</a></li>\n      <li id=\"projects_tab\"><a href=\"/projects.html\">projects</a></li>\n      <li id=\"people_tab\"><a href=\"/people.html\">people</a></li>\n      <li id=\"publications_tab\"><a href=\"/publications.html\">publications</a></li>\n      <li id=\"datasets_tab\"><a href=\"/datasets/index.html\">datasets</a></li>\n      <li id=\"events_tab\"><a href=\"/events.html\">events</a></li>\n      <li id=\"courses_tab\"><a href=\"/courses.html\">courses</a></li>\n      <li id=\"contact_tab\"><a href=\"/contact.html\">contact</a></li>\n      <li id=\"links_tab\"><a href=\"/links.html\">links</a></li>\n    </ul>\n  </div>\n\n  <div id=\"content\">\n    <div id=\"paper_title\">Detecting Actions, Poses, and Objects with Relational Phraselets</div>\n    <div id=\"paper_authors\"><a href=\"/people/32.html\">Chaitanya&nbsp;Desai</a>, <a href=\"/people/20.html\">Deva&nbsp;Ramanan</a></div>\n    <div id=\"paper_abstract\">\n      <img src=\"icon_drop.jpg\" alt=\"icon\">\n      We present a novel approach to modeling human pose, together with\ninteracting objects, based on compositional models of local visual\ninteractions and their relations. Skeleton models, while flexible\nenough to capture large articulations, fail to accurately model\nself-occlusions and interactions. Poselets and Visual Phrases address this\nlimitation, but do so at the expense of requiring a large set of templates.\nWe combine all three approaches with a compositional model that is flexible\nenough to model detailed articulations but still captures occlusions and\nobject interactions. Unlike much previous work on action classification,\nwe do not assume test images are labeled with a person, and instead\npresent results for \u201caction detection\u201d in an unlabeled image. Notably,\nfor each detection, our model reports back a detailed description including\nan action label, articulated human pose, object poses, and occlusion\nflags. We demonstrate that modeling occlusion is crucial for recognizing\nhuman-object interactions. We present results on the PASCAL Action\nClassification challenge that shows our unified model advances the\nstate-of-the-art for detection, action classification, and articulated pose\nestimation.\n\n    </div>\n    <div id=\"bibtext\">\n      <h3>Download: <a href=\"/papers/DesaiR_ECCV_2012/DesaiR_ECCV_2012.pdf\">pdf</a></h3>\n      <h3>Text Reference</h3>\nChaitanya Desai and Deva Ramanan.\nDetecting actions, poses, and objects with relational phraselets.\nIn <em>ECCV (4)</em>, 158&ndash;172. 2012.<br>\n<h3>BibTeX Reference</h3>\n@inproceedings{DesaiR_ECCV_2012,<br>\n&nbsp;&nbsp;&nbsp;&nbsp;author = \"Desai, Chaitanya and Ramanan, Deva\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;title = \"Detecting Actions, Poses, and Objects with Relational Phraselets\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;booktitle = \"ECCV (4)\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;year = \"2012\",<br>\n&nbsp;&nbsp;&nbsp;&nbsp;pages = \"158-172\"<br>\n}<br>\n    </div>\n  </div>\n  <div id=\"footer\">\n    <div>\n      <a href=\"/\">Computational Vision</a> |\n      <a href=\"http://www.ics.uci.edu/\">School of Information and Computer Sciences</a> |\n      <a href=\"http://www.uci.edu/\">UC Irvine</a>\n    </div>\n    <div id=\"updated\">&copy; 2007-2017 UC Irvine</div>\n  </div>\n  </div>\n</body>\n</html>\n\n", "encoding": "utf-8"}