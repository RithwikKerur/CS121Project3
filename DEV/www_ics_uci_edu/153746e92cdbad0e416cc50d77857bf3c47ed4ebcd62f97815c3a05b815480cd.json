{"url": "https://www.ics.uci.edu/~pattis/ICS-46/lectures/notes/recursion.txt", "content": "\t\t\t\tRecursion\r\n\r\n\r\nIn this lecture we will discuss the concept of recursion and examine recursive\r\nfunctions that operate on integers, strings, and linked lists, learning common\r\nidioms for each.  When we cover linked lists again, we will first examine\r\nfunctions that do NOT change the structure of the linked list, and then examine\r\nfunctions whose purpose is to CHANGE the structure of the linked list (add or\r\nremove values). We will study how to hand simulate such functions and more\r\nimportantly learn three rules for proving them correct.\r\n\r\nThe concept of recursively defined (sometimes called inductively defined) data\r\nand recursion is fundamental in many areas of computer science, and this concept\r\nshould be examined and discussed from many angles in many of your ICS classes;\r\nyou should become comfortable with seeing and applying recursion. In addition,\r\nsome programming languages (Lisp is the foremost example) use recursion (and\r\nalso decision: if) as their primary control structures: any iterative code can\r\nbe written recursively. Even languages that are not primarily recursive all\r\nsupport recursion (and have since the late 1950s), because sometimes using\r\nrecursion is the best way to write code to solve a problem (sometimes simplest,\r\nsometimes fastest, sometimes both). \r\n\r\nC++ (and Java/Python) are not primarily recursive languages. Each has strong\r\nfeatures for iterating through data (Python has the most powerful tools for such\r\niteration, including generators; Java/C++ have slightly more restricted for-each\r\nloops). But, it is important that we learn how to write recursive code in C++\r\ntoo. Later in the quarter we will recursively define tree data structures, which\r\ngeneralize linear linked lists) and learn how to manipulate them both\r\niteratively and recursively.\r\n\r\nSide-Note: Douglas Hofstadter's Pulitzer-prize winning book, \"Godel, Escher,\r\nBach\" is an investigation of cognition, and commonly uses recursion and\r\nself-reference to illustrate the concepts that it is discussing. This book is\r\nstill very popular reading among computer scientists; you can buy used copies\r\ncheaply online.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nRecursion vs Iteration\r\n\r\nRecursion is a programming technique in which a call to a function results in\r\nanother call to that same function. In direct recursion, a call to a function\r\nappears in the function's body; in indirect/mutual recursion, the pattern is\r\nsome function calls some other function ... which ultimately calls the first\r\nfunction. In the simplest case here, think of f calling g and g calling f: f\r\nand g are mutually recursive, with f calling f indirectly via calling g, and g\r\ncalling g indirectly via calling f.\r\n\r\nFor some data structures and problems, it is simpler to write recursive code\r\nthan its iterative equivalent. In modern programming languages, recursive\r\nfunctions may run a bit slower (maybe 15%) than equivalent iterative functions,\r\nbut this is not always the case (and sometimes there is no natural/simple\r\niterative solution to a problem); in a typical application, this  time\r\ndifferences is insignificant (most of the time it takes a program to run will\r\nbe taken up elsewhere anyway). Sometimes a programmer will write a simple\r\nrecursive solution, and rewrite it iteratively (not always possible) if the\r\ntime it is taking is significant, and the iterative solution can really run\r\nfaster. Recursive solutions can be faster (we will see such an example in a\r\nlecture on efficiency, later in the quarter).\r\n\r\nWe will begin by studying the form of general recursive functions; then apply\r\nthis form to functions operating on int values, and then apply this form to\r\nfunctions operating on strings and linked lists. In all these cases, we will\r\ndiscuss how values of these types are recursively defined and discuss the\r\n\"sizes\" of the problem solved.\r\n\r\nWe will start by looking at the general form of all recursive functions and try\r\nto gain an intuitive understanding of recursion and constrast it to iteration.\r\nRecursion is actually a more powerful control structure than iteration, and\r\nrecursion applied to non-linear linked structures (like trees and graphs) is a\r\nvery powerful programming technique.\r\n\r\nImagine that you have to solve the problem of raising $100 for charity. Assume\r\nanyone you approach would be willing to contribute the smallest amount of money,\r\na penny.\r\n\r\nIterative Approach:\r\n  Visit 10,000 people and ask for a penny from each\r\n\r\nRecursive Approach:\r\n  If you are asked to contribute a penny, contribute it to whoever asked\r\n  Otherwise,\r\n    Visit 10 people: ask each to raise 1/10 the amount you were asked to raise\r\n    Combine the money they raise into bag\r\n    Give it to the person who asked you\r\n\r\nIn the iterative version each subproblem is the same; raising a penny. In the\r\nrecursive solution, subproblems get smaller and smaller until they reach the\r\nsize of collecting a penny (they cannot get any smaller: this problem has the\r\nsmallest size). All the recursive subproblems are similar (raising money), but\r\nthey differ in the amount of money they must raise.\r\n\r\n\r\n------------------------------------------------------------------------------\r\n\r\nGeneral form or all recursive functions\r\n\r\nThe general form of a directly recursive function is\r\n\r\nSolve(Problem) {\r\n  if (Problem is minimal/not decomposable into a smaller problem: a base case)\r\n    Solve Problem directly and return solution; i.e., without recursion\r\n  else {\r\n    (1) Decompose Problem into one or more SIMILAR, STRICTLY SMALLER\r\n        subproblems: SP1, SP2, ... , SPn\r\n\r\n    (2) Recursively call Solve (this function) on each SMALLER SUBPROBLEM\r\n        (since they are all SIMILAR): Solve(SP1), Solve(SP2),..., Solve(SPN)\r\n\r\n    (3) Combine the returned solutions to these smaller subproblems into a\r\n        solution that solves the original, larger Problem (the one this\r\n        original function call must solve)\r\n  \r\n    (4) Return the solution to the original Problem\r\n  }\r\n} \r\n\r\n\r\n------------------------------------------------------------------------------\r\n\r\nSimple Recursion in C++\r\n\r\nWe will start by examining a recursive definition for the factorial function\r\n(e.g., 5! reads as \"five factorial\": ! is a postfix operator in mathematics)\r\nand then a recursive function that implements it.  The definition is directly\r\nrecursive, because we define a larger factorial in terms of a smaller\r\nfactorial. Note that the domain of the factorial function is the non-negative\r\nintegers (also called the natural numbers), of which 0 is the smallest value.\r\n\r\n   0! = 1\r\n   N! = N*(N-1)!  for all N>0, \r\n\r\nBy this definition (and just substitution of equals for equals) we see that\r\n\r\n  5! = 5*4! = 5*4*3! = 5*4*3*2! = 5*4*3*2*1! = 5*4*3*2*1*0! = 5*4*3*2*1*1 = 120\r\n\r\nBy the recursive definition, eventually all uses of the ! operator disappear\r\n(when we reach the base case, which is solved without recursion), and we are\r\nleft with an expression that has all multiplication operators. The first\r\ndefinition below is a transliteration of the general code above.\r\n\r\nint factorial (int n) {\r\n  if (n == 0)\t\t\t\t//Non-decomposable\r\n    return 1;\r\n  else {\r\n    int sp1        = n-1;\t     //(1)Decompose problem n into 1 subproblem\r\n    int solved_sp1 = factorial(sp1); //(2)Recursive call to Solve subproblem\r\n    int solved_n   = n * solved_sp1; //(3)Solve problem n with solved subproblem\r\n    return solved_n;                 //(4)Return solution\r\n  }\r\n}\r\n\r\nWe don't need to write all this code: we can simplify it in C++ as follows.\r\n\r\nint factorial (int n) {\r\n  if (n==0)\r\n    return 1;\r\n  else \r\n    return n*factorial(n-1);\r\n}\r\n\r\nThis looks clean and closely mirrors the recursive mathematical description of \r\nfactorial. In fact, because of the simplicity of this particular recursive\r\nfunction, we can write an even simpler solution using a conditional expression;\r\nbut I prefer the solution above, because it is more representative of other\r\nrecursive solutions (to more complicated problems), using an if/else\r\n\r\nint factorial (int n)\r\n{return (n==0 ? 1 : n*factorial(n-1));}\r\n\r\nContrast this code with the iterative code that implements this same function\r\n(below). Note that the iterative code requires several state change operators\r\nwhile the recursive code uses none. State change operators make it hard for us\r\nto think about the meaning of code (and makes it tough to prove that the code\r\nis correct too), and makes it hard for multi-core processors to coordinate in\r\nsolving a problem. \"Functional programming languages\" are more amenable to be\r\nautomatically parallelizable (can run more quickly on multi-core computers).\r\nYou'll see more about this in later classes at UCI (e.g., in Concepts of\r\nProgramming Languages).\r\n\r\nint factorial (int n) {\r\n  int answer = 1;\r\n  for (int i=1; i<=n; i++)\r\n    answer *= i;\r\n  return answer;\r\n}\r\n\r\nWe can mimic factorial's recursive definition for a function that raises a\r\nnumber to an integer power. Note that the domain of n for this power function\r\nrequires n to be a the non-negative integer.\r\n\r\n  A**0 = 1           (yes, this is even true when A=0)\r\n  A**N = A * A**N-1  for all N>0\r\n\r\nWe can likewise translate this definition into a simple recursive C++ function.\r\n\r\nint power(int a, int n) {\r\n  if (n == 0)\r\n    return 1;\r\n  else\r\n    return a * power(a,n-1);\r\n\r\nBy this definition (and just substitution of equals for equals) we see that\r\ncalling power(a,n) requires n multiplications.\r\n\r\n   power(a,3) = a*power(a,2) = a*a*power(a,1) = a*a*a*power(a,0) = a*a*a*1\r\n\r\nOf course we could write this code iteratively as follows, which also requires\r\nn multiplications\r\n\r\nint power(int a, int n) {\r\n  int answer = 1;\r\n  for (int i=1; i<=n; ++i)\r\n     answer *= a;\r\n  return answer;\r\n}\r\n\r\nBut there is a another way to compute power(a,n) recursively, shown below. This\r\nlonger function requires between Log2 n and 2*(Log2 n) multiplications. Here,\r\nthe Log2 means the log function using a base of 2. Note Log2 1000 is about 10,\r\nand Log2 1,000,000 is about 20, Log2 1,000,000,000 is about 30): so, to compute\r\npower(a,1000) using the function below requires between 10 and 20\r\nmultiplications (not the 1,000 multiplcations required by the original\r\ndefinitions -both recursive and iterative- of power).\r\n\r\nint power(int a, int n) {\r\n  if (n == 0)\r\n    return 1;\r\n  else if (n%2 == 1)          //is n odd\r\n    return a * power(a,n-1);    //yes, use standard defintion: n-1 is now even\r\n  else {\r\n    int temp = power(a,n/2);    //no (so n/2 is an integer with no truncation)\r\n    return temp*temp;\r\n  }\r\n\r\nHere we store temp once and then use its value, which is fine for recursive\r\ncode (generally we can assign a variable a value, but we should never change\r\nthe value stored in a variable). We could get rid of the local name temp by\r\ndefining the simple function\r\n\r\nint square(int n)\r\n{return n*n;}\r\n\r\nand then calling it in the else clause, with the single line of code:\r\n\r\n   return square( power(a,n/2) )\r\n\r\nFor one example\r\n  power(a,16) computes power(a,8) and returns its result with 1 more\r\n  multiplication; power(a,8) computes power(a,4) and returns its result with\r\n  1 more multiplication; power(a,4) computes power(a,2) and returns its\r\n  result with 1 more multiplication; power(a,2) computes power(a,1) and returns\r\n  its result with 1 more multiplication; power(a,1) computes a*power(a,0),\r\n  which requires 1 multiplication: computing power(a,0) requires 0\r\n  multiplications (it just retuns the value 1).\r\n\r\n  In all, power(a,16) requires just 5 multiplications, not 16. Note that this\r\n  function is efficient, but it is NOT guaranteed to always use the MINIMUM\r\n  number of multiplications. Here, power(a,15) uses 6  multiplications, but\r\n  computing x3 = x*x*x then x3*(square(square(x3))) requires only 5: see the\r\n  topic named \"addition-chain exponentiation\" if you are interested in what is\r\n  known about the minimimal number of multiplications for exponentiation.\r\n\r\n  Raising large integers (thousand of digits) to large power (ditto) is doable\r\n  only with a function like this one.\r\n\r\nWe will prove that this function computes the correct answer later in this\r\nlecture. Truth be told, we can write a fast power function like this\r\niteratively too, but it looks much more complicated and is much more\r\ncomplicated to understand and analyze its behavior and prove that it is correct.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nHand Simulation\r\n\r\nNext, we will learn how to hand-simulate a recursive functions using a \"tower of\r\ncall frames\" in which each resident in an apartment executes the same code\r\n(acting as the function) to compute a factorial: he/she is called by the\r\nresident above and calls the resident underneath, when a recursive call is\r\nneeded (calling back the resident above when their answer is computed).\r\n\r\nWhile it is useful to be able to hand-simulate a recursive call, to better\r\nunderstand recursion, hand-simulation is not a good way to understand or debug\r\nrecursive functions (the 3 proof rules discussed below are a better way). I\r\nwill do this hand simulation on the document camera in class, using the\r\nfollowing form for computing factorial(5).\r\n\r\n\r\n       Factorial Towers\r\n       +---------------------------+\r\n       |   n int    return value   |\r\n       | +------+  +------------+  |\r\n       | |      |  |            |  |\r\n       | +------+  +------------+  |\r\n-------+---------------------------+--------\r\n       |   n int    return value   |\r\n       | +------+  +------------+  |\r\n       | |      |  |            |  |\r\n       | +------+  +------------+  |\r\n       +---------------------------+\r\n       |   n int    return value   |\r\n       | +------+  +------------+  |\r\n       | |      |  |            |  |\r\n       | +------+  +------------+  |\r\n       +---------------------------+\r\n       |   n int    return value   |\r\n       | +------+  +------------+  |\r\n       | |      |  |            |  |\r\n       | +------+  +------------+  |\r\n       +---------------------------+\r\n       |   n int    return value   |\r\n       | +------+  +------------+  |\r\n       | |      |  |            |  |\r\n       | +------+  +------------+  |\r\n       +---------------------------+\r\n       |   n int    return value   |\r\n       | +------+  +------------+  |\r\n       | |      |  |            |  |\r\n       | +------+  +------------+  |\r\n       +---------------------------+\r\n     \r\n                 ....\r\n\r\n------------------------------------------------------------------------------\r\n\r\nThe 3 Proof Rules for Recursive Functions\r\n\r\nNow, we will learn how to VERIFY that recursive functions are correct by three\r\nproof rules. Even more important than proving that existing functions are\r\ncorrect (to better understand them), we will use these same three proof rules\r\nto guide us when we SYNTHESIZE new recursive functions.\r\n\r\nNote that in direct recursion, we say that the function \"recurs\", not that it\r\n\"recurses\". Recurses describes what happens when you hit your thumb with a\r\nhammer the second time. I was taught that programmers who use the words\r\n\"recurse\" or \"recurses\" are not well-spoken.\r\n\r\nThe three proof rules should be simple to apply in most cases. These rules\r\nmirror rules for proofs by induction in mathematics. Recursion (thinking about\r\nsmaller and smaller problems) and induction (thinking about bigger and bigger\r\nproblems) are two sides of the same coin. Here we look back to the Solve\r\nfunction: the general form of a recursive function.\r\n\r\n1) Prove that Solve computes (without recursion) the correct answer to any\r\n   minimal (base case) problem. Base cases are simple, so this should be easy.\r\n\r\n2) Prove that the argument to any recursive call of Solve, e.g. SP1..SPN in the\r\n   general code above, is strictly smaller (closer to the minimal/base case)\r\n   than the Problem from which the subproblems are created.\r\n\r\n   The notion of strictly smaller should be easy to understand for the \r\n   recursive argument, so this should be easy. There are \"standard\" ways to\r\n   recur: ints get smaller by 1 or smaller by 1 digit (i.e., x/10 has one fewer\r\n   digit; Strings recur on a substring (fewer characters); linked lists recur on\r\n   x->next, which is a(nother) pointer to a linked list that is smaller by one\r\n   node (closer to the empty list, which is the typical base case for linked\r\n   lists); trees recur on  t->left and t->right (smaller subtrees of a root,\r\n   again with the typical base case being an empty tree). \r\n\r\n3) ASSUMING ALL RECURSIVE CALLS CORRECTLY SOLVE THEIR SMALLER SUBPROBLEMS -each\r\n   callt to Solve(SPI)- prove that the code correctly combines these subproblem\r\n   solutions to solve the original Problem (the parameter of the general\r\n   function). This part should be easy, because we get to ASSUME something very\r\n   important and powerful: all smaller subproblems are correctly solved.\r\n\r\nFor example, for factorial we might state the proof as follows.\r\n\r\n1) The smallest argument for which factorial is defined is 0. This function\r\n   immediately recognizes this base case and returns 1, which is the correct\r\n   value, because the rules state 0! = 1.\r\n\r\n2) For any non-negative argument n != 0, the recursive call is on the argument\r\n   n-1 which is always smaller, closer to the base case of 0, than n.\r\n\r\n3) Assuming factorial(n-1) computes (n-1)! correctly, this function returns\r\n   n*factorial(n-1), so it returns n*(n-1)!. By the definition we know N! =\r\n   N*(N-1)! so the code correctly uses the solved subproblem (for n-1) to\r\n   produce a solution to the original problem (for n).\r\n\r\nNotice that the focus of the proof is on ONE call of the function (not like the\r\nhand simulation method above, which looked at all the recursive calls). That is,\r\nwe look at what happens in two situations: the argument/parameter is a base\r\ncase (rule 1 above); the argument/parameter is not the base case and the\r\nfunctions recurs (rule 2-3 above). For the recursive case, we don't worry about\r\nmore recursive calls, because we get to assume that any further recursive calls\r\n(on smaller problems, which might be the base case or at least closer to the\r\nbase cases) compute the correct answer WITHOUT HAVING TO THINK about how that\r\nhappens during any recursive calls. When proving recursive functions correct,\r\nDO NOT think about what happens when the function is called recursively later,\r\njust assume in produces the correct answer.\r\n\r\nFor a second example, here is a proof that fast-power function is correct (the\r\ncode is duplicated from above):\r\n\r\nint power(int a, int n) {\r\n  if (n == 0)\r\n    return 1;\r\n  else if (n%2 == 1)          //is n odd\r\n    return a * power(a,n-1);    //yes, use standard defintion: n-1 is now even\r\n  else {\r\n    int temp = power(a,n/2);    //no (so n/2 is an integer with no truncation)\r\n    return temp*temp;\r\n  }\r\n\r\n1) The smallest power argument for which power is defined is 0. This\r\n   function immediately recognizes this base case and returns 1, which is the\r\n   correct value, because the rules state a**0! = 1.\r\n\r\n2) For any non-negative ODD argument n != 0, the recursive call on the argument\r\n   n-1 is always closer to the base case than n; for any non-negative EVEN\r\n   argument n != 0 (so examples are 2, 4, ...), the recursive call on the\r\n   argument n/2 is always closer to the base case than n: for large n, n/2 is\r\n   much closer to the base case than n-1, which is what gives this method its\r\n   speed.\r\n\r\n3) Assuming power(a,n-1) computes a**(n-1) correctly and power(a,n/2) computes\r\n   a**(n/2) correctly. If n is odd, this function returns a*power(a,n-1) which\r\n   is a*a**(n-1) which simplifies to a**n. So the code correctly uses the solved\r\n   subproblem (for n-1) to produce a solution to the original problem (for n).\r\n   Also, if n is even, this function returns power(a,n/2)**2 which is\r\n   (a**(n/2))**2, where n/2 is an integer, which simplifies to a**n. So the\r\n   code correctly uses the solved subproblem (for n/2) to produce a solution to\r\n   the original problem (for n). For example, with the even number 10:\r\n   (a**(10/2))**2 = (a**5)**2 =  a**10. It takes 1 more multiplication than\r\n   computing a**5 to compute a**10 (squaring a**5).\r\n\r\nAgain, the focus of the proof is on one call of the function: the parts concern\r\nonly the base case and the recursive case (now two cases, depending on whether\r\nn is odd or even): and for the recursive cases, we don't worry about more\r\nrecursive calls, because we get to assume that any recursive calls (on smaller\r\nproblems, closer to the base cases) compute the correct answer  without having\r\nto think about what happens during the recursion. In this function there are\r\ntwo ways to get closer to the base case, depending on whether n is odd or even.\r\n\r\n\r\nThe Three Proof Rules are Necessary:\r\n\r\nWhat happens if we write factorial incorrectly? Will the proof rules fail. Yes,\r\nfor any flawed definition, one will fail. Here are three examples (one failure\r\nfor each proof rule).\r\n\r\nint factorial (int n) {\r\n  if (n == 0)\r\n    return 0;\t\t\t\t//0! is not 0;\r\n  else\r\n    return n*factorial(n-1);\r\n}\r\n\r\nThis factorial function violates the first proof rule. It returns 0 for the\r\nbase case; since everything is multiplied by the base case, ultimately this\r\nfunction always multiplies by 0 and returns 0. Bar bet: you name the year and\r\nthe baseball team, and I will tell you the product of all the final scores\r\n(last inning) for all the games they played that year. How do I do it and why\r\ndon't I make this kind of bet on basketball teams?\r\n\r\nint factorial (int n) {\r\n  if (n == 0)\r\n    return 1;\r\n  else\r\n    return factorial(n+1)/(n+1);\t//n+1 not closer to 0\r\n}\r\n\r\nThis factorial function violates the second proof rule. It recurs on n+1, which\r\nis farther away from -not closer to- the base case. Although mathematically\r\n(n+1)!/(n+1) = (n+1)*n!/(n+1) = n! this function will continue calling\r\nfactorial with ever-larger arguments: a runaway (or infinite) recursion.\r\nActually, each recursive call takes up a bit of space (to store its argument\r\n-see the hand simulation, which requires binding an argument for each recursive\r\ncall), so eventually memory will be exhausted and C++ will terminate with an\r\nerror.\r\n\r\nint factorial (int n) {\r\n  if (n == 0)\r\n    return 1;\r\n  else\r\n    return n + factorial(n-1);\t\t//n+(n-1)! is not n!\r\n}\r\n\r\nThis factorial function violates the third proof rule. Even if we assume that\r\nfactorial(n-1) computes the correct answer, this function returns n added to\r\n(not multiplied by) that value, so it does not return the correct answer. In\r\nfact, it returns one more than the sum of all the integer from 1 to n (because\r\nfor 0 it returns 1) not the product of these numbers.\r\n\r\nIn summary, each of these functions violates a proof rule and therefore doesn't\r\nalways return the correct value. The first function always returns the wrong\r\nvalue; the second function never returns a value; the third function returns\r\nthe correct value, but only for the the base case.\r\n\r\n\r\nThe Three Proof Rules are Sufficient:\r\n\r\nWe can actually prove that these proof rules are correct! Here is the proof.\r\nThis is not simple to understand -unless you have thought a lot about\r\nrecursion- but it is short so I will write the proof here and let you think\r\nabout it (and reread it a dozen times, maybe later in the quarter :). The proof\r\nform (a proof by contradiction) should be familiar to ICS 6B/6D students.\r\n\r\nAssume that we have correctly proven that these three proof rules are correct\r\nfor some recursive function f. And assume that we assert that the function is\r\nNOT correct. We will show that these two assertions lead to a contradiction.\r\n\r\nFirst, if f is not correct, then there must be some problem that it does not\r\ncorrectly solve. And, if there are any problems that f does not solve correctly,\r\nthere must be a SMALLEST problem that it does not correctly solve: call this\r\nsmallest unsolvable problem p.\r\n\r\nBecause of proof rule (1) we know that p cannot be the base case, because we\r\nhave proven f recognizes and solves the base case correctly. So, f must solve p\r\nby recursion. Since f solves p by recursion, it first recursively solves a\r\nproblem smaller than p: we know by proof rule (2) that it always recurs on a\r\nSTRICTLY SMALLER problem size; and we know that f correctly solves this smaller\r\nproblem, because p, by definition, is the SMALLEST PROBLEM THAT F SOLVES\r\nINCORRECTLY. But we also know by proof (3) that assuming f solves all problems\r\nsmaller than p (which it does, because p is the SMALLEST PROBLEM F DOES NOT\r\nSOLVE CORRECTLY), then f will use these solutions of smaller problems to solve\r\nthe bigger problem p correctly. So, f must solve p correctly, contradicting our\r\nassumption.\r\n\r\nTherefore, it is impossible to find a smallest problem that f incorrectly\r\nsolves; so, f must solve all problems correctly.\r\n\r\nWell, that is how the proof goes. We assume that we have proven the 3 proof\r\nrules and that the function is incorrect: that leads us to a contradiction,\r\nso either we haven't proven the 3 proof rules or the function is not incorrect\r\n(yes, a double negative, so it is correct).\r\n\r\n------------------------------------------------------------------------------\r\n\r\nMathematics Recursively\r\n(we will skip this section; you might be interested in reading it)\r\n\r\nWe can construct all the standard mathematical and relational operators on\r\nnatural numbers (integers >= 0) given just three functions and if/recursion. We\r\ncan recursively define the natural numbers as:\r\n\r\n   0 is the smallest natural number\r\n   for any natural number n, s(n) (the successor of n: n+1) is a natural number\r\n\r\nNow we define three simple functions z(ero), p(redecessor), and s(uccessor).\r\n\r\nbool z(int n)\t\t// z(n) returns whether or not n is 0\r\n{return n == 0;}\r\n\r\nint s(int n)\t\t// s(n) returns the successor to n (n+1)\r\n{return n+1;}\r\n\r\nint p(int n) {\t\t// p(n) returns the predecessor of n, if one exists\r\n  if (!z(n))\t\t// if n == 0, it has no predecessor\r\n    return n-1;\r\n  else\r\n    throw Exception(\"p: cannot compute predecessor of 0\");\r\n}\r\n\r\nNote we should be able to prove/argue/understand the following equivalences:\r\n\r\nz(s(n)) is always false: the successor of any number is never 0\r\np(s(n)) is always n: predecessor is the inverse function of successor\r\ns(p(n)) is n, but only if n != 0 (otherwise p(n) throws an exception)\r\n           successor is the inverse function of predecessor, so long as\r\n           the predecessor exists (p(0) does not exist).\r\n\r\nGiven these functions, we can define functions for all arithmetic (+ - * / **)\r\nand relational ( == <... and all the other relational) operators. For example\r\n\r\nint sum(int a, int b) {\r\n  if( z(a) )\t\t\t# a == 0\r\n    return b;\t\t\t# return b: 0 + b = b\r\n  else      \t\t\t# a != 0\r\n    return sum( p(a), s(b) );\t# return (a-1)+(b+1) = a+b = sum(a,b)\r\n}\r\n\r\nProof of correctness\r\n\r\n1) The smallest first argument for which addition is defined is 0. This function\r\n   immediately recognizes this base case and returns b, which is the correct\r\n   answer: 0+b = b.\r\n\r\n2) For any non-negative argument a != 0, the recursive call is on the argument\r\n   p(a) which is always closer to the base case than a.\r\n\r\n3) Assuming sum(p(a),s(b)) computes (a-1)+(b+1) correctly, this function returns\r\n   that answer, so it returns (a-1)+(b+1) = a+b = sum(a,b).\r\n\r\nAnother way to define this function is as follows (notice that the s function\r\nhere is applied to the recursive call, not to one of its arguments as is the\r\ncode above)\r\n\r\nint sum(int a, int b) {\r\n  if( z(a))\t\t\t# a == 0\r\n    return b;\t\t\t# return b: 0 + b = b\r\n  else      \t\t\t# a != 0, so can call p(a)\r\n    return s (sum( p(a), b);\t# return (a-1)+(b) + 1 = a+b = sum(a,b)\r\n}\r\n\r\nWe can also use the 3 proof rules to prove this function correctly computes the\r\nsum of any two non-negative integers.\r\n\r\nWe can similarly define the mult function, multiplying by repeated addition.\r\nAssuming sum is correct...\r\n\r\nint mult(int a, int b) {\r\n  if ( z(a) )\t\t\t# a = 0\r\n    return 0;\t\t\t# return 0: 0*b = 0\r\n  else      \t\t\t# a != 0, so can call p(a)\r\n    return sum(b, mult(p(a),b)) # return b+((a-1)*b) = b+a*b-b = a*b = mult(a,b)\r\n\r\nSwitching from arithmetic to relational operators....\r\n\r\nbool equal(int a,int b) {\r\n  if (z(a) || z(b))\t\t# a = 0 or b = 0 (either == 0)\r\n    return z(a) && z(b);\t# return true (if both == 0) false (if one != 0)\r\n  else      \t\t\t# a != 0 and b != 0, so can call p(a) and p(b)\r\n    return equal(p(a),p(b));\t# return a-1 == b-1 which is the same as a == b\r\n\r\nbool less_than(int a,int b) {\r\n  if (z(a))\t   \t\t# a = 0\r\n    return !z(b);\t\t# return true (if b != 0): 0 < anything but 0\r\n  else if z(b) \t\t\t# a != 0 and b == 0\r\n    return false;               # return false; nothing < 0\r\n  else      \t\t\t# a != 0 and b != 0, so can call p(a) and p(b)\r\n    return less_than(p(a),p(b));# return a-1 < b-1 which is the same as a < b\r\n\r\nWe also might find it useful to do a hand simulation of these functions, with\r\nthe two parameters a and b stored in each \"apartment\" and passed as arguments.\r\n \r\nThe right way to illustrate all this mathematics is to write a class Natural,\r\nwith these functions, and then overload/define operator+ etc. for all the \r\noperators. I just didn't have the time to do that now.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nSynthesizing a recursive string function\r\n\r\nWe can define strings recursively:\r\n  \"\" is the smallest string\r\n  a character concatenated to the front of a string is a (bigger) string;\r\n    so \"a\" is really 'a' concatenated on the front of the empty string \"\",\r\n    and \"ba\" is 'b' concatenated on the front of the string (see above) \"a\",...\r\n    all strings can be constructed as catenations of characters to smaller\r\n    strings (except the empty string).\r\n\r\nLet's use these proof rules to write a reciple for synthesizing (and therefore\r\nproving correct as we are writing them) a few recursive functions that process\r\nstrings. Here is our approach:\r\n\r\n(1) Find the base (non-decomposable) case(s)\r\n    Write the code that detects the base case and returns the correct answer\r\n      for it, without using recursion\r\n\r\n(2) Assume that we can decompose all non base-case problems and then solve\r\n      these smaller subproblems via recursion\r\n    Choose (requires some ingenuity) the decomposition; it should be \"natural\"\r\n\r\n(3) Write code that combines these solved subproblems (often there is just one)\r\n      to solve the problem specified by the parameter\r\n\r\nWe can use these rules to synthesize a function that reverses a string. We start\r\nwith\r\n\r\nstd::string reverse(std::string s)\r\n\r\n(1) Please take time to think about the base case: the smallest string. Most\r\nstudents will think that a single-character string is the smallest, when in\r\nfact a zero-character string (the empty string) is smallest. It has been my\r\nexperience that more students screw-up on the base case than the recursive case.\r\nOnce we know the smallest string is the empty string, we need to detect it and\r\nreturn the correct result without recursion: the reverse of an empty string is\r\nan empty string. If we chose a 1-character string as the base case, then the\r\nfunction would not work correctly for an empty string.\r\n\r\nstd::string reverse(std::string s) {\r\n  if (s == \"\")\r\n    return \"\";\r\n  else{\r\n    Recur to solve a smaller problem\r\n    Use the solution of the smaller problem to solve the original problem\r\n  }\r\n}\r\n\r\nWe can guess the form of the recursion as reverse(s.substr(1)) note that\r\ns.substr(1) computes a string with all characters but the one at index 0: all\r\nthe characters after the first. We are guaranteed to be calling substr on only\r\nnon-empty strings (those whose answer is not computed by the base case), so\r\ns.substr(1) will always be a smaller string. We get to assume that the\r\nrecursive call correctly returns the reverse of the string that contains all\r\ncharacters but the first.\r\n\r\nstd::string reverse(std::string s) {\r\n  if (s == \"\")\r\n    return \"\";\r\n  else\r\n    Use the solution of reverse(s.substr(1)) to solve the original problem\r\n}\r\n\r\nNow, think concretely, using an example. if we called reverse(\"abcd\") we get to\r\nassume that the recursive call works: so reverse(s.substr(1)) is computing\r\nreverse(\"bcd\") which we get to assume returns the correct answer: \"dcb\"). How\r\ndo we use the solution of this subproblem to solve the original problem, which\r\nmust return \"dcba\"? We need to concatenate 'a' (the first character, the one at\r\ns[0]) to the end of the reversal of all the other characters: \"dcb\" + 'a', which\r\nevaluates to \"dbca\", the reversal of all the characters in the parameter's\r\nstring. Generally we write this function as\r\n\r\nstd::string reverse(std::string s) {\r\n  if (s == \"\")\r\n    return \"\";\r\n  else\r\n    return reverse(s.substr(1)) + s[0];\r\n}\r\n\r\nWe have now written this function by ensuring the three proof rules are\r\nsatisfied, so we dont' have to prove them; but, we will note that \r\n\r\n(1) the reverse of the smallest string (empty) is computed/returned correctly\r\n\r\n(2) the recursive call is on a string argument smaller than s\r\n    (all the characters from index 1 to the end, skipping the character at\r\n    index 0, and therefore a string with one fewer characters)\r\n\r\n(3) ASSUMING THE RECURSIVE CALL WORKS CORRECTLY FOR THE SMALLER STRING, then\r\n    by concatenating the first character on the end of the solution to the\r\n    smaller problem, we have correctly reversed the entire string (solving the\r\n    problem for the parameter).\r\n\r\nIn fact, we can use a conditional expression to rewrite this simple code as a\r\nsingle line as well.\r\n\r\nstd::string reverse(std::string s)\r\n{return (s == \"\" ? \"\" : reverse(s.substr(1)) + s[0]);}\r\n\r\nIt is not always possible to directly/simply guess the form of recursion, but\r\nthe standard ways should be tried first.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nRecursion on Linked Lists (Queries/Accessors)\r\n\r\nLinked lists have a natural, recursive definition:\r\n\r\n  1) An empty list (the smallest linked list) is nullptr \r\n\r\n  2) Any non-empty list is a pointer to an object (from class LN) whose \"next\"\r\n     instance variable points to some smaller linked list (one fewer LN objects)\r\n     either empty or not\r\n\r\nUsing this defintion as a guide, we can often write linked-list processing code\r\nrecursively. This definition suggests an idiom for writing recursive functions,\r\ntreating an empty list as the base case. We start our discussion with a\r\nfunction that recursively computes the length of any linked list (the number of\r\nLN objects it contains), using the standard recursive form and the empty base\r\ncase:\r\n\r\ntemplate<class T>\r\nint length (LN<T>* l) {\r\n  if (l == nullptr)\r\n    return 0;\r\n  else\r\n    return 1 + length(l->next);\r\n}\r\n\r\nThis function has an iterative version that is just as simple, although it does\r\ninvolve straightforward state changes to the local variables count and p. But\r\nthe check == nullptr, adding one to a value, moving the cursor to the next LN\r\nappear in some form in each function.\r\n\r\ntemplate<class T>\r\nint length (LN<T>* l) {\r\n  int count = 0;\r\n  for (LN<T>* p = l; p != nullptr; p = p->next)\r\n      ++count;\r\n   return count;\r\n}\r\n\r\nA previous note shows some simple variants of functions that iteratively process\r\nall the values in a list: to sum up all the values and to display all the values\r\nof a list on std::cout (separated by spaces). Here are their recursive versions.\r\n\r\ntemplate<class T>\r\nint sum(LN<T>* l) {\r\n  if (l == nullptr)\r\n    return 0;\r\n  else\r\n    return l->value + sum(l->next);\r\n}\r\n\r\ntemplate<class T>\r\nvoid display(LN<T>* l)\r\n  if (l == nullptr)\r\n     std::cout << \"nullptr\";\r\n  else{\r\n    std::cout << l->value << \"->\"; \r\n    display(l->next);\r\n  }\r\n}\r\n\r\nWhat is interesting about this function is that a small change to the code\r\n(reversing the order of std::cout << and the recursive call in the recursive\r\ncase) leads to a big change in what the function does: it displays all the\r\nvalues from the linked list, but in the REVERSE order.\r\n\r\nThis is a task that we cannot do easily iteratively. The best we can do\r\niteratively is to reverse the list, then display it, then reverse it again (to\r\nget back to the original list). Another option is to push all the values in a\r\nstack and then empty the stack, printing the values last to first. Contrast\r\nthis with a hand-simulation of this code, which implicitly uses the call-frame\r\nstack to get the job done in a similar way, but with no explicit stack or stack\r\noperations.\r\n\r\nHere is the recursive code for printing all the values in a list in reverse\r\norder, with all the values separated by spaces. It is followed by a proof that\r\nit display all list values in the reverse order.\r\n\r\ntemplate<class T>\r\nvoid display(LN<T>* l)\r\n  if (l == nullptr)\r\n     ;\t\t\t\t\t//Do nothing, explicitly\r\n  else{\r\n    display(l->next);\t\t\t//These lines \r\n    std::cout << l->value << \" \";\t//are reversed\r\n  }\r\n}\r\n\r\n1) The smallest argument for which display is defined is an empty list. This\r\n   function immediately recognizes this base case and returns, which correctly\r\n   prints all the values in an empty list (there are none) in the reverse order.\r\n\r\n2) For any non-nullptr argument l, the recursive call is on the argument\r\n   l->next which is always closer to the base case than l: itis a list with\r\n   one fewer LN objects..\r\n\r\n3) Assuming display(l->next) correctly prints the values in a linked list in\r\n   the reverse order, display(l) prints those values followed by the first\r\n   value on the list (i.e., the first value is printed last), which means it\r\n   prints all values in the linked  list l in reverse order.\r\n\r\nThe following code searches for a value in a linked list and returns a pointer\r\nto the first LN storing its values, if there is one (or returns nullptr\r\notherwise).\r\n\r\ntemplate<class T>\r\nLN<T>* find (LN<T>* l, T to_find) {\r\n  if (l == nullptr)\r\n    return nullptr;\r\n  else if (l->value == to_find)\r\n    return l;\r\n  else\r\n    return find(l->next, to_find);\r\n}\r\n\r\nWe can simplify this code a bit as follows combining the nullptr and found\r\ncases (using short circuit evaluation to ensure l->value is legal):\r\n\r\ntemplate<class T>\r\nLN<T>* find (LN<T>* l, T to_find) {\r\n  if (l == nullptr || l->value == to_find)\r\n    return l;  // may return nullptr, or a pointer to an LN<T> storing to_find\r\n  else\r\n    return find(l->next, to_find);\r\n}\r\n\r\nHere is a simple and elegant recursive function that makes a copy of a linked \r\nlist.\r\n\r\ntemplate<class T>\r\nLN<T>*  copy (LN<T>* l) {\r\n  if (l == nullptr)\r\n    return nullptr;\r\n  else\r\n    return new LN<T>(l->value, copy(l->next));\r\n}\r\n\r\n1) The smallest argument for which copy is defined is an empty list. This\r\n   function immediately recognizes this base case and returns nullptr, which\r\n   correctly returns a copy of all the values in an empty list.\r\n\r\n2) For any non-nullptr argument l, the recursive call is on the argument\r\n   l->next which is always closer to the base case than l: it is a list with\r\n   one fewer LN objects..\r\n\r\n3) Assuming copy(l->next) correctly returns a pointer to a copy of all the LN\r\n   objects in l after the first, new LN<T>(l->value, copy(l->next)); uses this\r\n   result to return a pointer to a copy of the first LN object on the linked\r\n   list l, whose next instance variable points to a copy of all LN objects\r\n   after the first: so this function returns a copy of all LN objects in l.\r\n\r\nContrast this with the iterative function that we used previously for copying.\r\nThe best/fastest iterative code for this function is not so simple (or easy to\r\nunderstand), although getting used to reading recursive functions does take a\r\nbit of time. Note that the complexity of both functions is O(N): N iterations\r\nvs. N recursive calls. There are more variables and complex state changes in\r\nthe iterative code. More on complexity classes and analysis of algorithms next\r\nweek.\r\n\r\nNext we will look at a function that recurs on two linked lists: it determines\r\nwhether the two linked lists are \"equal\" (have the same number of nodes, each\r\nstoring the same values, in the same order). Note that this version DOESN'T\r\ncompute the length of either list first: it recurs down both lists so long as\r\neach contains another value to check for equality. There are four cases (3 of\r\nwhich are base cases, allowing an immediate answer to be returned without\r\nrecurring):\r\n\r\n                        Linked list l2\r\n                  nullptr      non-nullptr\r\n                 +----------+------------+\r\n    nullptr      |  equal   |  not equal |\r\nLinked list l1   +----------+------------+\r\n    non-nullptr  | not equal| check/recur|\r\n                 +----------+------------+\r\n\r\nSo, if either linked list is nullptr (or both are nullptr), we can compute the\r\nanswer immediately: the lists are equal only if both are nullptr; if one is\r\nnullptr and one isn't nullptr, then the lists cannot be equal (they have a\r\ndifferent number of nodes). This handles 3 of the 4 possibilties in the\r\ncode.\r\n\r\nOtherwise (if both linked lists have at least one node) we can check the first\r\nvalues in these nodes for equality (since  both lists are NOT nullptr, both\r\nhave first values), and if they are equal, we must also check for equality for\r\nthe rest of the nodes in the linked lists; if they are not equal, the linked\r\nlists are not equal and we don't need to do any further computation.\r\n\r\nThere are many ways to code these 3 checks: the nullptr-ness of at least one\r\nlist. For example, we can very explicitly write\r\n\r\n    if (l1 == nullptr &&  l2 == nullptr)\r\n      return true;\r\n    if (l1 == nullptr && l2 != nullptr)\r\n      return false;\r\n    if (l1 != nullptr && l2 == nullptr)\r\n      return false;\r\n\r\nwhich tests each of these three cases separately. It is equivalent (try all 3\r\ncases) to the shorter (but less obvious)\r\n\r\n    //Returns a value if either l1 or l2 is nullptr\r\n    if (l1 == nullptr)\r\n      return l2 == nullptr;\r\n    if (l2 == nullptr)\r\n      return false; //if got here because l1 != nullptr, but l2 == nullptr\r\n\r\nHere is how I wrote this function (with one if for the 3 base cases)\r\n\r\ntemplate<class T>\r\nbool equals (LN<T>* l1, LN<T>* l2) {\r\n  if (l1 == nullptr || l2 == nullptr)        //if either is nullptr, return true\r\n    return l1 == nullptr && l2 == nullptr;   // if and only if both are \r\n  else\r\n    return l1->value == l2->value  &&  equals(l1->next,l2->next);\r\n}\r\n\r\nNotice because of the short-circuit property of of &&, if at any time in the\r\nrecursion l1.value == l2.value returns false, there will be no more recursion,\r\nbecause &&, when its first argument is false, doesn't evaluate its second\r\nargument -doesn't perform the recursive call (because whether it is true or\r\nfalse, the result of false && anything is false).\r\n\r\nWriting this test as \r\n\r\n    return equals(l1->next,l2->next) && l1->value == l2->value;\r\n\r\nhas the same LOGICAL meaning, but can be much less  efficient for large\r\nunequal lists; if the lists are equal, C++ recurs to the end of each with\r\neither form of the \"return\".\r\n\r\n\r\n------------------------------------------------------------------------------\r\n\r\nRecursion on Linked Lists (Commands/Mutators)\r\n\r\nNow we will show and briefly discuss recursive add_rear/remove, first without\r\nreference parameters, then with reference parameters (which simplify the code,\r\nas it did with iterative implementations of these functions). The first of these\r\nfunctions are called like x = add_rear(x,some_value); or\r\nx = remove(x,some_value); each returns a reference to a linked list that can\r\nhave been altered.\r\n\r\ntemplate<class T>\r\nLN<T>* add_rear(LN<T>* l, T value) {\r\n  if (l == nullptr)\r\n    return new LN<T>(value);\r\n  else {\r\n    l->next = add_rear(l->next,value);\r\n    return l;\r\n  }\r\n}\r\n\r\ntemplate<class T>\r\nLN<T>* remove (LN<T>* l, T to_remove) {\r\n  if (l == nullptr)\r\n    return nullptr;                       //not present\r\n  else if(l->value == to_remove) {\r\n    LN<T>* rest_of_list = l->next;\r\n    delete l;\r\n    return rest_of_list;\r\n  }else{\r\n    l->next = remove(l->next,to_remove);\r\n    return l;\r\n  }\r\n}\r\n\r\nNote the code\r\n\r\n  l->next = remove(l->next,to_remove);\r\n  return l;\r\n\r\nkeeps the first node in the returned linked list (by returning l, the pointer\r\nto it) but first ensures that the nodes in the linked list after it (by\r\nstoring into l.next) do not store the first occurrence of to_remove (i.e., that\r\nnode, if present, is removed). I admit this is a bit subtle, but it appears in\r\nthe SAME form in add_rear.\r\n\r\nFinally, we can simplify these functions using reference parameters with\r\nrecursive calls.  These functions are called like add_rear(x,some_value); or\r\nremove(x,some_value) - as void functions that don't return values.\r\n\r\ntemplate<class T>\r\nvoid add_rear(LN<T>*& l, T value) {\r\n  if (l == nullptr)\r\n    l = new LN<T>(value);\r\n  else\r\n    add_rear(l->next,value);\r\n}\r\n\r\nHere each recursive call to add_rear has its parameter l referenced to the\r\npointer to the first node in the list or to some next instance variable;\r\neventually (the last call for a non-empty list) it is referenced to the next in\r\nthe last LN<T> in linked list (storing nullptr), which this code udpates to\r\nstore a pointer to a new LN<T>.\r\n\r\ntemplate<class T>\r\nvoid remove (LN<T>*& l, T to_remove) {\r\n  if (l == nullptr)\r\n    return;                          //not present\r\n  else if(l->value != to_remove)     //not here\r\n    remove(l->next,to_remove);\r\n  else{\t\t\t\t     \r\n    LN<T>* to_delete = l;\t     //remove one\r\n    l = l->next;\r\n    delete to_delete;\t             //must come after l = l->next\r\n  }\r\n}\r\n\r\nThe picture appearing with this lecture shows a hand simulation of how the code\r\nabove removes the first occurrence of to_remove from a linked list. Notice how\r\nthe parameters in each recursive call of the function are aliased to an LN<T>*:\r\neither the variable that refers to the first node, or a \"next\" instance variable\r\nin one of the nodes.\r\n", "encoding": "ascii"}