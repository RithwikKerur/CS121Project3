{"url": "https://www.ics.uci.edu/~eppstein/261/s13-hw2-answers.txt", "content": "CS 261, Spring 2013, Homework 2 Solutions\n\n1. Prove that tabulation hashing is not 4-independent, by finding a set\nof four keys for which all 4-tuples of indexes are not equally likely.\n\nANSWER:\n\nLet x and y be two different byte values (e.g. 0 and 1).\nThen the four keys with bytes (0,0,x,x), (0,0,x,y), (0,0,y,x), (0,0,y,y)\nhave hash values with the property that\nhash(0,0,x,x) xor hash(0,0,x,y) xor hash(0,0,y,x) xor hash(0,0,y,y) = 0,\nbecause each of the table values H1(0), H2(0), H3(x), H3(y), H4(x), and\nH4(y) contributes either two or four times to the total xor, cancelling\nitself out. So not every four-tuple of hash values is possible: the\nfour-tuples that don't xor to zero have probability zero of being\nchosen, and the remaining four-tuples have higher probability than they\notherwise would.\n\n(Some choices in this example were arbitrary, and could have been made\nequally well in other ways: for instance, we could have varied a\ndifferent two bytes than the last two, we could have used two different\npairs of byte values in the variable bytes, or we could have used a\ndifferent byte value than zero in the other two bytes.)\n\n\n\n2. Suppose that we are performing hash chaining, using a hash table with\nN cells, that n key-value pairs are already stored in the hash table,\nand that we wish to add a new key-value pair (k,v) to the table.\n\n(a) Using the standard hashing assumption that all hash functions are\nequally likely to be chosen, write a formula for the probability that\n(k,v) collides with exactly x other keys. (Hint: how many ways are there\nof choosing x other keys to collide with? What is the probability that\nthat precise collision occurs?)\n\n(b) Assuming a constant load factor, how big must x be for the\nprobability from part (a) to be less than 1/n? Express your answer using\nO-notation as a function of n.\n\n(Hint: find a simpler approximation to your answer from part (a), use\nhttp://en.wikipedia.org/wiki/Stirling's_approximation and take\nlogarithms).\n\nNote: since there are n different keys, each of which may collide with\nsome number of other keys, the answer to part (b) tells you how big the\nlargest chain is likely to be.\n\nANSWER:\n\n(a) (n choose x) (1/N)^x (1 - n/N)^{n-x}\nIt would also be ok to expand the binomial coefficient into factorials.\n\n(b) O(log n / log log n)\n\n\n3. In class we described a way of preventing infinite loops in the set\nalgorithm of cuckoo hashing, by counting steps and stopping when the\ncount gets too large. But this method has a problem, that you need to\nknow the constant factor to use in the Theta(log n) bound on the number\nof steps. Describe an alternative method of preventing infinite loops,\nwithout counting, by detecting a loop whenever it happens. Ideally, your\nsolution should\n- Use a constant amount of additional memory\n- Only perform a constant amount of additional work per step of the set\n  algorithm\n- Not use a step counter\n- Detect any loop within a number of steps proportional to the number of\n  keys involved in the loop\n- Only report that there is a loop when the set algorithm really has an\n  infinite loop\n\n(Hint: consider what happens to the key given as the original argument\nto the set algorithm during a loop.)\n\nANSWER: Keep a pointer to the key originally given as an argument to the\nsearch routine, and a counter of how many times we have tried to place\nthat key into a cell. If we ever try to place the starting key three\ntimes, then we are in a loop.\n\n(There are probably other correct answers as well, and if so they should\nget full credit, but this is the one I had in mind when I wrote the\nproblem.)\n", "encoding": "ascii"}