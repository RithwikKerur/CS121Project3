{"url": "https://www.ics.uci.edu/~pattis/ICS-33/lectures/treesi.txt", "content": "\t\t\t\tTrees\r\n\r\nIn this lecture we upgrade our discussion of self-referential structures from\r\nlinked lists to (binary) trees, by creating TN: a class that includes a value\r\nand two references to other objects from the TN class (or None). What seems\r\nlike a trivial extension turns out to be profound: like going from a\r\n1-dimensional world to a 2-dimensional world. There are entire books written\r\nabout trees (in both computer science and mathematics), but (almost) no books\r\nwritten solely about linked lists.\r\n\r\nOver the next two lectures we will examine a few applications for trees. We will\r\ndiscuss ordered binary trees (search trees) and structure trees (expression\r\ntrees) and discuss various recursive functions that operate on them. Both use\r\nthe same defintion of the TN (tree node) class shown below\r\n\r\nclass TN: # A binary tree: each TN has two children\r\n    def __init__(self : \"TN\",\r\n                 value : object, left : \"TN\" = None, right : \"TN\" = None):\r\n        self.value = value\r\n\tself.left  = left\r\n\tself.right = right\r\n\r\nWe write \"TN\" in the annotations above, because when defining TN we cannot use\r\nTN for an annotation (because it hasn't been completely defined yet).\r\n\r\nWe will discuss many operations on trees below, written as functions. We can\r\nalso define methods that implement these operations as methods in the TN class.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nBinary Search Trees\r\n\r\nBinary trees have structure and order property. Its STRUCTURE PROPERTY dictates\r\nthat every PARENT node has 0, 1, or 2 CHILDREN nodes (called left and right;\r\neach is another binary tree (TN) or None). We draw a binary trees with its ROOT\r\non the top, its left and right children below, and its leaves at the bottom (a\r\nLEAF is a node with 0/no children: its self.left and self.right are both None;\r\nan INTERNAL node has at least one non-None child). A binary SEARCH tree (one\r\nspecial kind of binary tree)  also has an ORDER PROPERTY: it dictates that all\r\nvalues in the left subtree of any node are LESS THAN that node, and all values\r\nin the right subtree of any node are GREATER THAN that node. Typically binary\r\nsearch trees store unique values (and we will assume so in this lecture; if we\r\nneeded to store duplicates, we could change the order property to all values in\r\nthe left subtree of any node are LESS THAN OR EQUAL to that node).\r\n\r\nStructurally, binary trees are much more interesting than linked lists:\r\nstructurally (ignoring values) there is only one linked list of length 4:\r\n\r\n     x\r\n   +---+    +---+---+    +---+---+    +---+---+    +---+---+\r\n   | --+--->| ? | --+--->| ? | --+--->| ? | --+--->| ? | / |\r\n   +---+    +---+---+    +---+---+    +---+---+    +---+---+\r\n\r\nBut there are 14 different binary trees with four nodes. Here is a listing of\r\nall 14. They are arranged in two groups, such that in each group a tree and its\r\nmirror image are above/below each other.\r\n\r\n       ?                ?                ?\r\n      / \\              / \\              / \r\n     ?   ?            ?   ?            ?\r\n    /                  \\              / \\  \r\n   ?                    ?            ?   ?\r\n\r\n\r\n      ?                 ?                ?\r\n     / \\               / \\                \\\r\n    ?   ?             ?   ?                ?\r\n         \\               /                / \\ \r\n          ?             ?                ?   ?\r\n\r\n-----\r\n\r\n      ?                 ?                ?                 ?\r\n     /                 /                /                 /\r\n    ?                 ?                ?                 ?\r\n   /                 /                  \\                 \\\r\n  ?                 ?                    ?                 ?\r\n /                   \\                  /                   \\\r\n?                     ?                ?                     ?\r\n\r\n\r\n      ?                 ?               ?                   ?\r\n       \\                 \\               \\                   \\\r\n        ?                 ?               ?                   ?\r\n         \\                 \\             /                   / \r\n          ?                 ?           ?                   ?\r\n           \\               /             \\                 /\r\n            ?             ?               ?               ?\r\n\r\n\r\nNote that the shape of a binary search trees is NOT UNIQUELY DETERMINED by the\r\nvalues that it contains. For example, a binary search tree with the values 1,\r\n2, 3, and 4 can be represented by these structures\r\n\r\n      3              2                 4\r\n    /   \\          /   \\              /\r\n   1    4    or   1     3      or    1     \r\n     \\                   \\            \\\r\n       2                  4            3\r\n                                      /\r\n                                     2\r\n\r\nor any of the 14 structures above, with the right selection of node values.\r\n\r\nNote that for EVERY NODE in the binary search trees above (not just the ROOT),\r\nthe parent is > all values in its left subtree and < all values in its right\r\nsubtree.\r\n\r\nLater, when we study the add function, we will learn that the shape of a binary\r\nsearch tree is determined not just by the values that it contains, but also by\r\nthe ORDER IN WHICH THESE VALUES WERE ADDED to the binary search tree.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nMetrics:\r\n\r\nThere is just one standard metric for linked lists: length. For trees there are\r\ntwo standard metrics: size and height. Size counts the number of nodes in a\r\ntree (therefore it is similar to length for linked lists). It is easy to\r\ncompute size recursively, using a function similar to a recursive computation\r\nof the length of a list (but with two recursive call: one for computing the\r\nsize each subtree, instead of one for computing the size of the list afterwards.\r\n\r\ndef size(atree):\r\n    if atree == None:\r\n        return 0\r\n    else:\r\n        return 1 + size(atree.left) + size(atree.right)\r\n\r\nThere is no simple way to compute size with a loop: for every node in the tree\r\nwe must visit both its left and right subtrees, so every time that we go to the\r\nleft subtree, we must also save/remember the right subtree for future\r\nexploration too; we can write this function iteratively by using an extra list\r\nof nodes, but the code is not simple to write nor easy to understand. I suggest\r\nthat you can hand simulate it to understand how the nodes are all counted.\r\n\r\ndef size_i(atree)\r\n    nodes = []\r\n    size = 0\r\n    nodes.append(atree)\r\n    while len(nodes) > 0:\r\n        next = nodes.pop(0)\r\n        if next != None:\r\n            size += 1\r\n            nodes.append(next.left)\r\n            nodes.append(next.right)\r\n    return size\r\n\r\nThe second metric for trees is height. In fact, we can apply height to any node\r\nin the tree. The standard definition of the height of a node is a bit strange:\r\nit is the number of steps needed to get from that node to the deepest leaf in\r\neither of the node's subtrees. So the height of a leaf (the base case) is 0 and\r\nthe height of a tree is the height of its root node. We can directly translate\r\nthis definition into the following code. Again there are (at most) two\r\nrecursive calls, in the case of a node with two non-None children.\r\n\r\ndef height(atree)\r\n   if atree.left == None and atree.right == None:   # leaf check as base case\r\n       return 0\r\n   elif atree.right == None:\t\t\t    # only a left subtree\r\n       return 1 + height(atree.left)\t\t    #   recur only to left\r\n   elif atree.left == None:\t\t\t    # only a right subtree\r\n       return 1 + height(atree.right)\t\t    #   recur only to right\r\n   else\t\t\t\t\t            # both a left/right subtree\r\n       return 1 + max(height(atree.left),height(atree.right)) # recur on both\r\n\r\nThis function deals with all the necessary cases: a leaf node, an internal node\r\nwith only a left (or only a right) subtree, and an internal node with both left\r\nand right subtrees. This function does not work on empty trees, which have no\r\ndirectly defined height, given the previous definition: the height of a NODE...\r\n(there are no nodes in an empty tree!)\r\n\r\nBut, this code is much more complicated than the code for computing size. The\r\ncomplexity results from using a leaf node as the base case. Let us simplify\r\nthis code by using an empty tree as a base case, even though it makes no sense\r\nfor the standard definition of the height of a node:\r\n\r\n  The number of steps needed to get from the node to the deepest leaf in either\r\n  of the node's subtrees.\r\n\r\nIn an empty tree, we have no node to start at and no leaf to reach.\r\n\r\nWith this new definition, we will \"arbitrarily\" define the height of an empty\r\ntree to be -1. This might seem like a very strange approach, but it seems\r\nreasonable too: an empty tree should have a height that is one less than a leaf\r\nnode (whose height is 0). By using this definition (and no others), we can\r\nsimplify the height function dramatically (as well as defining it for all\r\npossible trees, even empty ones).\r\n\r\ndef height(atree):\r\n    if atree == None:\r\n        return -1\r\n    else:\r\n        return 1 + max( height(atree.left), height(atree.right) )\r\n\r\nMathematicians generalize definitions such as this one all the time. For any\r\nvalue a, a**0 is defined as 1. There are many ways to justify this definition\r\n(some quite complicated, using limits and calculus); the simplest way is to\r\nnote the algebraic law a**x * a**y = a **(x+y). By this law (a quite useful one\r\nto have) a**0 * a**x = a**(0+x) = a**x; which means that a**0 must be equal to\r\n1 for this identity to hold.\r\n\r\nIf we couldn't guess that -1 was the correct answer, we could deduce it. If\r\nwe started by writing the correct recursive case\r\n\r\ndef height(atree):\r\n    if atree == None:\r\n        return empty-height     # actual value of empty-height to be determined\r\n    else:\r\n        return 1+ max( height(atree.left), height(atree.right) )\r\n\r\nand looked at height called on a leaf node (which we know must compute a height\r\nof 0), we would have\r\n\r\n  0 = 1 + max( height(None), height(None) )  # height(None) because it is a leaf\r\n  0 = 1 + max( empty-height, empty-height )  # height(None) returns empty-height\r\n  0 = 1 + empty-height                       # max(x,x) = x for all x\r\n -1 = empty-height\t\t\t     # subtract 1 from each side\r\n\r\nThe second line comes from computing the height of each base case; the third\r\ncomes from simplifying that max(x,x) = x (the maximum of a value and itself is\r\nthat value); the fourth line comes from subtracting 1 from each side of the\r\nequality. So, we have deduced (from the recursive call) what the base case\r\n(None) should return -1.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nConverting between a Binary Tree and the List Representation of a Binary Tree\r\n\r\nNext we will look at functions that convert between trees and lists, showing\r\nthat there is a standard way to represent a tree as a nested list of values. We\r\nrepresent every TN as a 3-list containing (in order) the value, left, and right\r\nsubtrees (each subtree is itself a 3-list). So, we represent the tree\r\n\r\n         5\r\n       /   \\\r\n      3     8\r\n           / \r\n          6\r\n\r\nby the list [5, [3, None, None], [8, [6, None, None], None]]. Note that each\r\nlist in this data structure always has exactly 3 values (empty subtrees will be\r\nonly None). We could also put the value in the middle of the 3-list, which would\r\nresult in [[None, 3, None], 5, [[None, 6, None], 8, None]] for the tree above.\r\nThese lists can be deeply nested for tall trees.\r\n\r\nThere are simple recursive functions to translate a tree argument returning a\r\nlist, and a list argument returning a tree. Again, each uses two recursive calls\r\n\r\ndef list_to_tree(alist : list) -> TN:\r\n    if alist == None:\r\n        return None\r\n    else:\r\n        return TN( alist[0], list_to_tree(alist[1]), list_to_tree(alist[2]) ) \r\n\r\nEach recursive call on a non-empty list builds a TN with a value (alist[0]),\r\nand then produces subtrees from the next two values in the 3-list; eventually\r\nNone will be reached as base cases.\r\n\r\nLikewise, we can just as easily translate from a tree (TN) to a list.\r\n\r\ndef tree_to_list(atree : TN) -> list:\r\n    if atree == None:\r\n        return None\r\n    else:\r\n        return [atree.value, tree_to_list(atree.left), tree_to_list(atree.right)]\r\n\r\nEach recursive call on a non-empty tree builds a 3-list of the value, followed\r\nby the list equivalent of the left and right subtrees; eventually None will be\r\nreached as base cases.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nPrinting a Binary Tree\r\n\r\nThe following function prints a tree rotated 90 degree counter-clockwise. So\r\nthe binary tree we show as\r\n\r\n             30\r\n          /      \\\r\n       15          50\r\n    /     \\      /    \\\r\n  10       25  35      70 \r\n         /\r\n       20\r\n\r\nprints as follows. Notice where the root (30) appears, and where the roots of\r\nits left (15) and right (50) subtrees appear, and the left/right roots of those\r\nsubtrees, etc.\r\n\r\n....70\r\n..50\r\n....35\r\n30\r\n....25\r\n......20\r\n..15\r\n....10\r\n\r\nThis function declares print_tree_1, as a local helper function that does all\r\nthe recursive work (using the indent_char/indent_delta parameters), and then\r\ncalls print_tree_1 with an initial identation of 0 and the same atree. The\r\nhelper function either does nothing (for printing an empty tree), or prints all\r\nvalues in its right subtree (first, with more indentation), its own value, and\r\nthen all values in its left subtree (with more indentation).\r\n\r\ndef print_tree(atree,indent_char =' ',indent_delta=2):\r\n    def print_tree_1(indent,atree):\r\n        if atree == None:\r\n            return None     # print nothing\r\n        else:\r\n            print_tree_1(indent+indent_delta, atree.right)\r\n            print(indent*indent_char+str(atree.value))\r\n            print_tree_1(indent+indent_delta, atree.left)\r\n    print_tree_1(0,atree) \r\n\r\nAt this point, we have dealt with the structure of trees, but not their values.\r\nIn a binary search trees, we can use its extra order property to search for, add\r\na value, and remove a value efficiently: think of a tree representing a set of\r\nvalues (each value in a set is unique; that mirrors our intent of having unique\r\nvalues in binary trees).\r\n\r\n------------------------------------------------------------------------------\r\n\r\nSearching for a value in a Binary Search Tree\r\n\r\nWe can use the following iterative function to search for a value; unlike the\r\nother functions written above, this one goes only one way (left or right) for\r\neach tree node. We know that if the value we are searching for is less than a\r\nnode's value, by the order property of a binary search tree it must be in the\r\nleft subtree; if the value we are searching for is greater than a node's value,\r\nit must be in the right subtree. So for a value node equal to a node's value\r\n(in which case we have already found the value) we go one way or the other.\r\n\r\ndef search_i(atree,value):\r\n    while atree != None and atree.value != value:    # Short-circutit evaluation\r\n        if value < atree.value\r\n           atree = atree.left\r\n        else:\r\n           atree = atree.right\r\n    return atree  # either None or the TN storing value\r\n\r\nNote that the if statement is selecting which value (atree.left or atree.right)\r\nto store in atree, so we can simplify this if statement using a conditional\r\nexpression.    \r\n\r\ndef search_i(atree,value):\r\n    while atree != None and atree.value != value:    # Short-circutit evaluation\r\n        atree = (atree.left if value < atree.value else atree.right)\r\n    return atree  # either None or the TN storing value\r\n    \r\nWe can also write this function recursively.\r\n\r\ndef search_r(atree,value):\r\n    if atree == None:\r\n        return None\r\n    else:\r\n        if value == atree.value:\r\n            return atree\r\n        elif value < atree.value:\r\n            return search_r(atree.left,value)\r\n        else: # value > atree.value # true by law of trichotomy: ==, <, or >\r\n            return search_r(atree.right,value)\r\n    \r\nWe can combine the base check and equality check, and use a conditional\r\nexpression to shorten this function to the following\r\n\r\ndef search(atree,value):\r\n    if atree == None or atree.value == value\r\n        return atree          # atree may be empty; if not, atree.value == value\r\n    else:\r\n        return search( (atree.left if value < atree.value else atree.right), value)\r\n\r\nIn the function above, the \"base\" case is an empty tree or the node storing the\r\nvalue; the same recursive call is executed for subtrees, with the first\r\n\"smaller\" tree (having fewer nodes) being either atree.left or atree.right.\r\n\r\nBecause this is a tail-recursive function, we expect to be able to write it\r\niteratively (as we did above).\r\n\r\n------------------------------------------------------------------------------\r\n\r\nAdding/Removing a value to/from a Binary Search Tree\r\n\r\nNow, here is a similar (to the top) function to add a value to a tree. We call\r\nit like: atree = add(atree,value) -similarly to how we added a value to a list.\r\n\r\ndef add(atree,value):\r\n    if atree == None:\r\n        return TN(value)\r\n    elif value == atree.value:\r\n        return atree                   # already in tree; do not change the tree\r\n    else:\r\n        if value < atree.value:\r\n            atree.left = add(atree.left,value)\r\n          else: # value > atree.value: # true by law of trichotomy: ==, <, or >\r\n            atree.right = add(atree.right,value)\r\n        return atree\r\n\r\nIn all cases, this function returns a reference to a tree to which a TN with\r\nvalue has been added as a subtree (returning all the values in the original\r\ntree including the new node/value). By the 3 proof rules.\r\n\r\n1) The code detects the base case (an empty tree) and return a tree containing\r\nonly a node storing value (all the nodes in the original tree -there are none-\r\nincluding a node storing value).\r\n\r\n2) Each recursive call (there are two) is on a left or right subtree (which is\r\nsmaller than the entire tree, at least by one node, probably by many more if\r\nthe other side contains some nodes).\r\n\r\n3) Assume calling add returns a new tree containing all the nodes in its\r\nsmaller argument tree, including a node containing value. When the value is\r\nequal to atree.value, it returns just atree (which already contains value, not\r\nduplicating that value). When the value is less/greater than atree.value, it\r\ncalls add recursively, which returns the left/right tree with value included,\r\nand stores it back in atree.left/atree.right; finally it returns atree, which is\r\ntree containing value (now either in left/right subtree of atree).\r\n\r\nRecall that the structure of a tree is not determined solely by the values it\r\ncontains. As we saw above, there are many legal binary search trees storing the\r\nsame values. The structure is determined by the order those values are added to\r\nthe tree. Adding values in increasing order, decreasing order, at random, will\r\nall produce different shaped trees.\r\n\r\nI will defer showing the remove function, but I will describe it here and you\r\nshould use this description to practice deleting values from trees (shown\r\npictorally). Use the following simple tree for a first example\r\n\r\n             30\r\n          /      \\\r\n       15          50\r\n    /     \\      /    \\\r\n  10       25  35      70 \r\n         /\r\n       20\r\n\r\n\r\nHere are the rules:\r\n\r\n1) To remove a value in a leaf, make its parent refer to None\r\n\r\n2) To remove a value in a node with one child, make its parent refer to its\r\n    child (this works whether the node is a left/right child of its parent, \r\n    and whether its child is a left/right child)\r\n\r\n3) To remove a value in a node with 2 children:\r\n      (a) Find the biggest node less than it (or smallest node greater than it)\r\n            that node must have either 0 or 1 children (can you explain why?)\r\n      (b) Remove that node by rule 1 or 2\r\n      (c) Take its value and put it as the value of the node being removed\r\n          So the node being removed isn't really removed (another one is):\r\n            but, its value is replaced by another value, so the value is removed\r\n\r\nThe first two rules are very simple. Here is an example of applying the third.\r\nIf we remove the value at the root, 30, we would (a) find the node 25,\r\n(b) remove the value here by making 15's right refer to 20, (c) move the value\r\n25 to the node that contains 30. Note the order property is preserved: all\r\nvalues to the left of the node that used to store 30 are less than what it now\r\nstores, 25 (25 was the biggest of the nodes < 30); all values to the right of\r\nthe node that used to store 30 are greater than what it now stores, 25 (25 is\r\n< 30, so nodes > 30 are > 25).\r\n\r\n             25\r\n          /      \\\r\n       15          50\r\n    /     \\      /    \\\r\n  10       20  35      70 \r\n\r\n\r\nThe binarysearchtree module contains simple recursive functions for copying a\r\ntree and determining whether two trees are equal (not only store the same\r\nvalues overall, but store trees that have these values in the same shape).\r\nExamine those functions, which appear below (or better yet, try to write them\r\nyourself first).\r\n\r\ndef copy(atree):\r\n    if atree == None:\r\n        return None\r\n    else:\r\n        return TN(atree.value, copy(atree.left), copy(atree.right)) \r\n\r\n\r\ndef equal(t1,t2):\r\n    if t1 == None or t2 == None:\r\n        return t1 == None and t2 == None\r\n    else:\r\n        return t1.value == t2.value and equal(t1.left,t2.left) and equal(t1.right,t2.right)\r\n\r\nNote that for the short-circut \"and\" operator in equal, if the values in any\r\nnode are not equal, the value False is returned immediately, without making the\r\nrecursive calls to equal.\r\n\r\nIn that module the generator_in_order generator yields all the values (from\r\nlowest to highest) in the tree it is called on. In the next lecture we will\r\nstudy traversal orders more generally, discussing pre-order, in-order,\r\npost-order, and breadth-first order.\r\n\r\nWe can use binary search trees easily to represent a dictionary: each TN would\r\nstore a value that is 2-tuple, a key-value pair. The keys in a dictionary are\r\nknown to be unique. When processing a tree, Python will always compare/process\r\nthe first value in the 2-tuple (the key). In a binary search tree representation\r\nof a dictionary, all keys must be comparable; in a Python dict, we can have keys\r\nthat aren't comparable: one key could be an int and another a str. So, Python\r\ndictionaries are NOT represented by binary search trees, but by something even\r\nfaster and more interesting: hash tables. ICS-46 covers runtime performance\r\n(efficiency) of lists, trees, and hash tables (which is how Python stores both\r\nsets and dictionaries; hash tables are covered in a later ICS-33 lecture note).\r\n\r\nA well-balanced binary search tree (all nodes having about an equal number of\r\nchildren in its left and right subtrees) can be searched much faster than a\r\nlist or linked list. The amount of time it takes to search any binary search\r\ntree is bounded by its height: the number of comparisons in needs to go downard\r\nin the tree until it reaches the value it is searching for (or goes beyond a\r\nleaf, meaning that the value is not in the tree).\r\n\r\nThe height of an N-node tree must be at least Log2 N (log base 2 of the number\r\nof nodes in the tree). The typical height, when values are added randomly, is\r\n2-3 times that. In a linked list (or pathological binary search tree: a very\r\ndeep skinny one) the number of comparisons is N. Log2 N is generally a much\r\nsmaller number than N: Log2 1,000 is about 10; Log2 1,000,000 is about 20; and\r\nLog2 10^9 (a billion) is about 30. So, we could store a billion values in a\r\nwell-balanced binary search tree and determine whether a value is in it using\r\nonly about 60-90 comparisons.\r\n\r\nTry the following experiment, which prints the height of a tree with 1,000\r\nvalues, added in a random order.\r\n\r\n  values = [i for i in range(1000)]\r\n  random.shuffle(values)\r\n  print(height(add_all(None,values)))\r\n\r\nLog2 1,000 is about 10, so the typical height of such a tree is about 20-30,\r\nwhich means it takes 20-30 comparisons to find a value: much better than the\r\naverage of about 500 if the values are in an unordered list or linked-list.\r\nAlso, see the random_height function in the binarysearchtree.py module.\r\n\r\nAgain, in ICS-46 we will look at tree processing in more depth :).\r\n\r\n------------------------------------------------------------------------------\r\n\r\nExpression Trees\r\n\r\nWe can also use binary trees to represent mathematical formulas/expressions. In\r\nthese trees, leaf nodes represent values (either literals or names bound to\r\nvalues), and the internal nodes represent binary operators or unary operators\r\nor unary functions (whose operands will be in the right subtree). For example,\r\nthe expression (-b + sqrt(b**2 - 4*a*c))/(2*a) would be represented by the\r\nexpression tree.\r\n\r\n                       '/'\r\n            /                    \\\r\n           +                      *\r\n      /         \\                /  \\\r\n     -          sqrt            2    a\r\n      \\           \\\r\n       b           -\r\n                /      \\\r\n               **       *\r\n              /  \\     / \\ \r\n             b    2   *   c\r\n                     / \\\r\n                    4   a\r\n\r\nHere I wrote '/' for the divide operator, since / means a left subtree in the\r\nother parts of the pictures. Actually, all values are actually stores as\r\nstrings.\r\n\r\nNote that the structure of the tree determines how the subexpressions are\r\ncomputed. There is no need for operator precedence rules or parentheses: the\r\nstructure of the tree embodies these rules.\r\n\r\nThere is an algorithm that people can follow to construct such a tree: find the\r\nlast operator or function call the computer would evaluate and put that at the\r\nroot of the tree; now do the same for its one/two subtrees that are\r\nsubexpressions, and keep repeating finding the root of these until there are no\r\nmore operators or functions (names and literals stand for themselves). \r\n\r\nIn the expression above, the division between the numerator and denominator is\r\nevaluated last: on the left side the addition is evaluated last; on the right\r\nside there is only the multiplications, so that is done last. Continue this\r\nprocess. If we call print_tree on this tree, it would print\r\n\r\n....a\r\n..*\r\n....2\r\n/\r\n..........c\r\n........*\r\n............a\r\n..........*\r\n............4\r\n......-\r\n..........2\r\n........**\r\n..........b\r\n....sqrt\r\n..+\r\n......b\r\n....-\r\n\r\nOnce we have such a tree, we can peform many operations on it. The first and\r\nmost important is evaluating the tree. We can do this recursively (evaluating\r\nsubexpressions) by\r\n  (1) evaluating leaves as themselves\r\n  (2) evaluating either unary operators on their evaluated operand or unary\r\n        functions on their evaluated argument\r\n  (3) evaluating binary operators on their evaluated arguments\r\n\r\nThe code for this method follows this outline\r\n\r\ndef evaluate(etree):\r\n    #name/literal\r\n    if etree.left == None and etree.right == None:\r\n        return eval(str(etree.value))\r\n\r\n    #unary operator/function cal\r\n    elif etree.left == None:\r\n        if etree.value in {'+','-'}:\r\n            #unary operator\r\n            return eval(etree.value + str(evaluate(etree.right)))\r\n        else:\r\n            #function call: assume legal name\r\n            return eval(etree.value+'('+str(evaluate(etree.right))+')')\r\n    else:\r\n        #binary operator: assume etree.value in {'+','-','*','/','//','**'}\r\n\r\n        return eval(str(evaluate(etree.left)) + etree.value + str(evaluate(etree.right)))\r\n\r\nIf we set a=1, b=2, c=1, the calcuated value is -1.\r\n\r\nWe can translate this tree into infix (but overparenthesized) and postfix form:\r\nin the postfix form, each operator is proceeded by its two operands: \"a + 1\"\r\n(infix form) translates to \"a 1 +\" (postfix form). Using postfix notation (also\r\ncalled Polish notation because it was invented by Polish logicians right before\r\nWorld War II), we can write expressions unambiguously without any parentheses\r\nor knowledge of operator precedence! \"(a + b) * c\" translates to \"a b + c *\"\r\nand \"a + b * c\" translates to \"a b c * +\". Each binary operator applies to the\r\ntwo values before it.\r\n\r\nHere are the functions to perform these translations, and their results.\r\n\r\ndef infix(etree):\r\n    if etree.left == None and etree.right == None:\r\n        return '('+str(etree.value)+')'\r\n    elif etree.left == None:\r\n        return '('+etree.value+str(infix(etree.right))+')'\r\n    else:\r\n        return '('+str(infix(etree.left))+etree.value+str(infix(etree.right))+')'\r\n\r\nwhich produces: (((-(b))+(sqrt(((b)**(2))-(((4)*(a))*(c)))))/((2)*(a)))\r\nwhich is correctly but over parenthesized.\r\n\r\ndef postfix(etree):\r\n    if etree.left == None and etree.right == None:\r\n        return str(etree.value)\r\n    elif etree.left == None:\r\n        return str(postfix(etree.right)) + ' ' + etree.value\r\n    else:\r\n        return str(postfix(etree.left)) + ' ' + str(postfix(etree.right)) + ' ' + etree.value\r\n\r\nwhich produces: b - b 2 ** 4 a * c * - sqrt + 2 a * /\r\n\r\nIf you have never seen Polish notation this is difficult to read, but if you\r\nhave studied this notation, it is easy. To understand which operators apply to\r\nwhich data, start on the left and circle each operand: when you get to an\r\noperator circle it and the number of operands it takes (which all come before\r\nit). Look at smalller examples: 1+2*3 is 123*+ while (1+2)*3 is 12+3*. The\r\noperands in polish notation appear in the same order as regular notation, but\r\nthe operators appear in different spots based on operator precedence and\r\nparentheses.\r\n\r\nFinally, I have defined a parse_infix function that takes a string argument\r\nand produces a tree representing the string. It is limited in the following\r\nways: all tokens must be separated by spaces; it assumes all operators are\r\nbinary, and that all operators are left-associative (which ** is not). So, it\r\ndoes a bit of what Python does when it processes expressions written in Python,\r\nbut doesn't do everything correctly. But it does everything more simply.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nProblems\r\n\r\n1) Draw all 14 binary search trees with the values 1, 2, 3, and 4.\r\n\r\n2) Define a function named mirror, which takes one binary tree argument and \r\nreturns a binary tree that is its mirror image: for any node, its left and\r\nright subtrees are switched (not just switched for the root, but switched for\r\nevery node in the tree).\r\n\r\n3) Define a function named sum, which takes one binary tree argument and\r\nreturns the sum of all the node values.\r\n\r\n4) Define a function named is_bst, which takes one binary tree argument and\r\nreturns whether or not the tree is a binary search tree (satisfies the order\r\nproperty of binary search trees). It should return False for the following\r\ntree (which violates the order property):      \r\n\r\n                5\r\n             /     \r\n            3\r\n              \\\r\n                8         \r\n\r\nHint: I used two helper functions: all_less and all_greater.\r\n\r\n5) Define a function named all_satisfy, which takes two arguments: a binary\r\ntree argument and an predicate; it returns whether or not the predicate\r\nsatisifies (returns True for) all values in the binary tree.\r\n", "encoding": "ascii"}