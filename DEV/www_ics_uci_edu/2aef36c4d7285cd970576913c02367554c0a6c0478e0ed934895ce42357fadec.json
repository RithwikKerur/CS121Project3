{"url": "https://www.ics.uci.edu/~pattis/ICS-33/lectures/generators.txt", "content": "      Generator Functions (and yield): Functions that Return Iterators\r\n\r\n\r\nPython includes a special kind of function called a generator function that\r\nreturns an iterator when it is called. With generator functions, we can easily\r\n(almost trivially) write many different kinds of iterators, although it takes a\r\nnew way of thinking to understand how. In this lecture we will first study\r\ngenerator functions by themselves, to understand their syntax and semantics\r\n(form and meaning), and then we will illustrate how to use them to write a\r\nvariety of iterators easily. I believe that the concept of a generator function\r\nis one of the most intuitively easy to understand features in Python (and\r\npowerful to boot), so I think you will enjoy reading this lecture. As always,\r\nthere are always a few subtleties that we will explore more deeply.\r\n\r\nFrom now on, this lectue will use the term \"generator\" to stand for \"generator\r\nfunction\". For example, \"We call generators like functions; when we call a\r\ngenerator, it returns an iterator: something we can call the next function on.\"\r\n\r\nGenerators are defined almost exactly like regular functions; the one difference\r\nis that generators include one or more \"yield\" statements. In fact, if we look\r\nat a definition and want to know whether or not it is a generator, we look for\r\nat least one yield statement in its body: if there is one or more yield, then\r\nit defines a generator: that is how Python determines whether it is a generator\r\ntoo. Just like functions, generators can also include \"return\" statements (and\r\nthere is an implicit return at the end of every generator). Let's explore the\r\ndifference between a yield and return statement in a generator.\r\n\r\nA basic yield statement has the same form as a return statement: each keyword is\r\nfollowed by an expression that is evaluated, stopping the code (but in different\r\nways: see below) resulting in a value. The key difference is that the code in a\r\ngenerator's body can be RESTARTED after executing a yield statement -and it\r\nrestarts exactly where it left off in the computation: in the same state, from\r\nthe next line. Python remembers this information when executing generators,\r\nunlike regular functions: once the body of a regular function executes a return\r\nstatement, it can be restarted only from the beginning, by calling the function\r\nagain. In fact, when a generator executes a return statement, it also signals\r\nthat it is truely finished executing and cannot be restarted unless it is called\r\nagain: Python translates the return into raising a StopIteration exception.\r\n\r\nNow, let's look at the difference between functions and generators more closely.\r\n\r\nWhen we call a FUNCTION, Python evaluates its arguments and binds its parameters\r\nto their matching arguments, and then executes its body. When it executes a\r\nreturn statement, the specified value is computed/returned (or the value None\r\nis automatically returned if the last statement of a function body is executed\r\nwithout ever executing a return). When a function returns this value, it is\r\nfinished and Python forgets the states of its parameters and local variables;\r\nit forgets from where it executed the return statement: when called again, a \r\nfunction always starts at the beginning.\r\n\r\nWhen we call a GENERATOR FUNCTION, likewise Python evaluates its arguments and\r\nbinds its parameters to their matching arguments, but Python DOES NOT START\r\nEXECUTING its body yet. Instead, the generator immediately \"suspends\" by\r\nreturning an iterator representing the code in the generators's body. To start\r\nor later re-execute this code, Python must call \"next\" on the iterator returned\r\nby the generator. So calling a generator is similar to calling iter(...) on an\r\nobject that supports iteration: both result in an iterator: an object on which\r\nnext(...) can be called. In fact, we often use generators to specify for loops,\r\nwhich  automatically call iter(...) on the result returned by the generator:\r\nrecall that when Python executes iter(...) on an iterator, it typically just\r\nreturns the same iterator object (we programmed our prange_iter class, and\r\nothers, to behave this way).\r\n\r\nEach time next is called on this iterator, the generator's body resumes\r\nexecution from where it was suspended (initally, it suspends BEFORE EXECUTING\r\nANY STATEMENTS IN ITS BODY), further executing its body. When it executes a\r\nyield statement, the specified value is returned from the call to next. When a\r\ngenerator yields a value, it then suspends itself again (again remembering the\r\nstate of its parameters, local variables, and its execution point). When Python\r\ncalls next(...) on it again, it resumes exactly where it left off. A common and\r\nsimple use for generator is being called to start a for loop: the call to the\r\ngenerator function creates an iterator; the call to iter passes along this\r\niterator to _hidden (in the while-loop translation), and Python repeatedly\r\ncalls next on _hidden (the result returned by calling the generator function)\r\nas it executes the for loop.\r\n\r\nA generator's body can also return; doing so ignores the returned value (if it\r\nis specified) and just raises the StopIteration exception: a generator function\r\ncan do this explicitly by executing a return statement or implicitly, if it\r\nruns out of statments to execute in its body. Once it has raised StopIteration,\r\ncalling next again reraises the StopIteration exception. Stopped means stopped\r\nforever.\r\n\r\n-----\r\n***Starting in Python 3.5, the only correct way for a generator to terminate\r\n***when exhausted is by executing an explicit or implicit return. We\r\n***should adopt this convention, whether using Python 3.5 or any earlier\r\n***version of Python -as we will in all the examples below.\r\n\r\n***Starting in Python 3.5, if a generator explicitly raises the StopIteration\r\n***exception (one that is not caught inside a try/except in the generator's\r\n***body), Python will actually raise the RuntimeError exception instead. So\r\n***EXPLICITLY raising the StopIteration exception now signals a RuntimeError,\r\n***not just normal termination. So, executing a return will still raise the\r\n***StopIteration exception, correctly signalling normal termination of a\r\n**generator's body.\r\n\r\n***In earlier Python versions, executing return or raise StopIteration were\r\n***equivalent: both terminated the generator's body normally.\r\n\r\n***Now, normal termination of the generator function is signalled by executing\r\n***an explicit or implicit return; now, raising StopIteration (which is\r\n***translated into raising RuntimeError), signals an abnormal termination.\r\n-----\r\n\r\nNow it is time for a concrete example that we will study, going back to apply\r\nthe general rules stated above in particular cases. In the generator below, the\r\nwhile loop is infinite (if max == None) or finite (p will get no bigger than\r\nmax if max != None). Each iteration checks whether the current p is a prime and\r\nyields p's value if so; otherwise it increments p and checks if it is prime\r\n(unless p has surpassed a non-None max). So primes is a generator that\r\nyields/produces only prime numbers: either a finite number of them or primes\r\nwithout limits (there are an infinite number of primes, so there is always\r\nanother one to produce).\r\n\r\nAside: So here one a big difference between iterating over a data object (like\r\na list) and iterating over a generator object: iterating over a list will\r\nproduce a finite number of values, but we cannot guarantee that for a generator.\r\nWhile it makes sense to call the len function on a list, in general it makes\r\nno sense to call len on an arbitrary generator object.\r\n\r\nfrom predicate import is_prime      # Could use other predicates just as easily\r\ndef primes(max = None):\r\n    p = 2                           # 2 is the first prime; so start there\r\n    while max == None or p <= max:  # Short-circuit evaluation is critical here!\r\n        if is_prime(p):\r\n            yield p\r\n        p += 1 \r\n\r\nQuick note: this while's test uses the short-circuit property of \"or\": if\r\nmax == None is True, then the entire expression is True, so Python does not\r\nhave to evaluate the right operand; if Python did evaluate the right operatnd,\r\nit would raise an exception because Python cannot compare p (an int value) to\r\nmax (if max is equal to None); instead it would raise the exception: TypeError:\r\nunorderable types: int() <= NoneType(). Of course we might want to assert that\r\ntype(max) is either NoneType or int, but I want to focus purely on generator\r\nfunctions here so I have omitted this extra code.\r\n\r\nBefore looking at an example in detail that uses this generator, it is easy to\r\ndetermine what it does: it yields only prime numbers, either without limit or\r\nwhose values are limited to be <= max if max is not None. The code is\r\nstraightford and does the obvious thing: to most programmers its mechanism,\r\nsuspending and resuming execution, is easy/intuitive to understand and use to\r\nwrite generators. If it helps, think about yield like a print statement\r\n(discussed in more detail below): this function yields/prints all the required\r\nprimes.\r\n\r\nLet us determine what happens if we execute the following Python code, which\r\nfirst binds the name i to the result of calling the primes generator (which \r\nreturns an iterator: something we can call next on); it then continues to print\r\nthe values returned by calling next(i) repeatedly. \r\n\r\ni = primes(10) # calling this genereator returns an iterator\r\nprint(i)       # generator object is the same as iterator\r\nprint(next(i)) # can call next on the iterator/generator object\r\nprint(next(i))\r\nprint(next(i))\r\nprint(next(i))\r\nprint(next(i))\r\n\r\nWhen Python executes this script, it produces the following results. An\r\nexplanation of these results follows.\r\n\r\n  <generator object primes at 0x029C5850>\r\n  2\r\n  3\r\n  5\r\n  7\r\n  Traceback (most recent call last):\r\n    File \"C:\\Users\\Pattis\\workspace\\zexperiment\\experiment.py\", line 12, in <module>\r\n      print(next(i))\r\n  StopIteration\r\n\r\nWhen we call primes(10), this generator binds its parameter max to 10 and then\r\nimmediately returns an iterator representing prime's SUSPENDED BODY (before\r\nexecuting any of the statements in its body). It doesn't run, so it doesn't\r\nyield any values yet: but it will yield values when we call next on it, so it is\r\nsimilar to what calling iter(...) does, returning an iterator.\r\n\r\nGenerators print much like functions, indicating they are a generator object\r\n(a special kind of iterator), named primes, and stored at some memory location\r\n(a value we are unconcerned with knowing, other than to find that if we executed\r\ni1 = primes(10) followed by i2 = primes(10) followed by print(i1,i2) the\r\nlocations of i1 and i2 are DIFFERENT. Two calls to prime have produed two\r\ndifferent iterator objects. This is like the fact that calling iter(...) twice\r\non a range objects produces two different objects that we can iterate over\r\nindependently.\r\n\r\nThe first call of next(i) resumes the suspended execution of the generator,\r\nwhich starts by binding p to 2 and then begins executing the while loop. Since\r\nmax != None it will continue to loop so long as p <= 10. It executes the body\r\nof the loop and the if statement checks whether p (now 2) is prime; it is, so\r\nit yields the value 2 (returning it from the call to next and suspending the\r\ngenerator for further use). Python prints 2.\r\n\r\nThe second call of next(i) resumes the suspended execution of the generator\r\nafter the yield, which increments p to 3 and then re-executes the while loop's\r\nbody (p is <= 10). The if statement checks whether p (now 3) is prime; it is,\r\nso it yields the value 3 (returning it from the call to next and suspending the\r\ngenerator). Python prints 3.\r\n\r\nThe third call of next(i) resumes the suspended execution of the generator\r\nafter the yield, which increments p to 4 and then re-executes the while loop's\r\nbody (p is <= 10). The if statement checks whether p (now 4) is prime; it\r\nisn't, so Python increments p to 5 and  re-executes the while loop's body\r\n(p <= 10). The if statement checks whether p (now 5) is prime; it is, so, it\r\nyields the value 5 (returning it from the call to next and suspending the\r\ngenerator). Python prints 5 (by skipping/not yielding the value 4).\r\n\r\nThe fourth call of next(i) resumes the suspended execution of the generator\r\nafter the yield, which increments p to 6 and then re-executes the while loop's\r\nbody (p is <= 10). The if statement checks whether p (now 6) is prime; it\r\nisn't, so Python increments p to 7 and re-executes the while loop's body\r\n(p <= 10). The if statement checks whether p (now 7) is prime; it is, so, it\r\nyields the value 7 (returning it from the call to next and suspending the\r\ngenerator). Python prints 7 (by skipping/not yielding the value 6).\r\n\r\nThe fifth call of next(i) resumes the suspended execution of the generator,\r\nafter the yield, which increments p to 8 and then re-executes the while loop's\r\nbody (p is <= 10). The if statement checks whether p (now 8) is prime; it\r\nisn't, so Python increments p to 9 and re-executes the while loop's body\r\n(p <= 10). The if statment checks whether p (now 9) is prime; it isn't so\r\nPython increments p to 10 and re-executes the while loop's body (p <= 10). The\r\nif statment checks whether p (now 10) is prime; it isn't, so Python increments\r\np to 11 but terminates the loop (does not re-execute its body), because p > 10.\r\n\r\nBecause there are no more statements to execute in the generator, it implicitly\r\nexecutes a return, which inside an generator automatically raises the\r\nStopIteration exception, which is not handled in any try/except block in its\r\ncode, so it propagates to Python, which prints it and then terminates execution\r\nof the script.\r\n\r\nNote what happens if we reset i to a new call of primes(10)\r\n\r\ni = primes(10)\r\n\r\nprint(next(i))\r\nprint(next(i))\r\nprint(next(i))\r\n\r\ni = primes(10)\r\n\r\nprint(next(i))\r\nprint(next(i))\r\n\r\nPython would print\r\n\r\n  2\r\n  3\r\n  5\r\n  2\r\n  3\r\n\r\nbecause calling primes(10) create a new generator object which will yield 2\r\nthe first time it is called. We bind i to the new object, starting it over. If\r\nwe wrote the script\r\n\r\ni1 = primes(10)\r\ni2 = primes(10)\r\nprint(next(i1))\r\nprint(next(i2))\r\nprint(next(i1))\r\nprint(next(i2))\r\nprint(next(i1))\r\nprint(next(i2))\r\n\r\nPython would print\r\n\r\n  2\r\n  2\r\n  3\r\n  3\r\n  5\r\n  5\r\n\r\nbecause we now have two different generator objects, and each works\r\nindependently of the other. So each time we call a generator, it constructs a\r\nnew object to return and later iterate over.\r\n\r\nConstrast this with\r\n\r\ni1 = primes(10)\r\ni2 = i1\r\nprint(next(i1))\r\nprint(next(i2))\r\nprint(next(i1))\r\nprint(next(i2))\r\n\r\nfor which Python would print\r\n\r\n  2\r\n  3\r\n  5\r\n  7\r\n\r\nbecause now both i1 and i2 alias (refer to) the same iterator/generator object.\r\nAnother call to next would raise the StopIteration exception\r\n\r\n----------\r\nFunction/Generators Aside: Terminology, Predicates, iter function\r\n\r\nThe module named inspect in Python (see the 29.12 in the Python Library) has\r\nhas many functions, including the predicates isfunction, isgeneratorfunction,\r\nan isgenerator, which respectively return whether or not their arguments are a\r\nfunction, generator function, or generator object (an object returned by calling\r\na generator function). Assume we import these by executing\r\n\r\n  from inspect import isfunction, isgenerator\r\n\r\nThen isfunction(primes) and isgeneratorfunction(primes) both return True:\r\nPython considers primes both function and more specifically a generatorfunction.\r\nAlso isgenerator(primes) returns False, but isgenerator(primes()) returns True.\r\nSo technically, primes is a generator FUNCTION that when called returns a\r\nGENERATOR object (really an iterator: something that we can call next on).\r\n\r\nIf we call type(primes()) it prints as the string <class 'generator'> but I\r\ndo not know how to refer to the name of the generator class explicitly, only\r\nhow to call the isgenerator predicate, to determine whether or not an object is\r\na generator. So, while we write type(x) is int to determine whether or not x is\r\nan integer,  we call inspect.isgenerator(x) to determine whether or not x is a\r\ngenerator.\r\n\r\nWith these concepts we can write an even more accurate verison of iter as\r\nfollows. In this version, we illustrate that calling iter on a generator just\r\nreturns that generator itself; otherwise, it calls __iter__ on its argument and\r\nreturns that value, so long as Python can call next on that value (checked in\r\nboth the namespace of the object and the namespace of the class from which the\r\nobject was constructed).\r\n\r\ndef iter(i):\r\n    if isgenerator(i):\r\n        return i\r\n\r\n    x = i.__iter__()\r\n    if '__next__' not in x.__dict__ and '__next__' not in type(x).__dict__:\r\n        raise TypeError('iter() returned non-iterator of type '+type_as_str(x))\r\n\r\n    return x\r\n\r\n\r\nSo, technically when translating the following for loop into a while loop,\r\n\r\n    for i in primes(10):\r\n        print(i)\r\n\r\nPython executes _hidden = iter(primes(10)). In this case the primes generator\r\nfunction is called and returns a generator object (like an iterator); when iter\r\nis called on the generator object it immediately returns that same object (on\r\nwhich it will automatically call next in the translation of the body of the for\r\nloop). \r\n\r\nWe had this same problem in the previous lecture, solving it by writing an\r\n__iter__ method in the nested iterator class, which just returned self. In this\r\nway, calling iter on an iterable just returned that iterable.\r\n\r\nHere are a few other predicates we can call after importing from inspect:\r\nismodule, isclass, and ismethod. It also defines way to get interesting\r\ninformation about objects. For example, if we define the f function on line 1\r\nof a module\r\n\r\n1  def f(x):\r\n2     return x;\r\n\r\ngetsourcelines(f) returns\r\n\r\n(['def f(x):\\n', '    return x\\n'], 1)\r\n\r\nA tuple whose first index is a list of the lines in the function's definintion\r\nand whose second index is the line in the file on which the function starts.\r\n\r\ngetsource(f) returns the function as one large string: its str is\r\n\r\ndef f(x):\r\n    return x\r\n\r\nand its repr is\r\n\r\n'def f(x):\\n    return x\\n'\r\n\r\nThe concept of \"introspection\" allows a running program to examine information\r\nabout itself. In Program #4, we will see introspection about the parameter\r\nstructure of a function, and the binding of arguments to parameters when a\r\nfunciton is called, using functions in the inspect module. We can introspect\r\nabout all this information in a Python function.\r\n----------\r\n\r\nFinally, although we have been slogging around with explicit calls to\r\nnext(...), which we can do with generators, as we did with iterators, they are\r\nmost simple to use in the typical contexts in which we use iterators: \"for\"\r\nloops. The script\r\n\r\nfor i in primes(50):\r\n    print(i,end=' ')\r\n\r\nwould print all the primes <= 50: 2 3 5 7 11 13 17 19 23 29 31 37 41 43 47\r\n\r\nAnd the script\r\n\r\nfor i in primes():\r\n    print(i)\r\n\r\nbinds the parameter max to None (its default value) so the while loop would\r\nbe infinite, and it would keep printing primes forever: so the primes generator\r\ncan either be a definite (bounded) or indefinite (unbounded) generator of\r\nprimes (because there are an infinite number of primes).\r\n\r\nWe could alter the meaning of primes to bound not the VALUE of the prime\r\nproduced, but to bound the NUMBER of primes produced. Here is the code for this\r\ntask\r\n\r\nfrom predicate import is_prime\r\ndef primes(max_number_to_return = None):\r\n    p = 2\r\n    while max_number_to_return == None or max_number_to_return > 0:\r\n        if is_prime(p):\r\n            if max_number_to_return != None:\r\n                max_number_to_return -= 1\r\n            yield p\r\n        p += 1 \r\n\r\nfor i in primes(20):\r\n    print(i,end=' ')\r\n\r\nThis script produces not primes up to 20, but 20 primes. When run it prints\r\n\r\n  2 3 5 7 11 13 17 19 23 29 31 37 41 43 47 53 59 61 67 71\r\n\r\nWhich loop is easier to understand: the one above or \r\n\r\n    while True:\r\n        if max_number_to_return != None and max_number_to_return == 0:\r\n            return\r\n        ...\r\n\r\nNote that we could have also written this primes generator to create a finite\r\nlist of max_to_return primes and return that eniter list, which the for loop\r\nabove could iterate over. But the advantage of the generator above is two-fold:\r\nit can produce an infinite number of primes (not useful in the loop shown above,\r\nbut useful in other examples), and the space it occupies is fixed (always a few\r\nlocal variable names, none of which bind to a complicated data structure: not a\r\ntuple/list/set/dict) no matter how many primes it must generate (unlike a\r\nprimes function that returns a list, whose space would grow with the value of\r\nits parameters). Generators commmonly have this \"can be infinite\" and \"use\r\nlittle fixed space\" properties, when compared to functions that return many\r\nvalues all at once (e.g., putting all of the values in a list).\r\n\r\nThat finishes our discussion of generators unto themselves. The next sections\r\ndiscuss how to use generators to implement the __iter__/__next__ protocol of\r\niterators for classes, and how to write iterator decorators.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nGenerators for implementing __iter__/__next__ in classes\r\n\r\nIn the previous lecture, I wrote the __iter__ method as follows. I could have\r\njust returned iter(list(self.histogram)) using the standard list iterator, but\r\nI wanted to show how to write an iterator that did its own indexing of the list\r\n(as the list iterator actually, does, to show you how to do it).\r\n\r\n    # standard __iter__: defines a class with __init__/__next__ and returns\r\n    #   an object from that class\r\n    def __iter__(self):\r\n        class PH_iter:\r\n            def __init__(self,histogram):\r\n\t        # make copy here, so iteration not affected by mutation\r\n                self.histogram = list(histogram)\r\n                self.next = 0\r\n\r\n            def __next__(self):\r\n                if self.next == 10:\r\n                    raise StopIteration\r\n                answer = self.histogram[self.next]\r\n                self.next += 1\r\n                return answer\r\n\r\n            def __iter__(self):\r\n                return self\r\n\r\n        return PH_iter(self.histogram)\r\n \r\nUsing generators, we can rewrite this method much more simply. First we will\r\nuse a class function _gen: the leading _ indicates that this is a helper method\r\nin the class and only methods inside the class (like the __iter__ method)\r\nshould call it. It still uses indexes to iterate over the list; it still does\r\nnot use the list iterator.\r\n\r\n    @staticmethod\r\n    def _gen(bins)\r\n        for i in range(10):\r\n            yield bins[i]\r\n                \r\n    def __iter__(self):\r\n        # copy so iteration not affected by mutation (e.g., clear/tally method)\r\n        return Percent_Histogram._gen(list(self.histogram))\r\n\r\nSimilarly to how we defined a class in an __iter__ method, we can define the\r\ngen generator inside __iter__ method as well; hiding this helper inside __iter__\r\nmakes it more difficult to ever call it outside of __iter__, so I'm now calling\r\nit just gen.\r\n\r\n    def __iter__(self):     #1: Correct\r\n        def gen(bins):\r\n            for i in range(10):\r\n                yield bins[i]\r\n                \r\n        # copy so iteration not affected by mutation (e.g., clear/tally method)\r\n        return gen(list(self.histogram))\r\n\r\nIn fact, we can ALMOST further simplfy this code to just a single method that\r\nIS a generator, which uses a local variable to store a copy of the histogram\r\nlist. BUT THIS IS WRONG!\r\n\r\n    def __iter__(self):     #2: WRONG!\r\n         hist_copy = list(self.histogram)\r\n         for i in range(10):\r\n            yield hist_copy[i]\r\n\r\n__iter__ itself now becomes a generator. Calling it (as with any generator)\r\nreturns an iterator, which can be called by next in the future, to yield its\r\nvalues (which is, after all, the purpose of __iter__).\r\n\r\nBUT, THERE IS A SUBTLE DIFFERENCE between these two code fragments; the copy of\r\nself.histogram in #1 is made when the ITERATOR IS CALLED. The copy in #2 is made\r\nwhen next() is CALLED THE FIRST TIME. Recall that executing #2 (which is itself\r\na generator function) suspends as soon as it is called (it binds the parameters\r\nbut executes no code in its body). Its body is executed only when \"next\" is\r\ncalled on the suspended generator. So the copying the list DOES NOT occur at the\r\ntime when __iter__ is called. We can see different behaviors concretely using\r\nthe following code.\r\n\r\np1 = Percent_Histogram() #1 version\t    p2 = Percent_Histogram() #2 version\r\ni1 = iter(p1)\t\t    \t\t    i2 = iter(p2)\r\np1.tally(0)\t\t\t\t    p2.tally(0)\r\nprint(next(i1))\t\t\t\t    print(next(i2))\r\n\r\nThe code for version #1 prints 0 (for the first histogram bin) because....\r\nWhen the iter(p1) function is called it makes a copy of the self.histogram list,\r\nwhich then has all 0s and then calls and returns the _gen generator, whose\r\nparameter is bound to that list copy and whose body does not yet execute.\r\nCalling p1.tally(0) updates self.histogram, but does not affect the copy that\r\nis bound to _gen's parameter. Calling print(next(i1)) starts executing the body\r\nof the _gen generator, whose first iteration returns the first value in that\r\ncopied self.histogram which has remained 0.\r\n\r\nThe code for version #2 prints 1 (for the first histogram bin) because....\r\nWhen the iter(p1) generator is called it returns a generator but its body does\r\nnot yet execute: the copy is NOT made yet. Calling p1.tally(0) updates\r\nself.histogram. Calling print(next(i1)) starts executing the body\r\nof the __iter__ generator, whose first statement copies self.historam which has\r\nALREADY BEEN UPDATED to tally the value 0. It continues executing the body\r\nof the __iter__ generator, whose first iteration returns the first value in that\r\nnow copied self.histogram which stores 1.\r\n\r\nThe two codes produce the same results only whenever the first call to next\r\ncomes immediately after the construction of the iterator, before any call that\r\nmutates it (which doesn't happen above: the p1.tally(0) method call occurs\r\nbetween them). So, any for loop would get translated into a while loop that\r\ncalls next immediately after iter, so these two versions of the __iter__ code\r\nproduce the same result when used with a for loop.\r\n\r\nVersion #2 would be not be correct if we wanted the meaning of iterating over a\r\nPercent_Histogram object to \"see\" all the mutations made to it during iteration\r\nover it. That is because it will see only the first change (but then copy the\r\nobject it is iterating over).\r\n\r\nThe bottom line for this discussion is that writing an __iter__ function with a\r\nnested generator allows the programmer full control over copying/not copying.\r\n\r\nAs a final simplification, if we did want to iterate over the histogram (and\r\nnot a copy, so we iterate over the mutation), we can share this object by smply\r\nwriting\r\n\r\n    def __iter__(self):\r\n         for i in range(10):\r\n            yield self.histogram[i]\r\n \r\nwhich is the same as writing\r\n\r\n   def __iter__(self):\r\n        def gen(bins):\r\n            for i in range(10):\r\n                yield bins[i]\r\n                \r\n        # No copy so iteration affected by mutation (e.g., clear/tally method)\r\n        return gen(self.histogram)\r\n\r\nIt doesn't copy self.histogram in either case, but uses it directly. So in\r\nthis case the meanings of the two __iter__ methods are the same: the top\r\n__iter__ is a generator function itself; he bottom __iter__ is a method\r\nthat returns a called generator function. In both cases we can call \"next\" on\r\nthe result returned by calling __iter__.\r\n\r\n\r\nWhy is it easier to write generators that implement iterators, compared to\r\nwriting __iter__ and __next__ methods explicitly? Generally, an iterator must\r\nremember its state; it must know what value to return when __ next__ is called;\r\nand when it is called, it must update its state so that when __next__ is called\r\nagain, it returns a different value, sequencing through all the values it must\r\nreturn. Remember that __next__ is typically called repeated/automatically, in\r\nthe while-loop translation of a Python for-loop.\r\n\r\nFunctions don't retain state in their local variables when they return. So\r\ninstead, we must store the state of an iterator as attributes in an object,\r\non which __next__ is called repeatedly. We saw that we typically store such\r\nstate in an object constructed from a class defined/nested inside __iter__.\r\nIn prange an prange_iter object stores three attributes: self.n, self.stop,\r\nand self.step.\r\n\r\nBut generators DO RETAIN THEIR STATE AFTER THEY YIELD A VALUE (and remember\r\nwhat statement they are executing too). When next is called on them, they\r\ncontinuing executing, starting with the statement after the yield (or the first\r\nstatement in the generator, when next is called the first time). So it is often\r\neasier to use local variables and simple control structures to write a\r\ngenerator that yields the values that the iterator produces.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nIMPORTANT HINT for writing Generators:\r\n\r\nTo those new to writing generators: if you want a GENERATOR to YIELD a sequence\r\nof values, first think about/write a FUNCTION that simply PRINTS that same\r\nsequence of values. Then change every PRINT statement into a YIELD statement.\r\nNow in the generator, when next is called multiple times, will instead yield\r\neach of the values it printed. \r\n\r\nUsing this idea makes generators easier to think about, write, and debug. There\r\ncan still be some subtleties involved, but this will work for simple generators\r\nand get you off to a good start for complicated ones. Always think about the\r\nmeaning of what you write.\r\n\r\nHere is a simple function where something interesting happens because of\r\nmutation. Its generator equivalent (with print replaced by yield) will have\r\nthe same problem.\r\n\r\ndef strange(n):\r\n    l = ['?']\r\n    for v in range(n):\r\n        l[0] = v\r\n        print(l)\r\n\r\nThe call strange(3) prints the results\r\n  [0]\r\n  [1]\r\n  [2]\r\n\r\nIf we change print(i) to yield, then the code\r\n\r\nfor i in strange(3):\r\n    print(i)     \r\n\r\nprints the results\r\n  [0]\r\n  [1]\r\n  [2]\r\n\r\nYet the code\r\n\r\nprint( [r for r in strange(3)] )\r\n\r\nprints the result\r\n\r\n[[2], [2], [2]]  \r\n\r\nYou should hand simulate it this function generator, drawing pictures of its\r\nexecution, to understand why it produces this last result. Then modify the code\r\nso that the first second loop/call prints the same, while the last one prints\r\n\r\n[[0], [1], [2]]  \r\n\r\n------------------------------------------------------------------------------\r\n\r\nIterable Decorators: Generators (which are Iterable) that use Iterable Arguments\r\n\r\nIn the previous lecture I wrote a few classes that implemented decorators for\r\niterables: each of which took an iterable argument (and possibly some other\r\narguments) and resulted in an object that was also iterable. We called such\r\nclasses decorators (for iterables; we will see decorators for functions next\r\nweek).\r\n\r\nThese classes were not huge (about a dozen lines: __init__, __iter__, and inside\r\n__iter__ an embedded class with __init__ and __next__: that is a lot of\r\ninfrastructure), but each can be written almost trivially using generators in\r\njust a few lines: code not split across interconnected __init__, __iter__, and\r\n__next__ methods, but instead code all in one generator.\r\n\r\nNote the term decorator means that the thing created is the \"same kind\" of thing\r\nthat is its argument (but decorated: with a change in behavior). So all these\r\ngenerators take some iterable as an argument, and because they are generators\r\nthe result they return is also iterable: they iterate in a slightly different\r\nway than their argument, decorating their argument. Therefore we can compose\r\niterable on top of iterable on top of iterable (see the last example in this\r\nsection) using these decorators.\r\n\r\nHere are the classes from the previous lecture rewritten as generators, and\r\ndramatically simplfied.\r\n\r\n1) Repeatedly produce values from an iterable (over and over again)\r\n\r\ndef repeat(iterable):\r\n    while True:\r\n        for i in iterable:\r\n            yield i\r\n\r\nAgain, the way to understand this generator is to think about what it would\r\nprint if the generator were changed to a function that printed i instead of\r\nyielding it: it would repeatedly print everything in the iterable. Understand\r\nthe other generators (below) using the same idea.\r\n\r\nEvery time the inner for-loop finishes, it is restarted by the outer while\r\nloop. I generalized this generator as follows, allowing a limit to the\r\nrepetitions, with the default None (which operates like repeat above).\r\n\r\ndef repeat(iterable, max_times = None):\r\n    while max_times == None or max_times > 0:\r\n        for i in iterable:\r\n            yield i\r\n        if max_times != None:\r\n            max_times -= 1\r\n\r\n\r\n2) Produce unique values (never the same one twice)\r\n\r\ndef unique(iterable):\r\n    iterated = set()\r\n    for i in iterable:\r\n        if i not in iterated:\r\n            iterated.add(i)\r\n            yield i\r\n\r\nHere the iterated set remembers every value yielded: only values not appearing\r\nin this set are yielded (and such values are immediately put into the set so\r\nthey won't be yielded again). I generalized this generator as follows, allowing\r\na value to be repeated a certain number of times (with a default of 1, which\r\noperates like unique above).\r\n\r\nfrom collections import defaultdict  \r\n\r\ndef unique(iterable, max_times = 1):\r\n    times = defaultdict(int)\r\n    for i in iterable:\r\n        if times[i] < max_times:\r\n            times[i] += 1\r\n            yield i\r\n\r\nThis generator uses a defaultdict to remember how many times a value has been\r\nyielded, ensuring that is is skipped (not yielded) if it has been yielded over\r\nthe maximum allowed number of times.\r\n\r\nQuestions: if we reversed the order of the two statements in the if statement\r\nabove, would the function still work correctly?\r\n\r\n\r\n3) Filter an iterable, producing only values for which predicate p returns True\r\n(called pfilter because there is a filter function supplied in itertools).\r\n\r\ndef pfilter(iterable, p):\r\n    for i in iterable:\r\n        if p(i):\r\n            yield i\r\n\r\nSo writing \r\n\r\n  for i in pfilter(primes(1000), lambda x: x%10 == 3):\r\n      print(i)\r\n\r\nwould print all the primes <= 1000 which end in the digit 3: 3, 13, 23, 43,\r\n53, 73, 83, 103, 113, ...\r\n\r\n\r\n4) The enumerate generator: how to write this Python built-in function\r\n\r\ndef enumerate(iterable, counter = 0):\r\n    for value in iterable:\r\n        yield (counter, value)\r\n        counter += 1\r\n\r\n\r\n5) Produce values in a sorted sequence, according to key/reverse\r\n(called gen_sorted because there is a sorted function that returns\r\na list of all the values gen_sorted yields).\r\n\r\ndef gen_sorted(iterable,key=None,reverse=False):\r\n    l = list(iterable)\r\n    l.sort(key=key,reverse=reverse)\r\n    for i in l:\r\n        yield i\r\n\r\nBy making a local copy of the list, we can sort it without mutating the list\r\npassed as an argument. Also, changes to the original list will not be seen by\r\nthe iterator (unless those change mutate values in the list). Note here we\r\nmust know all of the values before we can yield the first/smallest one. We\r\ncannot call this decorator on a general infinite generator.\r\n\r\nWe can easily test generators on strings, which are iterable (returning the\r\nindividual characters). E.g., the following example prints only the vowels, in\r\nsorted order, uniquely, that are in my name: 'a', 'e', 'i'\r\n\r\nfor i in pfilter(gen_sorted(unique('richardepattis')), lambda x : x in 'aeiou'):\r\n    print(i,end='')\r\n\r\nLet's now return to the original primes generator at the start of this lecture.\r\nWe now have some tools that we can use to simplify (actually avoid) this\r\ngenerator. The general component below generates a sequence of integers, either\r\nbound or unbounded (unlike range, which is always bounded) either ascending or\r\ndescending\r\n\r\ndef ints(start, limit = None, step = 1):\r\n    i = start\r\n    while limit==None or (step>=1 and i<limit) or (step<=-1 and i>limit):\r\n        yield i\r\n        i += step\r\n\r\nNote that unlike range, we cannot call len or other range methods on ints. Also,\r\nunlike range, supplying one argument binds it to start, not limit. It would take\r\nmore complicated code to duplicate the parameter structure of range (as we\r\nshowed using *args in a previous lecture).\r\n\r\nNow, instead of calling primes we would call pfilter(ints(2),is_prime) to\r\nrepresent the same iterator. And if we defined any other predicates, we could\r\nsupply them to pfilter to generate only values that satisfied those predicates.\r\n\r\nWhat do you think the difference is between the following three functions: all\r\nattempt to find the nth prime (so nth_prime(1_000_000_000) returns the billionth\r\nnumber that is prime)? Which ones work, which ones don't? Why?\r\n\r\ndef nth_prime(nth):\r\n    for n,p in enumerate( pfilter(ints(2),is_prime), 1 ):\r\n    \tif n == nth:\r\n            return p\r\n\r\ndef nth_prime(nth):\r\n    primes = [i for i in ints(2) if is_prime(i)]\r\n    for n,p in enumerate( primes, 1 ):\r\n    \tif n == nth:\r\n            return p\r\n\r\ndef nth_prime(nth):\r\n    primes = (i for i in ints(2) if is_prime(i))\r\n    for n,p in enumerate( primes, 1 ):\r\n    \tif n == nth:\r\n            return p\r\n\r\nPython has a module called itertools (see the library documentation) which\r\ndefine many iterator decorators, whose composition allows for powerful\r\niteration in Python. We will return to looking at the itertools module more\r\ndeeply later in the quarter.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nSpace Efficiency\r\n\r\nNote that generators embody a small amount of code and often don't store any\r\nlarge data structures (unique and gen_sorted above did use extra space in a\r\nset/dict and list). Generators store/produce one value at a time, unlike, say,\r\nmost comprehensions, which produce an entire list/set/dict of values that must\r\nall be stored at the same time; but generators are like tuple comprehensions,\r\nwhich we saw are a bit different: like generators we can examine the sequence\r\nof values produced one at a time with a for loop, or call a constructor to put\r\nall the values in a data structure.\r\n\r\n-----\r\nRecall, tuple comprehensions in Python produce generators objects! Try\r\n\r\n  a = (i for i in range(10))\r\n  print(a)\r\n  t1 = tuple(a)\r\n  print(t1)\r\n  t2 = tuple(a)\r\n  print(t2)\r\n\r\n  l = [i for i in range(10)]\r\n  print(l)\r\n\r\n----\r\n\r\nSo when writing generators, we should always try to avoid storing a large\r\nnumber of values in a data structure. It might make writing the generator more\r\ndifficult, but few generators need to store large amounts of data to work\r\ncorrectly.\r\n\r\nAlthough, for some applicatons (like reversed and sorted), Python must look at\r\nall the iterated values before deciding what to yield first, so they typically\r\nwork by first storing all the values iterated over in some data structure (a\r\ntuple or list: see gen_sorted above and gen_reversed below and then process\r\nvalues in the tuple/list) which we hope is not huge.\r\n\r\nfrom goody import irange\r\n\r\ndef gen_reversed(iterable):\r\n    l = list(iterable)                # Put all values in a list or tupel\r\n    for i in irange(len(l)-1,-1,-1):  # Iterate the list backwards, 0 included\r\n        yield l[i]\r\n\r\nIn fact, there is a clever way to generate reversed values without ever storing\r\nthe iterable in a list! But the time is takes (in its doubly nested loop) can\r\nbe huge; so for choosing the implementation we want, we have to make a\r\nchoice whether time or space is more important: maybe we should define two\r\ngenerators: reversed_save_time (same as gen_reversed) and reversed_save_space\r\n(defined below)\r\n\r\ndef reversed_save_space(iterable):\r\n    # compute the length of the iterable once;\r\n    # it stores no values in a data structure, just computes the length\r\n    length = 0;\r\n    for i in iterable:               # iterate once to compute its length\r\n        length += 1\r\n\r\n    for c in range(length-1,-1,-1):  # c indexes last, second to last, ... first\r\n        temp = iter(iterable)        #   restart iteration on iterable\r\n        for i in range(c):           #   skip c-1 values from front\r\n            next(temp)               #     ...call next, but ignore values\r\n        yield next(temp)             #   yield the cth value: after skipping c-1\r\n\r\nObserve it working by calling\r\n\r\nfor i in reversed_save_space(\"abcd\"):\r\n    print(i)\r\n        \r\nWhile this seems very fast for small lists it can very run slowly for large\r\nlists, because it is repeatedly skipping large numbers of values in the inner\r\nloop for each single yield in the outer loop. For a list with 1,000 values, it\r\ngoes through all to find the length, then 999 to yield the value at the end,\r\nthen 998 to yield the value two from the end, then 997 to yield the value three\r\nfrom the end... Eventually it skips 500,500 values: 1009*1001/2)\r\n\r\nAlso, it requires being able to start over iterable: by calling iter(iterable).\r\nThis doesn't always work: if iterable is the result returned by a generate \r\nfunction, then calling iter(iterable) produces the same object. Once exhaused,\r\nit CANNOT RESTART at the beginning. \r\n\r\n------------------------------------------------------------------------------\r\n\r\nYOU CAN SKIP READING THIS SECTION: IT HAS MORE DETAILS THAN WE USE IN ICS-33\r\n\r\nCoroutines: Sending Information into Generators (after calling them)\r\n\r\nAt present, we have seen how to use generators in only a limited (although very\r\nuseful/powerful) way: once a generator is called (we send information to its\r\nparameters), we repeatedly call next on the iterator which produces information.\r\nBut, we have not yet seen how to send more information into a generator, after\r\nit starts executing. In this section, we explore the details of generators\r\nfurther, showing how we can send new information into a running generator, to\r\naffect its behavior.\r\n\r\nFirst, we will generalize the next function by using the send function. Assume\r\nthat g = some_generator(...); we can think of  calling next(g) as equivalent to\r\ncalling g.next(). We will soon learn about the send function, which generalizes\r\nrestarting a generator by allowing us to pass it arbitrary information: calling\r\ng.send(None) is equivalent to calling next either way.\r\n\r\nApart from introducing the send function itself, most of the new information\r\nabout generators concerns what yield does. In our previous understanding of\r\nyield, it is a statement that yields a value. We will now learn that yield\r\nactually is an expression that performs two jobs. When executed in a generator,\r\nyield\r\n\r\n  (a) yields a value to where next/send is called on the generator\r\n\r\n  (b) returns a value: the argument to the call of send that restarts the\r\n                       generator (if restarted by next, which is equivalent to\r\n                       send(None) yield returns None)\r\n\r\nSo, we will see yield used both ways, in code like\r\n\r\n   rv = yield yv\r\n\r\nWhen executing this statement, Python yields the value stored in yv; when the\r\ngenerator is restarted by a call to .send(v1) then yield returns the value v1\r\nand also stores this value into rv. The generator might use this new value in\r\nrv to affect its behavior. So, we have a way to send information to a generator\r\nat the time it suspends; when it resumes the generator can use that information\r\nto affect its continued execution.\r\n\r\nFinally, the FIRST time the body of a generator is executed, it must be with\r\neither a call to next or to send(None), which are equivalent. Otherwise Python\r\nwill raise a TypeError exception:\r\n\r\n  TypeError: can't send non-None value to a just-started generator\r\n\r\nWhy is calling next on the generator the first time different? Because the\r\ngenerator's body has hasn't suspended at a yield -it hasn't evenstarted\r\nexecuting yet, so there no way to store any sent value.\r\n\r\nLet us look in depth at the following example\r\n\r\n# get_primes yields all prime numbers starting at number (if restarted by next)\r\n# if get_primes is restarted by send (with a non-None argument), it continues\r\n#   yielding primes by checking numbers starting at send's argument\r\n\r\ndef get_primes(number):\r\n    while True:\r\n        if is_prime(number):\r\n            sent = yield number\r\n            if sent != None:\r\n                number = sent-1\r\n        number += 1\r\n\r\nSo calling\r\n  g = get_primes(5)\r\n  print(next(g), next(g), next(g))\r\n\r\nprints: 5 7 11\r\n\r\nHere, yield always returns None (because the generator is restated using next,\r\nwhich translates to send(None)), storing it in sent, so number is never set to\r\nsent-1.\r\n\r\nThe same result would come from calling\r\n\r\n  g = get_primes(5)\r\n  print(g.send(None), g.send(None), g.send(None))\r\n\r\nBut calling\r\n  g = get_primes(5)\r\n  p1 = next(g)\r\n  p2 = g.send(p1+10)\r\n  p3 = g.send(p2+10)\r\n  print(p1, p2, p3)\r\n\r\nprints: 5 17 29\r\n\r\n0) The call to get_primes(5) binds get_prime's paramenter number to 5. Recall\r\n   that the body is not yet executed.\r\n\r\n1) The call to next(g) starts executing the body of the generator. Because\r\n   5 is prime, it yields that value, which is stored into p1. Recall the\r\n   that the first time the body of the generator is executed, it must be with\r\n   either a call to next or to send(None), which it is here. This makes sense\r\n   because it is starting from the beginning, not starting from a yield that\r\n   can return a useful value.\r\n\r\n2) The call to g.send(p1+10) restarts executing the body of the generator. The\r\n   yield expression returns 15 (p1+10 = 5+10 = 15) and stores it into sent;\r\n   because sent is != None, number is reset to sent-1=14; number is incremented\r\n   to 15, which is not prime, so number is incremented to 16, which is not\r\n   prime, so number is incremented to 17, which is prime, so it yields 17 which\r\n   is stored into p2.\r\n\r\n3) The call to g.send(p2+10) restarts executing the body of the generator. The\r\n    yield expression returns 27 (p2+10 = 17+10 = 17) and stores it into sent;\r\n   because sent is != None, number is reset to send-1=26; number is incremented\r\n   to 27, which is not prime, so number is incremented to 28, which is not\r\n   prime, so number is incremented to 29, which is prime, so it yields 29 which\r\n   is stored into p2.\r\n\r\n4) The values stored in p1, p2, and p3 are printed.\r\n\r\nYou can instrument this code with calls to print (or single step it -using step\r\nover and step into- in thedebugger) to get a better idea of what is happening.\r\nThe main point to remember is that whenever the generator yields a value, the\r\ngenerator can be restarted with a new non-None value passed to it via an\r\nargument to send, which is returned from yield as the first step in restarting\r\nthe code.\r\n\r\nActually, when a generator returns, it raises the StopIteration exception; the\r\n.value attribute of the raised exception is whatever the returned value is.\r\nUsing this information, here is an example of how to write a generator that\r\naccepts values to average, and returns the average whenever it is sent None.\r\n\r\ndef averager():\r\n    count,total = 0,0\r\n    while True:\r\n        new = yield\r\n        if new == None:\r\n            return total/count\r\n        count,total = count+1, total+new\r\n\r\nNotice the yield has no expression on its right side; it is designed to just\r\nreceive information, which it locally accumulates, returning the average when\r\nit is sent None. To average the value 10, 20, and 30, we would write the code\r\n\r\na = averager()\r\nnext(a)                      # Start generator (suspends at yield)\r\na.send(10)                   # afterward update, count is 1, total is 10\r\na.send(20)\t\t     # afterward update, count is 2, total is 30\r\na.send(30)\t\t     # afterward update, count is 3, total is 60\r\ntry:\r\n    a.send(None)             # Force return, raising StopIteration exception\r\nexcept StopIteration as exc:\r\n    print(exc.value)         # exc.value is value of raised exception.\r\n\r\nWhat is interesting about this use of generators, is that we can start averaging\r\nwithout knowing all the things that are going to be averaged. We can compute a\r\nrunning average of the values we know, and in the future either get finish\r\naveraging, or continue supplying more values to average.\r\n\r\nFinally, to allow generators to act more like function calls, we can invoke one\r\ngenerator inside another more easily by using the \"yield from\" statement. So,\r\nif generator f wants to yield all the values yielded from generator g\r\n(before f continues to yield more of its own values), we can write in f:\r\n\r\n  yield from g(...)\r\n\r\nwhich is equivalent to writing\r\n\r\n  for i in g(...):\r\n      yield i\r\n\r\nThe truth is more complex, but this information suffices for the following\r\nexample.\r\n\r\nWhen we discuss trees, we will examine a generator that yields binary tree nodes\r\nin a preorder traversal by using recursion and \"yield from\" as follows:\r\n\r\ndef generator_pre_order(atree):\r\n    yield atree.value\r\n    for c in atree.children:\r\n        yield from generator_pre_order(c)\r\n\r\n------------------------------------------------------------------------------\r\n\r\n1) Define a generator named match_indexes that takes a pattern string and a\r\ntext string as parameters. It yields every index in text which matches\r\npattern (compare the pattern to a slice in the tet). For example.\r\n\r\nfor i in match_indexes ('ab','aabbaabacab'):\r\n    print(i,end='')\r\n\r\nprints: 1 5 9\r\n\r\nUpgrade your match_indexes generator to match a pattern string that is a\r\nregular expression.\r\n\r\n2) Using a generator executing a while loop, rewrite the prange_iterator\r\nsimilarly to how the Percent_Histogram iterator was writen above.\r\n\r\n3) Define a decorator for iterables  named take_starting using at generator;\r\nit takes an iterable and predicate as arguments, and produces all values in\r\nthe iterator starting with the first one for which the predicate is true.\r\n\r\n4) Define a decorator for iterables named product using a generator; it\r\ntakes two iterables as arguments, and produces all tuples with one value\r\ntaken from the first iterable and one taken from the second. For example, if\r\nwe wanted to generate a hand of playing cards (a list of 2-tuples, whose\r\nfirst values are 1-13 (for ace-king) and whose second values are a suit (either\r\n'H', 'C', 'D', or 'S' for heart, club diamond, or spade) we could call\r\nproduct(irange(1,13),'HCDS') to produce this list.\r\n\r\n5) Define a decorator for iterables named transform using a generator; it\r\ntakes an iterable and a function (whose domain is the iterable) as arguments,\r\nand produces a transformed value for each value the iterable produces by\r\ncalling the function.\r\n\r\n6) Using the definition of get_primes above (unchanged), write a generator that\r\neasily yields the first one digit prime, the first two digit prime, etc. up\r\nuntil the first n digit parmameter. Every time it yields a prime, it restarts\r\nthe generator looking at a higher number of digits. Note that\r\n\r\n    n = 5\r\n    for i in range(n):\r\n        print(10**i,sep=' ')\r\n\r\nprints: 1 10 100 1000 10000\r\n\r\nThese are the smallest 1 digit, 2 digit, 3 digit, 4 digit, and 5 digit numbers.\r\nThe following are the first primes 1 to 5 digits: 2, 11, 101, 1009, and 10007.\r\n", "encoding": "ascii"}