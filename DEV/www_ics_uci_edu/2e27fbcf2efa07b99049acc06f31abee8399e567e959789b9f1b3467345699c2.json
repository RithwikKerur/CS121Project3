{"url": "https://www.ics.uci.edu/~eppstein/180a/970422.html", "content": "<HTML>\n<HEAD>\n<TITLE>ICS 180, April 22, 1997</TITLE>\n<META name=\"Owner\" value=\"eppstein\">\n<META name=\"Reply-To\" value=\"eppstein@ics.uci.edu\">\n</HEAD><BODY>\n<IMG SRC=\"icslogo2.gif\" WIDTH=472 HEIGHT=72 ALT=\"\"><P>\n<A HREF=\"index.html\">\n<H1>ICS 180A, Spring 1997:<BR>\nStrategy and board game programming</H1></A>\n\n<H2>Lecture notes for April 22, 1997<BR>\nAlpha-Beta Search</H2>\n\n<H3>Shallow Pruning</H3>\nSuppose you're doing a minimax search (as we described last time) of the \nfollowing tree:\n\n<P><CENTER><IMG SRC=\"shallow-prune.gif\"></CENTER>\n\n<P>You've searched F, and found its children's evaluations to be 11, 12, 7, \nand 9; at this level of search, the first player is to move, and we expect \nhim to choose the best of these values, 12.  So, the minimax value of F is \n12.\n\n<P>Now, you start searching G, and its first child returns a value of \n15.  When this happens, you know because of it that G's value will be at \nleast 15, possibly even higher (if another of the children of G is even \nbetter).  What this implies is that we don't expect the second player to \nmove to G; from the second player's point of view, F's value of 12 is \nalways better than G's value of 15 or higher.  So, we know that G is not on \nthe principal variation.  We can <I>prune</I> the remaining children of G, \nnot evaluate them, and return immediately from searching G, since any \nfurther work evaluating descendants of G would just be wasted.\n\n<P>In general, we can prune like we did in node G when one of its children \nreturns a value better (from the point of view of the player whose turn it \nis at node G) than the previously computed evaluation of one of G's \nsiblings.\n\n<H3>Deep Pruning</H3>\n\n<P>Other more complicated forms of pruning are possible as well.\nFor example, suppose in the same search tree that we've evaluated all of G, \nH, and I to be better than 12, so that 12 is the total evaluation at node \nB.  Now, we search node C, and two levels down, see an evaluation of 10 at \nnode N:\n\n<P><CENTER><IMG SRC=\"deep-prune.gif\"></CENTER>\n\n<P>We can use a more complicated line of reasoning to prune again.\nWe know that N will return a 10 or smaller (the second player is to move, \nand wants to choose small numbers).  We don't know whether this value of 10 \nor smaller will be returned at J as well, or whether one of the other \nchildren of J will be better.  If a value 10 or smaller is returned from J \nto C, we can prune at C because it has a better sibling (B).\nSo, in this case, further exploration of the children of N is pointless.\nThe other case is that some other child of J returns a better value than \n10; but again, in this case, further exploration of N is pointless.\nSo as soon as we see 10, we can safely return from N.\n\n<H3>Alpha-Beta Pseudocode</H3>\n\n<P>In general, when a returned value is better than the value of a sibling \nan even number of levels up in the tree, we can return immediately.  If we \npass the minimum value of any of these siblings in as a parameter <I>beta</I> to the \nsearch, we can do this pruning very efficiently.  We also use another \nparameter <I>alpha</I> to keep track of the siblings at odd levels of the \ntree.  Pruning using these two values is very simple; code to do so is \nlisted below.  Like last time, we use the <I>negamax</I> formulation, in \nwhich evaluations at alternate levels of the trees are negated.\n\n<PRE>\ndouble alphabeta(int depth, double alpha, double beta)\n{\n    if (depth &lt;= 0 || game is over) return evaluation();\n    generate and sort list of moves available in the position\n    for (each move m) {\n        make move m;\n        double val = -alphabeta(depth - 1, -beta, -alpha);\n        unmake move m;\n        if (val &gt;= beta) return val;\n        if (val &gt; alpha) alpha = val;\n    }\n    return alpha;\n}\n</PRE>\n\nWe'll explain Thursday what the sorting step is and why it's important.\n\n<H3>Aspiration Search</H3>\n\nWhat should we supply as the initial values of alpha and beta at the root \nof the tree?\n\n<P>Alpha and beta define an interval of the real number line \n(alpha,beta) of the evaluations we consider <I>interesting</I>.  If a value \nis greater than beta we prune and immediately return, because we know it's \nnot part of the principal variation; we don't really care about the exact \nvalue, only that it's greater than beta.  If a value is less than alpha, we \ndon't prune, but we still don't consider it interesting, because we know \nthere's a better move somewhere else in the tree.\n\n<P>But at the root of the tree, we don't know\nwhat range of evaluation values are likely to be \ninteresting, and if we want to be sure of not accidentally pruning \nsomething important,\nwe have to just set alpha=-infinity and beta=infinity.\n\n<P>However, especially if we are using iterated deepening, it is likely \nthat we have a pretty good idea what the principal variation is going to \nlook like.  Suppose we guess that its value is going to be x (e.g., just \nlet x be the value found when you previously searched to depth D-1), and \nlet epsilon be a small number representing the amount by which we expect a \ndepth-D search to vary from a depth-(D-1) search.  We can then try calling \nalphabeta(D, x-epsilon, x+epsilon).  Three different things can happen as a \nresult:\n\n<OL>\n<LI>The search might return a value within the interval (x-epsilon, x+epsilon). \nIn this case, we know that it returned the correct value, and we can \nsafely choose the move in the search tree leading to a node with that \nvalue.\n\n<LI>The search might return a value v&nbsp;<U>&gt;</U>&nbsp;x+epsilon.\nIn this case, we know that the true search value is also \n<U>&gt;</U>&nbsp;x+epsilon, but we don't know what it is (the correct \nprincipal variation might have been pruned as soon as we saw some other \nmove having a value greater than beta).  We have to adjust our guess x to \nbe a higher value and try again (probably also with a larger value of \nepsilon).  This condition is known as a <I>fail high</I>.\n\n<LI>The search might return a value v&nbsp;<U>&lt;</U>&nbsp;x-epsilon.\nIn this case, we know that the true search value is also \n<U>&lt;</U>&nbsp;x-epsilon, but we don't know what it is.  We have to \nadjust our guess x to be a smaller value and try again (probably also with \na larger value of epsilon).  This condition is known as a <I>fail low</I>.\n</OL>\n\nEven though it can fail in these two ways, using the aspiration search \n(having an initial interval (alpha,beta) smaller than (-infinity,infinity)) \nis usually an improvement overall, because it does so much more pruning.\n\n<H3>Analysis</H3>\n\nLet's do an analysis of alpha-beta search to see why it's such a useful \nidea.  Unlike the usual kind of analysis of algorithms, we'll do a \n<I>best-case analysis</I>, in which we assume that alpha-beta prunes as \noften as it possibly can.  We'll see next time what we need to do to make \nalpha-beta search behave in a way consistent with this analysis.\nIn class I did this analysis only considering shallow cuts, but in these \nlecture notes I'll include deep cuts as well, because it makes the analysis \nmuch simpler.\n\n<P>In the best case, each node at depth D-1 will only examine one child at \ndepth D before pruning, except that one node on the principal variation \nwill not prune (if it did, the overall algorithm will end up failing high \nor failing low, which would certainly not be the best case).\n\n<P>At depth D-2, however, nobody can prune, because all the children \nreturned values greater than or equal to the values of beta they were \npassed, which at depth D-2 are negated and become less than or equal to \nalpha.\n\n<P>Continuing up the tree, at depth D-3 everyone (except on the principal \nvariation) prunes, and at depth D-4 nobody prunes, etc.\n\n<P>So, if the branching factor of the tree is B, the number of nodes\nincreases by a factor of B at half the levels of tree, and stays pretty\nmuch constant (ignoring the principal variation) at the other half of\nthe levels.  So the total size of the part of the tree that gets\nsearched ends up being roughly\nB<sup>D/2</sup>&nbsp;=&nbsp;sqrt(B)<sup>D</sup>.  Effectively,\nalpha-beta search ends up reducing the branching factor to the square\nroot of its original value, and lets one search twice as deeply.  For\nthis reason it is an essential part of any minimax-based game-playing\nprogram.\n\n<P><HR>\n<A HREF=\"/~eppstein/\">David Eppstein,\n<A HREF=\"/\">Dept. Information & Computer Science</A>,\n<A HREF=\"http://www.uci.edu/\">UC Irvine</A>,\n<!--#flastmod file=\"970422.html\" -->.\n</BODY></HTML>\n", "encoding": "ascii"}