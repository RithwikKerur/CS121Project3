{"url": "https://www.ics.uci.edu/~ejw/authoring/irvine/minutes.txt", "content": "\n\n\n\n                                WEBDAV Meeting Notes\n                                 January 27, 28 1997\n                               U.C. Irvine, Irvine CA\n\n\n          An open meeting was held for those interested in the WEBDAV\n          initiative. The meeting was held on the campus of the University\n          of California, Irvine. The primary focus of the meeting was to\n          review and discuss a proposed draft specification.\n\n\n\n          Chair:    Introductions and general remarks.\n\n          Web Collections ..................                   Yaron Goland\n\n          Presentation:\n               WC presented as a mechanism for giving structured response\n               to an HTTP request that is machine readable, without\n               breaking older clients. WC is encoded as a set of HTML tags\n               with some simple semantics.\n\n          Question: Why HTML? Why not straight up HTTP?\n          Answer:   Single message type for both \"pure\" HTTP and HTML\n                    downstream.\n\n          Presentation (continued):\n               WC data can be\n                    1.   referenced - <WCAT rel=foo HREF=\"anchor\">\n                    2.   hidden - using HDATA\n                    3.   explicit - between <WCDATA> ... </WCDATA> tags\n\n          Comment:  So you will have to encode binary data? This is\n                    expensive.\n\n\n          A General Discussion of the Issues Ensues:\n\n          Question: Why not use \"webmaps\" or \"sitemaps\"?\n          Answer:   WC is the same initiative as \"web/site maps\". Just the\n                    name has changed.\n\n          Question: (Clarification of above question:) So why tinker with\n                    the original \"webmap\" spec?\n          Answer:   Spec was inadequate.\n\n          Comment:  This is bad design:\n                         1.   WC is a flawed mechanism\n                         2.   not good overlap between machine\n                              readable/human readable response\n          Response: Focus on the object-model. Is it complete? Consistent?\n                    Web Collections are just a convenient vehicle for\n                    expressing the object model; if there is a better way\n                    of expressing the model, we'll use it.\n\f\n\n\n\n\n\n          1Hubub:   A protracted discussion on the merits/folly of using\n                    HTML to encode an object model for structured HTTP\n                    response ensues.\n\n          Chair:    Moves to discuss the Structured Response Object Model\n                    independently of encoding.\n          Response: Motion fails. More discussion as above.\n\n                                      ---------\n                                        break\n                                      ---------\n\n          Yaron:    Do we all agree that:\n                         1.   we need a well defined Structured Response\n                              Object Model and,\n                         2.   we should have no dependencies on\n                              incomplete/ongoing work in other working\n                              groups?\n                    [A short discussion period on the above points. Editor\n                    senses group general agreement on 1., 2. above,\n                    although no official poll is taken.]\n\n          Presentation (continued):\n               Hierarchical Collections are presented as a special case of\n               Web Collections, used to support FCS or \"directory\" like\n               behavior.\n\n\n          Light Links (Meta Data) ..............              Jim Whitehead\n\n          Presentation:\n               Explanation of link structure (source, dest, type) as an\n               expression of a binary relation on the cross product\n               RESOURCE X RESOURCE.\n\n          Question: Who manages the link \"types\" (e.g., registration)?\n          Answer:   Core link types (\"core\" to implementing WEBDAV) are\n                    defined in the specification. Other \"types\" owned and\n                    managed various groups (e.g., Dublin Core). Namespace\n                    convention for link types is schema.(schema.type).\n          Response: Take care! Define namespace requirements for links so\n                    that WEBDAV complies with the \"Schema\" work group\n                    (Chris Weider, Chair).\n\n          Comment:  Why be non-extensible w.r.t. the link definition? Allow\n                    other fields to be added to the core fields (source,\n                    dest, type).\n          Comment:  PICS is doing meta-data. The authors would be well\n                    advised to look at the PICS effort.\n\n\n\n               1 -  Shorthand for \"unstructured discussion\". No disrespect\n                    for the group or the Chair is intended.\n\f\n\n\n\n\n\n          Presentation (continued):\n               The LINK method is presented.\n\n          Comment:  Method name conflicts with the LINK in HTTP/1.1\n                    appendix.\n          Comment:  Links as presented are inadequate for annotation.\n\n                                      ---------\n                                        lunch\n                                      ---------\n\n          Question: Are links discoverable/extensible in a robust way? How\n                    does the Schema/Method stuff tie in?\n          Comment:  Look at PICS namespace registration stuff; it may have\n                    good ideas for schema registration.\n\n          Presentation (continued):\n               UNLINK method presented.\n\n          Question: Should first rev WEBDAV be dodging\n                    notification/transaction issues?\n          Comment:  This link model may not be efficient on the wire (Keith\n                    will write down his concerns on this issue and submit\n                    to the list).\n\n          Presentation (continued):\n               The convenience methods GETLINKS, GETLINKVAL and SETLINKVAL\n               are presented.\n\n          Question: What identifies a link?\n          Answer:   The triple (source, dest, type) is the unique ID.\n\n          Question: Must either source or dest equal the URI of the\n                    resource which contains the link?\n          Answer:   Yes, the authors (somewhat arbitrarily) decreed that\n                    source or dest should equal the URI of the resource\n                    where the link resides.\n          Response: (Roy) This restriction should be lifted.\n\n\n          The LINKSEARCH Method ...............                Yaron Goland\n\n          Presentation:\n               The LINKSEARCH method is briefly presented.\n\n          Comment:  Scoping rules for search are inadequate.\n          Comment:  Use \"agent\" rather than \"arbiter\".\n          Comment:  BNF errors need to be cleaned up.\n          Comment:  Interaction between the resource namespace and links\n                    (which are defined on resources) can be problematical\n                    in a distributes setting.\n          Comment:  BNF should be modified to reflect extensible link\n                    structure.\n          Comment:  Design team is shortsighted due to focus on schedule\n\f\n\n\n\n\n\n                    constraints. Is the team doing its homework? Do the\n                    team members understand the issues? Are the team\n                    members capable of understanding the logical\n                    consequences of their design decisions?\n\n                                      ---------\n                                        break\n                                      ---------\n\n          Locking ......................                       Steve Carter\n\n          Presentation:\n               The difference between \"checkout\" (for version control)\n               versus \"lock\" (for document repository) is explained. Lock\n               is intended to control resource \"collision\"; lock is not an\n               access control mechanism.\n\n          Question: Why can't lock tokens cross \"client space\" boundaries?\n                    This seems to be an arbitrary decree.\n\n          Comment:  Range locking as described abuses the HTTP/1.1 notion\n                    of range. Why not address ranges with teir own URI?\n          Comment:  Agrees with comment above. Design team broke its own\n                    rule (WEBDAV acts only URI addressable objects). URI\n                    addressable ranges more compatible with HTTP\n                    philosophy. Also, how do entity tags differ from lock\n                    tokens, functionally speaking?\n\n          Comment:  What is WEBDAV locking in the context of highly\n                    replicated resources?\n          Hubub:    Much discussion over replicated, distributed resources.\n\n          Chair:    Requests that range locking be taken to the discussion\n                    list, noting the following outstanding issues:\n                         1.   locking highly replicated resources,\n                         2.   advisory lock vs. exclusive lock,\n                         3.   support for \"graceful degradation\" of\n                              functionality.\n          Comment:  With respect to above recommendation by chair; the\n                    proper forum for resolving design issues in general is\n                    on the list. IETF is an open forum.\n\n          Question: What about \"orphaned\" lock tokens? Spec should say\n                    something about the conditions that can lead to lost\n                    tokens.\n\n\n                       --------------------------------------\n                                Special Presentation\n                                         ***\n                        Email Access to WEBDAV Functionality\n                       --------------------------------------\n\n          Email & WEBDAV  .................                 Einar Stefferud\n\f\n\n\n\n\n\n          Presentation:\n               Do not ignore mail transport level! Push vs pull models;\n               mail has some pluses:\n                    1.   Latency can work for you\n                    2.   Administrative functions - mail more autonomous,\n                    3.   Mail is mature, tested technology.\n\n               Industry has evolving, Jungian mindset:\n                    1.   Computing - no connectivity,\n                    2.   Networking - Autonomous homogeneous nodes,\n                    3.   Interneteorking - Autonomous heterogeneous nodes,\n                    4.   Interworking - Autonomous heterogenous distributed\n                         processes.\n\n\n                                   ---------------\n                                       Day Two\n                                   ---------------\n\n          Version Control ..................                  Jim Whitehead\n\n          Presentation:\n               Review of \"champion\" models. Presents the \"version tree\" as\n               conceived by the design team, with \"default published\n               version\" (dpv), \"history\" links and \"version tree handle\".\n\n          Comment:  Tree handle and the dpv: if we access the dpv through\n                    tree handle for some methods, how do we get to the\n                    handle itself?\n          Response: Can't use redirect; we get pushback from the Server\n                    Config crowd.\n          Question: Which methods act on dpv via tree handle? Which do not?\n                    Is there consistency here?\n\n          Hubub:    Extended discussion on what version \"control\" means in\n                    a distributed environment.\n          Chair:    Directs that a discussion of Version Control in a\n                    distributed, replicated environment be established on\n                    the list.\n\n          Question: Does the design accommodate \"derivitaive\" work?\n\n          Question: Where is the definition of \"history\" in the spec? Also,\n                    \"history\" may itself be a distributed object; does spec\n                    recognize this possibility?\n\n          Comment:  Spec assumes that server enforces a version control\n                    model. Shouldn't the client be asserting the model? At\n                    least some provision should be made for client setting\n                    policy rather than assume server always does so.\n\n          Comment:  Design should support derivative work in widely\n                    distributed context (i.e. design should support\n                    derivative work with client asserting policy).\n\f\n\n\n\n\n\n          Comment:  The concept of \"history\", dpv, indeed much of the spec\n                    assumes central point of control. Monolithic thinking\n                    defeats the long-term vision of \"Interworking\". Don't\n                    be seduced into taking the easy way of server-centric,\n                    single point of control - the way of the Dark Side.\n\n          Comment:  Think in terms of \"authoritative\" vs \"non-\n                    authoritative\" sources with respect to where things\n                    reside (e.g., \"Clear Case\").\n\n          Comment:  Interoperability is the IETF gold standard by which to\n                    measure the elements of any protocol. In this case,\n                    provision should be made for the client to set version\n                    policy, and it should be recognized that the \"tree\" may\n                    well be a highly distributed object with many locally\n                    idiosyncratic representations. The tree might not\n                    reside in a single, absolute reference frame; but the\n                    client should be able to assert any logically\n                    consistent framework from which to view the tree (in\n                    whole or part)that can be expressed as a \"well formed\"\n                    policy.\n\n          Comment:  WEBDAV should not exclude server/server transactions.\n                    Fine if WEBDAV doesn't define such transactions.\n\n          Comment:  Design team should focus on the needs of the Internet\n                    when writing spec; may help shift emphasis to\n                    client/interoperability. Why not split the spec? A\n                    monolithic spec leads to monolithic design!\n\n          Presentation (continued):\n               The CHECKOUT method is presented. Discovery of method\n               capability is deferred to a later presentation.\n\n          Question: Checkout function is too complicated. Must one do\n                    discovery? Seems to require three-step procedure.\n          Answer:   One need only ask once for server support of method\n                    capability.\n\n          Question: \"Derived-From\", wasn't this supposed to be addressable?\n                    What happend here?\n\n          Question: Where is \"UNCHECKOUT\"?\n\n                                      ---------\n                                        lunch\n                                      ---------\n\n          Chair:    Leads a discussion on whether to seek official status\n                    as a working group with the IETF, the W3C, or both.\n                    Much discussion.\n          Chair:    Moves for a vote on the following: Shall WEBDAV proceed\n                    to seek IETF working group status with all due speed?\n          Response: Motion seconded. The Ayes have it.\n\f\n\n\n\n\n\n          Chair:    Moves that the group take ten minutes discussing the\n                    following proposal: Should we split the draft spec?\n          Response: Motion seconded. Passed.\n                    Much discussion of pros and cons. An emerging consensus\n                    to re-evaluate the situation when IETF working group\n                    status is attained.\n\n          Chair:    When should we schedule WEBDAV work group meeting at\n                    Memphis?\n          Response: General response indicates Monday morning would be\n                    best.\n\n          Chair:    Directs editor to submit current draft to IETF asap.\n          Chair:    Directs editor to post meeting notes asap, with above\n                    directive taking precedence.\n\n\n          Namespace Manipulation  .........          Asad Faizi, Del Jensen\n\n          Presentation (Asad):\n               Asad briefly presents COPY MOVE etc.\n\n          Comment:  The statement \"byte move or anything else\" should be\n                    \"byte move and anything else\".\n\n          Comment:  Discoverability is fine, but how can a client enforce\n                    consistency?\n          Comment:  Having different things happen at different servers is\n                    a recipe for disaster.\n\n          Hubub:    On the meaning of the phrase \"byte for byte copy\", much\n                    discussion. What is COPY in Web context? The phrase\n                    \"byte for byte\" not sufficiently abstract. Should be\n                    phrased without reference to encoding or representation\n                    of the resource data. People who cannot grasp this\n                    abstraction have no business writing the specification.\n\n          Comment:  Change the name of COPYHEAD.\n          Comment:  WEBDAV header names should not mimic other header\n                    names. Too confusing, even if context resolves outright\n                    collisions.\n          Comment:  Should discuss on the list whether COPY/MOVEHEAD should\n                    be in spec.\n\n          [Ed. Note: The Chair also took notes on Namespace:]\n                    The methods copyhead and movehead also elicited some\n                    discussion. The rationale for these methods was stated\n                    as being a way for clients to discover, before the\n                    method is performed, the consequences of a copy or a\n                    move. Participants pushed back on this, stating that\n                    all that was needed was a way for clients to determine\n                    what happened after a method was performed. The need to\n                    discover ahead of time which links would be\n                    copied/moved was also raised, and there was some\n\f\n\n\n\n\n\n                    discussion on why predefined links might change from\n                    one part of the namespace to another.\n          [Ed. Note: End of Chair's Notes on Namespace]\n\n\n          UNDELETE, DESTROY ..................                   Del Jensen\n\n          Presentation:\n               Brief overview of semantics.\n\n          Comment:  HTTP/1.1 DELETE semantics imply all access to an object\n                    via HTTP is removed. Therefore UNDELETE-ing a DELETEd\n                    URI does violence to the HTTP object model.\n\n          Hubub:    Much discussion on UNDELETE and destroy, at the end of\n                    which there appears to be an emerging consensus that\n                    UNDELETE and DESTROY are not appropriate WEBDAV\n                    functionality.\n\n                                      ---------\n                                        break\n                                      ---------\n\n          Lauren:   Informs the group that the XML draft spec is available\n                    at <http://www.w3.org.pub/www/tr/wd-xml-961114.html>.\n\n\n          [Ed. Note: The Chair kindly took notes on the following\n          presentation]\n          Method Capability Discovery ............             Yaron Goland\n\n          Presentation:\n               Yaron gave an overview on his proposal (which he stated had\n               not been previously agreed to by the design team) for method\n               capability (interface) discovery, which he termed \"schema\n               discovery.\"\n\n          Comments: Participants noted that the functionality described for\n                    capability discovery in DAV was similar to the proposed\n                    functionality for the Protocol Extension Protocol (PEP)\n                    for HTTP, and there was a proposal to remove the\n                    capability discovery mechanism from the WebDAV\n                    specification and work it into a general-purpose HTTP\n                    extensibility mechanism.\n\n                    One participant also noted that there was a similar set\n                    of functionality being proposed by the Internet\n                    Printing group. Another observation made about the\n                    capability discovery mechanism was that it shared some\n                    similarities to an RPC-type system, and was half of an\n                    interface definition language.  Participants questioned\n                    whether this level of generality was needed. This then\n                    led into a high-level discussion on the need for a\n                    capability discovery mechanism.\n\f\n\n\n\n\n\n                    What came out during the discussion was that the design\n                    team had assumed a model where clients would have to\n                    discover the capabilities of a server, then adapt\n                    themselves to the current capabilities of the server.\n\n                    Several participants stressed that a better model to\n                    adopt would be to have simple clients able to operate\n                    with a variety of back ends (with a minimum of\n                    adaptation).  Several participants also noted that by\n                    having so many different functionality options, it was\n                    difficult to determine the core DAV functions that all\n                    clients can depend on.\n\n                    At the end of this session, there was a poll of opinion\n                    across the participants, where each participant was\n                    able to express their opinion on capability discovery. \n                    The sentiment exposed by this was that the capability\n                    discovery mechanism in the current specification is too\n                    complex, and too powerful for WebDAV needs.\n                    Furthermore, the sentiment was expressed that it would\n                    be good if the WebDAV specification could bemodified so\n                    that capability discovery isn't necessary at all.\n\n\n                                  ----------------\n                                   End Of Meeting\n                                  ----------------\n\f", "encoding": "ascii"}