{"url": "https://www.ics.uci.edu/~jutts/hyman.html", "content": "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML//EN\">\r\n<html>\r\n\r\n<head>\r\n<meta http-equiv=\"Content-Type\"\r\ncontent=\"text/html; charset=iso-8859-1\">\r\n<meta name=\"GENERATOR\" content=\"Microsoft FrontPage 2.0\">\r\n<title></title>\r\n<!-- This document was created from RTF source by rtftohtml version\r\n2.7.2 -->\r\n</head>\r\n\r\n<body bgcolor=\"#FFFFFF\" text=\"#000000\" link=\"#004D1A\"\r\nvlink=\"#004D1A\" alink=\"#C0C0C0\">\r\n\r\n<p align=\"right\"><em>Back to mceagle.com </em><a\r\nhref=\"http://www.mceagle.com/remote-viewing/refs/\"><em>References</em></a><em>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</em></p>\r\n\r\n<p><em>This document, for over two years, was hosted on the\r\nUniversity of Oregon web server. In Autumn of 1998 it was no\r\nlonger available through that source. This paper is part of a\r\ngroup of papers, all related to the same very public and very\r\ncontroversial report. It would be a form of bias to make the\r\nother papers available when this one is not. Since this document\r\nis no longer available via link from Dr. Hyman's university, we\r\nare providing a locally-hosted copy for review. -- Webmaster</em></p>\r\n\r\n<hr>\r\n\r\n<p><b>Evaluation of Program on Anomalous Mental Phenomena </b></p>\r\n\r\n<p>Ray Hyman</p>\r\n\r\n<p>University of Oregon</p>\r\n\r\n<p>Eugene, Oregon</p>\r\n\r\n<p>September 11, 1995</p>\r\n\r\n<p>INTRODUCTION</p>\r\n\r\n<p>Professor Jessica Utts and I were given the task of evaluating\r\nthe program on &quot;Anomalous Mental Phenomena&quot; carried out\r\nat SRI International (formerly the Stanford Research Institute)\r\nfrom 1973 through 1989 and continued at SAIC (Science\r\nApplications International Corporation) from 1992 through 1994.\r\nWe were asked to evaluate this research in terms of its\r\nscientific value. We were also asked to comment on its potential\r\nutility for intelligence applications.</p>\r\n\r\n<p>The investigators use the term Anomalous Mental Phenomena to\r\nrefer to what the parapsychologists label as <i>psi. Psi </i>includes\r\nboth extrasensory perception (called <i>Anomalous Cognition</i>\r\nby the present investigators) and psychokinesis (called <i>Anomalous\r\nPerturbation</i> by the present investigators). The experimenters\r\nclaim that their results support the existence of Anomalous\r\nCognition--especially clairvoyance (information transmission from\r\na target without the intervention of a human sender) and\r\nprecognition. They found no evidence for the existence of\r\nAnomalous Perturbation.</p>\r\n\r\n<p>Our evaluation will focus on the 10 experiments conducted at\r\nSAIC. These are the most recent in the program as well as the\r\nonly ones for which we have adequate documentation. The earlier\r\nSRI research on remote viewing suffered from methodological\r\ninadequacies. Another reason for concentrating upon this more\r\nrecent set of experiments is the limited time frame allotted for\r\nthis evaluation.</p>\r\n\r\n<p>I will not ignore entirely the earlier SRI research. I will\r\nalso consider some of the contemporary research in parapsychology\r\nat other laboratories. This is because a proper scientific\r\nevaluation of any research program has to place it in the context\r\nof the broader scientific community. In addition, some of this\r\ncontemporary research was subcontracted by the SAIC\r\ninvestigators.</p>\r\n\r\n<p>Professor Utts has provided an historical overview of the SRI\r\nand SAIC programs as well as descriptions of the experiments\r\nunder consideration. I will not duplicate what she has written on\r\nthese topics. Instead, I will focus on her conclusions that:</p>\r\n\r\n<p><i>Using the standards applied to any other area of science,\r\nit is concluded that psychic functioning has been well\r\nestablished. </i>[Utts, Sept. 1995, p 1]</p>\r\n\r\n<p><i>Arguments that these results could be due to methodological\r\nflaws in the experiments are soundly refuted. Effects of similar\r\nmagnitude to those found in government-sponsored research at SRI\r\nand SAIC have been replicated at a number of laboratories across\r\nthe world. Such consistency cannot be readily explained by claims\r\nof flaws or fraud. </i>[Utts, Sept. 1995, p 1]</p>\r\n\r\n<p>Because my report will emphasize points of disagreement\r\nbetween Professor Utts and me, I want to state that we agree on\r\nmany other points. We both agree that the SAIC experiments were\r\nfree of the methodological weaknesses that plagued the early SRI\r\nresearch. We also agree that the SAIC experiments appear to be\r\nfree of the more obvious and better known flaws that can\r\ninvalidate the results of parapsychological investigations. We\r\nagree that the effect sizes reported in the SAIC experiments are\r\ntoo large and consistent to be dismissed as statistical flukes. </p>\r\n\r\n<p>I also believe that Jessica Utts and I agree on what the next\r\nsteps should be.</p>\r\n\r\n<p>We disagree on key questions such as:</p>\r\n\r\n<p>1. Do these apparently non-chance effects justify concluding\r\nthat the existence of anomalous cognition has been established?</p>\r\n\r\n<p>2. Has the possibility of methodological flaws been completely\r\neliminated?</p>\r\n\r\n<p>3. Are the SAIC results consistent with the contemporary\r\nfindings in other parapsychological laboratories on remote\r\nviewing and the ganzfeld phenomenon?</p>\r\n\r\n<p>The remainder of this report will try to justify why I believe\r\nthe answer to these three questions is &quot;no.&quot;</p>\r\n\r\n<p>SCIENTIFIC STATUS OF THE PROGRAM</p>\r\n\r\n<p>Science is basically a <i>communal</i> activity. For any\r\ndeveloped field of inquiry, a community of experts exist. This\r\ncommunity provides the <i>disciplinary matrix</i> which\r\ndetermines what questions are worth asking, which issues are\r\nrelevant, what variables matter and which can be safely ignored,\r\nand the criteria for judging the adequacy of observational data.\r\nThe community provides checks and balances through the referee\r\nsystem, open criticism, and independent replications. Only those\r\nrelationships that are reasonably lawful and replicable across\r\nindependent laboratories become part of the shared scientific\r\nstore of &quot;knowledge.&quot;</p>\r\n\r\n<p>An individual investigator or laboratory can contribute to\r\nthis store. However, by itself, the output of a single\r\ninvestigator or laboratory does not constitute science. No matter\r\nhow careful and competent the research, the findings of a single\r\nlaboratory count for nothing unless they can be reliably\r\nreplicated in other laboratories. This rule is true of ordinary\r\nclaims. It holds true especially for claims that add something\r\nnew or novel to the existing database. When an investigator, for\r\nexample, announces the discovery of a new element, the claim is\r\nnot accepted until the finding has been successfully replicated\r\nby several independent laboratories. Of course, this rule is\r\nenforced even more when the claim has revolutionary implications\r\nthat challenge the fundamental principles underlying most\r\nsciences.</p>\r\n\r\n<p>GENERAL SCIENTIFIC HANDICAPS OF THE SAIC PROGRAM</p>\r\n\r\n<p>The brief characterization of scientific inquiry in the\r\npreceding section alerts us to serious problems in trying to\r\nassess the scientific status of the SAIC research. The secrecy\r\nunder which the SRI and SAIC programs was conducted necessarily\r\ncut them off from the communal aspects of scientific inquiry. The\r\nchecks and balances that come from being an open part of the\r\ndisciplinary matrix were absent. With the exception of the past\r\nyear or so, none of the reports went through the all-important\r\npeer-review system. Worse, promising findings did not have the\r\nopportunity of being replicated in other laboratories.</p>\r\n\r\n<p>The commendable improvements in protocols, methodology, and\r\ndata-gathering have not profited from the general shake-down and\r\ndebugging that comes mainly from other laboratories trying to use\r\nthe same improvements. Although the research program that started\r\nin 1973 continued for over twenty years, the secrecy and other\r\nconstraints have produced only ten adequate experiments for\r\nconsideration. Unfortunately, ten experiments--especially from\r\none laboratory (considering the SAIC program as a continuation of\r\nthe SRI program)--is far too few to establish reliable\r\nrelationships in almost any area of inquiry. In the traditionally\r\nelusive quest for psi, ten experiments from one laboratory\r\npromise very little in the way of useful conclusions.</p>\r\n\r\n<p>The ten SAIC experiments suffer another handicap in their\r\nquest for scientific status. The principal investigator was not\r\nfree to run the program to maximize scientific payoff. Instead,\r\nhe had to do experiments and add variables to suit the desires of\r\nhis sponsors. The result was an attempt to explore too many\r\nquestions with too few resources. In other words, the scientific\r\ninquiry was spread too thin. The 10 experiments were asked to\r\nprovide too many sorts of information.</p>\r\n\r\n<p>For these reasons, even before we get to the details (and\r\nremember the devil is usually in the details), the scientific\r\ncontribution of this set of studies will necessarily be limited.</p>\r\n\r\n<p>PARAPSYCHOLOGY'S STATUS AS A SCIENCE</p>\r\n\r\n<p>Parapsychology began its quest for scientific status in the\r\nmid-1800s. At that time it was known as psychical research. The\r\nSociety for Psychical Research was founded in London in 1882.\r\nSince that time, many investigators--including at least four\r\nNobel laureates--have tried to establish parapsychology as a\r\nlegitimate science. Beginning in the early 1930s, J.B. Rhine\r\ninitiated an impressive program to distance parapsychology from\r\nits tainted beginnings in spiritualistic seances and turn it into\r\nan experimental science. He pulled together various ideas of his\r\npredecessors in an attempt to make the study of ESP and PK a\r\nrigorous discipline based on careful controls and statistical\r\nanalysis.</p>\r\n\r\n<p>His first major publication caught the attention of the\r\nscientific community. Many were impressed with this display of a\r\nhuge database, gathered under controlled conditions, and analyzed\r\nwith the most modern statistical tools. Critics quickly attacked\r\nthe statistical basis of the research. However, Burton Camp, the\r\npresident of the Institute of Mathematical Statistics, came to\r\nthe parapsychologists' defense in 1937. He issued a statement\r\nthat if the critics were going to fault parapsychological\r\nresearch they could not do so on statistical grounds. The critics\r\nthen turned their attention to methodological weaknesses. Here\r\nthey had more success.</p>\r\n\r\n<p>What really turned scientists against parapsychological\r\nclaims, however, was the fact that several scientists failed to\r\nreplicate Rhine's results. This problem of replicability has\r\nplagued parapsychology ever since. The few, but well-publicized,\r\ncheating scandals that were uncovered also worked against\r\nparapsychology's acceptance into the general scientific\r\ncommunity.</p>\r\n\r\n<p>Parapsychology shares with other sciences a number of\r\nfeatures. The database comes from experiments using controlled\r\nprocedures, double-blind techniques where applicable, the latest\r\nand most sophisticated apparatus, and sophisticated statistical\r\nanalysis. In addition, the findings are reported at annual\r\nmeetings and in refereed journals.</p>\r\n\r\n<p>Unfortunately, as I have pointed out elsewhere, parapsychology\r\nhas other characteristics that make its status as a normal\r\nscience problematic. Here I will list only a few. These are worth\r\nmentioning because they impinge upon the assessment of the\r\nscientific status of the SAIC program. Probably the most\r\nfrequently discussed problem is the issue of replicability. Both\r\ncritics and parapsychologists have agreed that the lack of\r\nconsistently replicable results has been a major reason for\r\nparapsychology's failure to achieve acceptance by the scientific\r\nestablishment.</p>\r\n\r\n<p>Some parapsychologists have urged their colleagues to refrain\r\nfrom demanding such acceptance until they can put examples of\r\nreplicable experiments before the scientific community. The late\r\nparapsychologist J.G. Pratt went further and argued that\r\nparapsychology would never develop a replicable experiment. He\r\nargued that psi was real but would forever elude deliberate\r\ncontrol. More recently, the late Honorton claimed that the\r\nganzfeld experiments had, indeed, achieved the status of a\r\nreplicable paradigm. The title of the landmark paper in the\r\nJanuary 1994 issue of the <i>Psychological Bulletin </i>by Bem\r\nand Honorton is &quot;Does psi exist? Replicable evidence for an\r\nanomalous process of information transfer.&quot; In her position\r\npaper &quot;Replication and meta-analysis in parapsychology&quot;\r\n(<i>Statistical Science, </i>1991, 6, pp. 363-403), Jessica Utts\r\nreviews the evidence from meta-analyses of parapsychological\r\nresearch to argue that replication has been demonstrated and that\r\nthe overall evidence indicates that there is an anomalous effect\r\nin need of explanation.</p>\r\n\r\n<p>In evaluating the SAIC research, Utts points to the\r\nconsistency of effect sizes produced by the expert viewers across\r\nexperiments as well as the apparent consistency of average effect\r\nsizes of the SRI and SAIC experiments with those from other\r\nparapsychological laboratories. These consistencies in effect\r\nsizes across experiments and laboratories, in her opinion,\r\njustify the claim that anomalous mental phenomena can be reliably\r\nreplicated with appropriately designed experiments. This is an\r\nimportant breakthrough for parapsychology, if it is true.\r\nHowever, to anticipate some of my later commentary, I wish to\r\nemphasize that simply replicating effect size is not the same\r\nthing as showing the repeated occurrence of anomalous mental\r\nphenomena. Effect size is nothing more than a standardized\r\ndifference between an observed and an expected outcome\r\nhypothesized on the basis of an idealized probability model. An\r\nindefinite number of factors can cause departures from the\r\nidealized probability model. An investigator needs to go well\r\nbeyond the mere demonstration that effect sizes are the same\r\nbefore he/she can legitimately claim that they are caused by the\r\nsame underlying phenomenon.</p>\r\n\r\n<p>In my opinion, a more serious challenge to parapsychology's\r\nquest for scientific status is the lack of cumulativeness in its\r\ndatabase. Only parapsychology, among the fields of inquiry\r\nclaiming scientific status, lacks a cumulative database. Physics\r\nhas changed dramatically since Newton conducted his famous\r\nexperiment using prisms to show that white light contained all\r\nthe colors of the spectrum. Yet, Newton's experiment is still\r\nvalid and still yields the same results. Psychology has changed\r\nits ideas about the nature of memory since Ebbinghaus conducted\r\nhis famous experiments on the curve of forgetting in the 1880s.\r\nWe believe that memory is more dynamic and complicated than can\r\nbe captured by Ebbinghaus' ideas about a passive, rote memory\r\nsystem. Nevertheless, his findings still can be replicated and\r\nthey form an important part of our database on memory.</p>\r\n\r\n<p>Parapsychology, unlike the other sciences, has a shifting\r\ndatabase. Experimental data that one generation puts forth as\r\nrock-solid evidence for psi is discarded by later generations in\r\nfavor of new data. When the Society for Psychical Research was\r\nfounded in 1882, its first president Henry Sidgwick, pointed to\r\nthe experiments with the Creery sisters as the evidence that\r\nshould convince even the most hardened skeptic of the reality of\r\npsi. Soon, he and the other members of the Society argued that\r\nthe data from Smith-Blackburn experiments provided the\r\nfraud-proof case for the reality of telepathy. The next\r\ngeneration of psychical researchers, however, cast aside these\r\ncases as defective and we no longer hear about them. Instead,\r\nthey turned to new data to argue their case.</p>\r\n\r\n<p>During the 1930s and 1940s, the results of Rhine's card\r\nguessing experiments were offered as the solid evidence for the\r\nreality of psi. The next generation dropped Rhine's data as being\r\nflawed and difficult to replicate and it hailed the Soal-Goldney\r\nexperiments as the replicable and rock-solid basis for the\r\nexistence of telepathy. Next came the Sheep-Goat experiments.\r\nToday, the Rhine data, the Sheep-Goats experiments, and the\r\nSoal-Goldney experiments no longer are used to argue the case for\r\npsi. Contemporary parapsychologists, instead, point to the\r\nganzfeld experiments, the random-number generator experiments,\r\nand--with the declassifying of the SAIC experiments--the remote\r\nviewing experiments as their basis for insisting that psi exists.</p>\r\n\r\n<p>Professor Utts uses the ganzfeld data and the SAIC remote\r\nviewing results to assert that the existence of anomalous\r\ncognition has been proven. She does not completely discard\r\nearlier data. She cites meta-analyses of some of the earlier\r\nparapsychology experiments. Still, the cumulative database for\r\nanomalous mental phenomena does not exist. Most of the data\r\naccumulated by previous investigators has been discarded. In most\r\ncases the data have been discarded for good reasons. They were\r\nsubsequently discovered to be seriously flawed in one or more\r\nways that was not recognized by the original investigators. Yet,\r\nat the time they were part of the database, the parapsychologists\r\nwere certain that they offered incontestable evidence for the\r\nreality of psi.</p>\r\n\r\n<p>How does this discussion relate to our present concerns with\r\nthe scientific status of the SAIC program? This consideration of\r\nthe shifting database of parapsychology offers a cautionary note\r\nto the use of contemporary research on the ganzfeld and remote\r\nviewing as solid evidence for anomalous mental phenomena. More\r\nthan a century of parapsychological research teaches us that each\r\ngeneration of investigators was sure that it had found the `Holy\r\nGrail'--the indisputable evidence for psychic functioning. Each\r\nsubsequent generation has abandoned their predecessors' evidence\r\nas defective in one way or another. Instead, the new generation\r\nhad its own version of the holy grail.</p>\r\n\r\n<p>Today, the parapsychologists offer us the ganzfeld experiments\r\nand, along with Jessica Utts, will presumably will include the\r\nSAIC remote viewing experiments as today's reasons for concluding\r\nthat anomalous cognition has been demonstrated. Maybe this\r\ngeneration is correct. Maybe, this time the&quot;\r\nindisputable&quot; evidence will remain indisputable for\r\nsubsequent generations. However, it is too soon to tell. Only\r\nhistory will reveal the answer. As E.G. Boring once wrote, when\r\nwriting about the Soal-Goldney experiments, you cannot hurry\r\nhistory.</p>\r\n\r\n<p>Meanwhile, as I will point out later in this report, there are\r\nhints and suggestions that history may repeat itself. Where Utts\r\nsees consistency and incontestable proof, I see inconsistency and\r\nhints that all is not as rock-solid as she implies.</p>\r\n\r\n<p>I can list other reasons to suggest that parapsychology's\r\nstatus as a science is shaky, at best. Some of these reasons will\r\nemerge as I discuss specific aspects of the SAIC results and\r\ntheir relation to other contemporary parapsychological research.</p>\r\n\r\n<p>THE CLAIM THAT ANOMALOUS COGNITION EXISTS</p>\r\n\r\n<p>Professor Utts concludes that &quot;psychic functioning has\r\nbeen well established.&quot; She bases this conclusion on three\r\nother claims: 1) the statistical results of the SAIC and other\r\nparapsychological experiments &quot;are far beyond what is\r\nexpected by chance&quot; ; 2) &quot;arguments that these results\r\ncould be due to methodological flaws are soundly refuted&quot; ;\r\nand 3) &quot;Effects of similar magnitude to those found in\r\ngovernment-sponsored research at SRI and SAIC have been\r\nreplicated at a number of laboratories across the world.&quot;</p>\r\n\r\n<p>Later, in this report, I will raise questions about her major\r\nconclusion and the three supporting claims. In this section, I\r\nwant to unpack just what these claims entail. I will start with\r\nthe statistical findings. Parapsychological is unique among the\r\nsciences in relying solely on significant departures from a\r\nchance baseline to establish the presence of its alleged\r\nphenomenon. In the other sciences the defining phenomena can be\r\nreliably observed and do not require indirect statistical\r\nmeasures to justify their existence. Indeed, each branch of\r\nscience began with phenomena that could be observed directly.\r\nGilbert began the study of magnetism by systematically studying a\r\nphenomenon that had been observed and was known to the ancients\r\nas well as his contemporaries. Modern physics began by becoming\r\nmore systematic about moving objects and falling bodies.\r\nPsychology became a systematic science by looking for lawful\r\nrelationships among sensory discriminations. Another starting\r\npoint was the discovery of lawful relationships in the\r\nremembering and forgetting of verbal materials. Note that in none\r\nof these cases was the existence of the defining phenomena in\r\nquestion. No one required statistical tests and effect sizes to\r\ndecide if magnetism was present or if a body had fallen.\r\nPsychophysicists did not need to reject a null hypothesis to\r\ndecide if sensory processes were operating and memory researchers\r\ndid not have to rely on reaching accepted levels of significance\r\nto know if recall or forgetting had occurred.</p>\r\n\r\n<p>Each of the major sciences began with phenomena whose presence\r\nwas not in question. The existence of the primary phenomena was\r\nnever in question. Each science began by finding systematic <i>relationships</i>\r\namong <i>variations</i> in the magnitudes of attributes of the\r\ncentral phenomena and the attributes of independent variables\r\nsuch as time, location, etc. The questions for the investigation\r\nof memory had to do with how best to describe the forgetting\r\ncurve and what factors affected its parameters. No statistical\r\ntests or determination of effect sizes were required to decide\r\nif, in fact, forgetting was or was not present on any particular\r\noccasion.</p>\r\n\r\n<p>Only parapsychology claims to be a science on the basis of\r\nphenomena (or a phenomenon) whose presence can be detected only\r\nby rejecting a null hypothesis. To be fair, parapsychologists\r\nalso talk about doing process research where the emphasis is on\r\nfinding systematic relationships between attributes of psi and\r\nvariations in some independent variable. One conclusion from the\r\nSRI/SAIC project, for example, is that there is no relationship\r\nbetween the distance of the target from the viewer and the\r\nmagnitude of the effect size for anomalous cognition. However, it\r\nis still the case that the effect size, and even the question of\r\nwhether anomalous cognition was present in any experiment, is\r\nstill a matter of deciding if a departure from a chance base line\r\nis non-accidental.</p>\r\n\r\n<p>At this point I think it is worth emphasizing that the use of\r\nstatistical inference to draw conclusions about the null\r\nhypothesis assumes that the underlying probability model\r\nadequately represents the distributions and variations in the\r\nreal world situation. The underlying probability model is an <i>idealization</i>\r\nof the empirical situation for which it is being used. Whether or\r\nnot the model is appropriate for any given application is an\r\nempirical matter and the adequacy of the model has to be\r\njustified for each new application. Empirical studies have shown\r\nthat statistical models fit real world situations only\r\napproximately. The tails of real-world distributions, for\r\nexample, almost always contain more cases than the standard\r\nstatistics based on the normal curve assume. These departures\r\nfrom the idealized model do not have much practical import in\r\nmany typical statistical applications because the statistical\r\ntests are <i>robust</i>. That is, the departures of the actual\r\nsituation from the assumed probability model typically do not\r\ndistort the outcome of the statistical test.</p>\r\n\r\n<p>However, when statistical tests are used in situations beyond\r\ntheir ordinary application, they can result in rejections of the\r\nnull hypothesis for reasons other than a presumed departure from\r\nthe expected chance value. Parapsychologists often complain that\r\ntheir results fail to replicate because of inadequate power.\r\nHowever, because the underlying probability models are only\r\napproximations, <i>too much power</i> can lead to rejections of\r\nthe null hypothesis simply because the real world and the\r\nidealized statistical model are not exact matches. This\r\ndiscussion emphasizes that significant findings can arise for\r\nmany reasons--including the simple fact that statistical\r\ninference is based on idealized models that mirror the real world\r\nonly approximately.</p>\r\n\r\n<p>I agree with Jessica Utts that the effect sizes reported in\r\nthe SAIC experiments and in the recent ganzfeld studies probably\r\ncannot be dismissed as due to chance. Nor do they appear to be\r\naccounted for by multiple testing, file-drawer distortions,\r\ninappropriate statistical testing or other misuse of statistical\r\ninference. I do not rule out the possibility that some of this\r\napparent departure from the null hypothesis might simply reflect\r\nthe failure of the underlying model to be a truly adequate model\r\nof the experimental situation. However, I am willing to assume\r\nthat the effect sizes represent true effects beyond inadequacies\r\nin the underlying model. Statistical effects, by themselves, do\r\nnot justify claiming that anomalous cognition has been\r\ndemonstrated--or, for that matter, that an anomaly of any kind\r\nhas occurred.</p>\r\n\r\n<p>So, I accept Professor Utts' assertion that the statistical\r\nresults of the SAIC and other parapsychological experiments\r\n&quot;are far beyond what is expected by chance.&quot;\r\nParapsychologists, of course, realize that the truth of this\r\nclaim does not constitute proof of anomalous cognition. Numerous\r\nfactors can produce significant statistical results.\r\nOperationally, the presence of anomalous cognition is detected by\r\nthe elimination of all other possibilities. This reliance on a <i>negative\r\ndefinition of its central phenomenon</i> is another liability\r\nthat parapsychology brings with its attempt to become a\r\nrecognized science. Essentially, anomalous cognition is claimed\r\nto be present whenever statistically significant departures from\r\nthe null hypothesis are observed under conditions that preclude\r\nthe operation of all mundane causes of these departures. As\r\nBoring once observed, every success in parapsychological research\r\nis a failure. By this he meant that when the investigator or the\r\ncritics succeed in finding a scientifically acceptable\r\nexplanation for the significant effect the claim for ESP or\r\nanomalous cognition has failed.</p>\r\n\r\n<p>Having accepted the existence of non-chance effects, the focus\r\nnow is upon whether these effects have normal causes. Since the\r\nbeginning of psychical research, each claim that psychic\r\nfunctioning had been demonstrated was countered by critics who\r\nsuggested other reasons for the observed effects. Typical\r\nalternatives that have been suggested to account for the effects\r\nhave been fraud, statistical errors, and methodological\r\nartifacts. In the present discussion I am not considering fraud\r\nor statistical errors. This leaves only methodological oversight\r\nas the source for a plausible alternative to psychic functioning.\r\nUtts has concluded that &quot;arguments that these results could\r\nbe due to methodological flaws are soundly refuted.&quot; If she\r\nis correct, then I would have to agree with her bottom line\r\n&quot;that psychic functioning has been well established.&quot;</p>\r\n\r\n<p>Obviously I do not agree that all possibilities for\r\nalternative explanations of the non-chance results have been\r\neliminated. The SAIC experiments are well-designed and the\r\ninvestigators have taken pains to eliminate the known weaknesses\r\nin previous parapsychological research. In addition, I cannot\r\nprovide suitable candidates for what flaws, if any, might be\r\npresent. Just the same, it is impossible in principle to say that\r\nany particular experiment or experimental series is completely\r\nfree from possible flaws. An experimenter cannot control for\r\nevery possibility--especially for potential flaws that have not\r\nyet been discovered.</p>\r\n\r\n<p>At this point, a parapsychologist might protest that such\r\n&quot;in principle&quot; arguments can always be raised against\r\nany findings, no matter how well conceived was the study from\r\nwhich they emerged. Such a response is understandable, but I\r\nbelieve my caution is reasonable in this particular case.\r\nHistorically, many cases of evidence for psi were proffered on\r\nthe grounds that they came from experiments of impeccable\r\nmethodological design. Only subsequently, sometimes by fortunate\r\naccident, did the possibility of a serious flaw or alternative\r\nexplanation of the results become available. The founders of the\r\nSociety for Psychical Research believed that the Smith-Blackburn\r\nexperiments afforded no alternative to the conclusion that\r\ntelepathy was involved. They could conceive of no mundane\r\nexplanation. Then Blackburn confessed and explained in detail\r\njust how he and Smith had tricked the investigators.</p>\r\n\r\n<p>The critics became suspicious of the Soal-Goldney findings not\r\nonly because the results were too good, but also because Soal\r\nlost the original records under suspicious circumstances. Hansel,\r\nScott, and Price each generated elaborate scenarios to explain\r\nhow Soal might have cheated. Hansel and Scott reported finding\r\npeculiar patterns in the data. The scenarios, for accounting for\r\nthese data, however, were extremely complicated and required the\r\ncollusion of several individuals--some of whom were prominent\r\nstatesmen and academics. The discovery of how Soal actually had\r\ncheated was made by the parapsychologist Betty Markwick. The\r\nfinding came about through fortuitous circumstances. The method\r\nof cheating turned out to involve only one person and employed an\r\ningenious, but simple, method that none of the critics had\r\nanticipated.</p>\r\n\r\n<p>During the first four years of the original ganzfeld-psi\r\nexperiments, the investigators asserted that their findings\r\ndemonstrated psi because the experimental design precluded any\r\nnormal alternative. Only after I and a couple of\r\nparapsychologists independently pointed out how the use of a\r\nsingle set of targets could provide a mundane alternative to\r\npsychic communication did the ganzfeld experimenters realize the\r\nexistence of this flaw. After careful and lengthy scrutiny of the\r\nganzfeld database, I was able to generate a lengthy list of\r\npotential flaws.</p>\r\n\r\n<p>Honorton and his colleagues devised the autoganzfeld\r\nexperiments. These experiments were deliberately designed to\r\npreclude the flaws that I and others had eventually discovered in\r\nthe original ganzfeld database. When the statistically\r\nsignificant results emerged from these latter experiments, they\r\nwere proclaimed to be proof of anomalous communication because\r\nall alternative mundane explanations had been eliminated. When I\r\nwas first confronted with these findings, I had to admit that the\r\ninvestigators had eliminated all but one of the flaws that I had\r\nlisted for the original database. For some reason, Honorton and\r\nhis colleagues did not seem to consider seriously the necessity\r\nof insuring that their randomization procedures were optimal.\r\nHowever, putting this one oversight aside, I could find no\r\nobvious loopholes in the experiments as reported.</p>\r\n\r\n<p>When I was asked to comment on the paper that Daryl Bem and\r\nCharles Honorton wrote for the January 1994 issue of the <i>Psychological\r\nBulletin,</i> I was able to get much of the raw data from\r\nProfessor Bem. My analyses of that data revealed strong patterns\r\nthat, to me, pointed to an artifact of some sort. One pattern,\r\nfor example, was the finding that all the significant hitting\r\nabove chance occurred only on the second or later occurrence of a\r\ntarget. All the first occurrences of a target yielded results\r\nconsistent with chance. Although this was a post hoc finding, it\r\nwas not the result of a fishing expedition. I deliberately looked\r\nfor such a pattern as an indirect way of checking for the\r\nadequacy of the randomization procedures. The pattern was quite\r\nstrong and persisted in every breakdown of the data that I\r\ntried--by separate investigator, by target type, by individual\r\nexperiment, etc. The existence of this pattern by itself does not\r\nprove it is the result of an artifact. As expected, Professor Bem\r\nseized upon it as another peculiarity of psi. Subsequent to\r\nfinding this pattern, I have learned about many other weaknesses\r\nin this experiment which could have compromised the results.\r\nRobert Morris and his colleagues at the University of Edinburgh\r\ntook these flaws ,as well as some additional ones that they\r\nuncovered, into account when they designed the ganzfeld\r\nreplication experiments.</p>\r\n\r\n<p>The point of this discussion is that it takes some time before\r\nwe fully recognize the potential flaws in a newly designed\r\nexperimental protocol. In some cases, the discovery of a serious\r\nflaw is the result of a fortuitous occurrence. In other cases,\r\nthe uncovering of flaws came about only after the new protocol\r\nhad been used for a while. Every new experimental design, as is\r\nthe case for every new computer program, requires a shakedown\r\nperiod and debugging. The problems with any new method or design\r\nare not always apparent at first. Obvious flaws may be eliminated\r\nonly to be replaced by more subtle ones.</p>\r\n\r\n<p>How does this apply to the SAIC experiments? These experiments\r\nwere designed to eliminate the obvious flaws of the previous\r\nremote viewing experiments at SRI. Inspection of the protocol\r\nindicates that they succeeded in this respect. The new design and\r\nmethodology, however, has not had a chance to be used in other\r\nlaboratories or to be properly debugged. Many of the features\r\nthat could be considered an asset also have possible down sides.\r\nI will return to this later in the report when I discuss the use\r\nof the same viewers and the same judge across the different\r\nexperiments. For now, I just want to suggest some general grounds\r\nfor caution in accepting the claim that all possible\r\nmethodological flaws have been eliminated.</p>\r\n\r\n<p>The third warrant for Jessica Utts' conclusion that psi has\r\nbeen proven is that &quot;Effects of similar magnitude to those\r\nfound in government-sponsored research at SRI and SAIC have been\r\nreplicated at a number of laboratories across the world.&quot; I\r\nwill discuss this matter below. For now, I will point out that\r\neffects of similar magnitude can occur for several different\r\nreasons. Worse, the average effect size from different\r\nparapsychological research programs is typically a meaningless\r\ncomposite of arbitrary units. As such, these averages do not\r\nrepresent meaningful parameters in the real world. For example,\r\nHonorton claimed that the autoganzfeld experiments replicated the\r\noriginal ganzfeld experiments because the average effect size for\r\nboth databases was approximately identical. This apparent\r\nsimilarity in average effect size is meaningless for many\r\nreasons. For one thing, the similarity in size depends upon which\r\nof many possible averages one considers. In the case under\r\nconsideration the average effect size was obtained by adding up\r\nall the hits and trials for the 28 studies in the database. One\r\nexperimenter contributed almost half to this total. Others\r\ncontributed in greatly unequal numbers. The average will differ\r\nif each experimenter's contribution is given equal weight.</p>\r\n\r\n<p>In addition, the heterogeneity of effect sizes among separate\r\ninvestigators is huge. All the effect sizes, for example, of one\r\nthe investigators were negative. Another investigator contributed\r\nmostly moderately large effect sizes. If the first investigator\r\nhad contributed more trials to the total, then the average would\r\nobviously have been lower. Similar problems exist for the average\r\nfrom the autoganzfeld experiments. In these latter experiments,\r\nthe static targets--which most closely resembled the overwhelming\r\nmajority of targets in the original database--yielded an effect\r\nsize of zero. The dynamic targets yielded a highly significant\r\nand moderate effect size. Is the correct average effect size for\r\nthese experiments based on a composite of the results of the\r\nstatic and dynamic targets or should it be based only the dynamic\r\ntargets?</p>\r\n\r\n<p>THE SAIC PROGRAM</p>\r\n\r\n<p>As I have indicated, the SAIC experiments are an improvement\r\non both the preceding SRI experiments as well as previous\r\nparapsychological investigations. The investigators seem to have\r\ntaken pains to insure that randomization of targets for\r\npresentation and for judging was done properly. They have\r\neliminated the major flaw in original SRI remote viewing\r\nexperiments of non-independence in trials for a given viewer.\r\nSome of the other features can be considered as improvements but\r\nalso as possible problems. In this category I would list the use\r\nof the same experienced viewers in many experiments and the use\r\nof the same target set across experiments. The major limitations\r\nthat I see in these studies derive from their newness and their\r\nhaving been conducted in secrecy. The newness simply means that\r\nwe have not had sufficient time to debug and to grasp fully both\r\nthe strengths and weaknesses of this protocol. The secrecy\r\naggravated this limitation by preventing other investigators from\r\nreviewing and criticizing the experiments from the beginning, and\r\nby making it impossible for independent laboratories to replicate\r\nthe findings. (1)</p>\r\n\r\n<p>The fact that these experiments were conducted in the same\r\nlaboratory, with the same basic protocol, using the same viewers\r\nacross experiments, the same targets across experiments, and the\r\nsame investigators aggravates, rather than alleviates, the\r\nproblem of independent replication. If subtle, as-yet-undetected\r\nbias and flaws exist is the protocol, the very consistency of\r\nelements such as targets, viewers, investigators, and procedures\r\nacross experiments enhances the possibility that these flaws will\r\nbe compounded.</p>\r\n\r\n<p>Making matters even worse is the use of the same judge across\r\nall experiments. The judging of viewer responses is a critical\r\nfactor in free-response remote viewing experiments. Ed May, the\r\nprinciple investigator, as I understand it, has been the sole\r\njudge in all the free response experiments. May's rationale for\r\nthis unusual procedure was that he is familiar with the response\r\nstyles of the individual viewers. If a viewer, for example, talks\r\nabout bridges, May--from his familiarity with this viewer--might\r\nrealize that this viewer uses bridges to refer to any object that\r\nis on water. He could then interpret the response accordingly to\r\nmake the appropriate match to a target. Whatever merit this\r\nrationale has, it results in a methodological feature that\r\nviolates some key principles of scientific credibility. One might\r\nargue that the judge, for example, should be blind not only about\r\nthe correct target but also about who the viewer is. More\r\nimportant, the scientific community at large will be reluctant to\r\naccept evidence that depends upon the ability of one specific\r\nindividual. In this regard, the reliance on the same judge for\r\nall free-response experiments is like the experimenter effect. To\r\nthe extent that the results depend upon a particular investigator\r\nthe question of scientific objectivity arises. Scientific proof\r\ndepends upon the ability to generate evidence that, in principle,\r\nany serious and competent investigator--regardless of his or her\r\npersonality--can observe.</p>\r\n\r\n<p>The use of the same judge across experiments further compounds\r\nthe problem of non-independence of the experiments. Here, both\r\nProfessor Utts and I agree. We believe it is important that the\r\nremote viewing results be obtainable with different judges.\r\nAgain, the concern here is that the various factors that are\r\nsimilar across experiments, count against their separate findings\r\nas independent evidence for anomalous cognition.</p>\r\n\r\n<p>HAS ANOMALOUS COGNITION BEEN PROVEN?</p>\r\n\r\n<p>Obviously, I do not believe that the contemporary findings of\r\nparapsychology, including those from the SRI/SAIC program,\r\njustify concluding that anomalous mental phenomena have been\r\nproven. Professor Utts and some parapsychologists believe\r\notherwise. I admit that the latest findings should make them\r\noptimistic. The case for psychic functioning seems better than it\r\never has been. The contemporary findings along with the output of\r\nthe SRI/SAIC program do seem to indicate that something beyond\r\nodd statistical hiccups is taking place. I also have to admit\r\nthat I do not have a ready explanation for these observed\r\neffects. Inexplicable statistical departures from chance,\r\nhowever, are a far cry from compelling evidence for anomalous\r\ncognition.</p>\r\n\r\n<p>So what would be compelling evidence for the reality of\r\nanomalous cognition? Let's assume that the experimental results\r\nfrom the SAIC remote viewing experiments continue to hold up.\r\nFurther assume that along with continued statistical significance\r\nno flaws or mundane alternative possibilities come to light. We\r\nwould then want to ensure that similar results will occur with\r\nnew viewers, new target pools, and several independent judges.\r\nFinally, to satisfy the normal standards of science, we would\r\nneed to have the findings successfully replicated in independent\r\nlaboratories by other parapsychologists as well as\r\nnonparapsychologists.</p>\r\n\r\n<p>If the parapsychologists could achieve this state of affairs,\r\nwe are faced with a possible anomaly, but not necessarily\r\nanomalous cognition. As the parapsychologist John Palmer has\r\nrecognized, parapsychologists will have to go beyond\r\ndemonstrating the presence of a statistical anomaly before they\r\ncan claim the presence of psychic functioning. This is because,\r\namong other things, the existence of a statistical anomaly is\r\ndefined negatively. Something is occurring for which we have no\r\nobvious or ready explanation. This something may or may not turn\r\nout to be paranormal. According to Palmer, parapsychologists will\r\nhave to devise a <i>positive theory of the paranormal</i> before\r\nthey will be in a position to claim that the observed anomalies\r\nindicate paranormal functioning.</p>\r\n\r\n<p>Without such a positive theory, we have no way of specifying\r\nthe boundary conditions for anomalous mental phenomena. Without\r\nsuch a theory we have no way of specifying when psi is present\r\nand when it is absent. Because psi or anomalous cognition is\r\ncurrently detected only by departures from a null hypothesis all\r\nkinds of problems beset the quest for the claim and pursuit of\r\npsychic functioning. For example, the <i>decline effect, </i>which\r\nwas investigated in one of the SAIC experiments, was once used as\r\nan important sign for the presence of psi. J.B. Rhine discovered\r\nthis effect not only in some of his data but in his re-analyses\r\nof data collected by earlier investigators. He attached great\r\nimportance to his effect because it existed in data whose\r\ninvestigators neither knew of its existence nor had they been\r\nseeking it. In addition, the decline effect helped Rhine to\r\nexplain how seemingly null results really contained evidence for\r\npsi. This is because the decline effect often showed up as an\r\nexcess of hitting in the early half of the experiment and as a\r\ndeficit of hitting in the second half of the experiment. These\r\ntwo halves, when pooled together over the entire experiment,\r\nyielded an overall hit rate consistent with chance.</p>\r\n\r\n<p>Although Rhine and other parapsychologists attached great\r\nimportance to the decline effect as a reliable and often hidden\r\nsign of the presence of psychic functioning, the reliance on this\r\nindicator unwittingly emphasizes serious problems in the\r\nparapsychologist's quest. As the SAIC report on binary coding\r\nstates, the decline effect is claimed for a bewildering variety\r\nof possibilities. Some investigators have found a decline effect\r\ngoing from the first quarter to the last quarter of each separate\r\nscore sheet in their experiment. Other investigators have\r\nreported a decline effect as a decrease in hit rate from the\r\nfirst half to the second half of the total experiment. Still\r\nothers find a decline effect across separate experiments. Indeed,\r\nalmost any variation where the direction is from a higher hit\r\nrate to a lower hit rate has been offered as evidence for a\r\ndecline effect. To confuse matters further, some investigators\r\nhave claimed finding evidence for an<i> incline effect.</i></p>\r\n\r\n<p>If the decline effect is a token for the presence of psi, what\r\nshould one conclude when the data, as was the case in the SAIC\r\nexperiment on binary coding, show a significant departure from\r\nthe null hypothesis <i>but no decline effect?</i> We know what\r\nthe parapsychologist's conclude. As long as they get a\r\nsignificant effect, they do not interpret the absence of the\r\ndecline effect as the absence of psychic functioning. This state\r\nof affairs holds as well for several other effects that have been\r\nput forth as tokens or signs of anomalous mental functioning.\r\nSeveral such signs are listed in the <i>Handbook of\r\nParapsychology</i> [1977, B.B. Wolman, Editor].</p>\r\n\r\n<p>Typically, such signs are sought when the attempt to reject\r\nthe ordinary null hypothesis fails. <i>Displacement effects</i>\r\nare frequently invoked. When his attempts to replicate Rhine's\r\nresults failed, Soal was persuaded to re-analyze his data in\r\nterms of displacement effects. His retrospective analysis\r\nuncovered two subjects whose guesses significantly correlated\r\nwith the target one or two places ahead of the intended target.\r\nIn his subsequent experiments with these two subjects, one kept\r\nhitting on the symbol that came after the intended target while\r\nthe other produced significant outcomes only when her guesses\r\nwere matched against the symbol that occurred just before the\r\nintended target. Negative hitting, increased variability, and\r\nother types of departures from the underlying theoretical\r\nprobability model have all been used as hidden signs of the\r\npresence of psychic functioning.</p>\r\n\r\n<p>What makes this search for hidden tokens of psi problematic is\r\nlack of constraints. Any time the original null hypothesis cannot\r\nbe rejected, the eager investigator can search through the data\r\nfor one or more these markers. When one is found, the\r\ninvestigator has not hesitated in offering this as proof of the\r\npresence of psi. However, if the null hypothesis is rejected and\r\nnone of these hidden signs of psi can be found in the data, the\r\nthe investigator still claims the presence of psi. This creates\r\nthe scientifically questionable situation where any significant\r\ndeparture from a probability model is used as proof of psi but\r\nthe absence of these departures does not count as evidence\r\nagainst the presence of psi.</p>\r\n\r\n<p>So, acceptable evidence for the presence of anomalous\r\ncognition must be based on a positive theory that tells us when\r\npsi should and <i>should not </i>be present. Until we have such a\r\ntheory, the claim that anomalous cognition has been demonstrated\r\nis empty. Without such a theory, we might just as well argue that\r\nwhat has been demonstrated is a set of effects-<i>-each one of\r\nwhich be the result of an entirely different cause.</i></p>\r\n\r\n<p>Professor Utts implicitly acknowledges some of the preceding\r\nargument by using consistency of findings with other laboratories\r\nas evidence that anomalous cognition has been demonstrated. I\r\nhave already discussed why the apparent consistency in average\r\neffect size across experiments cannot be used as an argument for\r\nconsistency of phenomena across these experiments. To be fair,\r\nparapsychologists who argue consistency of phenomena across\r\nexperiments often go beyond simply pointing to consistency in\r\neffect sizes.</p>\r\n\r\n<p>One example is the claim that certain personality correlates\r\nreplicate across experiments. May and his colleagues correctly\r\npoint out, however, that these correlations tend to be low and\r\ninconsistent. Recently, parapsychologists have claimed that\r\nextroversion correlates positively with successful performance on\r\nanomalous cognition tasks. This was especially claimed to be true\r\nof the ganzfeld experiments. However, the apparently successful\r\nreplication of the autoganzfeld experiments by the Edinburgh\r\ngroup [under subcontract to the SAIC program] found that the\r\nintroverts, if anything, scored higher than the extroverts.</p>\r\n\r\n<p>The autoganzfeld experiments produced significant effects only\r\nfor the dynamic targets. The static targets produced zero effect\r\nsize. Yet the bulk of the targets in the original ganzfeld\r\ndatabase were static and they produced an effect size that was\r\nsignificantly greater than the zero effect size of the\r\nautoganzfeld experiments [ I was able to demonstrate that there\r\nwas adequate power to detect an effect size of the appropriate\r\nmagnitude for the static targets in the autoganzfeld\r\nexperiments]. Further indication of inconsistency is the SAIC\r\nexperiment which found that the only the static targets produced\r\na significant effect size, whereas the dynamic targets yielded a\r\nzero effect size. May and his colleagues speculated that the\r\nfailure of the dynamic targets was due to a `bandwidth' that was\r\ntoo wide. When they apparently narrowed the bandwidth of the\r\ndynamic targets in a second experiment, both dynamic and static\r\ntargets did equally well. It is unclear whether this should be\r\ntaken as evidence for consistency or inconsistency. Note that the\r\nhypothesis and claim for the autoganzfeld experiments is that\r\ndynamic targets should be significantly better than static ones.\r\nAs far as I can tell the original dynamic targets of the ganzfeld\r\nexperiments are consistent with an unlimited bandwidth.</p>\r\n\r\n<p>Other important inconsistencies exist among the contemporary\r\ndatabases. The <i>raison d'\u00e0tre </i>for the ganzfeld experiments\r\nis the belief among some parapsychologists that an altered state\r\nfacilitates picking up the psi signal because it lowers the\r\nnoise-to-signal ratio from external sensory input. The touchstone\r\nof this protocol is the creation of an altered state in the\r\nreceiver. This contrasts sharply with the remote viewing\r\nexperiments in which the viewer is always in a normal state. More\r\nimportant is that the ganzfeld researchers believe that they get\r\nbest results when each subject serves as his/her own judge. Those\r\nexperiments in the ganzfeld database that employed both external\r\njudges and subjects as their own judges found that their results\r\nwere more successful using subjects as their own judges. The\r\nreverse is true in the remote viewing experiments. The remote\r\nviewer experimenters believe that external judges provide much\r\nbetter hit rates than viewer-judges. This difference is even more\r\nextreme in the SAIC remote viewing where a single judge was used\r\nfor all experiments. This judge, who was also the principal\r\ninvestigator, believed that he could achieve best results if he\r\ndid the judging because of his familiarity with the response\r\nstyles of the individual viewers.</p>\r\n\r\n<p>So even if the ganzfeld and the SAIC remote viewing\r\nexperiments have achieved significant effects and average effect\r\nsizes of approximately the same magnitude, there is no compelling\r\nreason to assume they are dealing with the same phenomena or\r\nphenomenon. To make such a claim entails showing that the alleged\r\neffect shows the same pattern of relationships in each protocol.\r\nAlmost certainly, a positive theory of anomalous mental phenomena\r\nthat predicts lawful relationships of a recognizable type will be\r\nnecessary before a serious claim can be made that the same\r\nphenomenon is present across different research laboratories and\r\nexperiments. Such a positive theory will be necessary also to\r\ntell us when we are and when we are not in the presence of this\r\nalleged anomalous cognition.</p>\r\n\r\n<p>WHAT NEEDS TO BE EXPLAINED?</p>\r\n\r\n<p>Professor Utts and many parapsychologists argue that they have\r\nproduced evidence of an anomaly that requires explanation. They\r\nassert that the statistical effects they have documented cannot\r\nbe accounted for in terms of normal scientific principles or\r\nmethodological artifact. After reviewing the results from the\r\nSAIC experiments in the context of other contemporary\r\nparapsychological research, Utts is confident that more than an\r\nanomaly has been demonstrated. She believes the evidence suffices\r\nto conclude that the anomaly establishes the existence of psychic\r\nfunctioning.</p>\r\n\r\n<p>This evidence for anomalous cognition, according to Utts and\r\nthe parapsychologists, meets the standards employed by the other\r\nsciences. By this, I think Professor Utts means that in many\r\nareas of scientific inquiry the decision that a real effect has\r\noccurred is based on rules of statistical inference. Only if the\r\nnull hypothesis of no difference between two or more treatments\r\nis rejected can the investigator claim that the differences are\r\nreal in the sense that they are greater than might be expected on\r\nthe basis of some baseline variability. According to this\r\nstandard, it seems that the SAIC experiments as well as the\r\nrecent ganzfeld experiments have yielded effects that cannot be\r\ndismissed as the result of normal variability.</p>\r\n\r\n<p>While the rejection of the null hypothesis is typically a <i>necessary</i>\r\nstep for claiming that an hypothesized effect or relationship has\r\noccurred, it is never <i>sufficient</i>. Indeed, because the\r\nunderlying probability model is only an approximation, everyone\r\nrealizes that the null hypothesis is rarely, if ever, strictly\r\ntrue. In practice, the investigator hopes that the statistical\r\ntest is sufficiently <i>robust</i> that it will reject the null\r\nhypothesis only for meaningful departures from the null\r\nhypothesis. With sufficient power, the null hypothesis will\r\nalmost certainly be rejected in most realistic situations. This\r\nis because effect sizes will rarely be exactly zero. Even if the\r\ntrue effect size is zero in a particular instance, sufficient\r\npower can result in the rejection of the null hypothesis because\r\nthe assumed statistical model will depart from the real-world\r\nsituation in other ways. For most applications of statistical\r\ninference, then,<i> too much power</i> can result in mistaken\r\ninferences as well as <i>too little power.</i></p>\r\n\r\n<p>Here we encounter another way in which parapsychological\r\ninquiry differs from typical scientific inquiry. In those\r\nsciences that rely on statistical inference, they do so as an aid\r\nto weeding out effects that could be the result of chance\r\nvariability. When effect sizes are very small or if the\r\nexperimenter needs to use many more cases than is typical for the\r\nfield to obtain significance, the conclusions are often suspect.\r\nThis is because we know that with enough cases an investigator\r\nwill get a significant result, regardless of whether it is\r\nmeaningful or not. Parapsychologists are unique in postulating a\r\nnull hypothesis that entails a true effect size of zero if psi is\r\nnot operating. Any significant outcome, then, becomes evidence\r\nfor psi. My concern here is that small effects and other\r\ndepartures from the statistical model can be expected to occur in\r\nthe absence of psi. The statistical model is only an\r\napproximation. When power is sufficient and when the statistical\r\ntest is pushed too far, rejections of the null hypothesis are\r\nbound to occur. This is another important reason why claiming the\r\nexistence of an anomaly based solely on evidence from statistical\r\ninference is problematic.</p>\r\n\r\n<p>This is one concern about claiming the existence of an anomaly\r\non the basis of statistical evidence. In the context of this\r\nreport, I see it as a minor concern. As I have indicated, I am\r\nwilling to grant Professor Utts' claim that the rejection of the\r\nnull hypothesis is probably warranted in connection with the SAIC\r\nand the ganzfeld databases. I have other concerns. Both have to\r\ndo with the fact that no other science, so far as I know, would\r\ndraw conclusions about the existence of phenomena solely on the\r\nbasis of statistical findings. Although it is consistent with\r\nscientific practice to use statistical inference to reject the\r\nnull hypothesis, it is not consistent with such practice to\r\npostulate the existence of phenomena on this basis alone. Much\r\nmore is required. I will discuss at least two additional\r\nrequirements.</p>\r\n\r\n<p>Thomas Kuhn's classic characterization of normal and\r\nrevolutionary science has served as the catalyst for many\r\ndiscussions about the nature of scientific inquiry. He\r\npopularized the idea that normal scientific inquiry is guided by\r\nwhat he called a <i>paradigm</i>. Later, in the face of\r\ncriticisms, he admitted that he had used the term <i>paradigm</i>\r\nto cover several distinct and sometimes contradictory features of\r\nthe scientific process. One of his key uses of the term <i>paradigm</i>\r\nwas to refer to the store of <i>exemplars</i> or textbook cases\r\nof standard experiments that every field of scientific inquiry\r\npossesses. These exemplars are what enable members of a\r\nscientific community to quickly learn and share common\r\nprinciples, procedures, methods, and standards. These exemplars\r\nare also the basis for initiating new members into the community.\r\nNew research is conducted by adapting one or more of the patterns\r\nin existing exemplars as guidelines about what constitutes\r\nacceptable research in the field under consideration.</p>\r\n\r\n<p>Every field of inquiry, including parapsychology, has its\r\nstock of exemplars. In parapsychology these would include the\r\nclassic card guessing experiments of J.B. Rhine, the Sheep-Goat\r\nexperiments, etc. What is critical here is the striking\r\ndifference between the role of exemplars in parapsychology as\r\ncontrasted with their role in all other fields of scientific\r\ninquiry. These exemplars not only serve as models of proper\r\nprocedure, but they also are teaching tools. Students in a\r\nparticular field of inquiry can be assigned the task of\r\nreplicating some of these classic experiments. The instructor can\r\nmake this assignment with the confident expectation that each\r\nstudent will obtain results consistent with the original\r\nfindings. The physics instructor, for example, can ask novice\r\nstudents to try Newton's experiments with colors or Gilbert's\r\nexperiments with magnets. The students who do so will get the\r\nexpected results. The psychology instructor can ask novice\r\nstudents to repeat Ebbinghaus' experiments on forgetting or\r\nPeterson and Peterson's classic experiment on short-term memory\r\nand know that they will observe the same relationships as\r\nreported by the original experimenters.</p>\r\n\r\n<p>Parapsychology is the only field of scientific inquiry that<i>\r\ndoes not have even one exemplar that can be assigned to students\r\nwith the expectation that they will observe the original results!\r\n</i>In every domain of scientific inquiry, <i>with the exception\r\nof parapsychology</i>, many core exemplars or paradigms exist\r\nthat will reliably produce the expected, lawful relationships.\r\nThis is another way of saying that the other domains of inquiry\r\nare based upon robust, lawful phenomena whose conditions of\r\noccurrence can be specified in such a way that even novices will\r\nbe able to observe and/or produce them. Parapsychologists do not\r\npossess even one exemplar for which they can confidently specify\r\nconditions that will enable anyone--let alone a novice--to\r\nreliably witness the phenomenon.</p>\r\n\r\n<p>The situation is worse than I have so far described. The\r\nphenomena that can be observed with the standard exemplars do not\r\nrequire sensitive statistical rejections of the null hypothesis\r\nbased on many trials to announce their presence. The exemplar in\r\nwhich the student uses a prism to break white light into its\r\ncomponent colors requires no statistics or complicated inference\r\nat all. The forgetting curve in the Ebbinghaus experiment,\r\nrequires nothing more than plotting proportion recalled against\r\ntrial number. Yet, to the extent that parapsychology is\r\napproaching the day when it will possess at least one exemplar of\r\nthis sort, the &quot;observation&quot; of the\r\n&quot;phenomenon&quot; will presumably depend upon the indirect\r\nuse of statistical inference to document its presence.</p>\r\n\r\n<p>In the standard domains of science, this problem of having not\r\na single exemplar for reliably observing its alleged phenomenon,\r\nwould be taken as a sign that the domain has <i>no central\r\nphenomena. </i>When Soviet scientists announced the discovery of\r\nmitogenetic radiation, some western scientists attempted to\r\nreplicate the findings. Some reported success; others reported\r\nmixed results; and many failed entirely to observe the effect.\r\nEventually scientists, including the Soviets, abandoned the quest\r\nfor mitogenetic radiation. Because no one, including the original\r\ndiscover, could specify conditions under which the phenomenon--if\r\nthere be one--could be observed, the scientific community decided\r\nthat there was nothing to explain other than as-yet-undetected\r\nartifacts. The same story can be told about N-Rays, Polywater,\r\nand other candidate phenomena that could not be reliably observed\r\nor produced. We cannot explain something for which we do not have\r\nat least some conditions under which we can confidently say it\r\noccurs. Even this is not enough. The alleged phenomenon not only\r\nmust reliably occur at least under some conditions but it also<i>\r\nmust reliably vary in magnitude or other attributes as a function\r\nof other variables. </i>Without this minimal amount of\r\nlawfulness, the idea that there is something to explain is\r\nsenseless. Yet, at best, parapsychology's current claim to having\r\ndemonstrated a form of anomalous cognition rests on the\r\npossibility that it can generate significant differences from the\r\nnull hypothesis under conditions that are still not reliably\r\nspecified.</p>\r\n\r\n<p>I will suggest one more reason for my belief that it is\r\npremature to try to account for what the SAIC and the ganzfeld\r\nexperiments have so far put before us. On the basis of these\r\nexperiments, contemporary parapsychologists claim that they have\r\ndemonstrated the existence of an &quot;anomaly.&quot; I will\r\ngrant them that they have apparently demonstrated that the SAIC\r\nand the ganzfeld experiments have generated significant effect\r\nsizes beyond what we should expect from chance variations. I will\r\nfurther admit that, at this writing, I cannot suggest obvious\r\nmethodological flaws to account for these significant effects. As\r\nI have previously mentioned, this admission does not mean that\r\nthese experiments are free from subtle biases and potential bugs.\r\nThe experimental paradigms are too recent and insufficiently\r\nevaluated to know for sure. I can point to departures from\r\noptimality that might harbor potential flaws--such as the use of\r\na single judge across the remote viewing experiments, the active\r\ncoaching of viewers by the experimenter during judging procedures\r\nin the ganzfeld, my discovery of peculiar patterns of scoring in\r\nthe ganzfeld experiments, etc. Having granted that significant\r\neffects do occur in these experiments, I hasten to add that\r\nwithout further evidence, I do not think we can conclude that\r\nthese effects are all due to the same cause--let alone that they\r\nresult from a single phenomenon that is paranormal in origin.</p>\r\n\r\n<p>The additional reason for concern is the difference in the use\r\nof `anomaly' in this context and how the term `anomaly' is used\r\nin other sciences. In the present context, the parapsychologists\r\nare using the term `anomaly' to refer to apparently inexplicable\r\ndepartures from the null hypothesis. These departures are\r\nconsidered inexplicable in the sense that apparently all normal\r\nreasons for such departures from the null hypothesis have been\r\nexcluded. But these departures are not lawful in the sense that\r\nthe effect sizes are consistent. The effect sizes differ among\r\nviewers and subjects; they also differ for different\r\nexperimenters; they come and go in inexplicable ways within the\r\nsame subject. Possibly some of these variations in effect size\r\nwill be found to exhibit some lawfulness in the sense that they\r\nwill correlate with other variables. The SAIC investigators, for\r\nexample, hope they have found such correlates in the entropy and\r\nbandwidth of targets. At the moment this is just a hope.</p>\r\n\r\n<p>The term `anomaly' is used in a much more restricted sense in\r\nthe other sciences. Typically an anomaly refers to a lawful and\r\nprecise departure from a theoretical baseline. As such it is\r\nsomething the requires explaining. Astronomers were faced with a\r\npossible anomaly when discrepancies from Newtonian theory were\r\nreported in the orbit of Uranus. In the middle 1800s, Urban\r\nLeverrier decided to investigate this problem. He reviewed all\r\nthe data on previous sightings of Uranus--both before and after\r\nit had been discovered as new planet. On the basis of the\r\nprevious sightings, he laboriously recalculated the orbital path\r\nbased on Newtonian theory and the reported coordinates. Sure\r\nenough, he found errors in the original calculations. When he\r\ncorrected for these errors, the apparent discrepancy in Uranus'\r\norbit was much reduced. But the newly revised orbit was still\r\ndiscrepant from where it should be on Newtonian theory. With this\r\ncareful work, Leverrier had transformed a potential anomaly into\r\nan actual anomaly. Anomaly in this sense meant a precise and\r\nlawful departure from a well-defined theory. It was only after\r\nthe precise nature, direction, and magnitude of this discrepancy\r\nwas carefully specified did Leverrier and the scientific\r\ncommunity decide that here was an anomaly that required\r\nexplanation. What had to explain was quite precise. What was\r\nneeded was an explanation that exactly accounted for this\r\nspecific departure from the currently accepted theory.</p>\r\n\r\n<p>Leverrier's solution was to postulate a new planet beyond the\r\norbit of Uranus. This was no easy task because it involved the\r\nrelatively unconstrained and difficult problem of inverse\r\nperturbations. Leverrier had to decide on a size, orbit,\r\nlocation, and other attributes of a hitherto unknown body whose\r\ncharacteristics would be just those to produce the observed\r\neffects on Uranus without affecting the known orbit of Saturn.\r\nLeverrier's calculations resulted in his predicting the location\r\nof this hitherto unknown planet and the astronomer Galle located\r\nthis new planet, Neptune, close to where Leverrier had said it\r\nwould be.</p>\r\n\r\n<p>The point of this story is to emphasize the distinction\r\nbetween the parapsychologists' use of anomaly from that of other\r\nscientists'. Anomalies in most domains of scientific inquiry are\r\ncarefully specified deviations from a formal theory. What needs\r\nto be explained or accounted for is precisely described. The\r\nanomalies that parapsychologists are currently talking about\r\ndiffer from this standard meaning in that the departures are from\r\nthe general statistical model and are far from having the status\r\nof carefully specified and precise deviations from a theoretical\r\nbaseline. In this latter case we do not know what it is that we\r\nare being asked to explain. Under what conditions can we reliably\r\nobserve it? What theoretical baselines are the results a\r\ndeparture from? How much and in what direction and form do the\r\ndepartures exist? What specifically must our explanation account\r\nfor?</p>\r\n\r\n<p>Finally, I should add that some parapsychologists, at least in\r\nthe recent past, have agreed with my position that\r\nparapsychological results are not yet ready to be placed before\r\nthe scientific community. Parapsychologists such as Beloff,\r\nMartin Johnson, Gardner Murphy, J.G. Pratt and others have\r\ncomplained that parapsychological data are volatile and messy.\r\nSome of these investigators have urged their colleagues to first\r\nget their house in order before they ask the scientific community\r\nat large to take them seriously. Martin Johnson, especially, has\r\nurged his colleagues to refrain from asking the scientific\r\ncommunity to accept their findings until they can tame them and\r\nproduce lawful results under specified conditions. Clearly,\r\nparapsychology has still not reached this desired state. At best,\r\nthe results of the SAIC experiments combined with other\r\ncontemporary findings offer hope that the parapsychologists may\r\nbe getting closer to the day when they can put something before\r\nthe scientific community and challenge it to provide an\r\nexplanation.</p>\r\n\r\n<p>POTENTIALS FOR OPERATIONAL APPLICATIONS</p>\r\n\r\n<p>It may seem obvious that the utility of remote viewing for\r\nintelligence gathering should depend upon its scientific\r\nvalidity. If the scientific research cannot confirm the existence\r\nof a remote viewing ability, then it would seem to be pointless\r\nto try an use this non-existent ability for any practical\r\napplication. However, the matter is not this simple. If the\r\nscientific research confirms the existence of anomalous\r\ncognition, this does not guarantee that this ability would have\r\nuseful applications. Ed May, in his presentation to the\r\nevaluation panel, gave several reasons why remote viewing could\r\nbe real and, yet, not helpful for intelligence gathering. In his\r\nopinion, approximately 20 percent of the information supplied by\r\na viewer is accurate. Unfortunately, at the time the remote\r\nviewer is generating the information, we have no way of deciding\r\nwhich portion is likely to be the accurate one. Another problem\r\nis that the viewer's information could be accurate, yet not\r\nrelevant for the intelligence analyst's purposes.</p>\r\n\r\n<p>This question is related to the problem of boundary conditions\r\nwhich I discussed earlier in this report. From both a scientific\r\nand an operational viewpoint the claim that anomalous cognition\r\nexists is not very credible until we have ways to specify when\r\nand when it is not present. So far, parapsychology seems to have\r\nconcentrated only in finding ways to document the existence of\r\nanomalous cognition. The result is a patchwork quilt of markers\r\nthat, when present, are offered as evidence for the presence of\r\npsi. These markers or indicators include the decline effect,\r\nnegative hitting as well as positive hitting, displacement\r\nhitting, the incline effect, increased variability, decreased\r\nvariability and just about any other way a discrepancy from a\r\nprobability model can occur. A cynic will note that the absence\r\nof any or most of these markers is not used as evidence for the <i>absence\r\nof psi. </i>This lack of way to distinguish between the presence\r\nand absence of anomalous cognition creates many challenges for\r\nparapsychology, some of which I have already discussed.</p>\r\n\r\n<p>So, even if remote viewing is a real ability possessed by some\r\nindividuals, its usefulness for intelligence gathering is\r\nquestionable. If May is correct, then 80% of the all the\r\ninformation supplied by this talented viewer will be erroneous.\r\nWithout any way to tell which statements of the views are\r\nreliable and which are not, the use of this information may make\r\nmatters worse rather than better.</p>\r\n\r\n<p>Can remote viewing have utility for information gathering even\r\nif it cannot be scientifically validated? I can imagine some\r\npossibilities for remote viewing to be an asset to the\r\nintelligence analyst even when the viewer possesses no valid\r\nparanormal powers. The viewer might be a person of uncommonly\r\ngood sense or have a background that enables him or her to\r\nprovide helpful information even if it does not come from a\r\nparanormal source. Another possibility is that the viewer, even\r\nthough lacking in any truly accurate intelligence information,\r\nmight say things or open up new ways of dealing with the\r\nanalyst's problem. In this latter scenario the remote viewer is a\r\ncatalyst that may open up new ways of looking at an intelligence\r\nsituation much like programs for problem solving and creative\r\nthinking stimulate new ways of looking at a situation. However,\r\nif the usefulness of the remote viewer reduces to a matter of\r\ninjecting common sense or new perspectives into the situation, I\r\nbelieve that we can accomplish the same purpose in more efficient\r\nways.</p>\r\n\r\n<p>In considering potential utility, I am most concerned about\r\nseparation of the operational program in remote viewing from the\r\nresearch and development phase. By default, the assessment of the\r\nusefulness of the remote viewing in the operational arena is\r\ndecided entirely by subjective validation or what May and Utts\r\ncall <i>prima facie</i> evidence. Granted it is difficult to\r\nassess adequately the effectiveness of remote viewing in the\r\noperational domain. Nevertheless, better ways can be devised than\r\nhave apparently been used up to now. In our current attempt to\r\nget an initial idea about the effectiveness of the current\r\noperational use of remote viewing, we have simply been asking\r\nindividuals and agencies who have used the services of the remote\r\nviewers, if the information they received was accurate and\r\nuseful. Whatever information we get from this survey is extremely\r\nlimited for the purposes of judging the utility of remote viewing\r\nin the operational domain.</p>\r\n\r\n<p>Even psychologists who should know better underrate the power\r\nof subjective validation. Anyone who relies on <i>prima facie</i>\r\nevidence as a basis for affirming the validity of remote viewing\r\nshould carefully read that portion of Marks and Kamman's <i>The\r\nPsychology of the Psychic </i>[1981] in which they discuss the\r\nSRI and their own experiments on remote viewing. In the early\r\nstages of their attempt to replicate the SRI remote viewing\r\nexperiments, they were astonished at the high quality of their\r\nsubject's protocols and the apparent accuracy of the viewing.\r\nAfter each session, the experimenters and the subject (viewer)\r\nwould visit the target site and compare the verbal protocol with\r\nthe actual site. The specific details of the viewers' responses\r\nappeared to match specific objects in the target site with\r\nuncanny accuracy. When they gave the verbal protocols to the\r\njudge, a distinguished professor, to blindly match against the\r\nactual target sites, he was astonished at how well what he\r\nconsidered the closest matching protocol for each site matched\r\nactual details of the target. He had no doubt that the viewers\r\nhad demonstrated strong remote viewing abilities.</p>\r\n\r\n<p>So, both the viewers and the judge quickly became convinced of\r\nthe reality of remote viewing on the basis of the uncanny matches\r\nbetween the verbal descriptions and the actual target sites. The\r\nexperimenters received a rude awakening when they discovered\r\nthat, despite the striking matches observed between target and\r\nverbal description, the judge had matched the verbal protocols to\r\nthe wrong target sites. When all parties were given the results\r\nthe subjects could not understand how the judge could have\r\nmatched any but the actual target site to their descriptions. For\r\nthem the match was so obvious that it would be impossible for the\r\njudge to have missed it. The judge, on the other hand, could not\r\naccept that any but the matches he made could be paired with the\r\nactual target sites.</p>\r\n\r\n<p>This phenomenon of subjective validation is pervasive,\r\ncompelling and powerful. Psychologists have demonstrated it in a\r\nvariety of settings. I have demonstrated it and written about in\r\nthe context of the psychic reading. In the present context,\r\nsubjective validation comes about when a person evaluates the\r\nsimilarity between a relatively rich verbal description and an\r\nactual target or situation. Inevitably, many matches will be\r\nfound. Once the verbal description has been judged to be a good\r\nmatch to a given target, the description gets locked in and it\r\nbecomes virtually impossible for the judge to see the description\r\nas fitting any but the original target.</p>\r\n\r\n<p>Unfortunately, all the so-called<i> prima facie </i>evidence\r\nput before us is tainted by subjective validation. We are told\r\nthat the many details supplied by the viewers were indeed\r\ninaccurate. But some details were uncannily correct and even, in\r\none case, hidden code words were correctly revealed. Such\r\naccounts do indeed seem compelling. They have to be put in the\r\ncontext, however, of all such operational attempts. We have to\r\nknow the general background and expectations of the viewers, the\r\nquestioners, etc. Obviously, the targets selected for the viewers\r\nin the operational setting will have military and intelligence\r\nrelevance. If the viewer [some of the viewers have intelligence\r\nbackgrounds] suspects the general nature of the target, then\r\nprevious background knowledge might very well make the presence,\r\nsay of a gantry, highly likely. In addition, the interactions and\r\nquestioning of the viewers in these settings appear to be highly\r\nsuggestive and leading.</p>\r\n\r\n<p>I can imagine that the preceding paragraph might strike a\r\nreader as being unreasonable. Even allowing for subjective\r\nvalidation, the possibility that a viewer might accurately come\r\nup with secret code words and a detailed description of\r\nparticular gantry is quite remote on the basis of common sense\r\nand sophisticated guessing. I understand the complaint and I\r\nrealize the reluctance to dismiss such evidence out of hand.\r\nHowever, I have had experience with similarly compelling <i>prima\r\nfacie</i> evidence for more than a chance match between a\r\ndescription and a target. In the cases I have in mind, however,\r\nthe double blind controls were used to pair descriptions with the\r\ntrue as well as with the wrong target sites. In all these test\r\ncases with which I am familiar, the unwitting subjects found the\r\nmatches between their descriptions and the presumed target\r\nequally compelling regardless of whether the presumed target was\r\nthe actual or the wrong one.</p>\r\n\r\n<p>What this says about operational effectiveness, is that, for\r\nevaluation purposes, half of the time the viewers and the judges\r\nshould be mislead about the what was the actual target. In these\r\ncases, both the interrogator and the viewer, as well as the\r\njudge, have to be blind to the actual targets. Under such\r\nconditions, if the judges and the others find the matches between\r\nthe verbal descriptions and the actual targets consistently\r\nbetter than the matches between the verbal descriptions and the\r\ndecoy targets, then this would constitute some evidence for the\r\neffectiveness of remote viewing. I can confidently predict,\r\nregardless of the outcome of such an evaluation, that many of the\r\nverbal descriptions when matched with decoy targets will be\r\njudged to be uncanny matches.</p>\r\n\r\n<p>SUGGESTIONS: WHAT NEXT?</p>\r\n\r\n<p>I have played the devil's advocate in this report. I have\r\nargued that the case for the existence of anomalous cognition is\r\nstill shaky, at best. On the other hand, I want to state that I\r\nbelieve that the SAIC experiments as well as the contemporary\r\nganzfeld experiments display methodological and statistical\r\nsophistication well above previous parapsychological research.\r\nDespite better controls and careful use of statistical inference,\r\nthe investigators seem to be getting significant results that do\r\nnot appear to derive from the more obvious flaws of previous\r\nresearch. I have argued that this does not justify concluding\r\nthat anomalous cognition has been demonstrated. However, it does\r\nsuggest that it might be worthwhile to allocate some resources\r\ntoward seeing whether these findings can be independently\r\nreplicated. If so, then it will be time to reassess if it is\r\nworth pursuing the task of determining if these effects do indeed\r\nreflect the operation of anomalous cognition. This latter quest\r\nwill involve finding lawful relationships between attributes of\r\nthis hypothesized phenomenon and different independent variables.\r\nBoth the scientific and operational value of such an alleged\r\nphenomenon will depend upon how well the conditions for its\r\noccurrence can be specified and how well its functioning can be\r\nbrought under control.</p>\r\n\r\n<p>Both Professor Utts and I agree that the very first\r\nconsideration is to see if the SAIC remote viewing results will\r\nstill be significant when independent judges are used. I\r\nunderstand Ed May's desire to use a judge who is very familiar\r\nwith the response styles of the experienced viewers. However, if\r\nremote viewing is real, then conscientious judges, who are blind\r\nto the actual targets, should still be able to match the verbal\r\ndescriptions to the actual targets better than chance. If this\r\ncannot be done, the viability of the case for remote viewing\r\nbecomes problematical. On the other hand, assuming that\r\nindependent judges can match the descriptions to the correct\r\ntargets reasonably well, then it becomes worthwhile to try to\r\nindependently replicate the SAIC experiments.</p>\r\n\r\n<p>At this point we face some interesting questions. Should we\r\ntry to replicate the remote viewing studies by using the same\r\nviewers, the same targets, and the same protocol? Perhaps change\r\nonly the experimenters, the judge, and the laboratory? At some\r\npoint we would also want to change the targets. For completeness,\r\nwe would also want to search for new, talented viewers.</p>\r\n\r\n<p>If independent replications confirm the SAIC findings, we\r\nstill have a long way to go. However, at this stage in the\r\nproceedings, the scientific community at large might be willing\r\nto acknowledge that an anomaly of some sort has been\r\ndemonstrated. Before the scientific community will go beyond this\r\nacknowledgment, the parapsychologists will have to devise a\r\npositive theory of anomalous communication from which they can\r\nmake testable predictions about relationships between anomalous\r\ncommunication and other variables.</p>\r\n\r\n<p>CONCLUSIONS</p>\r\n\r\n<p>The Scientific Status of the SAIC Research Program</p>\r\n\r\n<p>1. The SAIC experiments on anomalous mental phenomena are\r\nstatistically and methodologically superior to the earlier SRI\r\nremote viewing research as well as to previous parapsychological\r\nstudies. In particular, the experiments avoided the major flaw of\r\nnon-independent trials for a given viewer. The investigators also\r\nmade sure to avoid the problems of multiple statistical testing\r\nthat was characteristic of much previous parapsychological\r\nresearch.</p>\r\n\r\n<p>2. From a scientific viewpoint, the SAIC program was hampered\r\nby its secrecy and the multiple demands placed upon it. The\r\nsecrecy kept the program from benefiting from the checks and\r\nbalances that comes from doing research in a public forum.\r\nScrutiny by peers and replication in other laboratories would\r\naccelerated the scientific contributions from the program. The\r\nmultiple demands placed on the program meant that too many things\r\nwere being investigated with too few resources. As a result, no\r\nparticular finding was followed up in sufficient detail to pin it\r\ndown scientifically. Ten experiments, no matter how well\r\nconducted, are insufficient to fully resolve one important\r\nquestion, let alone the several that were posed to the SAIC\r\ninvestigators.</p>\r\n\r\n<p>3. Although, I cannot point to any obvious flaws in the\r\nexperiments, the experimental program is too recent and\r\ninsufficiently evaluated to be sure that flaws and biases have\r\nbeen eliminated. Historically, each new paradigm in\r\nparapsychology has appeared to its designers and contemporary\r\ncritics as relatively flawless. Only subsequently did previously\r\nunrecognized drawbacks come to light. Just as new computer\r\nprograms require a shakedown period before hidden bugs come to\r\nlight, each new scientific program requires scrutiny over time in\r\nthe public arena before its defects emerge. Some possible sources\r\nof problems for the SAIC program are its reliance on experienced\r\nviewers, and the use of the same judge--one who is familiar to\r\nthe viewers, for all the remote viewing.</p>\r\n\r\n<p>4. The statistical departures from chance appear to be too\r\nlarge and consistent to attribute to statistical flukes of any\r\nsort. Although I cannot dismiss the possibility that these\r\nrejections of the null hypothesis might reflect limitations in\r\nthe statistical model as an approximation of the experimental\r\nsituation, I tend to agree with Professor Utts that real effects\r\nare occurring in these experiments. <i>Something</i> other than\r\nchance departures from the null hypothesis has occurred in these\r\nexperiments.</p>\r\n\r\n<p>5. However, the occurrence of statistical effects does not\r\nwarrant the conclusion that psychic functioning has been\r\ndemonstrated. Significant departures from the null hypothesis can\r\noccur for several reasons. Without a positive theory of anomalous\r\ncognition, we cannot say that these effects are due to a single\r\ncause, let alone claim they reflect anomalous cognition. We do\r\nnot yet know how replicable these results will be, especially in\r\nterms of showing consistent relations to other variables. The\r\ninvestigators report findings that they believe show that the\r\ndegree of anomalous cognition varies with target entropy and the\r\n`bandwidth' of the target set. These findings are preliminary and\r\nonly suggestive at this time. Parapsychologists, in the past,\r\nhave reported finding other correlates of psychic functioning\r\nsuch as extroversion, sheep/goats, altered states only to find\r\nthat later studies could not replicate them.</p>\r\n\r\n<p>6. Professor Utts and the investigators point to what they see\r\nas consistencies between the outcome of contemporary ganzfeld\r\nexperiments and the SAIC results. The major consistency is\r\nsimilarity of average effect sizes across experiments. Such\r\nconsistency is problematical because these average effect sizes,\r\nin each case, are the result of arbitrary combinations from\r\ndifferent investigators and conditions. None of these averages\r\ncan be justified as estimating a meaningful parameter. Effect\r\nsize, by itself, says nothing about its origin. Where\r\nparapsychologists see consistency, I see inconsistency. The\r\nganzfeld studies are premised on the idea that viewers must be in\r\naltered state for successful results. The remote viewing studies\r\nuse viewers in a normal state. The ganzfeld experimenters believe\r\nthat the viewers should judge the match between their ideation\r\nand the target for best results; the remote viewers believe that\r\nindependent judges provide better evidence for psi than viewers\r\njudging their own responses. The recent autoganzfeld studies\r\nfound successful hitting only with dynamic targets and only\r\nchance results with static targets. The SAIC investigators, in\r\none study, found hitting with static targets and not with dynamic\r\nones. In a subsequent study they found hitting for both types of\r\ntargets. They suggest that they may have solution to this\r\napparent inconsistency in terms of their concept of bandwidth. At\r\nthis time, this is only suggestive.</p>\r\n\r\n<p>7. The challenge to parapsychology, if it hopes to\r\nconvincingly claim the discovery of anomalous cognition, is to go\r\nbeyond the demonstration of significant effects. The\r\nparapsychologists need to achieve the ability to specify\r\nconditions under which one can reliably witness their alleged\r\nphenomenon. They have to show that they can generate lawful\r\nrelationships between attributes of this alleged phenomenon and\r\nindependent variables. They have to be able to specify boundary\r\nconditions that will enable us to detect when anomalous cognition\r\nis and <i>is not</i> present.</p>\r\n\r\n<p>Suggestions for Future Research</p>\r\n\r\n<p>1. Both Professor Utts and I agree that the first step should\r\nbe to have the SAIC protocols rejudged by independent judges who\r\nare blind to the actual target.</p>\r\n\r\n<p>2. Assuming that such independent judging confirms the\r\nextra-chance matchings, the findings should be replicated in\r\nindependent laboratories. Replication could take several forms.\r\nSome of the original viewers from the SAIC experiments could be\r\nused. However, it seems desirable to use a new target set and\r\nseveral independent judges.</p>\r\n\r\n<p>Operational Implications</p>\r\n\r\n<p>1. The current default assessment of the operational\r\neffectiveness of remote viewing is fraught with hazards.\r\nSubjective validation is well known to generate compelling, but\r\nfalse, convictions that a description matches a target in\r\nstriking ways. Better, double blind, ways of assessing\r\noperational effectiveness can be used. I suggest at least one way\r\nin the report.</p>\r\n\r\n<p>2. The ultimate assessment of the potential utility of remote\r\nviewing for intelligence gathering cannot be separated from the\r\nfindings of laboratory research.</p>\r\n\r\n<p>------------------</p>\r\n\r\n<p>(1) The SAIC did benefit from the input of a distinguished\r\noversight committee. But this still falls far short of what could\r\nhave taken place in an open forum.</p>\r\n\r\n<p>[End]</p>\r\n\r\n<hr>\r\n\r\n<p align=\"center\"><font face=\"Verdana\"><strong>Back to\r\nmceagle.com </strong></font><a\r\nhref=\"http://www.mceagle.com/remote-viewing/refs/\"><font\r\nface=\"Verdana\"><strong>References</strong></font></a></p>\r\n</body>\r\n</html>\r\n", "encoding": "ISO-8859-1"}