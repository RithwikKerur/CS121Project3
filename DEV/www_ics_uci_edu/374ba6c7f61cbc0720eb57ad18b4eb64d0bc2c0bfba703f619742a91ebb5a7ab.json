{"url": "https://www.ics.uci.edu/~pattis/ICS-46/lectures/notes/sorting3.txt", "content": "\t\t\tSorting: O(N) Sorting without Comparisons\r\n\r\n\r\nIn this lecture, we will examine two sorting methods that do NOT use\r\ncomparisons between values to sort the data. So, they are not constrained\r\nby the lower bound proved in the previous lecture. The algorithms are called\r\nBucket Sort and Radix Sort. Both are a bit strange; they work well for integers\r\n(and Radix Sort for Strings) but don't work well for other kinds of data (e.g.,\r\nanything that is not \"digital\", in the same sense as a digital tree).\r\n\r\n\r\nBucket Sort:\r\n\r\nBucket Sort allows us to sort N data values, where each lies in the range 0-M\r\nin time O(N+M). Note that if we don't know the range of integers, we can scan\r\nthe array first, to find the smallest and biggest one, and scale everything\r\nbetween those two values: scan the array (O(N)) to find S, the smallest value\r\nand B, the biggest value, scan it again (O(N)) subtracting S from every value\r\n(the range will be 0 to B-S), then sort these values using Bucket Sort (using an\r\narray of B-S+1 elements), then scan it a final time (O(N)) adding S to every\r\nvalue. The scaling and unscaling processes are each O(N) (adding three O(N)\r\npasses to the data: more time but the same complexity class).\r\n\r\nWe will analyze a few problems with various sizes of N and M below, to get a\r\nbetter understanding of what O(N+M) means.\r\n\r\nFor a first example, suppose that we needed to sort 1,000 exam scores, all in\r\nthe range 0 to 100 (so N = 1,000 and M = 100).\r\n\r\nFirst, here is the psuedo-code for this algorithm. It uses an array much like\r\na histogram (keeping track of the number of times a specific data value is\r\nseen in the array to be sorted).\r\n\r\n  1) Declare an int histogram array with indexes/buckets 0 to 100 and \r\n     initialize each to 0 (there has been 0 of each index value seen so far).\r\n\r\n  2) Look at every data value in the array to sort, and increment by 1 the \r\n     index (specified by that data value) in the histogram array. So, if 78 was\r\n     the next data value in the array to sort, increment the histogram array at\r\n     index 78.\r\n\r\n  3) Scan the entire histogram array from 0 to 100; whenever we get to an index\r\n     that stores c (with c != 0), put c values of that index into the next\r\n     positions in the array to sort (starting from the beginning, replacing the\r\n     values already in the array).\r\n     \r\nStep 1 is O(M), based only on the range of values (number of 0s we need to\r\nstore in the array indexes) and not on N, the number of values to sort.\r\n\r\nStep 2 is O(N), based only on the number of values to sort, not the range of\r\nvalues. For each of the N values, we can access index i in an array in O(1)\r\ntime to increment it. \r\n\r\nStep 3 is O(N+M), based both on N, the number of values to sort (since we are\r\nputting each into the sorted array), and M, the range of values (since we must\r\nscan through each bucket, whether or not it contains a values != 0).\r\n\r\nLooking at raw numbers, Step 1 requires 100 operations, Step 2 requires 1,000\r\noperations, and Step 3 requires 1,100 operations (so the total operations is\r\nabout 2,200). If we just sorted the array using an O(N Log2 N) algorithm (with\r\na constant of 1), it would require about 10,000 operations. So here bucket sort\r\nlooks pretty good, by a factor of 5 (although the concept of \"operations\" is a\r\nbit fuzzy here).\r\n\r\nFor a second example, suppose that we needed to sort 1,000,000 values from 0\r\nup to 1 billion (so N = 1,000,000 and M = 1,000,000,000). Here N << M (N is\r\nmuch less than M, by a factor of 1,000). We would\r\n\r\n  1) Declare an int histogram array with indexes 0 to 1 billion and initialize\r\n     it to 0 (0 of each index value seen so far).\r\n\r\n  2) Look at every value in the array to sort, and increment by 1 the index\r\n     (specified by that data value) in the histogram array. So, if 157,000,000\r\n     was the next value in the array to sort, increment the histogram array at\r\n     index 157,000,000.\r\n\r\n  3) Scan the entire histogram array from 0 to 1 billion; whenever you get to\r\n     an index that stores c (!= 0) put c values of that index into the next\r\n     position in the array to sort (starting from the beginning, replacing the\r\n     values already in the array).\r\n     \r\nLooking at raw numbers, Step 1 requires 1,000,000,000 operations, Step 2\r\nrequires 1,000,0000 operations, and Step 3 requires 1,001,000,000 operations\r\n(for a total of about 2,002,000,000 operations). If we just sorted the array\r\nusing an O(N Log2 N) algorithm (with a constant of 1), it would require about\r\n20,000,000 operations. So here bucket sort looks pretty bad, by a factor of 100.\r\nNote we are doing a tremendous number of operations to scan buckets that are\r\nlikely empty (a maximum of 1 in 1,000 buckes is non-0, achieved when every\r\nvalue in the array to sort is different; with duplicate values fewer buckets\r\nare non-0).\r\n\r\nIf we have to sort very many numbers in a very small range (or even billions of\r\nnumbers in the full int range: any time M<<N), then Bucket Sort would be more\r\nefficient than comparision-based sorting. But if the range of possible values\r\nis very big compared to the number of values to sort (N<<M), comparison-based\r\nsorting would probably be faster.\r\n\r\nAlso, this method doesn't work well for Strings of even moderate size. If we\r\nconverted each String of lower-case letters to an int to solve this problem,\r\nnote that there are 26^N different String of N values: and, 26^7 is already\r\nover 8 billion (so M is very big even for 7-character Strings).\r\n\r\n\r\nRadix Sort:\r\n\r\nFinally, we will examine Radix Sort. It repeatedly does something like Bucket\r\nSort, but always ensuring that M<<N, so the bucket sorts are effective. It is\r\napplicable when we sort numeric values that can be broken into pieces (the\r\ndigits in a number) where the \"significance\" of the pieces will be processed\r\nfrom least to most significant, using a stable algorithm.\r\n\r\nSo, Radix Sort works by repeatedly doing something like a Bucket Sort in the\r\ncases where Bucket Sort is efficient: sorting a large number of values each of\r\nwhich has a small range (say, sorting many numbers by one of their digits,\r\nwhere the range for each digit is 0-9).\r\n\r\nGenerally, suppose that we need to sort N positive int values. Numbers in the\r\nrange 0 to 1.5 billion have a most 10 digits (Log10 1.5 billion ~ 9.2). Here is\r\nthe psuedo-code for radix sorting.\r\n\r\nCreate an array of 10 buckets, each storing an empty queue\r\nfor every \"place\" (for 10 digits: 1s, 10s, 100s, 1,000s, ... 1,000,000,000s)\r\n  for every value in the array to sort\r\n    add it at the end of the queue in the correct bucket, according to the\r\n      digit in the current \"place\"\r\n  for every bucket (in order from 0 to 9)\r\n    move all the values in this queue back into the array to sort, left to\r\n    right in the array (leaving the queue empty)\r\n\r\nFor the first \"place\" (1s), the numbers will be sorted by their last digit\r\nonly. For the second \"place\" (10s), the numbers will be sorted by their next\r\ndigit: really their last two digits (because of the \"stability\" property of the\r\nqueue).... For the last \"place\" (1,000,000,000) the numbers will be sorted by\r\nall their digits. \r\n\r\nNote that each iteration is taking a result (sorted by all the lower places)\r\nand extending it to the current \"place\". Because we are using a stable\r\nmechanism (copying from the queues back into the array), all numbers with an\r\nequal digit in \"place\" are kept in the same order: already sorted by all the \r\nfollowing digits/places.\r\n\r\nLet's do a quick example, with much more restricted numbers. Let's use Radix\r\nSort to sort the following 10, three digit numbers (so we require three\r\npasses, with the places 1s, 10s, and 100s).\r\n\r\n  664, 947, 654, 305, 565, 424, 517, 252, 223, 326\r\n\r\nIn the pictures below, the queues go downward from each bucket (takes less\r\nspace in the pictures). First, we start with the 1s \"place\" and get\r\n\r\n    0   1   2   3   4   5   6   7   8   9\r\n  +---+---+---+---+---+---+---+---+---+---+\r\n  |   |   |   |   |   |   |   |   |   |   |\r\n  +---+---+---+---+---+---+---+---+---+---+\r\n           252 223 664 305 326 947     \r\n                   654 565     517            \r\n                   424                     \r\n\r\nNotice that each number is in the bucket based on its 1s \"place\": xx2, xx3,\r\nxx4, xx4, xx4, xx5, etc. The order the values appear in each queue is the order\r\nthey  appeared in the original aray scanned left to right: 664, 654, adn 424.\r\n\r\nThen we put these values back into the array, from buckets 0-9 (in that order),\r\nremoving each value from its queue. Notice that all numbers are sorted by their\r\nlast digits, but not any others. If their last digits are the same, their order\r\nis the same order as they appeared in the input array (e.g., 664, 654, and 424).\r\n\r\n  252, 223, 664, 654, 424, 305, 565, 326, 947, 517, \r\n\r\nThen, we continue doing the same process on this new array with the 10s\r\n\"place\" and get\r\n\r\n    0   1   2   3   4   5   6   7   8   9\r\n  +---+---+---+---+---+---+---+---+---+---+\r\n  |   |   |   |   |   |   |   |   |   |   |\r\n  +---+---+---+---+---+---+---+---+---+---+\r\n   305 517 223     947 252 664                \r\n           424         654 565\r\n           326                             \r\n\r\nNotice that each number is in the bucket based on its 10s \"place\": x0x, x1x,\r\nx2x, x2x, x2x, etc.\r\n\r\nThen we put these values back into the array, from buckets 0-9 (in that order),\r\nremoving each value from its queue. Notice that all numbers are sorted by their\r\nlast two digits. If their second to last digits are the same, their order is\r\nthe same order as they appeared in the input array, which was sorted on the\r\nlast digit (e.g., 223, 424, and 326) so now it is sorted on the last two digits.\r\n\r\n  305, 517, 223, 424, 326, 947, 252, 654, 664, 565\r\n                                           \r\nThen, we continue doing the same process on this new array with the 100s\r\n\"place\" (for these numbers, the most significant \"place\" and the final\r\niteration) and get\r\n\r\n    0   1   2   3   4   5   6   7   8   9\r\n  +---+---+---+---+---+---+---+---+---+---+\r\n  |   |   |   |   |   |   |   |   |   |   |\r\n  +---+---+---+---+---+---+---+---+---+---+\r\n           223 305 424 517 654         947\r\n           252 326     565 664             \r\n                                           \r\nNotice that each number is in the bucket based on its 100s \"place\" (the most\r\nsignificant one): 2xx, 2xx, 3xx, 3xx, 4xx, etc.\r\n\r\nThen we put these values back into the array, from buckets 0-9 (in that order),\r\nremoving each value from its queue. Notice that all numbers are sorted by all\r\ntheir digits.  If all their digits are the same, their order is the same order\r\nas they appeared in the input array.\r\n\r\n  223, 242, 305, 326, 424, 517, 565, 654, 664, 947\r\n         \r\nSo, this sorting mechanism requires O(N) extra space (the sum of the space\r\noccupied by all the queues is N and the original array is N) and it is stable.\r\nActually, if we are using a queue implementation that doesn't shrink its storage\r\nwhen values are dequeued (ArrayQueue and LinkedQueue do shrink) then the\r\nspace occupied by all the queues could be much worse than 2N, it could be MN\r\n(or 10N, since M is 10 here), with each queue expanding to fit all its values\r\n(sorting 10 equal numbers, each 1,234,567,890 will require 10 values in each of\r\nthe 10 queues).\r\n\r\nRadix Sort's running time is based on the following: inside the outer loop, we\r\ndo N operations to move the N values from the array into their correct queues\r\n(each queue operation is O(1)), and then do N more operations to transfer from\r\nthe queues back to the array. But we must multiply this operation count by the\r\nnumber of outer loop iterations (which we will analyze below).\r\n\r\nIf there are N distinct numbers to sort, say the integers 1-N, then the biggest\r\nnumber is N, and it has Log10 N digits, so the outer loop executes Log10 N\r\ntimes and the total complexity is O(N Log10 N). Does the base of the logarithm\r\nmake difference for complexity classes? Mathematically no, because Log10 N =\r\nLog2 N/Log2 10, and Log2 10 is just a constant that is absorbed by the big-O\r\nnotation we use for complexity classes. Of course, the actual running time\r\ndepends on this constant.\r\n\r\nThis argument says that we really can just write Log (without any base)\r\nin all our complexity classes, because different Logs, regardless of their\r\nbases, are only constant multiples of each other.\r\n\r\nThus, we characterize Radix Sort as \r\n  1) Worst case is O(N Log10 N)\r\n  2) Requires O(N) extra storage for the queues at any time\r\n  3) No comparisons; O(N Log10 N) data movements in all cases\r\n  4) Stable\r\n\r\nInstead of choosing a radix of 10, we can choose a radix of 100. With this\r\nchoice, we have 100 buckets and we first sort by the last two digits (1s and\r\n10s), then the next two (100s and 1,000s), etc. Here we tradeoff space (10\r\ntimes as much space in the buckets, which is still much less than the space\r\ntaken up by the numbers to sort) against loop iterations (1/2 as many). Now\r\nthe worst case running time is O(N Log100 N) - using logarithms base 100, which\r\nrequires half the iterations in the outer loop.\r\n\r\nIf we keep increasing the number of digits \"sorted\" by, eventually we get to\r\nsomething like bucket sort: the number of buckets is the same as the range of\r\nthe numbers being sorted, and each queue stores only one value (the number of\r\ntimes it apears in the array to be sorted). So, Radix Sort works well only when\r\nthere are many values in each bucket.\r\n\r\nWe could also just use 2 queues, and think of every number being sorted in its\r\nbinary form (57 is 111001). This would require first sorting by the 1s place, \r\nthen the 2s place, then the 4s place, etc. The outer loop execute Log2 N for\r\nsorting integers in the range 1-N, one bit at a time.\r\n\r\nThis method works for \"digital\" keys: keys that can be broken into \"digits\",\r\nlike integers and Strings (just as we did for storing/retrieving information in\r\n\"digital trees\"). For String Radix Sort we can use a # of buckets equal to the\r\nnumber of possible ASCII characters (128 works for English characters). Note\r\nthat the number of iterations in the outer loop is equal to the length of the\r\nlongest String, so this method works best if all the Strings are about the\r\nsame length.\r\n\r\nIn the next quiz you will implement Radix Sort (easy to do given any simple\r\nqueue implementation). When I put this unsophisticated code into my sorting\r\ntester, I found that Radix Sort using Radix 10 (on a random array of 1,000,000)\r\ntook a bit longert than Mergesort (which is also stable) and Heapsort. Quicksort\r\nstill beats them all (although it is unstable, unlike Mergesort and Radix Sort).\r\nWhen I made the radix larger (100, 1000, ...), I got close to the quicksort\r\ntime, but radix sort still never quite ran as fast for the biggest-sized arrays\r\nI could test (although slower, unlike quicksort it is stable but not in place).\r\nI didn't spend time trying to optimize the Queue implementation, which might be\r\naccounting for some of its slowness.\r\n\r\n\r\nSome real numbers for sorting:\r\n\r\nI ran this on my home computer. I generated 3 arrays (storing Integer wrapper\r\nclass values) of length N and called each sorting method 5 times. The results\r\nhere are the averages.\r\n\r\n\r\n     N\t   Selection   Insertion   Heap   Merge   Quick   Radix10   Radix1000\r\n----------+----------+-----------+------+-------+-------+---------+----------+\r\n    10,000|   .454   |   .287    |  *   |  *    |   *   |    *    |    *     |\r\n----------+----------+-----------+------+-------+-------+---------+----------+\r\n   100,000| 47.0     | 27.4      | .059 | .050  | .031  |  .093   | .045     |\r\n----------+----------+-----------+------+-------+-------+---------+----------+\r\n 1,000,000|   +      |   +       |1.359 | .890  | .478  | 1.411   | .695     |\r\n----------+----------+-----------+------+-------+-------+---------+----------+\r\n             U,I           S,I      U,I    S,N     U,I     S,N        S,N\r\n\r\n*   = Cannot be timed: <.001 seconds\r\n+   = Not timed      : > 1 minute\r\nU/S = Unstable/Stable\r\nI/N = In place (requires < O(N) more space: O(1) or O(Log N))/Not in place\r\n\r\nFor more details, look at the Wikipedia article on Sorting Algorithms:\r\n\r\nhttp://en.wikipedia.org/wiki/Sorting_algorithm\r\n", "encoding": "ascii"}