{"url": "https://www.ics.uci.edu/~majumder/VC/211HW3/vlfeat/doc/overview/covdet.html", "content": "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n   <html xmlns=\"http://www.w3.org/1999/xhtml\">\n <head>\n  <!-- IE Standards Mode -->\n  <meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"></meta>\n\n  <!-- Favicon -->\n  <link href=\"../images/vl_blue.ico\" type=\"image/x-icon\" rel=\"icon\"></link>\n  <link href=\"../images/vl_blue.ico\" type=\"image/x-icon\" rel=\"shortcut icon\"></link>\n\n  <!-- Page title -->\n  <title>VLFeat - Tutorials > Covariant feature detectors</title>\n\n  <!-- Stylesheets -->\n  <link href=\"../vlfeat.css\" type=\"text/css\" rel=\"stylesheet\"></link>\n  <link href=\"../pygmentize.css\" type=\"text/css\" rel=\"stylesheet\"></link>\n  <style xml:space=\"preserve\">\n    /* fixes a conflict between Pygmentize and MathJax */\n    .MathJax .mo, .MathJax .mi {color: inherit ! important}\n  </style>\n  \n\n  <!-- Scripts-->\n  \n\n  <!-- MathJax -->\n  <script xml:space=\"preserve\" type=\"text/x-mathjax-config\">\n    MathJax.Hub.Config({\n    tex2jax: {\n      inlineMath: [ ['$','$'], ['\\\\(','\\\\)'] ],\n      processEscapes: true,\n    },\n    TeX: {\n      Macros: {\n        balpha: '\\\\boldsymbol{\\\\alpha}',\n        bc: '\\\\mathbf{c}',\n        be: '\\\\mathbf{e}',\n        bg: '\\\\mathbf{g}',\n        bq: '\\\\mathbf{q}',\n        bu: '\\\\mathbf{u}',\n        bv: '\\\\mathbf{v}',\n        bw: '\\\\mathbf{w}',\n        bx: '\\\\mathbf{x}',\n        by: '\\\\mathbf{y}',\n        bz: '\\\\mathbf{z}',\n        bsigma: '\\\\mathbf{\\\\sigma}',\n        sign: '\\\\operatorname{sign}',\n        diag: '\\\\operatorname{diag}',\n        real: '\\\\mathbb{R}',\n      },\n      equationNumbers: { autoNumber: 'AMS' }\n      }\n    });\n  </script>\n  <script src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\" xml:space=\"preserve\" type=\"text/javascript\"></script>\n\n  <!-- Google Custom Search -->\n  <script xml:space=\"preserve\">\n    (function() {\n    var cx = '003215582122030917471:oq23albfeam';\n    var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;\n    gcse.src = (document.location.protocol == 'https' ? 'https:' : 'http:') +\n    '//www.google.com/cse/cse.js?cx=' + cx;\n    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);\n    })();\n  </script>\n\n  <!-- Google Analytics -->\n  <script xml:space=\"preserve\" type=\"text/javascript\">\n    var _gaq = _gaq || [];\n    _gaq.push(['_setAccount', 'UA-4936091-2']);\n    _gaq.push(['_trackPageview']);\n    (function() {\n    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;\n    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';\n    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);\n    })();\n  </script>\n </head>\n\n <!-- Body Start -->\n <body>\n  <div id=\"header-section\">\n    <div id=\"header\">\n      <!-- Google CSE Search Box -->\n      <div class=\"searchbox\">\n        <gcse:searchbox-only autoCompleteMaxCompletions=\"5\" autoCompleteMatchType=\"any\" resultsUrl=\"http://www.vlfeat.org/search.html\"></gcse:searchbox-only>\n      </div>\n      <h1 id=\"id-16\"><a shape=\"rect\" href=\"../index.html\" class=\"plain\"><span id=\"vlfeat\">VLFeat</span><span id=\"dotorg\">.org</span></a></h1>\n    </div>\n    <div id=\"sidebar\"> <!-- Navigation Start -->\n      <ul>\n<li><a href=\"../index.html\">Home</a>\n<ul>\n<li><a href=\"../about.html\">About</a>\n</li>\n<li><a href=\"../license.html\">License</a>\n</li>\n</ul></li>\n<li><a href=\"../download.html\">Download</a>\n<ul>\n<li><a href=\"../install-matlab.html\">Using from MATLAB</a>\n</li>\n<li><a href=\"../install-octave.html\">Using from Octave</a>\n</li>\n<li><a href=\"../install-shell.html\">Using from the command line</a>\n</li>\n<li><a href=\"../install-c.html\">Using from C</a>\n<ul>\n<li><a href=\"../xcode.html\">Xcode</a>\n</li>\n<li><a href=\"../vsexpress.html\">Visual C++</a>\n</li>\n<li><a href=\"../gcc.html\">g++</a>\n</li>\n</ul></li>\n<li><a href=\"../compiling.html\">Compiling</a>\n<ul>\n<li><a href=\"../compiling-unix.html\">Compiling on UNIX-like platforms</a>\n</li>\n<li><a href=\"../compiling-windows.html\">Compiling on Windows</a>\n</li>\n</ul></li>\n</ul></li>\n<li class='active'><a href=\"tut.html\">Tutorials</a>\n<ul>\n<li><a href=\"frame.html\">Local feature frames</a>\n</li>\n<li class='active' class='activeLeaf'><a href=\"covdet.html\">Covariant feature detectors</a>\n</li>\n<li><a href=\"hog.html\">HOG features</a>\n</li>\n<li><a href=\"sift.html\">SIFT detector and descriptor</a>\n</li>\n<li><a href=\"dsift.html\">Dense SIFT</a>\n</li>\n<li><a href=\"liop.html\">LIOP local descriptor</a>\n</li>\n<li><a href=\"mser.html\">MSER feature detector</a>\n</li>\n<li><a href=\"imdisttf.html\">Distance transform</a>\n</li>\n<li><a href=\"encodings.html\">Fisher Vector and VLAD</a>\n</li>\n<li><a href=\"gmm.html\">Gaussian Mixture Models</a>\n</li>\n<li><a href=\"kmeans.html\">K-means clustering</a>\n</li>\n<li><a href=\"aib.html\">Agglomerative Infromation Bottleneck</a>\n</li>\n<li><a href=\"quickshift.html\">Quick shift superpixels</a>\n</li>\n<li><a href=\"slic.html\">SLIC superpixels</a>\n</li>\n<li><a href=\"svm.html#tut.svm\">Support Vector Machines (SVMs)</a>\n</li>\n<li><a href=\"kdtree.html\">KD-trees and forests</a>\n</li>\n<li><a href=\"plots-rank.html\">Plotting AP and ROC curves</a>\n</li>\n<li><a href=\"utils.html\">Miscellaneous utilities</a>\n</li>\n<li><a href=\"ikm.html\">Integer K-means</a>\n</li>\n<li><a href=\"hikm.html\">Hierarchical integer k-means</a>\n</li>\n</ul></li>\n<li><a href=\"../applications/apps.html\">Applications</a>\n</li>\n<li><a href=\"../doc.html\">Documentation</a>\n<ul>\n<li><a href=\"../matlab/matlab.html\">MATLAB API</a>\n</li>\n<li><a href=\"../api/index.html\">C API</a>\n</li>\n<li><a href=\"../man/man.html\">Man pages</a>\n<ul>\n<li><a href=\"../man/mser.html\">mser</a>\n</li>\n<li><a href=\"../man/sift.html\">sift</a>\n</li>\n<li><a href=\"../man/vlfeat.html\">vlfeat</a>\n</li>\n</ul></li>\n</ul></li>\n</ul>\n\n    </div> <!-- sidebar -->\n  </div>\n  <div id=\"headbanner-section\">\n    <div id=\"headbanner\">\n      <span class='page'><a href=\"tut.html\">Tutorials</a></span><span class='separator'>></span><span class='page'><a href=\"covdet.html\">Covariant feature detectors</a></span>\n    </div>\n  </div>\n  <div id=\"content-section\">\n    <div id=\"content-wrapper\">\n      <div id=\"content\">\n        \n    \n\n<div class='toc'>\n<h3>Table of Contents</h3><ul><li class=\"level1\"><a href=\"#tut.covdet.extract\">Extracting frames and descriptors</a></li>\n<li class=\"level1\"><a href=\"#tut.covdet.frames\">Understanding feature frames</a></li>\n<li class=\"level1\"><a href=\"#tut.covdet.affine\">Affine adaptation</a></li>\n<li class=\"level1\"><a href=\"#tut.covdet.ori\">Feature orientation</a></li>\n<li class=\"level1\"><a href=\"#tut.covdet.descr\">Computing descriptors</a></li>\n<li class=\"level1\"><a href=\"#tut.covdet.custom\">Custom frames</a></li>\n<li class=\"level1\"><a href=\"#tut.covdet.ss\">Getting the scale spaces</a></li>\n</ul>\n</div><!-- Table of contents -->\n\n\n<p>This tutorial introduces the <code/><a href=../matlab/vl_covdet.html>vl_covdet</a></code> VLFeat command\nimplementing a number of co-variant feature detectors and\ncorresponding descriptors. This family of detectors\ninclude <a shape=\"rect\" href=\"../api/sift.html\">SIFT</a> as well as multi-scale conern\n(Harris-Laplace), and blob (Hessian-Laplace and Hessian-Hessian)\ndetectors. For example applications, see also\nthe <a shape=\"rect\" href=\"sift.html\">SIFT tutorial</a>.</p>\n\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n<h1 id=\"tut.covdet.extract\">Extracting frames and descriptors</h1>\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n\n<p>The first example shows how to\nuse <code/><a href=../matlab/vl_covdet.html>vl_covdet</a></code> to compute\nand visualize co-variant features. Fist, let us load an example image\nand visualize it:</p>\n\n<div style=\"clear:both;\">\n<div class=\"highlight\"><pre><span class=\"n\">im</span> <span class=\"p\">=</span> <span class=\"n\">vl_impattern</span><span class=\"p\">(</span><span class=\"s\">&#39;roofs1&#39;</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n<span class=\"n\">figure</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">)</span> <span class=\"p\">;</span> <span class=\"n\">clf</span> <span class=\"p\">;</span>\n<span class=\"n\">image</span><span class=\"p\">(</span><span class=\"n\">im</span><span class=\"p\">)</span> <span class=\"p\">;</span> <span class=\"n\">axis</span> <span class=\"n\">image</span> <span class=\"n\">off</span> <span class=\"p\">;</span>\n</pre></div>\n\n</div>\n\n<div class=\"figure\">\n <img src=\"../demo/covdet_basic_image.jpg\"></img>\n <div class=\"caption\">\n  <span class=\"content\">\n   An example input image.\n  </span>\n </div>\n</div>\n\n<p>The image must be converted to gray=scale and single precision. Then\n<code/><a href=../matlab/vl_covdet.html>vl_covdet</a></code> can be called in order to extract features (by\ndefault this uses the DoG cornerness measure, similarly to SIFT).</p>\n\n<div class=\"highlight\"><pre><span class=\"n\">imgs</span> <span class=\"p\">=</span> <span class=\"n\">im2single</span><span class=\"p\">(</span><span class=\"n\">rgb2gray</span><span class=\"p\">(</span><span class=\"n\">im</span><span class=\"p\">))</span> <span class=\"p\">;</span>\n<span class=\"n\">frames</span> <span class=\"p\">=</span> <span class=\"n\">vl_covdet</span><span class=\"p\">(</span><span class=\"n\">imgs</span><span class=\"p\">,</span> <span class=\"s\">&#39;verbose&#39;</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p>The <code/>verbose</code> option is not necessary, but it produces\nsome useful information:</p>\n\n<pre>\nvl_covdet: doubling image: yes\nvl_covdet: detector: DoG\nvl_covdet: peak threshold: 0.01, edge threshold: 10\nvl_covdet: detected 3518 features\nvl_covdet: kept 3413 inside the boundary margin (2)\n</pre>\n\n<p>The <code/><a href=../matlab/vl_plotframe.html>vl_plotframe</a></code> command can then be used to plot\nthese features</p>\n\n<div class=\"highlight\"><pre><span class=\"n\">hold</span> <span class=\"n\">on</span> <span class=\"p\">;</span>\n<span class=\"n\">vl_plotframe</span><span class=\"p\">(</span><span class=\"n\">frames</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p>which results in the image</p>\n\n<div class=\"figure\">\n <img src=\"../demo/covdet_basic_frames.jpg\"></img>\n <div class=\"caption\">\n  <span class=\"content\">\n   The default features detected by <code/><a href=../matlab/vl_covdet.html>vl_covdet</a></code> use the DoG\n   cornerness measure (like SIFT).\n  </span>\n </div>\n</div>\n\n<p>In addition to the DoG detector, <code/><a href=../matlab/vl_covdet.html>vl_covdet</a></code> supports a\nnumber of other ones:</p>\n\n<ul>\n<li>The <em>Difference of Gaussian operator</em> (also known\nas <em>trace of the Hessian operator</em> or <em>Laplacian\noperator</em>) uses the local extrema trace of the multiscale Laplacian\noperator to detect features in scale and space (as in SIFT).</li>\n\n<li>The <em>Hessian operator</em> uses the local extrema of the\nmutli-scale determinant of Hessian operator.</li>\n\n<li>The <em>Hessian Laplace</em> detector uses the extrema of the\nmultiscale determinant of Hessian operator for localisation in space,\nand the extrema of the multiscale Laplacian operator for localisation\nin scale.</li>\n\n<li><em>Harris Laplace</em> uses the multiscale Harris cornerness\nmeasure instead of the determinant of the Hessian for localization in\nspace, and is otherwise identical to the previous detector..</li>\n\n<li><em>Hessian Multiscale</em> detects features spatially at multiple\nscales by using the multiscale determinant of Hessian operator, but\ndoes not attempt to estimate their scale.</li>\n\n<li><em>Harris Multiscale</em> is like the previous one, but uses the\nmultiscale Harris measure instead.</li>\n</ul>\n\n<p>For example, to use the Hessian-Laplace operator instead of DoG,\nuse the code:</p>\n\n<div class=\"highlight\"><pre><span class=\"n\">frames</span> <span class=\"p\">=</span> <span class=\"n\">vl_covdet</span><span class=\"p\">(</span><span class=\"n\">imgs</span><span class=\"p\">,</span> <span class=\"s\">&#39;method&#39;</span><span class=\"p\">,</span> <span class=\"s\">&#39;HarrisLaplace&#39;</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p>The following figure shows example of the output of these\ndetectors:</p>\n\n<div class=\"figure\">\n <img src=\"../demo/covdet_detectors.jpg\"></img>\n <div class=\"caption\">\n  <span class=\"content\">\n    Different detectors can produce a fairly different set of\n    features.\n  </span>\n </div>\n</div>\n\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n<h1 id=\"tut.covdet.frames\">Understanding feature frames</h1>\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n\n<p>To understand the rest of the tutorial, it is important to\nunderstand the geometric meaning of a feature <em>frame</em>. Features\ncomputed by <code/><a href=../matlab/vl_covdet.html>vl_covdet</a></code> are <em>oriented ellipses</em> and\nare defined by a translation $T$ and linear map $A$ (a $2\\times 2$)\nwhich can be extracted as follows:</p>\n\n<pre>\n T = frame(1:2) ;\n A = reshape(frame(3:6),2,2)) ;\n</pre>\n\n<p>The map $(A,T)$ moves pixels from the feature frame (also called\nnormalised patch domain) to the image frame. The feature is\nrepresented as a circle of unit radius centered at the origin in the\nfeature reference frame, and this is transformed into an image ellipse\nby $(A,T)$.</p>\n\n<p>In term of extent, the normalised patch domain is a square box\ncentered at the origin, whereas the image domain uses the standard\nMATLAB convention and starts at (1,1). The Y axis points downward and\nthe X axis to the right. These notions are important in the\ncomputation of normalised patches and descriptors\n(see <a shape=\"rect\" href=\"%pathto:tut.covdet.descr\">later</a>).</p>\n\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n<h1 id=\"tut.covdet.affine\">Affine adaptation</h1>\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n\n<p><em>Affine adaptation</em> is the process of estimating the\naffine shape of an image region in order to construct an\naffinely co-variant feature frame. This is useful in order to\ncompensate for deformations of the image like slant, arising for\nexample for small perspective distortion.</p>\n\n<p>To switch on affine adaptation, use\nthe <code/>EstimateAffineShape</code> option:</p>\n\n<div class=\"highlight\"><pre><span class=\"n\">frames</span> <span class=\"p\">=</span> <span class=\"n\">vl_covdet</span><span class=\"p\">(</span><span class=\"n\">imgs</span><span class=\"p\">,</span> <span class=\"s\">&#39;EstimateAffineShape&#39;</span><span class=\"p\">,</span> <span class=\"n\">true</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p>which detects the following features:</p>\n\n<div class=\"figure\">\n <img src=\"../demo/covdet_affine_frames.jpg\"></img>\n <div class=\"caption\">\n  <span class=\"content\">\n   Affinely adapted features.\n  </span>\n </div>\n</div>\n\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n<h1 id=\"tut.covdet.ori\">Feature orientation</h1>\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n\n<p>The detection methods discussed so far are rotationally\ninvariant. This means that they detect the same circular or elliptical\nregions regardless of an image rotation, but they do not allow to fix\nand normalise rotation in the feature frame. Instead, features are\nestimated to be upright by default (formally, this means that the\naffine transformation $(A,T)$ maps the vertical axis $(0,1)$ to\nitself).</p>\n\n<p>Estimating and removing the effect of rotation from a feature frame\nis needed in order to compute rotationally invariant descriptors. This\ncan be obtained by specifying the <code/>EstimateOrientation</code>\noption:</p>\n\n<div class=\"highlight\"><pre><span class=\"n\">frames</span> <span class=\"p\">=</span> <span class=\"n\">vl_covdet</span><span class=\"p\">(</span><span class=\"n\">imgs</span><span class=\"p\">,</span> <span class=\"s\">&#39;EstimateOrientation&#39;</span><span class=\"p\">,</span> <span class=\"n\">true</span><span class=\"p\">,</span> <span class=\"s\">&#39;verbose&#39;</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p>which results in the following features being detected:</p>\n\n<div class=\"figure\">\n <img src=\"../demo/covdet_oriented_frames.jpg\"></img>\n <div class=\"caption\">\n  <span class=\"content\">\n    Features with orientation detection.\n  </span>\n </div>\n</div>\n\n<p>The method used is the same as the one proposed by D. Lowe: the\norientation is given by the dominant gradient direction. Intuitively,\nthis means that, in the normalized frame, brighter stuff should appear\non the right, or that there should be a left-to-right dark-to-bright\npattern.</p>\n\n<p>In practice, this method may result in an ambiguous detection of\nthe orientations; in this case, up to four different orientations may\nbe assigned to the same frame, resulting in a multiplication of\nthem.</p>\n\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n<h1 id=\"tut.covdet.descr\">Computing descriptors</h1>\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n\n<p><code/><a href=../matlab/vl_covdet.html>vl_covdet</a></code> can also compute descriptors. Three are\nsupported so far: SIFT, LIOP and raw patches (from which any other\ndescriptor can be computed). To use this functionality simply add an\noutput argument:</p>\n\n<div class=\"highlight\"><pre><span class=\"p\">[</span><span class=\"n\">frames</span><span class=\"p\">,</span> <span class=\"n\">descrs</span><span class=\"p\">]</span> <span class=\"p\">=</span> <span class=\"n\">vl_covdet</span><span class=\"p\">(</span><span class=\"n\">imgs</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p>This will compute SIFT descriptors for all the features. Each\ncolumn of <code/>descrs</code> is a 128-dimensional descriptor vector\nin single precision. Alternatively, to compute patches use:</p>\n\n<div class=\"highlight\"><pre><span class=\"p\">[</span><span class=\"n\">frames</span><span class=\"p\">,</span> <span class=\"n\">descrs</span><span class=\"p\">]</span> <span class=\"p\">=</span> <span class=\"n\">vl_covdet</span><span class=\"p\">(</span><span class=\"n\">imgs</span><span class=\"p\">,</span> <span class=\"s\">&#39;descriptor&#39;</span><span class=\"p\">,</span> <span class=\"s\">&#39;liop&#39;</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p> Using default settings, each column will be a 144-dimensional\ndescriptor vector in single precision. If you wish to change the\nsettings, use arguments described in <a shape=\"rect\" href=\"%pathto:tut.liop\">LIOP tutorial</a>\n</p>\n\n<div class=\"highlight\"><pre><span class=\"p\">[</span><span class=\"n\">frames</span><span class=\"p\">,</span> <span class=\"n\">descrs</span><span class=\"p\">]</span> <span class=\"p\">=</span> <span class=\"n\">vl_covdet</span><span class=\"p\">(</span><span class=\"n\">imgs</span><span class=\"p\">,</span> <span class=\"s\">&#39;descriptor&#39;</span><span class=\"p\">,</span> <span class=\"s\">&#39;patch&#39;</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p>In this case each column of <code/>descrs</code> is a stacked patch.\nTo visualize the first 100 patches, one can use for example:</p>\n\n<div class=\"highlight\"><pre><span class=\"n\">w</span> <span class=\"p\">=</span> <span class=\"nb\">sqrt</span><span class=\"p\">(</span><span class=\"nb\">size</span><span class=\"p\">(</span><span class=\"n\">patches</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">))</span> <span class=\"p\">;</span>\n<span class=\"n\">vl_imarraysc</span><span class=\"p\">(</span><span class=\"nb\">reshape</span><span class=\"p\">(</span><span class=\"n\">patches</span><span class=\"p\">(:,</span><span class=\"mi\">1</span><span class=\"p\">:</span><span class=\"mi\">10</span><span class=\"o\">*</span><span class=\"mi\">10</span><span class=\"p\">),</span> <span class=\"n\">w</span><span class=\"p\">,</span><span class=\"n\">w</span><span class=\"p\">,[]))</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<div class=\"figure\">\n <img src=\"../demo/covdet_patches.jpg\"></img>\n <img src=\"../demo/covdet_affine_patches.jpg\"></img>\n <div class=\"caption\">\n  <span class=\"content\">\n    Patches extracted with the standard detectors (left) and adding\n    affine adaptation (right).\n  </span>\n </div>\n</div>\n\n<p>There are several parameters affecting the patches associated to\nfeatures. First, <code/>PatchRelativeExtent</code> can be used to\ncontrol how large a patch is relative to the feature scale. The extent\nis half of the side of the patch domain, a square in\nthe <a shape=\"rect\" href=\"covdet.html#tut.covdet.frames\">frame reference\nframe</a>. Since most detectors latch on image structures (e.g. blobs)\nthat, in the normalised frame reference, have a size comparable to a\ncircle of radius one, setting <code/>PatchRelativeExtent</code> to 6\nmakes the patch about six times largerer than the size of the corner\nstructure. This is approximately the default extent of SIFT feature\ndescriptors.</p>\n\n<p>A second important parameter is <code/>PatchRelativeSigma</code>\nwhich expresses the amount of smoothing applied to the image in the\nnormalised patch frame. By default this is set to 1.0, but can be\nreduced to get sharper patches. Of course, the amount of\nsmoothing is bounded below by the resolution of the input image: a\nsmoothing of, say, less than half a pixel cannot be recovered due to\nthe limited sampling rate of the latter. Moreover, the patch must be\nsampled finely enough to avoid aliasing (see next).</p>\n\n<p>The last parameter is <code/>PatchResolution</code>. If this is\nequal to $w$, then the patch has a side of $2w+1$ pixels.  (hence the\nsampling step in the normalised frame is given by\n<code/>PatchRelativeExtent</code>/<code/>PatchResolution</code>).\nExtracting higher resolution patches may be needed for larger extent\nand smaller smoothing. A good setting for this parameter may be\n<code/>PatchRelativeExtent</code>/<code/>PatchRelativeSigma</code>.</p>\n\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n<h1 id=\"tut.covdet.custom\">Custom frames</h1>\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n\n<p>Finally, it is possible to use <code/><a href=../matlab/vl_covdet.html>vl_covdet</a></code> to compute\ndescriptors on custom feature frames, or to apply affine adaptation\nand/or orientation estimation to these.</p>\n\n<p>For example</p>\n\n<div class=\"highlight\"><pre><span class=\"n\">delta</span> <span class=\"p\">=</span> <span class=\"mi\">30</span> <span class=\"p\">;</span>\n<span class=\"n\">xr</span> <span class=\"p\">=</span> <span class=\"n\">delta</span><span class=\"p\">:</span><span class=\"n\">delta</span><span class=\"p\">:</span><span class=\"nb\">size</span><span class=\"p\">(</span><span class=\"n\">im</span><span class=\"p\">,</span><span class=\"mi\">2</span><span class=\"p\">)</span><span class=\"o\">-</span><span class=\"n\">delta</span><span class=\"o\">+</span><span class=\"mi\">1</span> <span class=\"p\">;</span>\n<span class=\"n\">yr</span> <span class=\"p\">=</span> <span class=\"n\">delta</span><span class=\"p\">:</span><span class=\"n\">delta</span><span class=\"p\">:</span><span class=\"nb\">size</span><span class=\"p\">(</span><span class=\"n\">im</span><span class=\"p\">,</span><span class=\"mi\">1</span><span class=\"p\">)</span><span class=\"o\">-</span><span class=\"n\">delta</span><span class=\"o\">+</span><span class=\"mi\">1</span> <span class=\"p\">;</span>\n<span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">y</span><span class=\"p\">]</span> <span class=\"p\">=</span> <span class=\"nb\">meshgrid</span><span class=\"p\">(</span><span class=\"n\">xr</span><span class=\"p\">,</span><span class=\"n\">yr</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n<span class=\"n\">frames</span> <span class=\"p\">=</span> <span class=\"p\">[</span><span class=\"n\">x</span><span class=\"p\">(:)</span><span class=\"o\">&#39;</span><span class=\"p\">;</span> <span class=\"n\">y</span><span class=\"p\">(:)</span><span class=\"o\">&#39;</span><span class=\"p\">]</span> <span class=\"p\">;</span>\n<span class=\"n\">frames</span><span class=\"p\">(</span><span class=\"k\">end</span><span class=\"o\">+</span><span class=\"mi\">1</span><span class=\"p\">,:)</span> <span class=\"p\">=</span> <span class=\"n\">delta</span><span class=\"o\">/</span><span class=\"mi\">2</span> <span class=\"p\">;</span>\n\n<span class=\"p\">[</span><span class=\"n\">frames</span><span class=\"p\">,</span> <span class=\"n\">patches</span><span class=\"p\">]</span> <span class=\"p\">=</span> <span class=\"n\">vl_covdet</span><span class=\"p\">(</span><span class=\"n\">imgs</span><span class=\"p\">,</span> <span class=\"c\">...</span>\n                              <span class=\"s\">&#39;frames&#39;</span><span class=\"p\">,</span> <span class=\"n\">frames</span><span class=\"p\">,</span> <span class=\"c\">...</span>\n                              <span class=\"s\">&#39;estimateAffineShape&#39;</span><span class=\"p\">,</span> <span class=\"n\">true</span><span class=\"p\">,</span> <span class=\"c\">...</span>\n                              <span class=\"s\">&#39;estimateOrientation&#39;</span><span class=\"p\">,</span> <span class=\"n\">true</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p>computes affinely adapted and oriented features on a grid:</p>\n\n<div class=\"figure\">\n <img src=\"../demo/covdet_custom_frames.jpg\"></img>\n <div class=\"caption\">\n   <span class=\"content\">\n     Custom frame (on a grid) after affine adaptation.\n   </span>\n </div>\n</div>\n\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n<h1 id=\"tut.covdet.ss\">Getting the scale spaces</h1>\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n\n<p><code/><a href=../matlab/vl_covdet.html>vl_covdet</a></code> can return additional information about the\nfeatures, including the scale spaces and scores for each detected\nfeature. To do so use the syntax:</p>\n\n<div class=\"highlight\"><pre><span class=\"p\">[</span><span class=\"n\">frames</span><span class=\"p\">,</span> <span class=\"n\">descrs</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"p\">]</span> <span class=\"p\">=</span> <span class=\"n\">vl_covdet</span><span class=\"p\">(</span><span class=\"n\">imgs</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p>This will return a structure info</p>\n\n<pre>\ninfo =\n\n                    gss: [1x1 struct]\n                    css: [1x1 struct]\n             peakScores: [1x351 single]\n             edgeScores: [1x351 single]\n       orientationScore: [1x351 single]\n    laplacianScaleScore: [1x351 single]\n</pre>\n\n<p>The last four fields are the peak, edge, orientation, and Laplacian\nscale scores of the detected features. The first two were discussed\nbefore, and the last two are the scores associated to a specific\norientation during orientation assignment and to a specific scale\nduring Laplacian scale estimation.</p>\n\n<p>The first two fields are the Gaussian scale space and the\ncornerness measure scale space, which can be plotted by means\nof <code/><a href=../matlab/vl_plotss.html>vl_plotss</a></code>. The following is the of the Gaussian scale\nspace for our example image:</p>\n\n<div class=\"figure\">\n <img src=\"../demo/covdet_gss.jpg\"></img>\n <div class=\"caption\">\n   <span class=\"content\">\n     Gaussian scale space.\n   </span>\n </div>\n</div>\n\n<p>The following is an example of the corresponding cornerness\nmeasure:</p>\n\n<div class=\"figure\">\n <img src=\"../demo/covdet_css.jpg\"></img>\n <div class=\"caption\">\n   <span class=\"content\">\n     Cornerness scale space (Difference of Gaussians).\n   </span>\n </div>\n</div>\n\n\n\n  \n      </div>\n      <div class=\"clear\">&nbsp;</div>\n    </div>\n  </div> <!-- content-section -->\n  <div id=\"footer-section\">\n    <div id=\"footer\">\n      &copy; 2007-13 The authors of VLFeat\n    </div> <!-- footer -->\n  </div> <!-- footer section -->\n </body>\n <!-- Body ends -->\n</html>\n ", "encoding": "ascii"}