{"url": "https://www.ics.uci.edu/~theory/269/140110.html", "content": "<!DOCTYPE html PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n<html>\n<head>\n<title>Theory Seminar, January 10, 2014</title>\n</head>\n<body>\n<a href=\"/~theory/\"><img src=\"http://www.ics.uci.edu/~theory/logo/CATOC2.jpg\"></a>\n<h2><a href=\"/~theory/269/\">CS 269S, Winter 2014: Theory Seminar</a><br>\nBren Hall, Room 1423, 1pm\n\n<hr>\nJanuary 10, 2014:</h2>\n<h1>\nFast and Accurate k-means for Large Datasets\n</h1>\n<h2>\nMichael Shindler\n</h2>\n<p>\nClustering is a popular problem with many applications. We consider\nthe $k$-means problem in the situation where the data is too large to\nbe stored in main memory and must be accessed sequentially, such as\nfrom a disk, and where we must use as little memory as possible. Our\nalgorithm is based on recent theoretical results, with significant\nimprovements to make it practical. Our approach greatly simplifies a\nrecently developed algorithm, both in design and in analysis, and\neliminates large constant factors in both the approximation guarantee\nand the memory requirements. We then incorporate approximate nearest\nneighbor search to compute $k$-means in $o(nk)$ (whereas computing\nthe cost, given a solution, takes $\\Theta(nk)$ time). We show that\nour algorithm compares favorably to existing algorithms - both\ntheoretically and experimentally.\n</p>\n\n</body>\n</html>\n\n", "encoding": "ascii"}