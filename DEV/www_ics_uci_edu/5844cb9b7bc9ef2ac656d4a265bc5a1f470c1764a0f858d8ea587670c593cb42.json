{"url": "https://www.ics.uci.edu/~dechter/courses/ics-280/spring-2003/ideas.html", "content": "<html>\n  <head>\n    <title>\n      Dr. Rina Dechter @ UCI\n    </title>\n    <link REL=\"Stylesheet\" HREF=\"/~dechter/basic.css\">\n  </head>\n\n<body bgcolor=\"#ffffff\" alink=\"00aaaa\" link=\"008080\" vlink=\"008080\">\n\n[an error occurred while processing this directive]\n\n<br><br>\n<center>\n<table width=\"90%\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\n\n<tr>\n  <td><img height=\"4\" src=\"/~dechter/images/transp-fill.gif\"></td>\n</tr>\n\n<tr>\n<td class=title>ICS-280, Current Topics in Automated Reasoning, Spring 2003</td>\n</tr>\n\n<tr>\n  <td><img width=\"100%\" height=\"2\"  src=\"/~dechter/images/black-fill.gif\"></td>\n</tr>\n</table>\n<p>\n\n<table width=\"90%\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\n\n<tr>\n<td>\n\n<P CLASS=\"section\">\nIdeas for Research Projects\n</P>\n<br><br>\n\n<OL>\n\t<LI>w-cutset: Investigate approximate algorithms and properties for finding a w-cutset.\n\t<LI>Convert any integer programming problem to a relational constraint optimization\tthat can interface through REES with all our algorithms.\n\t<LI>Develop an object oriented language for expressing constraint problems such as the Object oriented language of Pfeffer and Koller for probabilistc problems.\n\t<LI>LEARNING:  Read Rish Survey about learning, Read abut EM, Read Russel, Koller et. Al on learning.\n\t<OL TYPE=a>\n\t\t<LI>Investigating the learning EM algorithm with a stronger inference component than greedy inside EM. One can start with learning HMM. Can we improve learning HMM in some way by more advance inference?\n\t\t<LI>Develop a one iteration learning algorithms that replace EM:<BR>Complete each tuple using inference, then count the tuples giving each completed tuple its weight based on the computed probability. Is this a single iteration of EM?\n\t\t<LI>Algorithms for MAP applied to HMM's. Approximate MAP and incorporate in EM. Currently the expected counts are computed separately for every family. Alternative: compute expected completions per tuple, and only then take expected counts.\n\t\t<LI>Is there any relationship between EM and iterative belief propagation for MAP?\n\t</OL>\n\t<LI>Develop algorithms for MAP.\n\t<OL TYPE=a>\n\t\t<LI>Adapt search algorithms to MAP.\n\t\t<LI>Aanalyze MAP for trees.\n\t\t<LI>Develop iterative belief propagation for MAPs\n\t</OL>\n\t<LI>General search with caching simulating variable-elimination. Apply the idea of backtracking with no-good learning to any Look at Bacchus paper for the case of belief. Extend to optimization, either for MAX-CSP or for MPE first.\n\t<LI>Apply approximate inference with local search + iterative propagation as done by Pinkas and Dechter. Apply to optimization in general, to MPE and MAP.\n\t<LI>Develop Branch and bound for finding M-best solutions. Can we develop upper-bounds using mini-bucket for the ith solution and use it?\n</OL>\n</td>\n</tr>\n</table>\n</center>\n\n</body>\n", "encoding": "ascii"}