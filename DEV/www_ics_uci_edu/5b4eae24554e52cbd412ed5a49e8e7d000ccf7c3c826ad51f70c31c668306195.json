{"url": "https://www.ics.uci.edu/~yamingy/bayesD_demo1.r", "content": "source(\"bayesD_cocktail.r\")\n\n## setting up information matrices for a logistic regression model\nn=30\nm=2\nX=matrix(nrow=n, ncol=m)   \nX[,1]=1\nX[,2]=3*(1:n)/n-1\n      \nA=array(dim=c(25, n, m, m));   \nfor(i in 1:5)\n  for(j in 1:5){\n    theta=c(i-3, j-3)\n    eta=X%*%theta\n    for(k in 1:n)   \n      A[(i-1)*5+j, k, ,]=exp(eta[k])/(1+exp(eta[k]))^2 * X[k,]%*% t(X[k,]);\n  }\nprior=rep(1/25, 25); \n \nprint(\"Bayesian D-optimal design for logistic regression\");\nprint(\"model: Pr(y=1) = 1-Pr(y=0) = 1/(1+exp(-b1-b2*x))\");\nprint(\"design variable: -1<=x<=2 discretized\");\nprint(\"prior on b: uniform on {b1, b2 = -2, -1, 0, 1, 2}\"); \n\n## use cocktail algorithm (alg=1)\nw=bayesD(A, prior, maxiter=10000, small=1e-4, alpha=0, alg=1)\n\nprint(\"output:\");\nprint(\"optimal support points x(i)\");\nprint(X[w>0, 2]);\nprint(\"optimal weights w(i)\");\nprint(w[w>0]);\n\n", "encoding": "ascii"}