{"url": "https://www.ics.uci.edu/~pattis/ICS-46/lectures/notes/bst.txt", "content": "\t\t\t\tBinary Search Trees\r\n\r\n\r\nThis lecture will cover a specific kind of binary tree: a Binary Search Tree\r\n(BST). We can use these trees, if they are well balanced, to insert, search, and\r\nremove values with complexity of O(Log N). Such a data structure would be an\r\nimprovement for implementing sets, maps, and priority queues, where some of\r\nthese operations are O(N) for array and linked list implementations. We will\r\ndiscuss the ordering property of binary search trees, along with iterative and\r\nrecursive versions of the insert, search, and remove functions, and finally\r\nillustrate four kinds of tree traversal orders and how to create iterators for\r\nBSTs.  \r\n\r\n------------------------------------------------------------------------------\r\n\r\nOrder Property/Structure Property:\r\n\r\nThe order property of a binary search tree is that EVERY node (not just the\r\nroot), must have a value that is greater than all the values in its left\r\nsubtree and less than all the values in its right subtree. This property is\r\ntrivially true for empty trees and leaves (because they have no subtrees that\r\nmight contain nodes that have incorrect values).\r\n\r\nNote that this property applies between a parent and ALL its DESCENDANTS (ALL\r\nthe nodes in its left and right subtree), NOT JUST ITS CHILDREN. The following\r\nproperty is similar, simpler, and WRONG: \"a node must be greater than its left\r\nchild and less than its right child\". Certainly a BST by the definition above\r\nimplies that a node and its children satisfy this property, but the implication\r\ndoesn't go the other way around. So remember the right definition, not the\r\nwrong one.\r\n\r\nChallenge: Draw a small tree that satisifies the second property stated in this\r\nparagraph, but is not a true BST by the first property. Hint: you don't need\r\nmany nodes.\r\n\r\nNote that the values that are inserted in a BST do NOT determine the structure\r\n(shape) of the BST that contains them. The structure depends on the ORDER that\r\nthese VALUESi are INSERTED into the BST (see the insertion function below).\r\nDepending on the order that the values are inserted, the height of the tree can\r\nbe pathological or well-balanced: O(N) or O(Log N).\r\n\r\nIn later lectures we will examine other kinds of trees, with different order and\r\nstructure properties: e.g., heaps and AVL trees.\r\n\r\nFinally, we will generally assume that a BST stores unique values (as they\r\nwould in sets and maps -organized by unique keys). If we wanted to store\r\nmultiple copies of a value, there are two standard approaches:\r\n\r\n1) We could add an int field to each node keeping a count of how many times\r\n   its value occurred. Thus, there would still be unique values in every node.\r\n\r\n2) We could change the order property slightly, such that for any node, all\r\n   values in the left subtree are less than OR EQUAL and all values in the\r\n   right subtree are still strictly greater (or, symmetrically, values in the\r\n   left subtree are stictly < and all values in the right subtree are >=).\r\n\r\n------------------------------------------------------------------------------\r\n\r\nSeaching:\r\n\r\nGiven any tree satisfying the BST order property, there is a unique location in\r\nthat BST for any specific value in the tree. We can write simple functions, both\r\niterative and recursive, that attempts to find (and return a pointer to) the\r\nnode that stores such a value.\r\n\r\nBecause of this order property and the law of trichotomy (a==b, a<b, or a>b),\r\nwhen we compare the value we are searching for with any node in the tree -we\r\nstart at the root- and know\r\n\r\n  (a) value == node's value: we have found the node containing the value\r\n  (b) value <  nodes' value: the value, if in the tree, is in the left subtree\r\n  (c) value >  node's value: the value, if in the tree, is in the right subtree\r\n\r\nContrast this situation with the recursive tree functions that we have studied\r\n(e.g., size and height) which needed to examine BOTH subtrees to compute their\r\nanswers. We found that in these cases, we must do two recursive calls inside\r\nsuch functions, always recurring both in the left and to the right. For\r\nsearching in a BST, we must examine at most one subtree of a node (left OR\r\nright) based on a comparison at the root of a subtree, so we can write a search\r\nfunction iteratively. The following code mimics iterative code that searches a \r\nlinear-linked list, but instead of updating the cursor as c=c->next we have\r\neither c=c->left or c=c->right, depending on how to_find compares to c->value.\r\n\r\ntemplate<class T>\r\nTN<T>* find (TN<T>* root, T to_find) {\r\n  for (TN<T>* c=root; c!=nullptr; c = (to_find < c->value ? c->left : c->right))\r\n    if (to_find == c->value)\r\n      return c;\r\n\r\n  return nullptr;\r\n}\r\n\r\nWe can even \"simplify\" this code to include the \"==\" test in the for loop's\r\ntest (as \"!=\"), not a special if. Note that the loop terminates either when\r\nc==nullptr or to_find == c->value; the short-circuit evaluation guarantees the\r\nlater won't be tested if the former is true. Here the \"loop varaible\" c must\r\nbe moved out of the loop's scope, because it is used outside the loop.\r\n\r\ntemplate<class T>\r\nTN<T>* find (TN<T>* root, T to_find) {\r\n  TN<T>* c=root;\r\n  for (/* see declaration above */;\r\n       c!=nullptr && to_find != c->value;\r\n       c = (to_find < c->value ? c->left : c->right))\r\n    {}\r\n\r\n  return c;\r\n}\r\n\r\nWe can also write this function recursively. The recursive function is a bit\r\nlonger than the iterative one, but it has the added advantage that its\r\nstructure is almost identical to the recursive code for inserting a value in a\r\nBST (which we will examine soon; insertion is harder to do iteratively):\r\n\r\ntemplate<class T>\r\nTN<T>* find (TN<T>* t, T to_find) {\r\n  if (t == nullptr)\r\n    return nullptr;\r\n  else\r\n    if (to_find == t->value)\r\n      return t;\r\n    else if (to_find < t->value)\r\n      return find(t->left, to_find);\r\n    else /* if (to_find > t->value) */\r\n      return find(t->right,to_find);\r\n}\r\n\r\nThe test in the comment does not need to be performed: it is guaranteed to be\r\ntrue by the law of trichotomy, if the earlier tests are false.\r\n\r\nWe can simplify the final if/else in this code using a conditional expression,\r\nsimilar to what we wrote in the iterative function.\r\n\r\ntemplate<class T>\r\nTN<T>* find (TN<T>* t, T to_find) {\r\n  if (t == nullptr)\r\n    return nullptr;\r\n  else\r\n    if (to_find == t->value)\r\n      return t;\r\n    else\r\n      return find( (to_find < t->values ? t->left : t->right), to_find);\r\n}\r\n\r\nWe can prove that this function is correct as follows.\r\n\r\n1) There are no nodes containing any values in an empty tree. This function\r\n   immediately recognizes this base case and returns nulltpr.\r\n\r\n2) For any non-empty tree t, a recursive call on t->left or t->right is always\r\n   using an argument closer to the base case than t: each contains at least 1\r\n   fewer TNs than t does (and often each contains about 1/2 the TNs t does).\r\n\r\n3) Assuming find(t->left,to_find) and find(t->right,to_find) correctly return\r\n   a pointer to the node storing to_find in a subtree, this function checks\r\n   whether to_find is at its root and returns a pointer to that node if it\r\n   does; if it doesn't, it returns the answer computed by calling find on\r\n   either the left or right subtree, as appropriate for the order property of\r\n   the BST, and these functions return the correct result.\r\n\r\nWe can also combine the  nullptr/== case as follows (as we did above in the\r\niterative code), where both non-recursive results are returned in the if; here\r\nshort-circuit evaluation is again important.\r\n\r\ntemplate<class T>\r\nTN<T>* find (TN<T>* t, T to_find) {\r\n  if (t == nullptr || to_find == t->value)\r\n     return t;\r\n  else\r\n     return find( (to_find < t->value ? t->left : t->right), to_find);\r\n}\r\n\r\nThese functions, in the worst case, will search through the number of nodes\r\nequal to the height of the tree + 1: every recursive call is at a depth that is\r\n1 lower, and the height is the maximum depth. In a pathological tree, it will\r\nsearch all N nodes; in a well balanced tree (one with about the same number of\r\nleft and right descendants, for every node) it will search about Log2 N nodes.\r\nThus, when asked what is the complexity class of searching in a BST we would\r\nfirst have to know whether the tree is pathological or balanced. Or, we could\r\njust say O(Height of the tree), which is a correct -if a bit non-commital-\r\nanswer for both kinds of trees. We know H is both Omega(Log2 N) and O(N).\r\n\r\n------------------------------------------------------------------------------\r\n\r\nInsertion:\r\n\r\nInsertion is simlar to searching: the place where we would \"insert\" the node is\r\nthe place where we would \"find\" the node if searching for it (and we will likely\r\nsearch for it after we insert it). We will write this function in two recursive\r\nways: (1) returning a result and (2) void, but with a reference parameter.\r\nFinally we will show an iterative function that solves the problem, but is\r\nmuch messier and more complicated.\r\n\r\nNote that BSTs grow at their leaves: each insertion creates a new leaf, growing\r\nit from another leaf or an internal node with just one child.\r\n\r\n(1) By using the same technique we used to mutate linked lists in recursive\r\nfunctions (very similar to the recursive function that inserts a value at the\r\nrear of a linked list), we can solve this problem recursively with code that\r\nmirrors the recursive searching code. Here will will do nothing if the value is\r\nalready stored in the BST.\r\n\r\ntemplate<class T>\r\nTN<T>* insert (TN<T>* t, T to_insert) {\r\n  if (t == nullptr)\r\n    return new TN<T>(to_insert); //nullptr implicit for left/right subtrees\r\n  else {\r\n    if (to_insert < t->value)\r\n      t->left = insert(t->left, to_insert);\r\n    else if (to_insert > t->value)\r\n      t->right = insert(t->right, to_insert);\r\n  /*else,  for == case\r\n      ;*/\r\n\r\n    return t;\r\n  }\r\n}\r\n\r\nHere insert returns a pointer to the root of a mutated BST that now includes\r\nthe value to_insert.  So we call this function like\r\n\r\n   root = insert(root, to_insert);\r\n\r\nFor an empty BST, it directly returns a pointer to a new node; for a non-empty\r\nBST it will return the original root, but the root, or exactly one of the\r\nroot's descendants will have its left or right pointer now point to a new leaf\r\nnode storing to_insert.\r\n\r\nNote that if to_insert == t->value in the else, it is neither < or > t->value,\r\nso this function returns without making any changes to the BST. But it still\r\ntraverses the BST to find the already-present value.\r\n\r\n\r\n(2) By using a reference parameter for t, we can write even simpler code, but\r\nstill looking like the recursive insert code.\r\n\r\ntemplate<class T>\r\nvoid insert (TN<T>*& t, T to_insert) {\r\n  if (t == nullptr)\r\n    t = new TN<T>(to_insert);    //nullptr implicit for left/right subtrees\r\n  else\r\n    if (to_insert < t->value)\r\n      insert(t->left, to_insert);\r\n    else if (to_insert > t->value)\r\n      insert(t->right, to_insert);\r\n  /*else, for == case\r\n      ;*/\r\n}\r\n\r\nAgain, note that if to_insert == t->value in the else, this function returns\r\nwithout making any changes to the BST. Each recursive call aliases the parameter\r\nt either to t.left or t.right of it parent.\r\n\r\nNote that we call this function like insert(root, to_insert);\r\n\r\nFinally, here is an iterative function to insert a value into a BST. It is more\r\ncomplicated than the recursive functions above - and not much like the\r\niterative search function either. It works by searching downward (into either a\r\nleft or right subtree) for a node such that to_insert belongs to its left (or\r\nright) and there currently is no node to it left (or right) and then puts a\r\nnode with the value to_insert there. The nested if statements produce \r\ncomplicated logic.\r\n\r\ntemplate<class T>\r\nTN<T>* insert_i (TN<T>* root, T to_insert) {\r\n  if (root == nullptr)\r\n    return new TN<T>(to_insert);\r\n  else {\r\n    TN<T>* t = root;\r\n    for (;;)\r\n      if (to_insert == t->value)\r\n        return root;\r\n      else if (to_insert < t->value) {\r\n        if (t->left == nullptr) {\r\n          t->left = new TN<T>(to_insert);\r\n          return root;\r\n        }else\r\n          t = t->left;\r\n      }else /* to_insert > t->value */{\r\n        if (t->right == nullptr) {\r\n          t->right = new TN<T>(to_insert);\r\n          return root;\r\n        }else\r\n          t = t->right;\r\n      }\r\n  }\r\n}\r\n\r\nNote in this function, if the value belongs in the left/right subtree of a\r\nnode, but that subtree already contains a node, we just advance t to point to\r\nnode at the root of the the left/right subtree and continue downward.\r\n\r\nNote that we must call this function like root = insert(root, to_insert);\r\n\r\nThe root of the entire tree is always returned; but when inserting a value into\r\nan empty tree, the old root is nullptr so a new root is returned.\r\n\r\n\r\n------------------------------------------------------------------------------\r\n\r\nRemoval:\r\n\r\nThere are many different algorithms to remove a value from a BST. One property\r\ngood algorithms should have is that they do not increase the height of the\r\ntree. After all, we are removing a node, so the height should stay the same,\r\nor get smaller. The algorithm I'll show will have this property. The exact\r\ncode to execute depends on the number of children of the node being removed.\r\n\r\n( 1) Find the node containing the value to be removed\r\n\r\n(2a) If it is a LEAF, delete it: make the pointer from its parent (left or\r\n       right) nullptr, instead of pointing to the deleted node.\r\n\r\n(2b) If it is an INTERNAL node with ONE CHILD, delete it: make the pointer from\r\n       its parent (left or right) point to its child, instead of pointing to the\r\n        deleted node.\r\n\r\n(2c) If it is an internal node with TWO CHILDREN \r\n     (2c1) Find the node containing the closest value: either the largest value\r\n             smaller than it or the smallest value larger than it (it doesn't\r\n             matter which) \r\n     (2c2) Remove that node from the tree: it is guaranteed to have at most\r\n              one child, so it will be easy to remove using this algorithm via\r\n              steps 2a or 2b \r\n     (2c3) Replace the value of the original node (the one containing the value\r\n              to remove) with the value of this node just deleted\r\n\r\nThe actual C++ code for this algorithm (below) is a bit subtle (notice the &\r\nparameter). UNLIKE the other code that appears in this lecture, I do not expect\r\nyou to be able to replicate it. But I expect you to try to understand it. Here\r\nin the TWO CHILDREN case the node with the \"closest\" value will be the node that\r\nis the biggest value less than the value in the node being removed.\r\n\r\n\r\ntemplate<class T>\r\nT remove_closest(TN<T>*& t) {\r\n  if (t->right == nullptr) {\r\n    T to_return = t->value;\r\n    TN<T>* to_delete = t;\r\n    t = t->left;\r\n    delete to_delete;\r\n    return to_return;\r\n  }else\r\n    return remove_closest(t->right);\r\n}\r\n\r\ntemplate<class T>\r\nvoid remove (TN<T>*& t, T to_remove) {\r\n  if (t == nullptr)\r\n    return;\r\n  else\r\n    if (to_remove == t->value) {\r\n      if (t->left == nullptr) {\r\n        TN<T>* to_delete = t;\r\n        t = t->right;\r\n        delete to_delete;\r\n      }else if (t->right == nullptr) {\r\n        TN<T>* to_delete = t;\r\n        t = t->left;\r\n        delete to_delete;\r\n      }else                   //Removes biggest value less than to_remove\r\n        t->value = remove_closest(t->left);\r\n    }else\r\n      remove( (to_remove < t->value ? t->left : t->right), to_remove);\r\n}\r\n\r\n------------------------------------------------------------------------------\r\n\r\nMiscellaneous: Copying a Tree/Checking for \"equal\" Trees\r\n\r\nHere is an elegant recursive function that copies a binary tree (whether or not\r\nit is a BST); it is similar in form to copying a linear linked list. It is O(N)\r\nbecause each of the N nodes in the tree is processed once, in a constant amount\r\nof time: O(1) to call new and copy the information in the constructor.\r\n\r\ntemplate<class T>\r\nTN<T>* copy (TN<T>* t) {\r\n  if (t == nullptr)\r\n    return nullptr;\r\n  else\r\n    return new TN<T>(t->value, copy(t->left), copy(t->right));\r\n}\r\n\r\nLikewise, here is an elegant recursive function that determines whether two\r\nbinary trees (whether or not they are BST) are equal. Here, equal means the\r\nsame structure storing the same values. Notice how short-circuit evaluation\r\nmeans that if nodes have different values, their subtrees are not checked for\r\nequality, possibly speeding up the comparison.\r\n\r\ntemplate<class T>\r\nbool equal (TN<T>* t1, TN<T>* t2) {\r\n  if (t1 == nullptr || t2 == nullptr)\r\n    return t1 == nullptr && t2 == nullptr;\r\n  else\r\n    return t1->value == t2->value &&\r\n           equal(t1->left,t2->left) && equal(t1->right,t2->right);\r\n}\r\n\r\n------------------------------------------------------------------------------\r\n\r\nTraversals:\r\n\r\nWe will now discuss the four standard traversal orders: Preorder, Inorder,\r\nPostorder (which are all depth-first orders), and Breadth-First. As we continue\r\nto discuss tree-processing functions, we will see examples of all these orders.\r\nAlthough we are illustrating these traverals in a BST, we can discuss\r\ntraversing any kind of tree, with any number of children, and any (or no)\r\nordering among its nodes (e.g. \"left to right\", \"right to left\").\r\n\r\nNote that the first three traversals are all accomplished with variants of a\r\nsimple recursive function. In Preorder traversals, the parent is processed\r\nBEFORE (pre) its children; in Inorder the parent is processed IN-BETWEEN its\r\nchildren; and in Postorder the parent is processed AFTER (post) its children.\r\nNormally we will process the subtrees of a parent in left-to-right order, but\r\nany order is OK; see the print_rotated function in the previous lecture, which\r\nis an Inorder traversal that processes first the right subtree, then the parent,\r\nand finally the left subtree of every node in a binary tree.\r\n\r\nIn breadth first search nodes are processed by increasing depth from the root:\r\nfirst the root (depth 0), then its children (depth 1), then its grandchildren\r\n(depth 2), etc.\r\n\r\nThe exact meaning of \"processed\" changes depending on that we are doing with \r\nhe tree. In the example below, \"processed\" means print out the value of the\r\nnode.\r\n\r\nThe general method for visiting and printing the first three kinds of traverals\r\nis shown below. Preorder printing prints a node before its children; inorder\r\nprinting prints a node between its two children; postorder printing prints a\r\nnode after its children. The only difference is where the cout appears.\r\n\r\ntemplate(class T>\r\nvoid print (TN<T>* t) {  //Preorder, Inorder, Postorder form\r\n  if (t == nullptr)\r\n    return;\r\n  else {\r\n    //Uncomment for preorder traversals:  std::cout << t->value << std::endl;\r\n    print(t->left);\r\n    //Uncomment for inorder traversals:   std::cout << t->value << std::endl;\r\n    print(t->right);\r\n    //Uncomment for postorder traversals: std::cout << t->value << std::endl;\r\n  }\r\n}\r\n\r\nFinally, the breath-first order prints all the nodes at a certain depth\r\n(starting at the root) before any of the nodes at the next depth. There is no\r\nnice recursive solution here, but there is a simple function that uses a queue:\r\nadding all the nodes at each level before adding any nodes at the next\r\nlevel.\r\n\r\ntemplate<class T>\r\nvoid print_breadthfirst (TN<T>* t) { //Breadth-First\r\n  ics::ArrayQueue<TN<T>*> q;\r\n  q.enqueue(t);                           //Initialize with the root\r\n\r\n  while (!q.empty()) {\r\n    TN<T>* next = q.dequeue();\r\n    std::cout << next->value << \" \";\r\n    if (next->left != nullptr)     //Only non-nullptr values added\r\n      q.enqueue(next->left);\r\n    if (next->right != nullptr)\r\n      q.enqueue(next->right);\r\n  }\r\n}\r\n\r\nGiven a tree, you should be able to quickly and accurately show the order that\r\nits nodes are traversed for each traversal order.\r\n\r\nA preorder traversal is interesting because if we print the values from a tree\r\nin that order (say into a file) and read in that file as the order in which to\r\nadd values to a BST, we will get the original BST. Actually, reading a printed\r\nbreadth-first traversal does the same thing, although the order is different.\r\nRecall that a BST grows from the leaves, and both these orders guarantee that\r\nthe parents in the original tree will be proccessed (printed) before either of\r\ntheir children. So, nodes are always added into the tree after their parents,\r\nbut before their children, guaranteeing that they appear in the tree \"lower\"\r\nthan their parents but higher than their children: in the correct place.\r\n\r\nAn inorder traversal is interesting because it prints the values \"in order\"\r\nbased on the ordering property used to build the BST. Basically, printing an\r\ninorder traversal is like printing the \"sorted\" tree.\r\n\r\nNote that the complexity class of all these traversals is O(N): each node is\r\nvisited exactly once during a traversal. Students have a hard time\r\nunderstanding this complexity class, because of multiple recursion, but it is\r\nreally like printing N linked list nodes.\r\n\r\nFinally, we know that for a reasonably balanced tree, it takes O(N Log N)\r\nto build the tree: N inserts, each O(Log N). If we have all N values before\r\nstarting to build the tree (this is called an offline algorithm -a term we will\r\nexamine in more detail later, and when we study heaps), and want to build as\r\ngood of a tree for searching as we can (lowest height), we would sort the array\r\nfirst, which is itself O(N Log N). Then put the middle value in the tree first\r\n(it will become the root, with about as many values on the left as the right),\r\nthen recursive put all values before the middle in the left subtree and all\r\nvalues after the middle in a right subtree. Building this BST is O(N) (each\r\nnode is visited just once) so the total complexity class is O(N Log N) + O(N) =\r\nO(N Log N + N) =  O(N Log N), because the sorting complexity is dominant.\r\n\r\nSo if we know all the values going into a tree, we can build a well-balanced\r\ntree in O(N Log N) time; it would take the same amount of time to add these\r\nvalues into a BST (if by luck we happened to add them in the \"right\" order).\r\n\r\nHere is a simple recursive function to build a perfectly balanced tree from a\r\nsorted array of values.\r\n\r\ntemplate<class T>\r\nTN<T>* build_optimal_tree(int[] sorted, low, high) {\r\n  if (low > high)\r\n    return nullptr;\r\n  else {\r\n    int mid = (low + high)/2;\r\n    //Better to write ... = low/2 + high/2 +(low%2==1 && high%2==1 ? 1 : 0);\r\n    //Do you know why?\r\n    return new TN<T>(sorted[mid],\r\n                      build_optimal_tree(sorted, low, mid-1),\r\n                      build_optimal)tree(sorted, mid+1, high));\r\n  }\r\n}\r\n\r\nWe call this function like: root = buildTree(s, 0, length-1);\r\n\r\nOr we can write a build_optimal_tree function with a simpler interface (it has\r\nfewer parameters), which calls the function above (assuming the array is\r\nfilled) as \r\n\r\ntemplate<class T>\r\nTN<T> build_optimal_tree(int[] sorted,length)\r\n  {return build_optimlal_tree(sorted, 0, length-1);}\r\n\r\nWe call this function like: root = build_optimal_tree(s,10);\r\n\r\n\"Online\" algorithms receive their inputs ONE AT A TIME and have to completely\r\nupdate their data structure before the next value is received and processed.\r\nBuilding a BST by adding one value at a time is an example of an online\r\nalgorithm. When we build a BST online, it might be pathological (have height\r\nO(N) instead of O(Log N) and could take O(N^2) time to build.\r\n\r\n\"Offline\" algorithms receive ALL their inputs before they are required to \r\nstart processing any of them. We then use all these values (say by sorting them)\r\nto update the data structure in any order we want.\r\n\r\nThe code above is an offline algorithm to build a BALANCED (height is\r\nguaranteed to be O(Log N)) BST of N values. We would sort all the values that\r\nare going into the tree be BEFORE we start building it, and build it using\r\nthe function above.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nIterators for BSTs:\r\n\r\nAn easy way to create an iterator for a BST is just to traverse the tree\r\nrecursively (in one of the orders above), storing into an array pointers to all\r\nits nodes (the length of the array is the size of the tree). Then we can\r\nwrite the rest of this iterator to just iterate through the array of pointers\r\nthat is created.\r\n\r\nSuch an iterator takes O(N) time to construct (allocating the array, filling in\r\neach of its pointer value while traversing the tree) and uses O(N) extra space\r\nin the array. The ++ and * operators are just O(1). So, the cost of constructing\r\nsuch an iterator AND iterating through ALL its values is still O(N).\r\n\r\nHere is code to fill in the array with tree references. It builds an array from\r\nrecursively traversing a tree: in some sense it is the opposite of the code\r\nabove to build a tree from an array. In this code the tree is traversed using\r\nan inorder traversal, so the array values are sorted. The int value returned is\r\nthe next position in the array to put the value.\r\n\r\ntemplate<class T>\r\nint fill_inorder(TN<T>* t, TN<T>* a[], int next_index) {\r\n  if (t == nullptr)\r\n    return next_index;\r\n  else {\r\n    next_index = fill_inorder(t->left,  a, next_index);\r\n    a[next_index] = t->entry;\r\n    next_index = fill_inorder(t->right, a, next_index+1);\r\n    return next_index;\r\n  }\r\n}\r\n\r\nWe can create an iterator in an alternative way, so that there isn't such a big\r\ninitial cost for creating the iterator (either in time or space), but the cost\r\nfor each ++ or * operator is increased (mostly O(1) but sometimes O(Height of\r\nthe tree)). The cost of initially constructing such an iterator and iterating\r\nthrough ALL its values is still O(N) in the worst case, as it was with the\r\narray, but it is typically faster to construct the iterator and throughout the\r\niteration it uses less space.\r\n\r\nFor one example, we can write an iterator that does a breadth-first traveral.\r\nThe constructor would construct a queue and leave it empty if the tree is empty\r\nor enqueue the root if the tree isn't empty (so that is O(1)); the * operator\r\nchecks if the queue is empty and peeks at the next values (also both O(1)); the\r\n++ dequeues the first value in the queue (assuming the queue isn't empty) and\r\nenqueues each non-empty child onto the queue (also O(1)). Note that the biggest\r\nthis queue can get is O(N): the worst case is actually a completely full tree,\r\nin which case about N/2 values (all its leaves) can be in the queue at one time\r\n(right before the deepest depth is processed). See the print method above for an\r\nexample of such a traversal (but for an iterator, the loop is outside the\r\niterator code).\r\n\r\nIn fact, we can also do an inorder traversal using a stack. The constructor\r\nwould construct a stack and leave it empty if the tree is empty, or push the\r\nroot if the tree isn't empty and continually pushes left descendants until there\r\nare none (so that is O(Height)); the * operator determines if the stack is\r\nempty and peeks at the next value (also both O(1)); the ++ operator pops a value\r\nfrom the stack (assuming the stack isn't empty) and pushes its right child and\r\nall its left descendants until there are none (so, that is O(Height)).\r\n\r\nFor example suppose we are iterating over the following BST:\r\n\r\n                     50\r\n                 /          \\ \r\n           30                   70\r\n          /   \\               /    \\\r\n      20        40         60       80\r\n    /   \\       / \\       /   \\    /   \\\r\n  15     25   35   45    55   65  75   85\r\n\r\nSo to start, we push 50, 30, 20, and 15 onto the stack, which we will represent\r\nby\r\n\r\n  Stack:  50 | 30 | 20 | 15\r\n\r\nusing * returns 15; using ++ it has no right child so the stack is now\r\n           \r\n  Stack:  50 | 30 | 20\r\n\r\nusing * returns 20; using ++ it has one right child (25) but it has no left\r\ndescendants, so the stack is now\r\n           \r\n  Stack:  50 | 30 | 25\r\n\r\nusing * returns 25; using ++ it has no right child so the stack is now\r\n           \r\n  Stack:  50 | 30\r\n\r\nusing * 30; using ++ it has one right child (40) which has one left descendant\r\n35), so the stack is now\r\n\r\n  Stack:  50 | 40 | 35\r\n\r\nusing * returns 35; using ++ it has no right child so the stack is now\r\n           \r\n  Stack:  50 | 40\r\n\r\nusing * returns 40; using ++ it has one right child (45) but it has no left\r\ndescendants, so the stack is now\r\n           \r\n  Stack:  50 | 45\r\n\r\nusing * returns 45; using ++ it has no right child so the stack is now\r\n           \r\n  Stack:  50 \r\n\r\nusing * returns 50; using ++ it has one right child (70) which has left\r\ndescendant 60 and 55, so the stack is now\r\n\r\n  Stack:  70 | 60 | 55\r\n\r\n...and so on. Notice that the vaues are processed inorder.\r\n\r\nNote that the biggest this stack can get is O(Height), which for a well\r\nbalanced tree is O(Log2 N) - a much smaller amount of space than any of the\r\nother ways we discussed to implement iterators for trees, which all had a\r\nworst case of O(N) - the breadth first version was N/2 at worst, still O(N).\r\n\r\nOf course for a pathological democratic tree, whose height is O(N), this method\r\nof iteration requires O(N) space too: it starts by pushing all the values onto\r\nthe stack.\r\n\r\nThe biggest problem with any traversal other than the first (storing all the\r\npointers in the arrays) is that it is hard to erase the value the cursor refers\r\nto and keep traversing. Mostly the problem is concerned with erasing node\r\nwith 2 children, causing a node much further down in the tree to rise.\r\n\r\n", "encoding": "ascii"}