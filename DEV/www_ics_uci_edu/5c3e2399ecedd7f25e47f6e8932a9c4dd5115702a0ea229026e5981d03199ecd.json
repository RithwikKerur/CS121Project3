{"url": "https://www.ics.uci.edu/~ejw/papers/ejw_ohs98.html", "content": "<HTML>\n<HEAD>\n   <META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=iso-8859-1\">\n   <META NAME=\"GENERATOR\" CONTENT=\"Mozilla/4.05 [en] (X11; I; SunOS 5.5.1 sun4u) [Netscape]\">\n   <META NAME=\"Author\" CONTENT=\"E. James Whitehead, Jr.\">\n   <TITLE>Control Choices and Network Effects in Hypertext Systems</TITLE>\n</HEAD>\n<BODY>\n\n<CENTER>\n<H1>\nControl Choices and Network Effects in Hypertext Systems</H1></CENTER>\n\n<CENTER><B>E. James Whitehead, Jr.</B></CENTER>\n\n<CENTER><I>Dept. of Information and Computer Science</I></CENTER>\n\n<CENTER><I>University of California, Irvine</I></CENTER>\n\n<CENTER><I>ejw@ics.uci.edu</I></CENTER>\n\n<H2>\nAbstract</H2>\nA key element of open hypermedia systems is the provision of hypermedia\nservices to the multiple applications populating a typical user's computing\nenvironment.&nbsp; A reaction against monolithic hypermedia systems which\ncontrol the user interface, data, and hypermedia structure, open hypermedia\nsystems control the hypermedia structure, and sometimes the data, but relinquish\ncontrol over the user interface.&nbsp; Gaining strength from less control,\nopen hypermedia systems increase hypermedia network effects by including\nmore applications, hence more content, in the hypermedia web.\n\n<P>The World Wide Web was designed to be a single point of entry into a\ndistributed, multi-platform information space, and as a direct consequence\nchose different control tradeoffs.&nbsp; With the Web, the user interface\nis controlled via the browser, but the data and hypermedia structure are\nuncontrolled.&nbsp; Through these control choices, and the URL, HTML, and\nHTTP standards, the Web created a feedback cycle of positive network effects.\nThis paper examines how the core differences in control assumptions between\nmonolithic hypermedia systems, open hypermedia system, and the Web, lead\nto different levels of network effects.\n<H2>\n1. Introduction</H2>\nHypertext systems exhibit <I>network effects</I> [Rohlfs, 1974], where\nthe utility of the hypertext system depends on the number of users and\namount of data in the system.&nbsp; This differs markedly from traditional\ngoods where the utility of the good does not depend on the number of other\npeople who own the good.&nbsp; Breakfast cereal has the same usefulness\nwhether 1 or a million people own it.&nbsp; In contrast, 1 telephone has\nno utility, and two have not much more.&nbsp; But when a million, or a\nbillion people have telephones, the utility of a single telephone is immense.\n\n<P>Network effects in hypertext systems have many causes. Hypertext system\nutility can be viewed from the perspective of readers, and of data, or\ncontent providers. From the perspective of a reader, a hypertext link between\ntwo documents increases the usefulness of <I>both</I> documents by making\na relationship between the documents explicit, and reducing the burden\nof retrieving the associated information. As the number of links increases,\nthe utility of documents in the system is greater than those outside the\nsystem. For the content provider, the utility of each document in the system\nis related to the number of people who read it. As more people use the\nsystem, it is likely more people will access the content generated by a\nprovider.\n\n<P>Simple feedback loops lead to increases in readers and content providers.&nbsp;\nReaders are lured to the system to take advantage of the greater utility\nof content in the hypertext system.&nbsp; As more readers use the system,\ncontent providers have incentive to add more content.&nbsp; Content entices\nreaders, readers incentivize content, and so on. Past a critical threshold,\nthis feedback cycle causes users to be<I> locked-in</I> to the hypertext\nsystem as competing systems are unable to generate sufficient network effects\nto supplant the dominant system. Such is the case with the World Wide Web\ntoday.\n\n<P>For monolithic hypertext systems, the goal was to create a system that\nprovided hypertext functionality. Open hypermedia systems and the Web went\nfurther, wanting to provide hypermedia functionality in more open contexts\nthan could be addressed by the monolithic systems. Due to these differing\ngoals, each class of hypermedia system made different control decisions\nin its architecture. Monolithic hypertext systems control the user interface,\nhypermedia structure, and data, while open hypermedia systems control the\nhypermedia structure, and sometimes the data, but relinquish control over\nthe user interface. With the Web, the user interface is controlled via\nthe browser, but the data and hypermedia structure are uncontrolled.&nbsp;\nThis paper examines how these core differences in control assumptions between\nmonolithic hypertext systems, open hypermedia systems, and the Web, lead\nto different incentive structures for readers and content providers and\nhence varying levels of network effects.\n<H2>\n2. Monolithic Hypertext Systems, Control Choices and Network Effects</H2>\nTed Nelson intuitively understood the network effects of hypertext, using\nutopian rhetoric to describe a global docuverse of hyperlinked information\nin Literary Machines [Nelson, 1981]. Some engineers heeded Nelson's call\nto arms and labored to bridge the gap between the Nelson's ideals, and\nthe compromises and limitations of existing computing technology. Some\nworked directly on Xanadu, while others performed their own interpretations\nand implementations, leading directly and indirectly to the development\nof monolithic hypertext systems such as Intermedia [Yankelovich et al.,\n1988], KMS [Akscyn et al., 1987], HyperCard [Apple, 1987], and StorySpace\n[Bolter, 1987][Eastgate, 1991].\n\n<P>Monolithic hypertext systems, motivated by a desire to keep their information\nbase internally consistent, and to provide a consistent user interface,\nhave an architecture which tightly controls the data, hypertext structure,\nand user interface of the system.&nbsp; Hypertext readers using these systems\nhave a nice user experience with fast link traversals, and no broken links.&nbsp;\nContent providers using the monolithic hypertext systems are required to\nimport data into the system, or use system specific editors. Data storage\nis typically limited to a single file or database (e.g. HyperCard), network\nfile system, or to data storage on a local area network (e.g., KMS), limiting\nthe amount of data which can be accommodated by the system, and preventing\ndistribution of the data across a wide area network.\n\n<P>The choice to control all aspects of the system leads to limited network\neffects. While readers are attracted to these systems by the rich, highly\nuseful content type provide, the amount and variety of this content is\nlimited.&nbsp; Due to the need to learn new editors, and because there\nare relatively few initial readers, content providers do not have a lot\nof incentive to provide content.&nbsp; Since there are no provisions for\nremote access to the hypermedia content, the population of readers is limited\nto those who have access to the local file system.&nbsp; Thus, though there\nwas sufficient initial interest from readers of these hypertexts, there\nwas insufficient motivation for content providers to add new information,\neventually leading to a lack of interest from readers.&nbsp; No network\neffects were generated.\n\n<P>The need to provide incentive for content providers was noted in [Fountain\net al., 1990], which states:\n<BLOCKQUOTE>The use of hypertext and hypermedia systems is still largely\nconfined to the research community.&nbsp; This is partly because of the\nlimitations of commercially available systems and partly because of the\ntremendous effort required to create and maintain a hypertext system.&nbsp;\nThese issues are compounded by the fact that currently available hypertext\npackages are basically closed systems, so that if material is created in\none system it is very difficult to integrate it with material created in\nanother system. We believe that this is a major barrier to the growth and\ndevelopment of hypertext and hypermedia applications outside the research\ncommunity. [p. 299]</BLOCKQUOTE>\nHypercard and StorySpace provide some limited exceptions to the lack of\nnetwork effects for monolithic hypertext systems.&nbsp; Since HyperCard\nwas freely distributed with Macintosh computers for several years, and\nHyperCard players are still part of the MacOS, a sufficient base of potential\nreaders existed to provide incentive for development of commercial HyperCard\nstacks.&nbsp; The ability to neatly package a hypertext into an easily\ntransportable unit, the stack, also facilitated the development of commercial\nHyperCard stacks. By adding commercial incentive to produce content, more\ncontent was developed for HyperCard than if all content utility depended\nsolely on the number of people reading free content.&nbsp; However, today\nthe majority of HyperCard content is educational, produced by educators\nwhose job is to produce content for a small collection of readers (their\nstudents), and hence do not require the incentive of a large set of readers\nto derive utility from the content.\n<BR>&nbsp;\n<BR>StorySpace is another interesting exception.&nbsp; With StorySpace,\ncontent providers use the system as a form of self-expression, and are\nnot motivated primarily by a large readership for their hypertexts, although\na commercial market for literary hypertext does exist. The self-expression\nprovides sufficient motivation to produce content, and the value provided\nby large numbers of readers is not necessary to \"prime the pump\" to provide\nincentive for generation of content. Also, given the artistic requirements\nfor total visual control over the hypertext, a monolithic hypertext system\nbest meets the needs of literary hypertext.\n<H2>\n3. Open Hypermedia Systems, Control Choices and Network Effects</H2>\nOpen hypermedia systems began as an explicit reaction against the closed\nnature of monolithic hypertext systems. [Pearl, 89], which describes the\nfirst open hypermedia system, begins with a paragraph describing the closed\nnature of monolithic hypertext systems, and and follows with a paragraph\nextolling the openness of Sun's Link Service. For most open hypermedia\nsystems (a non-exhaustive list includes DHM [Gronbaek et al., 1993], Hyperform\n[Wiil, Leggett, 1992], Microcosm [Davis et al., 1992],&nbsp; Multicard\n[Rizk, Sauter, 1992], and Chimera [Anderson et al., 1994]), a key quality\nof openness is the support of the heterogeneous tools which populate a\nuser's computing environment. The rationale for this requirement is generally\npragmatic: content is produced by these tools, and they are the locus of\nwork on the computer. To provide hypertext support to the user's environment,\nhypertext must be brought to the tools, rather than bringing the output\nof the tools to the hypertext system.\n\n<P>By focusing on adding hypertext functionality to desktop applications,\nopen hypermedia systems consciously relinquish control over the user interface\nfor data in the hypermedia system, and accept the need for an application\nlauncher component to invoke applications as needed to view data after\na link traversal. Other control choices vary (for an in-depth description\nof the various control tradeoffs&nbsp; in open hypermedia systems, see\n[Osterbye, Wiil, 1996]). Link server systems maintain control over the\nhypertext structure, but also relinquish control over the data being linked,\nallowing it to reside in multiple repositories. Open hyperbase systems\ncontrol both the hypertext structure and the data being linked, thus providing\ngreater consistency, but requiring applications to use its data repository.\n\n<P>Unlike monolithic hypertext systems, some designers of open hypermedia\nsystems directly considered network effects. [Pearl, 1989], in the conclusion\nnotes:\n<BLOCKQUOTE>With an open protocol, the power of each element of a system\nexpands as it interoperates with others.&nbsp; Open linking can make the\npower of hypertext available to the world of software.&nbsp; We hope to\nsee linking, and attendant hypertext capabilities, as much a standard part\nof the computer desktop as the cutting and pasting of text are today. [p.145]</BLOCKQUOTE>\n[Davis et al, 1992], provides a call to arms in its introduction:\n<BLOCKQUOTE>The next generation of hypermedia must appear to the user as\na facility of the operating system that is permanently available to add\ninformation linking and navigation facilities with the minimum amount of\nuser intervention and without subtracting any of the functionality that\nwas previously available. [p. 182]</BLOCKQUOTE>\nThe analysis of network effects for open hypermedia systems can still be\nviewed in terms of readers and content providers, but is shifted towards\nconsiderations of tool integration because the user interface to the data\nin the hypermedia system is via pre-existing tools which are generally\nhypertext unaware. Complicating the analysis is the common lack of a clear\ndistinction between readers and content providers.&nbsp; Since many open\nhypermedia systems have little or no separation between reading and authoring,\nreaders and content providers are often the same.\n\n<P>Readers are motivated to use an open hypermedia system because of the\nhypertext linking between related documents. As noted above in [Pearl,\n1989], hypertext linking increases the utility of each application, due\nto the interoperation provided by hypertext link traversals. Content providers\nhave incentive to add links because they are immediately useful (i.e.,\nthey are in data used by the content producer), or can be traversed by\nother users of the system. The ability to link together data is limited\nonly by the number of hypertext-aware applications. This realization motivates\nthe desire to provide open hypermedia services in the operating system,\nsince pervasive availability of hypermedia services would lead to more\nhypertext-aware applications.\n\n<P>Open hypermedia systems have many problems that stem directly from not\ncontrolling the user interface and not controlling the hyperlinked data,\nand these problems limit the ability to generate network effects. The editing\nproblem, the data versioning problem, and difficulties with user interface\nconsistency are noted in [Davis et al., 1992]. Add to these the difficulty\nof configuration management of different versions and types of applications\nacross user environments, and the problem of limited screen real estate\nafter several applications have been launched. Finally, the lack of highly\nscalable remote data access support in open hypermedia systems is also\na noted problem which has spawned much current research.&nbsp; Altogether,\nthese issues reduce the incentives for readers, and increase the maintenance\nburden for content providers. The lack of distribution support further\ncaps the total possible number of readers, putting an upper limit on the\npotential utility of the information. However, even if global distribution\nwas available, the problems inherent in providing hypertext services across\nwidely divergent user machine and application configurations would also\nlimit the utility of these hypertexts for readers.\n<H2>\n4. World Wide Web, Control Choices and Network Effects</H2>\nThe Web began as a reaction against an information space very similar to\nthat being touted as ideal by the open hypermedia community. Rather than\nhaving to use multiple programs on several computers to access information,\nthe Web aimed at being a unified access point for the information provided\nby these programs. Slides from a 1993 presentation [Berners-Lee, 1993]\ndescribe the concept of universal readership:\n<BLOCKQUOTE>Before W3, typically to find some information at CERN one had\nto have one of a number of different terminals connected to a number of\ndifferent computers, and one had to learn a number of different programs\nto access that data. The W3 principle of universal readership is that once\ninformation is available, it should be accessible from any type of computer,\nin any country, and an (authorized) person should only have to use one\nsimple program to access it.</BLOCKQUOTE>\nTo achieve this goal, the Web made different control tradeoffs from either\nmonolithic or open hypermedia systems, choosing to control the user interface\n(via the browser) but not controlling either the hypertext structure, or\nthe hypertext data.&nbsp; The lack of control over the hypertext structure\nand data allowed these aspects of the system to be massively decentralized.\nThe triad of standards, URL [Berners-Lee et al., 1994], HTTP [Fielding\net al., 1997], and HTML [Raggett et al., 1998] provided the foundation\nfor interoperation in a widely distributed, large-scale information space.\n\n<P>With the clarity of hindsight, the Web appears optimally suited for\ngenerating network effects.&nbsp; As the 1993 talk notes:\n<BLOCKQUOTE>To allow the web to scale, it was designed without any centralized\nfacility. Anyone can publish information, and anyone (authorized) can read\nit. There is no central control. To publish data you run a server, and\nto read data you run a client. All the clients and all the servers are\nconnected to each other by the Internet. The W3 protocols and other standard\nprotocols allow all clients to communicate with all servers.</BLOCKQUOTE>\nSince the Web provided a single user interface to existing repositories\nof information (a valuable interface on the early Web was to the phone\nbook at CERN), as well as hypertext linking from documents which supported\nHTML, readers had incentive to use the system. For content providers, the\nWeb offers a significant barrier to entry, requiring the installation and\nconfiguration of a Web server and, for many providers, initial or improved\nconnection to the Internet. Not surprisingly, the early Web was limited\nby the small amount of information available, and the fact this information\nwas related almost entirely to high energy particle physics. Two events\nin 1993 reduced the barriers to entry for both readers and content providers.&nbsp;\nFirst, the NCSA HTTP server was released, and was rapidly ported to most\ncurrent computing platforms.&nbsp; Unlike the other existing server, the\nCERN server, this server could be installed by any user, and did not require\nsuper user (root) access, and this allowed installation of Web servers\nwithout the need for securing buy-in from typically conservative computing\nsupport organizations. Second, the release of the Mosaic browser on Unix,\nMac and PC platforms increased the base of potential users, and provided\na visually pleasing interface which increased reader's incentives for using\nthe system. While these two events would eventually have touched off the\nfrenzy of growth which categorized the Web in 1994-6, an article in the\nBusiness section of the New York Times in December, 1993 [Markoff, 1993]\nadded sufficient new users to jump-start the cycle of increasing network\neffects, as new readers increased the incentives for content providers,\nwho provided more information, leading to more readers, etc.\n\n<P>By controlling the user interface, the Web is able to provide a single,\nattractive, easy-to-use entry point into the system. Recognizing that a\nsingle application cannot provide viewers for all media types, the typical\nbrowser provides launch-only hypertext services to invoke an application\nwhich displays the unknown media type, and plug-ins, which allow viewers\nfor unknown types to use the same screen real estate as the browser. If\nthe Web controlled the hypermedia structure, it would have led to a single\nscalability choke point as increasing numbers of systems accessed the same\nsystem for link information. By not placing control requirements on the\ndata displayed by the system, the Web could accommodate a wide range of\ninformation repositories, enabling more information providers.\n\n<P>Though the web has its noted drawbacks, with broken links, slow data\naccess, and lack of versioning support being more frequently mentioned\nproblems, it is notable that these problems have not disincentivized readers\nor content providers sufficiently to cause them to abandon the system,\nnor did they noticeably dampen the rate of adoption of the Web.\n<H2>\n5. Conclusion</H2>\nThis paper described a simple model of how the interaction between information\nproducers (content providers) and consumers (readers) leads to the generation\nof network effects in hypertext systems.&nbsp; Three classes of hypertext\nsystems, monolithic, open, and Web are analyzed from the perspective of\nthe control decisions embedded in their architectures, and how these control\ndecisions led to differing levels of network effects.\n\n<P>Although preliminary, the discussion in this paper are suggestive of\nseveral points. First, lack of control over the data in a hypermedia system,\ncombined with a large-scale distribution infrastructure is a key aspect\nof achieving network effects, since this control choice affords large numbers\nof readers. Examination of network effects from the Web and monolithic\nhypermedia systems suggests that control over the user interface is a key\ncontributor to network effects, since it incentivizes readers, and allows\nfor more control over the presentation by content providers. Control over\nthe hypermedia structure provides a negative contribution to network effects,\nsince the control point limits scalability, thus capping the total number\nof readers.\n<H2>\nReferences</H2>\n[Akscyn et al., 1988] R. Akscyn, D. L. McCracken, E. Yoder, KMS: A distributed\nhypermedia system for sharing knowledge in organizations, <I>Comm. ACM</I>,\n31(7), 820-835, July, 1988.\n\n<P>[Anderson et al., 1994] K. M. Anderson, R. N. Taylor, E. J. Whitehead,\nJr., Chimera: Hypertext for heterogeneous software environments, <I>Proc.\nECHT'94</I>, Edinburgh, Scotland, September, 1994, pages 94-107.\n\n<P>[Apple, 1987] Apple Computer, Inc., <I>Hypercard User's Guide</I>, Cupertino,\nCalifornia, 1987.\n\n<P>[Berners-Lee, 1993] T. Berners-Lee, WorldWide Web Seminar, unpublished\nslides, &lt;http://www.w3.org/Talks/General.html>.\n\n<P>[Berners-Lee et al., 1994] T. Berners-Lee, L. Masinter, M. McCahill,\n\"Uniform Resource Locators (URL)\", CERN, Xerox, Univ. of Minnesota, Internet\nRFC 1738, December, 1984.\n\n<P>[Bolter, 1987] J. D. Bolter, M. Joyce, Hypertext and Creative Writing,\n<I>Proc. Hypertext'87</I>, Baltimore, 1987, pages 41-50.\n\n<P>[Davis et al., 1992] H. Davis, W. Hall, I. Heath, G. Hill, Towards an\nintegrated information environment with open hypermedia systems, <I>Proc.\nECHT'92</I>, Milano, Italy, November-December, 1992, pages 181-190.\n\n<P>[Eastgate, 1991] Eastgate Systems, Inc., <I>Storyspace </I>hypertext\nwriting environment for Macintosh computers, 1991.\n\n<P>[Fielding et al., 1997] R. Fielding, J. Gettys, J. Mogul, H. Frystyk,\nT. Berners-Lee, \"Hypertext Transfer Protocol -- HTTP/1.1\", U.C. Irvine,\nDEC, MIT/LCS, Internet RFC 2068, January, 1997.\n\n<P>[Fountain et al., 1990] A. M. Fountain, W. Hall, I. Heath, H. Davis,\nMicrocosm, An open model for hypermedia with dynamic linking, <I>Proc.\nECHT'90</I>, Versailles, France, November, 1990, pages 298-311.\n\n<P>[Gronbaek et al., 1993] K. Gronbaek, J. A. Hem, O. L. Madsen, L. Sloth,\nDesigning Dexter-based cooperative hypermedia systems, <I>Proc. Hypertext'93</I>,\nSeattle, Washington, November, 1993, pages 25-38.\n\n<P>[Markoff, 1983] J. Markoff, A free and simple computer link; enormous\nstores of data are just a click away, <I>New York Times</I>, v143, Wed,\nDec 8, 1993, col 3.\n\n<P>[Nelson, 1981] T. H. Nelson, <I>Literary Machines</I>, self-published,\n1981.\n\n<P>[Osterbye, Wiil, 1996] K. Osterbye, U. K. Wiil, The Flag taxonomy of\nopen hypermedia systems, <I>Proc. Hypertext'96</I>, Washington, DC, March,\n1996, pages 129-139.\n\n<P>[Pearl, 1989] A. Pearl, Sun's Link Service: A protocol for open linking,\n<I>Proc. Hypertext'89</I>, Pittsburgh, Pennsylvania, November, 1989, pages\n137-146.\n\n<P>[Raggett et al., 1998] D. Raggett, A. Le Hors, I. Jacobs, \"HTML 4.0\nSpecification\", W3C Recommendation REC-html40-19980424, April, 1998.\n\n<P>[Rizk, Sauter, 1992] A. Rizk, L. Sauter, Multicard: An open hypermedia\nsystem, <I>Proc. ECHT'92</I>, Milano, Italy, November-December, 1992, pages\n4-10.\n\n<P>[Rohlfs, 1974] J. Rohlfs, A theory of interdependent demand for a communications\nservice, <I>Bell Journal of Economics</I> 5(1), 1974, pages 16-37.\n\n<P>[Wiil, Leggett, 1992] U. K. Wiil, J. J. Leggett, Hyperform: Using extensibility\nto develop dynamic, open and distributed hypertext systems, <I>Proc. ECHT'92</I>,\nMilano, Italy, November-December, 1992, pages 251-261.\n\n<P>[Yankelovich et al., 1988] N. Yankelovich, B. Haan, N. Meyrowitz, S.\nDrucker, Intermedia: the concept and the construction of a seamless information\nenvironment. <I>IEEE Computer</I>, 21(1):81-96, January, 1988.\n</BODY>\n</HTML>\n", "encoding": "ascii"}