{"url": "https://www.ics.uci.edu/~pattis/ICS-46/lectures/notes/bt.txt", "content": "\t\t\t\tBinary Trees\r\n\r\n\r\nTrees are one of the two most important data structure studied in Computer\r\nScience and Mathematics (the other is Graphs; in fact, trees are just a special\r\n-but important- kind of a graph: one with no cycles, and each node having at\r\nmost one node with an edge leading to it). Trees are useful for representing\r\nall kinds of interesting information and relationships (like the structure of a\r\nfile system or the (single) inheritance hierarchy of classes in C++  libraries),\r\nand have been studied extensively. There are entire books written about trees.\r\n\r\nIn this lecture we will continue our study of self-referential classes by\r\nexamining trees. Like linked lists, trees contain nodes: these nodes are\r\nobjects instantiated from a class that contains instance variables that refer\r\nto other nodes from this same class. Whereas pointer in the linked list class\r\nindicate a \"follows\" relationship (and in the case of doubly-linked lists\r\nalso a \"precedes\" relationship), pointer in tree classes indicate an inclusion\r\nrelationship (where a parent node includes all its children nodes): these\r\nrelationships are much more interesting in terms of the kinds of information\r\nand relationships that they can represent.\r\n\r\nAlthough we will first examine general tree structures, we will focus most of\r\nour attention in the upcoming lectures on defining and processing binary trees.\r\nWithin this category we will soon see examples of ordered (search) trees and\r\nstructure (expression) trees. In the next lecture we will use ordered search\r\ntrees to store sets/maps of values that can be searched quickly: on average in\r\nO(Log2 N). In the lecture after that we will use another kind of ordered binary\r\ntree (a heap) to store values in a priority queue that can be enqueued and\r\ndequeued quickly: at worst in O(Log2 N). In the next tree lecture, we will\r\ndiscuss self-balancing search trees. Finally, we continue for a few more\r\nlectures, discussing other variants of trees and their uses - and we will see\r\nspecial \"interted\" trees when discussing equivalence classes.\r\n\r\nBecause tree nodes typically have two or more pointers, we will often find it\r\nmuch more natural to write recursive code to process trees (as opposed to\r\niterative code).\r\n\r\n------------------------------------------------------------------------------\r\n\r\nTerminology and Metrics:\r\n\r\nAll kinds of trees illustate one important relationship: inclusion between\r\nparts and a whole; another way to describe this relationship is that between\r\na parent node that includes children nodes. Every child node has a unique parent\r\n(although root nodes have no parent); every parent node can have any number of\r\nchildren (including none). As in trees used in geneology, we will write each\r\nparent node directly above its child(ren) node(s). In fact, we will use other\r\ngeneological terms, like ancestor and descendant, when describing nodes in a\r\ntree. We draw lines between parent/child nodes to illustrate their direct\r\nrelationship.\r\n\r\nThere is one unique node in every tree: this node has no parent and is called\r\nthe \"root\" of the tree; because all other nodes in the tree are its descendants,\r\nwe write the root node at the top of the tree.\r\n\r\nA mutually exclusive way to classify tree nodes is as \"internal\" or \"leaf\". An\r\ninternal node has one or more children; a leaf node has no children. So, any\r\nnode that is a parent is an internal node; a node that is only a child (not a\r\nparent to another child) is a leaf node.\r\n\r\nFor linked lists we defined one metric: the size of the linked list (or its\r\nlength: the number of LNs it contains).\r\n\r\nFor trees we also define the size of a tree as the total number of nodes that it\r\ncontains. In addition, we define a second metric: height. The height of a tree\r\nis the length of the longest path (each line in the path counts as one step)\r\nfrom a root to any of its descendants. Alternatively, we can define the depth\r\nof a node as the length of the path from the root to that node, which is the\r\nsame as the number of direct ancestors that it has; given this definition of\r\ndepth, we can define the height of a tree as the largest depth of any of its\r\nnodes (its deepest node0; we can define the height of any node (not just the\r\nentire tree) as the length of the longest path from that node to any of its\r\ndescendants. The height of a tree is the height of its root.\r\n\r\nNote that the root is at depth 0, because it has no ancestors; a tree\r\nconsisting solely of a root also has a height of 0. The concepts of size and\r\nheight for trees generalize the length of linear linked list. We will examine\r\nthe numerical relationship between these two metrics at the end of this lecture.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nTrees and Tree Functions for Metics:\r\n\r\nWe will start by looking at a simple templated class named TN, which we use to\r\nrepresent (binary) Tree Nodes:  each TN<T> object points to (the root of) its\r\nleft and right subtrees, from that same class -or to nothing, represented by\r\nnullptr).\r\n\r\nThis class declares three public instance variables, instead of private ones\r\nwith accessor/setter methods (just as we did for LN: list nodes): note the\r\nsetters would allow any value to be stored there, so setters aren't of much use\r\n(and would increase the syntactic complexity). It also declares one default and\r\ncopy constructor and another useful constructor (also all public).\r\n\r\ntemplate<class T>\r\nclass TN {\r\n  public:\r\n    TN ()                        : left(nullptr), right(nullptr){}\r\n    TN (const TN<T>& tn)         : value(tn.value), left(tn.left), right(tn.right){}\r\n    TN (T v, TN<T>* l = nullptr,\r\n             TN<T>* r = nullptr) : value(v), left(l), right(r){}\r\n\r\n    T      value;\r\n    TN<T>* left;\r\n    TN<T>* right;\r\n};\r\n\r\nBinary Trees have a natural, recursive definition:\r\n\r\n  1) An empty tree (the smallest tree) is nullptr \r\n\r\n  2) Any non-empty tree is a pointer to an object (from class TN) whose left and\r\n     right instance variables point to some smaller tree (fewer TN objects\r\n     based on size or smaller height TN objects) either empty or not.\r\n\r\nUsing this defintion as a guide, we can often write tree processing code\r\nrecursively. This definition suggests an idiom for writing recursive functions,\r\ntreating an empty tree as the base case. We start our discussion of tree\r\nprocessing with a function that recursively computes the size of a tree: the\r\nnumber of TNs it contains. This function is simlar to/generalizes the\r\nsize/length function for linked lists. Most functions on trees naturally use\r\nrecursion (although we will see a few in the next lecture that can be written\r\niteratively more simply: but not size).\r\n\r\ntemplate<class T>\r\nint size(TN<T>* t) {\r\n  if (t == nullptr)\r\n    return 0;\r\n  else\r\n    return 1 + size(t->left) + size(t->right);\r\n}\r\n\r\nThis function computes the size of an empty tree as 0, and the size of a\r\nnon-empty tree is 1 (for the node of the tree t points to) plus the sum of the\r\nsizes of its left and right subtrees (which may be empty). Note that here (and\r\nin many other recursive functions operating on binary trees) we write two\r\nrecursive calls: one to process (the root of) the left subtree and one to\r\nprocess (the root of) the right subtree.\r\n\r\nWe can prove that this function is correct as follows.\r\n\r\n1) The size of the smallest/empty tree is 0. This function immediately\r\n   recognizes an empty tree as this base case and returns 0 because it\r\n   has no nodes.\r\n\r\n2) For any non-empty tree t, a recursive call on t->left and t->right is always\r\n   using an argument closer to the base case than t: each contains at least 1\r\n   fewer TNs than t does (and each can contain fewer than 1/2 the TNs t does);\r\n   and the height of a subtree is always smaller by at least 1.\r\n\r\n3) Assuming size(t->left) and size(t->right) compute the size correctly of\r\n   these subtrees, adding 1 (for the TN t points to) to these sized correctly\r\n   computes the size of the entire tree.\r\n\r\nNote that without some kind of array or other data type, we CANNOT write this\r\nfunction iteratively. If we try to use one cursor (as opposed to an array or\r\nstack of cursors) once we point the cursor to one subtree (say the left one) we\r\nhave lost our pointer to its parent and therefore its right subtree. This was\r\nnot often a problem in linked lists, where once we processed a node we could\r\nset the cursor to the next node, not having to go back to its predecessor. So,\r\nbefore we advance a cursor down one subtree, we would have to remember how to\r\nget to the other subtree.\r\n\r\nIt may be useful for you to hand simulate this recursive function on a small\r\ntree to understand its workings better. In a hand simulation, calls would\r\ngo up and down the call frames, unlike linear (linked list) recursion, which\r\ntends to go all the way down once and then back to the top.\r\n\r\nBelow is an iterative function that uses an explicit Stack to compute the size\r\nof a tree. It remembers the roots of both the left and right subtrees for each\r\nTN it visits on a Stack, where it can use each TN value when needed.\r\n\r\ntemplate<class T>\r\nint size (TN<T>* t) {\r\n  int answer = 0;\r\n  ArrayStack<TN<T>*> s;     //Stack contains pointers to TN<T> objects\r\n  s.push(t);\t     \t    //Put the root on the \r\n  while (!s.empty()) {\r\n    TN<T>* next = s.pop();  //Examine some subtree (possibly empty)\r\n    if (next != nullptr) {  //If not empty\r\n      ++answer;\t\t    //  Count it\r\n      s.push(next->left);   //  Put roots of its left/right subtrees ontoStack\r\n      s.push(next->right);\r\n    }\r\n  }\r\n\r\n  return answer;\r\n}\r\n\r\nThis is not as elegant or clear as the recursive size function. It uses an\r\nexplicit stack, whereas recursion uses an implicit one.\r\n\r\nWe can also write a recursive function to compute the height of binary tree.\r\nFirst, we will do so by directly translating the meaning of height; then we\r\nwill write a smaller and simpler to understand function using a different\r\ndifferent meaning of height (allowing the height of empty trees to be computed,\r\nwhich leads to a dramatic simplification of the code).\r\n\r\nNote that height of a (sub)tree that is a leaf node is just 0: the length of the\r\nlongest path from a leaf node to its deepest descendant is 0 (it is its own\r\ndeepest descendent). Also note that the height of an internal node is 1 more\r\nthan the biggest height of its subtrees. Using these facts we can write the\r\nfollowing recursive function to compute the height of any non-empty tree.\r\n\r\ntemplate<class T>\r\nint height (TN<T>* t) {\r\n  if (t->left == nullptr && t->right == nullptr)//leaf check\r\n    return 0;\r\n  else if (t->left == nullptr)\t\t\t//1 subtree: branch to right\r\n    return 1 + height(t->right);\r\n  else if (t->right == nullptr)\t\t\t//1 subtree: branch to left\r\n    return 1 + height(t->left);\r\n  else\t\t\t\t\t\t//2 subtrees: branch left/right\r\n    return 1 + std::max(height(t->left),height(t->right));\r\n}\r\n\r\nThis function deals with all the necessary cases in a binary tree: a leaf node,\r\nan internal node with only a left (or only a right) subtree, and an internal\r\nnode with both left and right subtrees. But, this function does not work on\r\nempty trees, which have no directly defined height from the previous definition.\r\n\r\nThis function works only on non-empty trees: its base case is a leaf. Nest, we\r\nexamine whether there is an advantage to enlarging the domain of this function\r\nto include empty trees. There is, but we need to investigate how to correctly\r\ncompute the height of an empty tree.\r\n\r\nNow, let us simplify this code by defining the height of an empty tree to be -1.\r\nIn one case this seems very strange, but in another it seems obvious: an empty\r\ntree should have a height that is one less than a leaf node (whose height is 0).\r\nBy expanding the domain of computing heights to empty trees using this\r\ndefinition (and what we know previously), we can simplify the height function\r\n(as well as defining it for all possible trees, even empty ones) into the\r\nelegant function written below.\r\n\r\ntemplate<class T>\r\nint height (TN<T>* t) {\r\n  if (t == nullptr)\r\n    return -1;\r\n  else\r\n    return 1 + std::max(height(t->left),height(t->right));\r\n}\r\n\r\nAgain, if t is a leaf node (height 0), then its left and right subtrees are\r\nempty, so this function would perform the two recursive calls and return\r\n1 + std::max(-1,-1) which returns 0: the correct answer for a leaf node. So,\r\nusing this generalization of height, our code is simpler and always works (no\r\nmatter whether an empty or non-empty tree is passed as an argument); in the\r\nearlier method, passing an empty tree as a parameter would cause C++ to try to\r\nfollow a nullptr when it tried to determine if the node was a leaf.\r\n\r\nMathematicians generalize definitions such as this one all the time. You may or\r\nmay not know that a^0 is defined as 1 (even when a is 0). There are many ways to\r\njustify this definition (some quite complicated); the simplest way is to note\r\nthe simple algebraic law a^x * a^y = a^(x+y). By this law (a quite useful one to\r\nhave) a^0 * a^x = a^(0+x) = a^x; which means that a^0 must be equal to 1 for\r\nthis identity to hold. Note even 0^0 is 1.\r\n\r\nSo, although it might make no intuitive sense to define an empty tree to have a\r\nheight of -1 (height would seem to be required to be positive, or at least non-\r\nnegative), by using this definition we can define the height of any tree\r\n(nullptr or not) and simplify the method that computes heights. There is not\r\nanother value that we can return for the height of an empty tree that will allow\r\nthe height function to compute values correctly.\r\n\r\nHere is a function (and its helper function) that computes the depth of the\r\nnode containing a value: a node with this value must be UNIQUE, occurring only\r\nonce in the tree. If the node is not in the binary tree, it returns -1. We\r\nsometimes will need to write a helper function (typicaly one with more\r\nparameters) to process a tree recursively.\r\n\r\ntemplate<class T>\r\nint depth (TN<T>* t, const T& value)\r\n{return depth(t,value,0);}\r\n\r\ntemplate<class T>\r\nint depth (TN<T>* t, const T& value, int current_depth) {\r\n  if (t == nullptr)\r\n    return -1;\t\t\t//Not in tree\r\n  else if (t->value == value)\r\n    return current_depth;       //In tree, return accumulated\r\n  else\r\n    return std::max(depth(t->left,  value, current_depth+1),\r\n                    depth(t->right, value, current_depth+1));\r\n\r\nNote, we are not yet dealing with binary SEARCH trees, so the value might be\r\nin the left or right subtree. At most one recursive call will return a value\r\nnot equal to -1 (and both may return -1). If both recursive calls return -1,\r\nthen -1 is returned; if one returns a non-negative value, then that value is\r\nreturned.\r\n\r\nWe could improve the speed of this function by not computing depth(t->right...)\r\nwhen it finds value in the left subtree: we can change the final return\r\nstatement into the block\r\n\r\n...\r\n  else {\r\n    int left_depth = depth(t->left, value, current_depth+1);\r\n    if (left_depth != -1)\r\n      return left_depth;\r\n    else\r\n      return depth(t->right, value, current_depth+1);\r\n} \r\n\r\nCan you think of a way to compute depth for a single function whose prototype is\r\n\r\n  int depth (TN<T>* t, T value)\r\n\r\n\r\nAs a last function in this mold (a non-recursive function calling a recursive\r\nhelper function), here is how to overload << for printing binary trees (rotated\r\n90 degrees counter-clockwise). That is, if we had the binary tree\r\n\r\n                        a\r\n                     /      \\\r\n                  b            c\r\n               /    \\        /   \\\r\n             d        e     f     g\r\n\r\nit would print as follows (notice that each value at depth d has 2*d dots\r\npreceding its value).\r\n\r\n....g\r\n..c\r\n....f\r\na\r\n....e\r\n..b\r\n....d\r\n\r\ntemplate<class T>\r\nvoid print_rotated(TN<T>* t,std::string  indent, std::ostream& outs) {\r\n  if (t == nullptr)\r\n    return;\r\n  else {\r\n    print_rotated(t->right, indent+\"..\", outs);\r\n    outs << indent << t->value << std::endl;\r\n    print_rotated(t->left, indent+\"..\", outs);\r\n  }\r\n}\r\n\r\ntemplate<class T>\r\nstd::ostream& operator << (std::ostream& outs, TN<T>* t) {\r\n  print_rotated(t,\"\",outs);\r\n  return outs;\r\n}\r\n\r\nWe can prove that this function is correct as follows.\r\n\r\n1) An empty tree has no values and prints nothing. This function immediately\r\n   recognizes this base case and returns.\r\n\r\n2) For any non-empty tree t, a recursive call on t->right and t->left is always\r\n   using an argument closer to the base case than t: each contains at least 1\r\n   fewer TNs than t does (and often each contains about 1/2 the TNs t does).\r\n\r\n3) Assuming print_rotated(t->right) and print_rotated(t->left) print these\r\n   subtrees correctly, by printing t->value indented by some number of .. based\r\n   on the depth of the node, with t->right printed first (rotated 90 degrees \r\n   counter-clockwise, with every node indented two more than t->value), and\r\n   t->left printed second (rotated 90 degrees counter-clockwise with every node\r\n   indented two more than t->value), the entire tree t is printed rotated 90\r\n   degrees counter-clockwise with every node printed correctly.\r\n\r\nNote that in trees rotated 90 degrees counter-clockwise, the right subtree\r\nis printed first (on top of) the TN followed by the left subtree, each with\r\nthe correct .. indentation.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nRelationships between size and height\r\n\r\nWe can use the structure of binary trees to derive some mathematical\r\nrelationships between their sizes and heights. First, we should reiterate that\r\nthe \"inclusion\" relationships modeled by trees is much more interesting than\r\nthe \"follows\" relationship that is modeled by linear linked lists. One way to\r\nillustrate the difference in \"interestingness\" is by examining all structurally\r\ndifferent (different looking) linked lists containing 4 nodes, independent of\r\nthe values they store: there is only one. Although all 4 node linear linked\r\nlists have the same structure, there are 14 differently-structured binary trees\r\nwith 4 nodes (and 42 different trees with 5 nodes). See the picture accompanying\r\nthis lecture.\r\n\r\n-----\r\nSide note:\r\n\r\nThere is a formula using combinatorics to compute the number of different binary\r\ntrees of size n: (2n)!/( n!(n+1)! ), which is closely approximated by\r\n4^n/sqrt(pi*n^3) having about a 10% error for n=10 and less than a 1% error for\r\nn=100, and even less error for larger n. There are Cn different n node trees\r\n(Cn is the nth Catalan number). Here is a method that is more intuitive for\r\ncomputing this value\r\n\r\n  int count_binary_trees (int n) {\r\n    if (n == 0 || n == 1)\r\n      return 1;\r\n    else {\r\n      int count = 0;\r\n      for (int left_n = 0; left_n < n; ++left_n)\r\n        count += count_binary_trees(left_n) * count_binary_trees(n-left_n-1) ;\r\n      return count;\r\n    }\r\n  }\r\n\r\nThis function uses both iteration and recursion together to compute its result\r\n(and it won't be the last function that we see with this combination). Here the\r\nbase cases shows that all empty or 1 node trees look the same (there is exactly\r\none structure for each). Otherwise, we sum the number of trees  whose left\r\nsubtree is of size 0, 1, 2, ... , n-1 and whose right subtree is the remaining\r\nsize (minus 1 for the parent of the two subtrees). If there are l different\r\ntrees on the left and r different trees on the right, for that size there are a\r\ntotal of l*r different trees for that n.\r\n\r\nThis computation is similar to computing the number of isomers of a chemical\r\nmolecule (which is more a graph than a tree, because of possible double-bonds).\r\n-----\r\n\r\nWe define a pathological tree as one with only one node at each depth (the 8 at\r\nthe bottom of the picture). In all pathological trees, we have height = size-1.\r\n\r\nAt the other end of the spectrum is a perfect tree, in which every depth is\r\nfilled with as many nodes as possible (none of the trees mentioned above satisfy\r\nthis criteria). The next picture shows perfect trees of height 0, 1, 2, and 3.\r\n\r\nIf we tabulate this data we have.\r\n\r\nheight\tmaximum size\r\n  0\t  1\r\n  1\t  3\r\n  2\t  7\r\n  3\t 15\r\n\r\nIf we study and extend this table, we can guess a simple but interesting\r\nrelationship between the height of a perfect tree and its size:\r\nmaximum size = 2^(height+1) - 1. First, verify that this formula is correct for\r\nthe heights/sizes shown. Now, let's prove it by induction.\r\n\r\n1. For a perfect tree of height 0, the formula is true (by evaluation).\r\n\r\n2. Lets's assume that this formula is true for all perfect trees of height less\r\n   than or equal to h, and prove that it is true for a tree of height h+1.\r\n   To construct a perfect tree of height h+1 examine the last picture for this\r\n   lecture. The number of nodes in the entire perfect tree is\r\n\r\n   1 + 2^(h+1) - 1 + 2^(h+1) - 1 = 2^( (h+1) + 1 ) - 1\r\n\r\n   Which matches the formula and complete the proof.\r\n\r\nRewriting this equality to express minimum height as a function of size, we\r\nhave, minimum height = Log2(size+1) - 1.\r\n\r\nNow we will look at the relationship between the two tree metrics: size and\r\nheight. We will use N for the size and H for the height.\r\n\r\nIt is simple to see that the maximum height of a tree with N nodes is N-1 (each\r\nparent node in the tree has one child). So H <= N-1. From the proof above, the\r\nmaximum size of a tree has N <= 2^(H+1)-1. So, H-1 <= N <= 2^(H+1)-1. Thus, we\r\ncan say that N is Omega(H) and O(2^H): N must grow at least as fast as the\r\nheight, but no faster than 2 raised to the height power. Note that since\r\nN <= 2(H+1) - 1 = 2 * 2^H -1, which is O(2^H) by removing the multiplicative\r\nand additive constants\r\n\r\nWe can look at this relationship from the perspective from N as well, to compute\r\nbounds on H from N: \r\n\r\n  (1) H <= N-1\r\n  (2) H >= (Log2 N+1) - 1 >=  (Log2 N) - 1\r\n\r\nSo H is O(N) and H is Omega(Log2 N): H must grow at least as fast as Log2 of\r\nthe size, but can grow no faster than the size.\r\n\r\nSo, here are two more examples where we have lower-bounds and upper-bounds\r\nrelating N and H, so we can use big-Omega and big-O notation in a meaningful\r\nway. There is no big-Theta because these bounds are in different complexity\r\nclasses.\r\n\r\nIn the next lecture we will learn that the complexity class for searching a\r\nBinary Search Tree (BST) is related to its height: it is O(H). For perfect\r\ntrees the complexity class is O(Log2 N), but in the worst case it is O(N). If we\r\ncan keep our binary trees reasonably full/well-balanced, we will be able to\r\nsearch them in the same complexity class as doing binary search on sorted\r\narrays.\r\n\r\nIn fact, balanced BSTs allow us to simultaneously (on average) achieve O(Log2 N)\r\nbehavior for adding, searching, and removing values -not achievable with arrays\r\nor linked lists: where some operations can have this complexity class, but\r\nothers will be O(N). For example, we can search a sorted array in O(Log2 N), but\r\nadding or removing values requires, in the worst case, shifting N values in the\r\narray, so that operation is O(N).\r\n", "encoding": "ascii"}