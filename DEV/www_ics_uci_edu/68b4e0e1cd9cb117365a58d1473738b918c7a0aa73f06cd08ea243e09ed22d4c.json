{"url": "https://www.ics.uci.edu/~majumder/VC/211HW3/vlfeat/doc/matlab/vl_svmtrain.html", "content": "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n   <html xmlns=\"http://www.w3.org/1999/xhtml\">\n <head>\n  <!-- IE Standards Mode -->\n  <meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"></meta>\n\n  <!-- Favicon -->\n  <link href=\"../images/vl_blue.ico\" type=\"image/x-icon\" rel=\"icon\"></link>\n  <link href=\"../images/vl_blue.ico\" type=\"image/x-icon\" rel=\"shortcut icon\"></link>\n\n  <!-- Page title -->\n  <title>VLFeat - Documentation > MATLAB API > MISC - vl_svmtrain</title>\n\n  <!-- Stylesheets -->\n  <link href=\"../vlfeat.css\" type=\"text/css\" rel=\"stylesheet\"></link>\n  <link href=\"../pygmentize.css\" type=\"text/css\" rel=\"stylesheet\"></link>\n  <style xml:space=\"preserve\">\n    /* fixes a conflict between Pygmentize and MathJax */\n    .MathJax .mo, .MathJax .mi {color: inherit ! important}\n  </style>\n  \n\n  <!-- Scripts-->\n  \n\n  <!-- MathJax -->\n  <script xml:space=\"preserve\" type=\"text/x-mathjax-config\">\n    MathJax.Hub.Config({\n    tex2jax: {\n      inlineMath: [ ['$','$'], ['\\\\(','\\\\)'] ],\n      processEscapes: true,\n    },\n    TeX: {\n      Macros: {\n        balpha: '\\\\boldsymbol{\\\\alpha}',\n        bc: '\\\\mathbf{c}',\n        be: '\\\\mathbf{e}',\n        bg: '\\\\mathbf{g}',\n        bq: '\\\\mathbf{q}',\n        bu: '\\\\mathbf{u}',\n        bv: '\\\\mathbf{v}',\n        bw: '\\\\mathbf{w}',\n        bx: '\\\\mathbf{x}',\n        by: '\\\\mathbf{y}',\n        bz: '\\\\mathbf{z}',\n        bsigma: '\\\\mathbf{\\\\sigma}',\n        sign: '\\\\operatorname{sign}',\n        diag: '\\\\operatorname{diag}',\n        real: '\\\\mathbb{R}',\n      },\n      equationNumbers: { autoNumber: 'AMS' }\n      }\n    });\n  </script>\n  <script src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\" xml:space=\"preserve\" type=\"text/javascript\"></script>\n\n  <!-- Google Custom Search -->\n  <script xml:space=\"preserve\">\n    (function() {\n    var cx = '003215582122030917471:oq23albfeam';\n    var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;\n    gcse.src = (document.location.protocol == 'https' ? 'https:' : 'http:') +\n    '//www.google.com/cse/cse.js?cx=' + cx;\n    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);\n    })();\n  </script>\n\n  <!-- Google Analytics -->\n  <script xml:space=\"preserve\" type=\"text/javascript\">\n    var _gaq = _gaq || [];\n    _gaq.push(['_setAccount', 'UA-4936091-2']);\n    _gaq.push(['_trackPageview']);\n    (function() {\n    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;\n    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';\n    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);\n    })();\n  </script>\n </head>\n\n <!-- Body Start -->\n <body>\n  <div id=\"header-section\">\n    <div id=\"header\">\n      <!-- Google CSE Search Box -->\n      <div class=\"searchbox\">\n        <gcse:searchbox-only autoCompleteMaxCompletions=\"5\" autoCompleteMatchType=\"any\" resultsUrl=\"http://www.vlfeat.org/search.html\"></gcse:searchbox-only>\n      </div>\n      <h1 id=\"id-16\"><a shape=\"rect\" href=\"../index.html\" class=\"plain\"><span id=\"vlfeat\">VLFeat</span><span id=\"dotorg\">.org</span></a></h1>\n    </div>\n    <div id=\"sidebar\"> <!-- Navigation Start -->\n      <ul>\n<li><a href=\"../index.html\">Home</a>\n<ul>\n<li><a href=\"../about.html\">About</a>\n</li>\n<li><a href=\"../license.html\">License</a>\n</li>\n</ul></li>\n<li><a href=\"../download.html\">Download</a>\n<ul>\n<li><a href=\"../install-matlab.html\">Using from MATLAB</a>\n</li>\n<li><a href=\"../install-octave.html\">Using from Octave</a>\n</li>\n<li><a href=\"../install-shell.html\">Using from the command line</a>\n</li>\n<li><a href=\"../install-c.html\">Using from C</a>\n<ul>\n<li><a href=\"../xcode.html\">Xcode</a>\n</li>\n<li><a href=\"../vsexpress.html\">Visual C++</a>\n</li>\n<li><a href=\"../gcc.html\">g++</a>\n</li>\n</ul></li>\n<li><a href=\"../compiling.html\">Compiling</a>\n<ul>\n<li><a href=\"../compiling-unix.html\">Compiling on UNIX-like platforms</a>\n</li>\n<li><a href=\"../compiling-windows.html\">Compiling on Windows</a>\n</li>\n</ul></li>\n</ul></li>\n<li><a href=\"../overview/tut.html\">Tutorials</a>\n<ul>\n<li><a href=\"../overview/frame.html\">Local feature frames</a>\n</li>\n<li><a href=\"../overview/covdet.html\">Covariant feature detectors</a>\n</li>\n<li><a href=\"../overview/hog.html\">HOG features</a>\n</li>\n<li><a href=\"../overview/sift.html\">SIFT detector and descriptor</a>\n</li>\n<li><a href=\"../overview/dsift.html\">Dense SIFT</a>\n</li>\n<li><a href=\"../overview/liop.html\">LIOP local descriptor</a>\n</li>\n<li><a href=\"../overview/mser.html\">MSER feature detector</a>\n</li>\n<li><a href=\"../overview/imdisttf.html\">Distance transform</a>\n</li>\n<li><a href=\"../overview/encodings.html\">Fisher Vector and VLAD</a>\n</li>\n<li><a href=\"../overview/gmm.html\">Gaussian Mixture Models</a>\n</li>\n<li><a href=\"../overview/kmeans.html\">K-means clustering</a>\n</li>\n<li><a href=\"../overview/aib.html\">Agglomerative Infromation Bottleneck</a>\n</li>\n<li><a href=\"../overview/quickshift.html\">Quick shift superpixels</a>\n</li>\n<li><a href=\"../overview/slic.html\">SLIC superpixels</a>\n</li>\n<li><a href=\"../overview/svm.html#tut.svm\">Support Vector Machines (SVMs)</a>\n</li>\n<li><a href=\"../overview/kdtree.html\">KD-trees and forests</a>\n</li>\n<li><a href=\"../overview/plots-rank.html\">Plotting AP and ROC curves</a>\n</li>\n<li><a href=\"../overview/utils.html\">Miscellaneous utilities</a>\n</li>\n<li><a href=\"../overview/ikm.html\">Integer K-means</a>\n</li>\n<li><a href=\"../overview/hikm.html\">Hierarchical integer k-means</a>\n</li>\n</ul></li>\n<li><a href=\"../applications/apps.html\">Applications</a>\n</li>\n<li class='active'><a href=\"../doc.html\">Documentation</a>\n<ul>\n<li class='active'><a href=\"matlab.html\">MATLAB API</a>\n</li>\n<li><a href=\"../api/index.html\">C API</a>\n</li>\n<li><a href=\"../man/man.html\">Man pages</a>\n<ul>\n<li><a href=\"../man/mser.html\">mser</a>\n</li>\n<li><a href=\"../man/sift.html\">sift</a>\n</li>\n<li><a href=\"../man/vlfeat.html\">vlfeat</a>\n</li>\n</ul></li>\n</ul></li>\n</ul>\n\n    </div> <!-- sidebar -->\n  </div>\n  <div id=\"headbanner-section\">\n    <div id=\"headbanner\">\n      <span class='page'><a href=\"../doc.html\">Documentation</a></span><span class='separator'>></span><span class='page'><a href=\"matlab.html\">MATLAB API</a></span><span class='separator'>></span><span class='page'><a href=\"vl_svmtrain.html\">MISC - vl_svmtrain</a></span>\n    </div>\n  </div>\n  <div id=\"content-section\">\n    <div id=\"content-wrapper\">\n      <div id=\"content\">\n        <div class=\"mdoc\">\n<ul class=\"breadcrumb\"><li><a href=\"matlab.html\">Index</a></li><li><a href=\"vl_svmpegasos.html\">Prev</a></li><li><a href=\"vl_threads.html\">Next</a></li></ul><div class=\"documentation\"><p>\n[W B] = <a href=\"vl_svmtrain.html\">VL_SVMTRAIN</a>(X, Y, LAMBDA) trains a linear Support Vector\nMachine (SVM) from the data vectors X and the labels Y. X is a D\nby N matrix, with one column per example and D feature dimensions\n(SINGLE or DOUBLE). Y is a DOUBLE vector with N elements with a\nbinary (-1 or +1) label for each training point. To a first order\napproximation, the function computes a weight vector W and offset\nB such that the score W'*X(:,i)+B has the same sign of LABELS(i)\nfor all i.\n</p><p>\n<a href=\"vl_svmtrain.html\">VL_SVMTRAIN</a>(DATASET, LABELS, LAMBDA) takes as input a DATASET\nstructure, which allows more sophisticated input formats to be\nsupported (see <a href=\"vl_svmdataset.html\">VL_SVMDATASET</a>()).\n</p><p>\n[W, B, INFO] = <a href=\"vl_svmtrain.html\">VL_SVMTRAIN</a>(...) additionally returns a structure\nINFO with the following fields:\n</p><dl><dt>\niteration\n</dt><dd><p>\nNumber of iterations performed.\n</p></dd><dt>\nepoch\n</dt><dd><p>\nNumber of iterations over number of training data points.\n</p></dd><dt>\nelapsedTime\n</dt><dd><p>\nTime elapsed since the start of training.\n</p></dd><dt>\nobjective\n</dt><dd><p>\nSVM objective value.\n</p></dd><dt>\nregularizer\n</dt><dd><p>\nRegularizer value.\n</p></dd><dt>\nloss\n</dt><dd><p>\nLoss value.\n</p></dd><dt>\nscoreVariation\n<span class=\"defaults\">[SGD only]</span></dt><dd><p>\nMean square root of the difference between the last two\nvalues of the SVM scores for each point.\n</p></dd><dt>\ndualObjective\n<span class=\"defaults\">[SDCA only]</span></dt><dd><p>\nDual objective value.\n</p></dd><dt>\ndualLoss\n<span class=\"defaults\">[SDCA only]</span></dt><dd><dl><dt>\nDual loss value\n</dt></dl></dd><dt>\ndualityGap\n<span class=\"defaults\">[SDCA only]</span></dt><dd><p>\nDifference between the objective and the dual objective.\n</p></dd></dl><p>\n[W, B, INFO, SCORES] = <a href=\"vl_svmtrain.html\">VL_SVMTRAIN</a>(X, Y, LABMDA) returns a row\nvector of the SVM score for each training point. This can be used\nin combination with the options SOLVER, MODEL, and BIAS to\nevaluate an existing SVM on new data points. Furthermore INFO will\ncontain the corresponding SVM loss, regularizer, and objective\nfunction value. If this information is not of interest, it is\npossible to pass a null vector Y instead of the actual labels as\nwell as a null regularizer.\n</p><p>\n<a href=\"vl_svmtrain.html\">VL_SVMTRAIN</a>() accepts the following options:\n</p><dl><dt>\nVerbose\n</dt><dd><p>\nSpecify one or multiple times to increase the verbosity level.\nGiven only once, produces messages at the beginning and end of\nthe learning. Verbosity of at least 2 prints information at\nevery diagnostic step.\n</p></dd><dt>\nEpsilon\n<span class=\"defaults\">1e-3</span></dt><dd><p>\nTolerance for the stopping criterion.\n</p></dd><dt>\nMaxNumIterations\n<span class=\"defaults\">10/LAMBDA</span></dt><dd><p>\nMaximum number of iterations.\n</p></dd><dt>\nBiasMultiplier\n<span class=\"defaults\">1</span></dt><dd><p>\nValue of the constant B0 used as bias term (see below).\n</p></dd><dt>\nBiasLearningRate\n<span class=\"defaults\">0.5</span></dt><dd><p>\nLearning rate for the bias (SGD solver only).\n</p></dd><dt>\nDiagnosticFunction\n<span class=\"defaults\">[]</span></dt><dd><p>\nDiagnostic function callback. The callback takes the INFO\nstructure as only argument. To trace energies and plot graphs,\nthe callback can update a global variable or, preferably, be\ndefined as a nested function and update a local variable in the\nparent function.\n</p></dd><dt>\nDiagnosticFrequency\n<span class=\"defaults\">Number of data points</span></dt><dd><p>\nAfter how many iteration the diagnostic is run. This step check\nfor convergence, and is done rarely, typically after each epoch\n(pass over the data). It also calls the DiangosticFunction,\nif any is specified.\n</p></dd><dt>\nLoss\n<span class=\"defaults\">HINGE</span></dt><dd><p>\nLoss function. One of HINGE, HINGE2, L1, L2, LOGISTIC.\n</p></dd><dt>\nSolver\n<span class=\"defaults\">SDCA</span></dt><dd><p>\nOne of SGD (stochastic gradient descent [1]), SDCA (stochastic\ndual coordinate ascent [2,3]), or NONE (no training). The\nlast option can be used in combination with the options MODEL\nand BIAS to evaluate an existing SVM.\n</p></dd><dt>\nModel\n<span class=\"defaults\">null vector</span></dt><dd><p>\nSpecifies the initial value for the weight vector W (SGD only).\n</p></dd><dt>\nBias\n<span class=\"defaults\">0</span></dt><dd><p>\nSpecifies the initial value of the bias term (SGD only).\n</p></dd><dt>\nWeights\n<span class=\"defaults\">[]</span></dt><dd><p>\nSpecifies a weight vector to assign a different non-negative\nweight to each data point. An application is to rebalance\nunbalanced datasets.\n</p></dd></dl><p>\nFORMULATION\n</p><p>\n<a href=\"vl_svmtrain.html\">VL_SVMTRAIN</a>() minimizes the objective function of the form:\n</p><pre>\n  LAMBDA/2 |W|^2 + 1/N SUM_i LOSS(W' X(:,i), Y(i))\n</pre><p>\nwhere LOSS(W' Xi,Yi) is the loss (hinge by default) for i-th\ndata point. The bias is incorporated by extending each data\npoint X with a feature of constant value B0, such that the\nobjective becomes\n</p><pre>\n LAMBDA/2 (|W|^2 + WB^2) 1/N SUM_i LOSS(W' X(:,i) + WB B0, Y(i))\n</pre><p>\nNote that this causes the learned bias B = WB B0 to shrink\ntowards the origin.\n</p><dl><dt>\nExample\n</dt><dd><p>\nLearn a linear SVM from data X and labels Y using 0.1\nas regularization coefficient:\n</p><pre>\n  [w, b] = vl_svmtrain(x, y, 0.1) ;\n</pre><p>\nThe SVM can be evaluated on new data XTEST with:\n</p><pre>\n  scores = w'*xtest + b ;\n</pre><p>\nAlternatively, <a href=\"vl_svmtrain.html\">VL_SVMTRAIN</a>() can be used for evaluation too:\n</p><pre>\n  [~,~,~, scores] = vl_svmtrain(xtest, y, 0, 'model', w, 'bias', b, 'solver', 'none') ;\n</pre><p>\nThe latter form is particularly useful when X is a DATASET structure.\n</p></dd></dl><p>\nSee also: <a href=\"../api/svm.html\">SVM fundamentals</a>,\n<a href=\"vl_svmdataset.html\">VL_SVMDATASET</a>(), <a href=\"vl_help.html\">VL_HELP</a>().\n</p></div></div>\n      </div>\n      <div class=\"clear\">&nbsp;</div>\n    </div>\n  </div> <!-- content-section -->\n  <div id=\"footer-section\">\n    <div id=\"footer\">\n      &copy; 2007-13 The authors of VLFeat\n    </div> <!-- footer -->\n  </div> <!-- footer section -->\n </body>\n <!-- Body ends -->\n</html>\n ", "encoding": "ascii"}