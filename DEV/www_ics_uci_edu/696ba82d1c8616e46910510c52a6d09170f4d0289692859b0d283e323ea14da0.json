{"url": "https://www.ics.uci.edu/~thornton/ics46/Notes/AmortizedAnalysis/", "content": "<?xml version=\"1.0\" encoding=\"iso-8859-1\"?>\r\n<!DOCTYPE html PUBLIC\r\n \"-//W3C//DTD XHTML 1.1//EN\"\r\n \"http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd\">\r\n\r\n<html xmlns=\"http://www.w3.org/1999/xhtml\" xml:lang=\"en\">\r\n\r\n<head>\r\n<meta http-equiv=\"content-type\" content=\"text/html; charset=iso-8859-1\" />\r\n<link rel=\"stylesheet\" href=\"../../course.css\" type=\"text/css\" />\r\n\r\n<title>ICS 46 Spring 2018, Notes and Examples: Amortized Analysis</title>\r\n\r\n</head>\r\n\r\n<body>\r\n\r\n<div class=\"navbar\">\r\n\r\n<p>\r\nICS 46 Spring 2018 |\r\n<a href=\"../../index.html\">News</a> |\r\n<a href=\"../../CourseReference.html\">Course Reference</a> |\r\n<a href=\"../../Schedule.html\">Schedule</a> |\r\n<a href=\"../../ProjectGuide\">Project Guide</a> |\r\n<a href=\"../../Notes\">Notes and Examples</a> |\r\n<a href=\"http://www.ics.uci.edu/~thornton/\">About Alex</a>\r\n</p>\r\n\r\n<hr />\r\n\r\n</div>\r\n\r\n<div class=\"header\">\r\n\r\n<p>ICS 46 Spring 2018<br />\r\n   Notes and Examples: Amortized Analysis</p>\r\n\r\n</div>\r\n\r\n<div class=\"section\">\r\n\r\n<hr />\r\n\r\n<p class=\"title\">Analyzing the behavior of std::vector</p>\r\n\r\n<p>In previous coursework, you've likely used the <b>std::vector</b> class template in the C++ Standard Libary.  Vectors implement the abstract notion of a list &mdash; a sequence of elements &mdash; by storing its elements in an array.  When there are <i>n</i> elements stored in the vector, they're required to be stored in the first <i>n</i> cells of the array, with any additional capacity in the array left available for additional elements to be added.  At any given time, you can ask a vector its size (i.e., how many elements it currently stores) and its capacity (i.e., how big the underlying array is).</p>\r\n\r\n<p>Based on our previous understanding of arrays, we can do some quick asymptotic analysis on various <b>std::vector</b> operations, so we can understand their performance impact.</p>\r\n\r\n<ul>\r\n  <li><i>Accessing the element at index i</i>.  Any particular element of an array can be accessed, given its index, in &Theta;(1) time.  Since the elements of a vector are stored in an array, the same fact applies here.  Generally, if you know where something is in an array or a vector, you can get to it in constant time.</li>\r\n  <li><i>Getting the size or the capacity</i>.  Vectors store this in separate member variables, so getting their value is a simple matter of accessing them.  These operations run in &Theta;(1) time, as well.</li>\r\n  <li><i>The <b>front</b> member function</i>, which returns the first element in the vector.  The first element will always be in cell 0, so this also runs in &Theta;(1) time (i.e., if you know where something is, you can get there in constant time).</li>\r\n  <li><i>The <b>back</b> member function</i>, which returns the last element in the vector.  The last element will always be in the cell with index <b>size</b> &minus; 1, so this, too, runs in &Theta;(1) time.</li>\r\n</ul>\r\n\r\n<p>As you consider these operations, it looks like vectors are an unvarnished win; everything looks like it runs in constant time!  But let's consider one of the most important member functions: <b>push_back</b> (or its similar cousin, <b>emplace_back</b>).  The answer here is trickier, because there are two scenarios:</p>\r\n\r\n<ul>\r\n  <li><b>size</b> &lt; <b>capacity</b>, in which case the array has at least one unused cell into which the new element can be stored.  Furthermore, we'll know that the unused cell has index <b>size</b>, so we can get to it in &Theta;(1) time; we'll also need to increment <b>size</b>, which is also a constant amount of time.  So far, so good!</li>\r\n  <li><b>size</b> = <b>capacity</b>, in which case the array is full.  You may have noticed in previous usage that vectors automatically handle this case for you, but you may not know what it actually does, which is important if we want to understand how well this operation performs.\r\n    <ul>\r\n      <li>First, a new array &mdash; a multiple of the capacity of the original &mdash; is created.  (There is no explicit rule about what the new array's capacity will be, but you can think of it as being twice as big for the purposes of this discussion; in general, as long as the size increases multiplicatively, our analysis will ultimately hold true.)</li>\r\n      <li>Next, the elements in the original array are copied (or, if possible, moved), one by one, into the new array.</li>\r\n      <li>Finally, the old array can be deleted, in which case the vector will now contain only the new array, which has available capacity; at this point, the new element can be added normally.</li>\r\n    </ul>\r\n    The important question, then, is how long this takes.  Let's break it down into its component parts:\r\n    <ul>\r\n      <li>The time it takes to allocate memory is not explicitly a function of the amount of memory you're allocating, since C++ generally doesn't initialize the contents of newly-allocated memory (e.g., with zeros).  It's certainly true that larger allocations can be more difficult to do than smaller ones, but it's not an explicit function of the array's capacity, so we'll assume that this takes &Theta;(1) time.</li>\r\n      <li>Copying the elements from the old array into the new array requires copying all of them.  If the vector contains <i>n</i> elements, this takes &Theta;(<i>n</i>) time, since each has to be copied individually.  We'll say that copying each element takes &Theta;(1) time because the size is not a factor that affects how long each element will take to copy (though it's certainly true, in practice, that the elements would take longer to copy if they're larger than if they're smaller).\r\n        <ul>\r\n          <li>Aside: It turns out that <b>std::vector</b> will actually <i>move</i> the elements rather than copying them, <i>unless</i> moving might throw an exception.  This allows <b>push_back</b> to provide the strong exception guarantee &mdash; nothing will change if anything fails &mdash; while still being fast, in the case that moves don't throw exceptions.  Either way, it's &Theta;(<i>n</i>) time, in total; moving as opposed to copying is just a way to reduce the constant factor.</li>\r\n        </ul>\r\n      </li>\r\n      <li>Deletion, like allocation, is not a function of the amount of memory; in general, deletion can be thought of as a constant-time operation.</li>\r\n      <li>Finally, when the new element is added to the newly-allocated capacity, that takes &Theta;(1) time, as we saw before.</li>\r\n    </ul>\r\n    Adding all of that together, we see that the total is &Theta;(<i>n</i>).\r\n  </li>\r\n</ul>\r\n\r\n<p>All of this leaves us with an interesting problem.  What can we say, definitively, about the performance of <b>push_back</b>?</p>\r\n\r\n<ul>\r\n  <li>Generally, the strongest statement we can make about <b>push_back</b> is that it's <i>O</i>(<i>n</i>), because it might require linear time (i.e., if the array is full), though it also might require substantially less (i.e., if there's available capacity).</li>\r\n  <li>In the best case, we can say that <b>push_back</b> runs in &Theta;(1) time.</li>\r\n  <li>In the worst case, we can say that <b>push_back</b> runs in &Theta;(<i>n</i>) time.</li>\r\n</ul>\r\n\r\n<p>So, ultimately, our analysis is a bit of a mixed bag: optimistic in parts, while pessimistic in others.  But, in reality, which is it?  Missing from our analysis is a notion of how often the worst-case scenario happens, relative to the best-case scenario.  Is it something we should be concerned about?  If so, how much?</p>\r\n\r\n<p>To answer these questions, we'll need a new kind of analysis we've not yet done, which is called <i>amortized analysis</i>.</p>\r\n\r\n</div>\r\n\r\n<div class=\"section\">\r\n\r\n<hr />\r\n\r\n<p class=\"title\">Amortized analysis</p>\r\n\r\n<p>In English, the word <i>amortization</i> is often used to describe spreading out large costs over time, so their impact in the short term is minimized.  For example, many people buy homes without having the cash saved to pay for the full cost; they do this by borrowing the money and paying it back gradually, <i>amortizing</i> the cost of the home over a long period of time (sometimes as long as 30 years, or occasionally even longer).  This isn't without its downsides, of course; as you pay the money back, you pay an additional <i>interest</i> fee to the lender, which compensates them for the effect of inflation &mdash; the money you pay them back with will be worth less than the money you borrowed &mdash; as well as the risk that you might not pay the loan back.  The interest can be substantial; with prevailing interest rates as of this writing, a typical 30-year home loan would require you to pay a total of around 165% of the cost of the home, albeit spread over a 30-year period.  Nonetheless, by spreading the cost over such a long period, it becomes possible for people of fairly modest means to purchase a home if they choose.</p>\r\n\r\n<p>This notion of spreading large costs over a period of time can be applied to the analysis of algorithms and data structures, as well.  It's certainly true, for example, that <b>std::vector</b>'s <b>push_back</b> operation can sometimes take linear time to run; however, it's also true that it won't happen repeatedly, because the newly-allocated array will be twice the size of the original one.  The larger the vector gets over time, the more it will cost to perform the occasional reallocation, but the less often the reallocation will be necessary going forward, because we obtain ever larger amounts of additional capacity each time.  This fact leads to a surprising conclusion, though we need a new technique, <i>amortized analysis</i>, to see it.</p>\r\n\r\n<p class=\"subtitle\">Amortized running time</p>\r\n\r\n<p>We say that the <i>amortized running time</i> of an operation is the worst-case running time of a sequence of operations divided by the number of operations in the series.  At first blush, that sounds like an average, but there's a nuance here that's important to understand: We're only talking about sequences of operations that can actually happen.  <b>push_back</b> won't run in &Theta;(<i>n</i>) time every time you call it, so we need not consider that circumstance; instead, we should focus our attention on sequences that actually arise in practice.</p>\r\n\r\n<p>To perform an analysis of <b>push_back</b>, let's consider a sequence of calls to it.  To start with, we'll assume that both the size and capacity are <i>c</i>, then we'll consider how long it will take for a sequence of subsequent <b>push_back</b> calls to run, with the goal of measuring the average cost of each call, so we can see how that average changes as the vector grows.  As a proxy for the amount of time required, we'll count the number of times that we write a value into a cell of an array, which is a mainly where the cost of <b>push_back</b> lies.</p>\r\n\r\n<table class=\"normal\">\r\n  <tr class=\"top\">\r\n    <td>Calls</td>\r\n    <td>Size</td>\r\n    <td>Capacity</td>\r\n    <td>Total&nbsp;Writes</td>\r\n    <td>Avg.&nbsp;Writes</td>\r\n    <td>Commentary</td>\r\n  </tr>\r\n  <tr>\r\n    <td>0</td>\r\n    <td><i>c</i></td>\r\n    <td><i>c</i></td>\r\n    <td>0</td>\r\n    <td></td>\r\n    <td>We'll begin measuring with a vector whose array is full.  No work has been done yet.</td>\r\n  </tr>\r\n  <tr>\r\n    <td>1</td>\r\n    <td><i>c</i>&nbsp;+&nbsp;1</td>\r\n    <td>2<i>c</i></td>\r\n    <td><i>c</i>&nbsp;+&nbsp;1</td>\r\n    <td></td>\r\n    <td>The first call to <b>push_back</b> requires a reallocation, since the array is full.  That means we need to copy all <i>c</i> elements from the old array into the new one (<i>c</i> writes), then add the new element (one more write).</td>\r\n  </tr>\r\n  <tr>\r\n    <td><i>c</i></td>\r\n    <td>2<i>c</i></td>\r\n    <td>2<i>c</i></td>\r\n    <td>2<i>c</i></td>\r\n    <td>2</td>\r\n    <td>The next <i>c</i> &minus; 1 calls to <b>push_back</b> will be cheap ones &mdash; each requiring a write into a single cell &mdash; since there is available capacity in the array.  And note that, at this point, the average cost of the calls to <b>push_back</b> is 2 writes.</td>\r\n  </tr>\r\n  <tr>\r\n    <td><i>c</i>&nbsp;+&nbsp;1</td>\r\n    <td>2<i>c</i>&nbsp;+&nbsp;1</td>\r\n    <td>4<i>c</i></td>\r\n    <td>4<i>c</i>&nbsp;+&nbsp;1</td>\r\n    <td></td>\r\n    <td>The next call requires a reallocation.  Note that this reallocation took about twice as long &mdash; copying 2<i>c</i> elements instead of <i>c</i> &mdash; as the last one.</td>\r\n  </tr>\r\n  <tr>\r\n    <td>3<i>c</i></td>\r\n    <td>4<i>c</i></td>\r\n    <td>4<i>c</i></td>\r\n    <td>6<i>c</i></td>\r\n    <td>2</td>\r\n    <td>Having reallocated, the next 2<i>c</i> &minus; 1 calls are cheap ones that each require a single write.  Note, importantly, that the average cost is back to 2 writes again.</td>\r\n  </tr>\r\n  <tr>\r\n    <td>3<i>c</i>&nbsp;+&nbsp;1</td>\r\n    <td>4<i>c</i>&nbsp;+&nbsp;1</td>\r\n    <td>8<i>c</i></td>\r\n    <td>10<i>c</i>&nbsp;+&nbsp;1</td>\r\n    <td></td>\r\n    <td>Another expensive call requiring a reallocation, but that will buy us even more cheap calls afterward.</td>\r\n  </tr>\r\n  <tr>\r\n    <td>7<i>c</i></td>\r\n    <td>8<i>c</i></td>\r\n    <td>8<i>c</i></td>\r\n    <td>14<i>c</i></td>\r\n    <td>2</td>\r\n    <td>What do you know?  Once again, after using up all of the cheap calls we got after an expensive one, our average has dropped again to 2 writes.</td>\r\n  </tr>\r\n</table>\r\n\r\n<p>This same pattern would continue going forward.  In general, the average cost of each <b>push_back</b> operation in a long sequence of them is a constant!</p>\r\n\r\n<p>So we would say that the amortized running time of <b>push_back</b> is &Theta;(1).</p>\r\n\r\n<p class=\"subtitle\">How amortized running time is different from worst-case</p>\r\n\r\n<p>It's important to note that this analysis doesn't change the reality that <b>push_back</b> has a worst-case running time of &Theta;(<i>n</i>), because an expensive reallocation might be required.  Knowing that it has an amortized running time of &Theta;(1) tells us that if we call it repeatedly, the cost will smooth out over time, so that a long sequence of calls will appear to have each been inexpensive.  But there's a difference between the cost \"smoothing out over time\" and the cost being constant in the worst case, which makes a practical difference that we should be cognizant of.</p>\r\n\r\n<p>For a lot of real-world uses, an amortized running time of &Theta;(1) is good enough, because all we care about is how long it takes to run a long task that involves lots of calls to <b>push_back</b>.  On the other hand, there are realistic scenarios where keeping the worst-case running time low is vital.  Here are a couple of examples:</p>\r\n\r\n<ul>\r\n  <li>Robotics control software, with hard real-time requirements (i.e., we'd better be sure that a certain part of our code doesn't take longer than we expect, so we're sure that motors are turned on or off precisely when they should be).</li>\r\n  <li>A video game with 3D graphics, where we might want to ensure that 60 frames are drawn every second, no matter what.</li>\r\n</ul>\r\n\r\n<p>Understanding the actual requirements &mdash; do you need every operation to be fast, or only for the average of all of them to be fast? &mdash; can help you to determine whether a good amortized running time is enough for your uses.</p>\r\n\r\n<p class=\"subtitle\">Why it's important that the resizing is done multiplicatively</p>\r\n\r\n<p>We saw above that a typical implementation of <b>std::vector</b> will resize the array to a multiple of its size whenever <b>push_back</b> is called when the array is full.  This isn't a cavalier choice; it's actually a requirement, because it's the fact that makes the analysis above work out the way it does.  The spirit of it is that the resizings cost more as the array gets larger, but each one buys you proportionally more cheap calls to <b>push_back</b> afterward.</p>\r\n\r\n<p>What if we, say, add 10 elements to the size of the array every time instead?  Do we get that same benefit?  Let's do the same analysis and see what happens.</p>\r\n\r\n<table class=\"normal\">\r\n  <tr class=\"top\">\r\n    <td>Calls</td>\r\n    <td>Size</td>\r\n    <td>Capacity</td>\r\n    <td>Total&nbsp;Writes</td>\r\n    <td>Avg.&nbsp;Writes</td>\r\n    <td>Commentary</td>\r\n  </tr>\r\n  <tr>\r\n    <td>0</td>\r\n    <td><i>c</i></td>\r\n    <td><i>c</i></td>\r\n    <td>0</td>\r\n    <td></td>\r\n    <td>We'll begin measuring with a vector whose array is full.  No work has been done yet.</td>\r\n  </tr>\r\n  <tr>\r\n    <td>1</td>\r\n    <td><i>c</i>&nbsp;+&nbsp;1</td>\r\n    <td><i>c</i>&nbsp;+&nbsp;10</td>\r\n    <td><i>c</i>&nbsp;+&nbsp;1</td>\r\n    <td></td>\r\n    <td>The first call to <b>push_back</b> requires a reallocation, since the array is full.  That means we need to copy all <i>c</i> elements from the old array into the new one (<i>c</i> writes), then add the new element (one more write).</td>\r\n  </tr>\r\n  <tr>\r\n    <td>10</td>\r\n    <td><i>c</i>&nbsp;+&nbsp;10</td>\r\n    <td><i>c</i>&nbsp;+&nbsp;10</td>\r\n    <td><i>c</i>&nbsp;+&nbsp;10</td>\r\n    <td><i>c</i>/10&nbsp;+&nbsp;1</td>\r\n    <td>The next nine calls to <b>push_back</b> will be cheap ones &mdash; each requiring a write into a single cell &mdash; since there is available capacity in the array.  Note, too, that the average number of writes per call at this point is linear with respect to <i>c</i>; this is our first bit of bad news.</td>\r\n  </tr>\r\n  <tr>\r\n    <td>11</td>\r\n    <td><i>c</i>&nbsp;+&nbsp;11</td>\r\n    <td><i>c</i>&nbsp;+&nbsp;20</td>\r\n    <td>2<i>c</i>&nbsp;+&nbsp;21</td>\r\n    <td></td>\r\n    <td>The next call requires a reallocation.  Note that this reallocation took longer than the last one, because we had to copy <i>c</i> + 10 elements (and then add the new one) this time.</td>\r\n  </tr>\r\n  <tr>\r\n    <td>20</td>\r\n    <td><i>c</i>&nbsp;+&nbsp;20</td>\r\n    <td><i>c</i>&nbsp;+&nbsp;20</td>\r\n    <td>2<i>c</i>&nbsp;+&nbsp;30</td>\r\n    <td><i>c</i>/10&nbsp;+&nbsp;3/2</td>\r\n    <td>Having reallocated, the next nine calls are cheap ones that each require a single write.  Note, importantly, that the average cost is back to being linear again.  This is not an accident.</td>\r\n  </tr>\r\n  <tr>\r\n    <td>21</td>\r\n    <td><i>c</i>&nbsp;+&nbsp;21</td>\r\n    <td><i>c</i>&nbsp;+&nbsp;30</td>\r\n    <td>3<i>c</i>&nbsp;+&nbsp;51</td>\r\n    <td></td>\r\n    <td>Another expensive call requiring reallocation, but we're only going to get nine cheap calls to <b>push_back</b> in return for the price we paid.  Every time we do this, we're paying more and getting back the same return.</td>\r\n  </tr>\r\n  <tr>\r\n    <td>30</td>\r\n    <td><i>c</i>&nbsp;+&nbsp;30</td>\r\n    <td><i>c</i>&nbsp;+&nbsp;30</td>\r\n    <td>3<i>c</i>&nbsp;+&nbsp;60</td>\r\n    <td><i>c</i>/10 + 2</td>\r\n    <td>And so we see, on the average, that we're still spending linear time per call to <b>push_back</b>.</td>\r\n  </tr>\r\n</table>\r\n\r\n<p>So we would say that the amortized running time of this version of <b>push_back</b> &mdash; one that adds a constant number of elements to the array's size every time it reallocated, rather than multiplying it &mdash; is &Theta;(<i>n</i>).</p>\r\n\r\n<p>While the C++ Standard is actually silent on the precise implementation details of <b>std::vector</b>, it does call out the amortized constant running time as a requirement, which means that you can be fairly certain that <b>push_back</b> will multiply the capacity of the array in practice whenever it fills.</p>\r\n\r\n</div>\r\n\r\n</body>\r\n</html>\r\n", "encoding": "ascii"}