{"url": "https://www.ics.uci.edu/~eppstein/161/960206.html", "content": "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 3.2//EN\">\n<html>\n<head>\n<title>Minimum spanning trees</title>\n<meta name=\"Owner\" value=\"eppstein\">\n<meta name=\"Reply-To\" value=\"eppstein@ics.uci.edu\">\n</head>\n<body>\n<h1>ICS 161: Design and Analysis of Algorithms<br>\nLecture notes for February 6, 1996</h1>\n\n<!--#config timefmt=\"%d %h %Y, %T %Z\" -->\n<hr>\n<p></p>\n\n<h1>Minimum Spanning Trees</h1>\n\n<h2>Spanning trees</h2>\n\nA <i>spanning tree</i> of a graph is just a subgraph that contains\nall the vertices and is a tree. A graph may have many spanning\ntrees; for instance the complete graph on four vertices \n\n<pre>\n    o---o\n    |\\ /|\n    | X |\n    |/ \\|\n    o---o\n</pre>\n\nhas sixteen spanning trees: \n\n<pre>\n    o---o    o---o    o   o    o---o\n    |   |    |        |   |        |\n    |   |    |        |   |        |\n    |   |    |        |   |        |\n    o   o    o---o    o---o    o---o\n\n    o---o    o   o    o   o    o   o\n     \\ /     |\\ /      \\ /      \\ /|\n      X      | X        X        X |\n     / \\     |/ \\      / \\      / \\|\n    o   o    o   o    o---o    o   o\n\n    o   o    o---o    o   o    o---o\n    |\\  |       /     |  /|     \\\n    | \\ |      /      | / |      \\\n    |  \\|     /       |/  |       \\\n    o   o    o---o    o   o    o---o\n\n    o---o    o   o    o   o    o---o\n    |\\       |  /      \\  |       /|\n    | \\      | /        \\ |      / |\n    |  \\     |/          \\|     /  |\n    o   o    o---o    o---o    o   o\n</pre>\n\n<h2>Minimum spanning trees</h2>\n\nNow suppose the edges of the graph have weights or lengths. The\nweight of a tree is just the sum of weights of its edges.\nObviously, different trees have different lengths. The problem: how\nto find the minimum length spanning tree? \n\n<p>This problem can be solved by many different algorithms. It is\nthe topic of some very recent research. There are several \"best\"\nalgorithms, depending on the assumptions you make:</p>\n\n<ul>\n<li>A randomized algorithm can solve it in linear expected time.\n[Karger, Klein, and Tarjan, \"A randomized linear-time algorithm to\nfind minimum spanning trees\", J. ACM, vol. 42, 1995, pp.\n321-328.]</li>\n\n<li>It can be solved in linear worst case time if the weights are\nsmall integers. [Fredman and Willard, \"Trans-dichotomous algorithms\nfor minimum spanning trees and shortest paths\", 31st IEEE Symp.\nFoundations of Comp. Sci., 1990, pp. 719--725.] <a name=\"beta\">\n</a></li>\n\n<li>Otherwise, the best solution is very close to linear but not\nexactly linear. The exact bound is O(m log beta(m,n)) where the\nbeta function has a complicated definition: the smallest i such\nthat log(log(log(...log(n)...))) is less than m/n, where the logs\nare nested i times. [Gabow, Galil, Spencer, and Tarjan, Efficient\nalgorithms for finding minimum spanning trees in undirected and\ndirected graphs. Combinatorica, vol. 6, 1986, pp. 109--122.]</li>\n</ul>\n\nThese algorithms are all quite complicated, and probably not that\ngreat in practice unless you're looking at really huge graphs. The\nbook tries to keep things simpler, so it only describes one\nalgorithm but (in my opinion) doesn't do a very good job of it.\nI'll go through three simple classical algorithms (spending not so\nmuch time on each one). \n\n<h2>Why minimum spanning trees?</h2>\n\n<a name=\"phone\">The standard application is to a problem like phone\nnetwork design. You have a business with several offices; you want\nto lease phone lines to connect them up with each other; and the\nphone company charges different amounts of money to connect\ndifferent pairs of cities. You want a set of lines that connects\nall your offices with a minimum total cost. It should be a spanning\ntree, since if a network isn't a tree you can always remove some\nedges and save money.</a> \n\n<p><a name=\"tsp\">A less obvious application is that the minimum\nspanning tree can be used to approximately solve the traveling\nsalesman problem. A convenient formal way of defining this problem\nis to find the shortest path that visits each point at least\nonce.</a></p>\n\n<p>Note that if you have a path visiting all points exactly once,\nit's a special kind of tree. For instance in the example above,\ntwelve of sixteen spanning trees are actually paths. If you have a\npath visiting some vertices more than once, you can always drop\nsome edges to get a tree. So in general the MST weight is less than\nthe TSP weight, because it's a minimization over a strictly larger\nset.</p>\n\n<p><a name=\"chris\">On the other hand, if you draw a path tracing\naround the minimum spanning tree, you trace each edge twice and\nvisit all points, so the TSP weight is less than twice the MST\nweight. Therefore this tour is within a factor of two of optimal.\nThere is a more complicated way (<i><a href= \n\"people.html#christofides\">Christofides</a>' heuristic</i>) of\nusing minimum spanning trees to find a tour within a factor of 1.5\nof optimal; I won't describe this here but it might be covered in\nICS 163 (graph algorithms) next year.</a></p>\n\n<h2>How to find minimum spanning tree?</h2>\n\nThe stupid method is to list all spanning trees, and find minimum\nof list. We already know how to find minima... But there are far\ntoo many trees for this to be efficient. It's also not really an\nalgorithm, because you'd still need to know how to list all the\ntrees. \n\n<p>A better idea is to find some key property of the MST that lets\nus be sure that some edge is part of it, and use this property to\nbuild up the MST one edge at a time.</p>\n\n<p>For simplicity, we assume that there is a unique minimum\nspanning tree. (Problem 4.3 of Baase is related to this\nassumption). You can get ideas like this to work without this\nassumption but it becomes harder to state your theorems or write\nyour algorithms precisely.</p>\n\n<blockquote>Lemma: Let X be any subset of the vertices of G, and\nlet edge e be the smallest edge connecting X to G-X. Then e is part\nof the minimum spanning tree. \n\n<p>Proof: Suppose you have a tree T not containing e; then I want\nto show that T is not the MST. Let e=(u,v), with u in X and v not\nin X. Then because T is a spanning tree it contains a unique path\nfrom u to v, which together with e forms a cycle in G. This path\nhas to include another edge f connecting X to G-X. T+e-f is another\nspanning tree (it has the same number of edges, and remains\nconnected since you can replace any path containing f by one going\nthe other way around the cycle). It has smaller weight than t since\ne has smaller weight than f. So T was not minimum, which is what we\nwanted to prove.</p>\n</blockquote>\n\n<h2>Kruskal's algorithm</h2>\n\nWe'll start with <a href=\"people.html#kruskal\">Kruskal</a>'s\nalgorithm, which is easiest to understand and probably the best one\nfor solving problems by hand. \n\n<pre>\n    Kruskal's algorithm:\n    sort the edges of G in increasing order by length\n    keep a subgraph S of G, initially empty\n    for each edge e in sorted order\n        if the endpoints of e are disconnected in S\n        add e to S\n    return S\n</pre>\n\nNote that, whenever you add an edge (u,v), it's always the smallest\nconnecting the part of S reachable from u with the rest of G, so by\nthe lemma it must be part of the MST. \n\n<p>This algorithm is known as a <i>greedy algorithm</i>, because it\nchooses at each step the cheapest edge to add to S. You should be\nvery careful when trying to use greedy algorithms to solve other\nproblems, since it usually doesn't work. E.g. if you want to find a\nshortest path from a to b, it might be a bad idea to keep taking\nthe shortest edges. The greedy idea only works in Kruskal's\nalgorithm because of the key property we proved.</p>\n\n<p><a name=\"uf\">Analysis: The line testing whether two endpoints\nare disconnected looks like it should be slow (linear time per\niteration, or O(mn) total). But actually there are some complicated\ndata structures that let us perform each test in close to constant\ntime; this is known as the <i>union-find</i> problem and is\ndiscussed in Baase section 8.5 (I won't get to it in this class,\nthough). The slowest part turns out to be the sorting step, which\ntakes O(m log n) time.</a></p>\n\n<h2>Prim's algorithm</h2>\n\nRather than build a subgraph one edge at a time, <a href= \n\"people.html#prim\">Prim</a>'s algorithm builds a tree one vertex at\na time. \n\n<pre>\n    Prim's algorithm:\n    let T be a single vertex x\n    while (T has fewer than n vertices)\n    {\n        find the smallest edge connecting T to G-T\n        add it to T\n    }\n</pre>\n\nSince each edge added is the smallest connecting T to G-T, the\nlemma we proved shows that we only add edges that should be part of\nthe MST. \n\n<p>Again, it looks like the loop has a slow step in it. But again,\nsome data structures can be used to speed this up. The idea is to\nuse a <a href=\"960116.html#binheap\">heap</a> to remember, for each\nvertex, the smallest edge connecting T with that vertex.</p>\n\n<pre>\n    Prim with heaps:\n    make a heap of values (vertex,edge,weight(edge))\n        initially (v,-,infinity) for each vertex\n        let tree T be empty\n    while (T has fewer than n vertices)\n    {\n        let (v,e,weight(e)) have the smallest weight in the heap\n        remove (v,e,weight(e)) from the heap\n        add v and e to T\n        for each edge f=(u,v)\n        if u is not already in T\n            find value (u,g,weight(g)) in heap\n            if weight(f) &lt; weight(g)\n            replace (u,g,weight(g)) with (u,f,weight(f))\n    }\n</pre>\n\n<a name=\"fib\">Analysis: We perform n steps in which we remove the\nsmallest element in the heap, and at most 2m steps in which we\nexamine an edge f=(u,v). For each of those steps, we might replace\na value on the heap, reducing it's weight. (You also have to find\nthe right value on the heap, but that can be done easily enough by\nkeeping a pointer from the vertices to the corresponding values.) I\nhaven't described how to reduce the weight of an element of a\nbinary heap, but it's easy to do in O(log n) time. Alternately by\nusing a more complicated data structure known as a Fibonacci heap,\nyou can reduce the weight of an element in constant time. The\nresult is a total time bound of O(m + n log n).</a>\n<h2>Boruvka's algorithm</h2>\n\n(Actually <a href=\"people.html#boruvka\">Boruvka</a> should be\nspelled with a small raised circle accent over the \"u\".) Although\nthis seems a little complicated to explain, it's probably the\neasiest one for computer implementation since it doesn't require\nany complicated data structures. The idea is to do steps like\nPrim's algorithm, in parallel all over the graph at the same time. \n\n<pre>\n    Boruvka's algorithm:\n    make a list L of n trees, each a single vertex\n    while (L has more than one tree)\n        for each T in L, find the smallest edge connecting T to G-T\n        add all those edges to the MST\n        (causing pairs of trees in L to merge)\n</pre>\n\nAs we saw in Prim's algorithm, each edge you add must be part of\nthe MST, so it must be ok to add them all at once. \n\n<p>Analysis: This is similar to merge sort. Each pass reduces the\nnumber of trees by a factor of two, so there are O(log n) passes.\nEach pass takes time O(m) (first figure out which tree each vertex\nis in, then for each edge test whether it connects two trees and is\nbetter than the ones seen before for the trees on either endpoint)\nso the total is O(m log n).</p>\n\n<h2>A hybrid algorithm</h2>\n\nThis isn't really a separate algorithm, but you can combine two of\nthe classical algorithms and do better than either one alone. The\nidea is to do O(log log n) passes of Boruvka's algorithm, then\nswitch to Prim's algorithm. Prim's algorithm then builds one large\ntree by connecting it with the small trees in the list L built by\nBoruvka's algorithm, keeping a heap which stores, for each tree in\nL, the best edge that can be used to connect it to the large tree.\nAlternately, you can think of collapsing the trees found by\nBoruvka's algorithm into \"supervertices\" and running Prim's\nalgorithm on the resulting smaller graph. The point is that this\nreduces the number of remove min operations in the heap used by\nPrim's algorithm, to equal the number of trees left in L after\nBoruvka's algorithm, which is O(n / log n). \n\n<p>Analysis: O(m log log n) for the first part, O(m + (n/log n) log\nn) = O(m + n) for the second, so O(m log log n) total.</p>\n\n<hr>\n<p><a href=\"/~eppstein/161/\">ICS 161</a> -- <a href=\"/\">Dept.\nInformation &amp; Computer Science</a> -- <a href= \n\"http://www.uci.edu/\">UC Irvine</a><br>\n<small>Last update: \n<!--#flastmod file=\"960206.html\" --></small></p>\n</body>\n</html>\n\n", "encoding": "ascii"}