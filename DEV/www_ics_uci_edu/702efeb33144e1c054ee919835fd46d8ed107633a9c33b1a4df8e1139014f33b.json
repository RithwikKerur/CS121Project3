{"url": "https://www.ics.uci.edu/~eppstein/261/s13-hw8-answers.txt", "content": "CS 261, Spring 2013, Homework 8, Due Thursday, June 6\n\n1. In the lecture we described a linear-time algorithm for finding the\nCartesian tree for an array of numbers, but we also described a more\ngeneral definition of a Cartesian tree from another tree, that applies\nto the problem of finding maximum-bandwidth paths. Prove that it is not\nalways possible to construct the Cartesian tree of a tree in linear time\n(in a comparison model of computation) by showing that, if you could do\nthat, you could use the construction to sort arbitrary sets of n numbers\nin linear time.\n\n    Given a set of n numbers as input, construct a tree T with one root\n    vertex connected to n leaves, with the given numbers as edge weights.\n    The Cartesian tree of T is just a path with the minimum weight\n    edge at its root and with the edges listed in sorted order by weight\n    along the path. Therefore, if you could construct a Cartesian tree\n    of T in linear time, you could sort n numbers in linear time\n    by constructing T, constructing its Cartesian tree, and reading\n    off the numbers from the path. Since sorting takes time\n    Omega(n log n) (in a comparison model of computation) so does\n    Cartesian tree construction.\n\n    (To correctly answer the homework you don't need to describe how\n    to construct the Cartesian tree. It is possible to construct the\n    Cartesian tree of a given tree T in time O(n log n) but this\n    was not part of the problem.)\n\n\n2. In a binary tree (that is, a tree where each node may have at most\none parent, at most one left child, and at most one right child),\nsuppose that we wish to route a message from node u to node v. Describe\nhow to use lowest common ancestor queries to determine in constant time\nwhich of the three neighbors of u is the one on the shortest path to v.\n\n    if (LCA of v and left child of v == left child of v):\n        the shortest path goes through the left child\n    else if (LCA of v and right child of v == right child of v):\n        the shortest path goes through the right child\n    else\n        the shortest path goes through the parent\n\n    (There is also a fourth case, that u == v, but you didn't need\n    to include that case to answer the problem correctly.)\n\n\n3. A queue data structure has two update operations (enqueue and\ndequeue) and one query operation (top). The sequence of values returned\nby top as dequeue operations are made should be the same as the sequence\nin which the same values were added to the queue by enqueue operations.\nA non-persistent queue can be represented by two pointers (head and\ntail) into a collection of nodes that each have \"data\" and \"next\"\ninstance variables, and in which the condition of being an empty queue\nis represented by the tail pointer being null. To perform an enqueue\noperation in an empty queue, a new node is created with the given data\nvalue and with next=null, and head and tail are both set to point to it.\nTo perform an enqueue operation in a non-empty queue, tail.next is set\nto be a new node, with the given data value and with next=null, and then\ntail is set to point to the new node. To perform a dequeue operation, head is set\nto head.next, and if this is null then tail is also set to null. To\nperform a top operation, head.top is returned.\n\nNow suppose that we want to make a queue persistent. Which of the two\ntechniques (fat nodes or path copying) would be more effective for this\nrepresentation of a queue? Explain why.\n\n    Fat nodes are better.\n\n    Path copying works with tree structures, where each node has\n    pointers to its children (but not to its parent or siblings),\n    and replaces all the nodes on a path from the root to a changed node.\n    The queue structure described here can be thought of as a tree\n    where the root is at the head and the \"next\" pointer is a child,\n    and path copying works correctly with this interpretation,\n    but not efficiently, because the changed node is always at\n    the other end of the queue (the step in an enqueue where we\n    set tail.next is a change to that node) so we always need\n    to replace every node in the whole data structure.\n\n    In contrast, fat nodes work correctly and reasonably efficiently\n    for this data structure. They work especially well for partial\n    persistence, because in this case every node only ever needs\n    to store two versions (the one before and after its next pointer\n    is changed). If we store the head and tail pointers together with\n    the version number as part of a version identifier, rather than\n    making them fat as well, the time per operation is O(1).\n    Even if we use a fat object to store the head and tail, the\n    time per operation is still only O(log n) and the space per\n    update is O(1).\n\n    a version of a data structure by its head and tail pointers\n    together with a version number. ", "encoding": "ascii"}