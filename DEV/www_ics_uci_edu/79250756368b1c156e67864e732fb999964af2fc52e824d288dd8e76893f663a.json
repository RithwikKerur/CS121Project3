{"url": "https://www.ics.uci.edu/~pattis/ICS-33/lectures/filereading.txt", "content": "\t\tA Quick note on Simple and Efficient File Reading\r\n\r\n\r\nReading information from text files is a common and important operation in\r\nPython. In this lecture we will first discuss various options for reading files,\r\nand characterize them based on simplicity and efficiency (mostly with regards to\r\nefficiency in the use of space/memory, which is important when reading very \r\nlarge files).\r\n\r\nIn a nutshell, you should avoid using the .read() and .readlines() methods, and\r\ninstead directly iterate over open file objects (using a standard for loop\r\nor a for loop in a comprehension). Doing so requires less code and consumes\r\nless memory; this simple method is almost always the right way to read files.\r\n\r\nThe second section in these notes defines the parse_line generator function\r\n(available in the goody module) and discusses how to use it: it supplies a\r\ngeneral and easy way to read files that contain a fixed number of records\r\n(fields of values, possibly of different types). One parameter binds to a\r\ntuple/list of function objects, each specifying how to convert the field in its\r\nposition (a substring of each line) into a value of the appropriate type. We\r\nwill discuss how this method is implemented when we discuss generators (notice\r\nthat parse_line use a yield statement, not a return statements) in Week #4.\r\n\r\nThe third section discusses binary (non-text) files. There are many uses of\r\nbinary files: here we base our presentation on the standard pickle module, which\r\neasily allows programmers to store data structures (typically large/complex\r\nones, that a program spends a long time building) into files; then these file\r\ncan be easily (and quickly) read in a subsequent program, restoring the contents\r\nof the complicated data structure.\r\n\r\n------------------------------------------------------------------------------\r\n\r\n\r\nSimple and Space Efficient Code:\r\n\r\nTo start, let's suppose we are reading a file where each line in the file is\r\njust a string of text. The simplest and most efficient way to read such a file\r\nis iterating over an \"open\" (file) object.\r\n\r\n  for line in open(file_name):  # where file_name is a string naming a file\r\n      process(line)             # where process is a function or some code block\r\n\r\nTypically, we need to strip off the newline character at the end of each line\r\nas it is read from the file, before it is processed further. We can strip off\r\nthis information by calling the .rstrip('\\n') method (right strip). The code\r\nwould become\r\n\r\nfor line in open(file_name):\r\n    process(line.rstrip('\\n'))\r\n\r\nor\r\n\r\nfor line in open(file_name):\r\n    line = line.rstrip('\\n') # re-bind line (also rebind on next loop itration)\r\n    process(line)\r\n\r\n  Technically the os module binds the name linesep to the character(s) forming\r\n  a newline on that operating system. For PCs os.linesep is '\\r\\n'; on Macs it\r\n  is '\\n'. So, we could call .rstrip(os.linesep) on the line. But when we read\r\n  a line from a text file in Python, it converts any newline character(s) to\r\n  just the single character '\\n', regardless of the operating system. This\r\n  makes it easier to write Python code that works on all operating systems.\r\n\r\nNote that if we call .rstrip() with no arguments, all white-space characters\r\n(including the newline character(s), spaces, and tabs) are stripped from the\r\nright end of the string. We can use this simpler alternative if we don't\r\nmeaningfully process whitespace at the ends of lines, but if we need to preserve\r\nall text but the newline character at the end, we must call .rstrip('\\n'). \r\n\r\nRecall that there are NO MUTATOR methods on strings: so, when we call the\r\nline.rstrip(...) method, it DOES NOT MUTATE the string object associated with\r\nline, but instead it produces a reference to a NEW STRING object that has the\r\nsame contents, except with the requested character(s) stripped off its right\r\nend; we pass this new string object as an argument to the process function, or\r\nwe rebind line to that new string.\r\n\r\n  CORRECT      \t   \t   \t     INCORRECT\r\n\r\n  for line in open(file_name): \t     for line in open(file_name):\r\n      line = line.rstrip('\\n')\t         line.rstrip('\\n') # LINE HAS NO EFFECT!\r\n      process(line)\t\t         process(line)\r\n\r\nThe for loops in the code fragments above are all space efficient, because at\r\nany time Python stores only one line of the file in memory (although the file\r\nitself is likely cached/stored in a memory buffer). Note that if we wanted to\r\ncreate a list of lines read from the file (where the newline character(s) are\r\nremoved from each string), we can write the following simple comprehension.\r\n\r\nline_list = [line.rstrip('\\n') for line in open(file_name)]\r\n\r\nNote that in this example, line_list occupies about the same amount of space as\r\nthe file: all lines are stored in memory (one per list entry) at the same time.\r\n\r\nIf we can process lines INDEPENDENTLY of each other (process each one without\r\nneeding to know the contents of any previous or subsequent lines) we should NOT\r\nwrite code to store all the lines in a list, because it is not space efficient.\r\nWe often process files by iterating through their lines, and an open file is\r\niterable in the same way a list is.\r\n\r\nFinally, in ICS-32 you learned that we can use open as a context manager in\r\na with statement, which handles file exceptions and automatically closes the\r\nfile when the context manager finishes (which is often useful/important, but\r\nnot always). With the open context manager, we would write the above code\r\nfragments as\r\n\r\nwith open(file_name) as open_file:\r\n    for line in open_file:\r\n        process(line.rstrip('\\n'))\r\n\r\nor\r\n\r\nwith open(file_name) as open_file:\r\n    line_list = [line.rstrip('\\n') for line in open_file]\r\n\r\nUsing context managers does not change the space efficiency of the file reading.\r\nWe will study context managers so that you can write your own during Week #3.\r\n\r\n\r\n----------------------------------------\r\n\r\n\r\nThe .readlines() and .read() methods: Less Simple and Less Efficient\r\n\r\nWe can apply the .readlines() method to an open file: it produces a list of all\r\nthe lines in the file, where each line still ends in the newline character '\\n'.\r\n\r\nSo, if open_file refers to the following open file,\r\n\r\nLine 1\r\nLine 2\r\nLine 3\r\n\r\ncalling open_file.readlines() returns the list\r\n\r\n['Line 1\\n', 'Line 2\\n', Line 3\\n']\r\n\r\nIf we wanted to call .readlines() and process every string in the file (without\r\nthe '\\n' characters at the end) we would write \r\n\r\nfor line in open(file_name).readlines():\r\n    process(line.rstrip('\\n'))\r\n\r\nor\r\n\r\nfor line in open(file_name).readlines():\r\n    line = line.rstrip('\\n') # re-bind line (also rebind on next loop itration)\r\n    process(line)\r\n\r\nNotice that this code is LONGER than the loops written in the previous section,\r\nand it is LESS SPACE EFFICIENT, because it first computes a list of all the\r\nlines in the file (storing it in memory along with the file) and then it\r\niterates over the strings in that list; the loop in the previous section stores\r\nin memory only one line at a time from the file, while it process that line, not\r\nan entire list of lines.\r\n\r\nIf we wanted to create a list of lines without the '\\n' characters at the end\r\ncalling readlines, we could write \r\n\r\nline_list = [line.rstrip('\\n') for line in open(file_name).readlines()]\r\n\r\nwhich is similar to, but also MORE COMPLICATED THAN, the code in the previous\r\nsection that does the same thing. This code fragment takes TWICE THE AMOUNT OF\r\nSPACE to create line_list because calling .readlines() creates a list of all\r\nthe lines in the file, and then the comprehension creates another/second list\r\nof the lines without '\\n'. It is INEFFICIENT.\r\n\r\nFinally, if we wanted to compute a list of lines WITH all the '\\n' characters\r\nat the end, then calling\r\n\r\nline_list = open(file_name).readlines()\r\n\r\nis simpler than the comprehension code below, which does this same task.\r\n\r\nline_list = [line for line in open(file_name)]\r\n\r\nIt also occupies the equivalent amount of storage. So this is one of the few\r\nexamples (and not really a common one) where calling the .readlines() method is\r\nuseful.\r\n\r\n----------\r\n\r\nWe can also apply the .read() method to an open file: it produces one giant\r\nstring that contains all the lines in the file, each ended by the newline\r\ncharacter '\\n'.\r\n\r\nSo, if open_file refers to the following open file,\r\n\r\nLine 1\r\nLine 2\r\nLine 3\r\n\r\ncalling open_file.read() returns the string\r\n\r\n'Line 1\\nLine 2\\nLine 3\\n'\r\n\r\nWe can split this string into a list of strings by calling the .split method.\r\n\r\nline_list = open(file_name).read().split('\\n')\r\n\r\nand this code is a bit simpler than what we have seen before, which is\r\nequivalent to\r\n\r\nline_list = [line.rstrip('\\n') for line in open(file_name)]\r\n\r\nBut, the .read().split('\\n') code above is LESS SPACE EFFICIENT than the simpler\r\ncomprehension, because it stores BOTH the ENTIRE FILE AS A STRING and a LIST\r\nOF ALL THE LINES IN THE FILE at the same time; the comprehension stores the\r\nlist of all the lines in the file, but not a string whose contents is the\r\nentire file itself.\r\n\r\nLikewise, if we wanted to process every string in the file (without the '\\n'\r\ncharacters at the ends we can write \r\n\r\nfor line in open(file_name).read().split('\\n'):\r\n    process(line)\r\n\r\nThis for loop code is MORE COMPLICATED than the for loop in the first section,\r\nand it USES SPACE MUCH LESS EFFICIENTLY: this code stores the entire file (and a\r\nlist of lines in the file) in memory at one time; the loop in the first\r\nsection stores in memory only one line at a time of the file. Note that because\r\nof the call to split after read, there is no need for a call to rstrip inside\r\nthe loop: this code breaks the big string into a list of lines by splitting on\r\n(and removing) the '\\n' characters at the end of each line.\r\n\r\nBottom Line:\r\n\r\nThere is little to be gained when reading files by calling the .readlines() or\r\nthe .read() method. The simplest and most space efficient way to read a file is\r\nto iterate directly over the \"open\" file with a standard for loop, or a for loop\r\ninside a comprehension. You should use this simplest/most efficient form in your\r\ncode to receive full credit.\r\n\r\n------------------------------------------------------------------------------\r\n\r\n\r\nReading Files and Parsing their Contents:\r\n\r\nSome text files contain lines that store other types or mixed-types of\r\ninformation. Suppose that we wanted to read a text file that stored strings\r\nrepresenting numbers (one number per line). We can easily rewrite our original\r\ncode to the following, calling the int conversion function on each rstripped\r\nline.\r\n\r\nfor line in open(file_name):\r\n    process( int(line.rstrip('\\n')) )\r\n\r\nHere we are assuming process takes an integer value as an argument.\r\n\r\nIn some files each line is a \"record\": a fixed number of fields of values, with\r\npossibly different types, separated by some special character (often a space or\r\npunctuation character like a comma or colon). To process each record in a file,\r\nwe must \r\n\r\n  (1) read its line\r\n  (2) separate its fields of values (still each value is a string)\r\n  (3) call a conversion function for each string to get its value\r\n\r\nThe goody module contains the parse_lines function (technically a generator\r\nfunction, which we will study in Week #4 in ICS-33) that easily supports reading\r\nrecords from files (similarly to how lines are read from \"open\" files). We can\r\ndefine this (generator) function simply as follows (don't worry about how it is\r\ndefined now, because you likely don't know what generator functions are, but I\r\nwant to illustrate the code is simple for the behavior that I describe below).\r\n\r\ndef parse_lines(open_file, sep, conversions):\r\n    for line in open_file:\r\n        yield [conv(item) for conv,item in\r\n                  zip(conversions,line.rstrip('\\n').split(sep))]\r\n\r\nHere sep is the special character used to separate the fields in the record;\r\nconversions is a tuple (or list: technically it can be anything that is\r\niterable) of function objects: they are applied in sequence to the string\r\nvalues extracted from the separated fields. When we iterate over a call to\r\nparse_lines (simlar to iterating over a call to \"open\"), the index\r\nvariable is bound to a list of the values of the fields in the record.\r\n\r\nFor example, the following file contains fields of a name (str) followed by two\r\ntest scores (ints) all separated by commas (like a .csv file in Excel).\r\n\r\nBob Smith,75,80\r\nMary Jones,85,90\r\n\r\nWe could read this file and print out the names of each student and their\r\naverage test score by\r\n\r\nfor fields in parse_lines( open(file_name), ',' , (str,int,int) ):\r\n  print(fields[0], (fields[1]+fields[2])/2)\r\n\r\nHere fields is repeatedly bound to a 3-list containing a name (str) followed\r\nby two test scores (ints): fields is first bound to ['Bob Smith', 75, 80] and\r\nthen to ['Mary Jones', 85, 90]. \r\n\r\n-----Start: Details of behavior with bad arguments\r\n1) Note that if we specified conversions as (str,int) it would return the\r\n2-lists ['Bob Smith', 75] followed by ['Mary Jones', 85] (because looping over\r\na zip stops when one of its arguments runs out of values: here each line\r\ncontains more field values than conversion functions).  If we supplied just two\r\nconversion functions Accessing fields[2] in the code above would raise an\r\nIndexError exception.\r\n\r\n2) Likewise (because looping over a zip stops when one of its arguments runs\r\nout of values), if the a line contains a name and 3 integer values, only the\r\nname and first two integers would be returned in the 3-list: the line\r\n\r\nPaul White,80,75,85\r\n\r\nreturns only the 3-list ['Paul White', 80, 75]\r\n\r\nSo parse_lines would not raise any exceptions in the code above; instead it\r\nincorrectly reads the file contents with no warning.\r\n\r\nWe could define a more complicated parse_lines function that checked and\r\nimmediately raised an exception if the number of separated field values in a\r\nrecord was not equal to the length of the tuple of conversion functions.\r\n-----End: Details of behavior with bad arguments\r\n\r\nA simpler way to write such code is to use multiple index variables and \r\nunpacking (as we do when we write: for k,v in adict.items()). I have found that\r\nstudents often don't understand the power and simplicity of unpacking; you\r\nshould use this simple Python feature in your code to receive full credit.\r\nUnpacking is covered in detail in the review lecture notes.\r\n\r\nfor  name, test1, test2  in  parse_lines(open(file_name),',',(str,int,int)):\r\n  print(name, (test1+test2)/2)\r\n\r\nWith this for loop, the first error noted above would also raise an exception\r\nbecause there would not be three values to unpack into name, test1, and test2;\r\nthe second error would again go unnoticed.\r\n\r\nFinally, note that besides using the standard conversion function(s) like str\r\nand int, we can define our own more complicated conversion function(s). For\r\nexample, suppose that each record in the file specified a string name, some\r\nnumber of int quiz results separated by colons, and an int final exam, with\r\nthese three fields (name, quizzes, final) separated by commas. Such a file\r\nmight look like\r\n\r\nBob Smith,75:80,90\r\nMary Jones,85:90:77,85\r\n\r\nHere Bob took two quizzes but Mary took three. We can process both lines by\r\ndefining\r\n\r\ndef quiz_list(scores):\r\n    return [int(q) for q in scores.split(':')]\r\n\r\nand then write\r\n\r\nfor name,quizzes,final in parse_lines(open(file_name),',',(str,quiz_list,int)):\r\n    print(name, sum(quizzes)/len(quizzes), final)\r\n\r\nwhich would print\r\n\r\nBob Smith 77.5 90\r\nMary Jones 84.0 85\r\n\r\nNote that 77.5 is (75+80)/2 and 84 is (85+90+77)/3. If we instead wrote\r\n\r\nfor fields in parse_lines(open(file_name),',',(str,quiz_list,int)):\r\n  print(fields)\r\n\r\nit would print the following 3-lists: index 1 of each is a list of quiz scores.\r\n\r\n['Bob Smith', [75, 80], 90]\r\n['Mary Jones', [85, 90, 77], 85]\r\n\r\nOf course, we can also use lambdas (also covered in the review lecture) instead\r\nof named functions; below we have substituted a lambda for the quiz_list\r\nfunction.\r\n\r\nfor name,quizzes,final in parse_lines(open(file_name),',',\r\n                          (str,\r\n                           lambda scores : [int(q) for q in scores.split(':')],\r\n                           int)):\r\n  print(name,quizzes,final)\r\n\r\nwhich again prints\r\n\r\n['Bob Smith', [75, 80], 90]\r\n['Mary Jones', [85, 90, 77], 85]\r\n\r\n------------------------------------------------------------------------------\r\n\r\nText and Binary Files: Pickling\r\n\r\nPython programs (.py files) are actually text files that are read by Python\r\nitself. Some Python programs also read or write (text and/or binary) files when\r\nexecuted.\r\n\r\nIn this section we will briefly survey binary files (comparing them to text\r\nfiles) and how to use binary files with the pickle module to save the state\r\nof complicated data structures that a program creates, so they can be\r\nefficiently stored and loaded (read back) into a subsequent program.\r\n\r\nText files contain ASCII (really Unicode, but the distinction is not important\r\nhere) characters. We can use standard text-editors (like the one in Eclipse)\r\nto create/examine/update text files. We have seen how to read strings from the\r\nlines in a text file (throughout this lecture note) and convert these strings\r\ninto other types (in the previous section).\r\n\r\nWe might store a float value in a text file as the characters \"2.99792458E8\".\r\nIf we store each character as one byte (8 bits) of information, then it takes\r\n12 bytes to store this float; in addition, if we call the float(...) conversion\r\nfunction after reading this string (to get its true float value: a value on\r\nwhich we can perform arithmetic) the conversion takes additional time.\r\n\r\nBut all float values are stored in a special 64 bit format (equivalent to 8\r\nbytes). Instead of converting a float value to a string, storing it in a file,\r\nreading it back from the file, and converting it back into a float (a lengthy\r\nprocess needing 12 bytes of storage in the file for this example), we can write\r\na float value directly into a (binary) file using 8 bytes, and then read back\r\nthose 8 bytes, with no conversion writing or reading the file, and the value is \r\nstored in the file using only 8 bytes.\r\n\r\nSo we gain efficiency (time and space) storing information in binary files; what\r\nwe give up is the ability to easily \"see\" the contents of files: although we\r\ncan still \"edit\" them with a text editor, they look garbled. For example, the\r\ntext editor would interpret the 8 bytes in a float number as 8 characters\r\n(which they are not, and so the characters would look very weird)!\r\n\r\nThe topic of data representation in computers/files at the lowest level (bits\r\nand bytes) is covered in depth in ICS-51. Once you have such knowledge, you can\r\neasily UNDERSTAND how Python can read and write binary files. For now, we will\r\njust illustrate USING binary files in conjunction with the pickle module, to do\r\nsomething useful and important, that can be understood on its own.\r\n\r\nFor the discussion below of the pickle module (from the standard Python library)\r\nwe will focus on two useful functions, which we will describe and illustrate\r\nbriefly (avoiding unnecessary -but still interesting- details).\r\n\r\n  pickle.dump(object, open-file) # called for effect; returns None\r\n  pickle.load(open-file)         # returns value of pickled data structure\r\n\r\nHere is a short program that stores the pickled version of a Python dictionary.\r\nWhen files are opened with only one argument (a name), the second argument by\r\ndefault is 'r', which means r(ead). For the code below, we must explicitly\r\nspecify a second argument \"wb\".\r\n\r\n  import pickle\r\n\r\n  adict = dict(a=1,b=2,c=3)                      # create a dict\r\n\r\n  with open('pickletest.dat', 'wb') as storage:  # File mode is w(rite)b(inary)\r\n      pickle.dump(adict,storage)                 #   store dict in a binary file\r\n\r\nWhen this code executes, it writes a 38 byte binary file named pickletest.dat,\r\nstoring the 3-item dictionary. Run this code and then try to load this file\r\ninto a text-editor and observe the results.\r\n\r\nWe can read the data file for this dictionary using the following program.\r\n\r\n  import pickle\r\n\r\n  with open('pickletest.dat', 'rb') as storage:  # File mode is r(ead)b(inary)\r\n      adict = pickle.load(storage)               #   restore dict from file\r\n\r\n  print(adict)                                   # Print orginal/pickled dict\r\n\r\nwhich prints: {'a': 1, 'b': 2, 'c': 3}\r\n\r\nIf we needed to pickle more than one data structure, we can put each data\r\nstructure in a list, pickle the list, then read back the list, and bind each\r\nindividual data structure (mabye even using unpacking).\r\n\r\nThe documention says the following can be pickled\r\n\r\n  1) None, True, and False\r\n  2) integers, floating point numbers, complex numbers\r\n  3) strings, bytes, bytearrays\r\n  4) tuples, lists, sets, and dictionaries containing only picklable objects\r\n  5) functions defined at the top level of a module (using def, not lambda)\r\n  6) built-in functions defined at the top level of a module\r\n  7) classes that are defined at the top level of a module\r\n  8) instances of such classes whose __dict__ or the result of calling\r\n       __getstate__() is picklable\r\n\r\n  Attempts to pickle unpicklable objects will raise the PicklingError exception.\r\n\r\nThis explains only the tip of the pickling iceberg, but it encapsulates some\r\ninteresting aspects of pickling and binary files that you might find useful\r\nwhen you write programs.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nQuestions:\r\n\r\n1) Suppose that we want to process the lower case version of every word on\r\nevery line (where the words on a line are separated by spaces) in a file named\r\nfile.txt. Which of the following code fragments correctly does so? For those\r\nthat don't, explain why they fail. For example, if the file contained the three\r\nlines:\r\n\r\n  See spot\r\n  See spot run\r\n  Run spot run\r\n\r\nit should process the following words in the following order:\r\n  'see', 'spot', 'see', 'spot', 'run', 'run', 'spot', 'run'.\r\n\r\nfor line in open('file.txt'):\r\n    for word in line.rstrip().lower().split():\r\n        process(word)  \r\n\r\nfor line in open('file.txt'):\r\n    for word in line.rstrip().split().lower():\r\n        process(word)  \r\n\r\nfor line in open('file.txt'):\r\n    for word in line.lower().rstrip().split():\r\n        process(word)  \r\n\r\nfor line in open('file.txt'):\r\n    for word in line.lower().split().rstrip():\r\n        process(word)  \r\n\r\nfor line in open('file.txt'):\r\n    for word in line.split().rstrip().lower():\r\n        process(word)  \r\n\r\nfor line in open('file.txt'):\r\n    for word in line.split().lower().rstrip():\r\n        process(word)  \r\n\r\nfor word in open('file.txt').read().lower().split('\\n'):\r\n    process(word)  \r\n\r\nfor word in open('file.txt').read().split('\\n').lower():\r\n    process(word)\r\n", "encoding": "ascii"}