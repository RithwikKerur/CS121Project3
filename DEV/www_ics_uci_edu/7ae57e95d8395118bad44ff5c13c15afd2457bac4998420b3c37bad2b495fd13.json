{"url": "https://www.ics.uci.edu/~pattis/ICS-46/lectures/notes/equivalence.txt", "content": "\t\tEquivalence Relations/Equivalence Classes\r\n\r\n\r\nIn this lecture we will examine equivalence relations (a data type) and a\r\nuseful (and simple) tree data structure to represent and efficiently manipulate\r\nequivalence relations (implement the data type). The tree structure is\r\nfundamentally different from other trees that we have studied: nodes refer only\r\nto their parents, not their children. We will represent such trees not by nodes\r\nand pointers, but by a Map data type: mapping any child to its parent.\r\n\r\nAny equivalence relation (R) has the following three properties\r\n\r\n  (1) Reflexivity : a R a\r\n  (2) Symmetry    : a R b implies b R a\r\n  (3) Transitivity: a R b, and b R c implies a R c\r\n\r\nHere a R b means a is equivalent (by R) to b.\r\n\r\nA simple equivalence relation is \"has the same birthday as\" (here meaning on the\r\nsame month/day, not including the year): (1) Everyone has the same birthday as\r\nthemself. (2) If a has the same birthday as b, then b has the same birthday as\r\na. (3) if a has the same birthday as b, and b has the same birthday as c, then\r\na has the same birthday as c.\r\n\r\nAll the values in an equivalence relation are partitioned into equivalence\r\nclasses: where every value in an equivalence class is known to be equivalent to\r\nevery other value in that same equivalence class, but not to any other values\r\nin any other equivalence classes. So if we partition people by their birthday,\r\neach equivalence class contains all the people with the same birthday.\r\n\r\nFundamentally there are three basic operations that we can perform on\r\nequivalence relations/equivalence classes\r\n\r\n  (1) Add a new value (called a singleton) to the equivalence, starting in its\r\n      own equivalence class (it is not yet equivalent to any other known value)\r\n\r\n  (2) Determine whether or not two values are equivalent (are in the same\r\n      equivalence class)\r\n\r\n  (3) Merge the equivalence classes of two values, creating one equivalence\r\n       class containing all the values in each of the equivalence classes: all\r\n       those values are now equivalent.\r\n\r\n(A variant of this problem is known as the union/find problem, in which we can\r\nfind the equivalance class of a value and union (merge) two equivalence classes)\r\n\r\nWhen restricted to these three operations, to put a value into an existing \r\nequivalence class we must first add it to its own/new equivalence class, and\r\nthen merge its own/new class with the class in which we want to add it.\r\n\r\nWe will define a C++ class for storing equivalences as follows.\r\n\r\ntemplate<class T>\r\nclass ...Equivalence { //Actually Array/BST/Hash/... Equivalence\r\n  public:\r\n    //Fundamental constructors, destructors, and methods\r\n    Equivalence();\r\n    ~Equivalence();\r\n    void add_singleton    (const T& a);\r\n    bool in_same_class    (const T& a, const T& b);\r\n    void merge_classes_of (const T& a, const T& b);\r\n\r\n    //Other methods\r\n    int size        () const;\r\n    int class_count () const;\r\n    ics::ArraySet<ics::ArraySet<T>> classes ();  //Or other Set implementations\r\n\r\n    //Useful for debugging\r\n    ics::ArrayMap<T,int> heights () const;\r\n    int max_height               () const;\r\n    void show_equivalence        () const;\r\n  private:\r\n    //implementation discussed later, involves trees and heights\r\n}\r\n\r\nNote that in_same_class seems like it should be const, but it is not. Later in\r\nthis lecture we will see that a \"compression hueristic\" will be used to\r\nimplement this method more efficiently ,and can change some of its instance\r\nvariables.\r\n\r\nIn addition to the three fundamental methods discussed above, there are 6 more\r\nin the class.\r\n\r\n  1) size returns the number of values in all the equivalence classes\r\n     (equal to the number of times that add_singleton was called)\r\n\r\n  2) class_count returns the number of different equivalence classes.\r\n     It always returns a value between 1 and size() inclusive: if everything\r\n     has been merged, it returns 1; if nothing has been merged (there are size()\r\n     singletons), it returns size().\r\n\r\n  3) classes returns a Set of equivalence classes, where each value is another\r\n     Set (which represents one equivalence class: that is, all the values in\r\n     that equivalence class).\r\n\r\n  4) heights returns the heights of all trees representing an equivalence class\r\n     (based on the implementation discussed below). It actually returns a map\r\n     where each key is a (representative) value in one equivalence class that\r\n     is associated with the height of the tree representing that class.\r\n\r\n  5) max_height returns the maximum height from heights (see 4 above). Iterate\r\n     over the map and return the largest associated value.\r\n\r\n  6) show_equivalence prints the data structures used in the implementation\r\n     (useful for debugging small equivalence classes)\r\n\r\nIf we called classes() before merging any equivalence classes, we would get a\r\nSet in which each value is a Set containing a singleton that we initially added.\r\nIf we merged all the values into one big equivalence class, classes() we would\r\nreturn a Set with just one value: that value would be a Set containing all the\r\nvalues that we orginally added as singletons.\r\n\r\nLet's look at these operations abstractly first. For an example, suppose that\r\nwe start out with 5 singletons: a, b, c, d, and e each in their own equivalence\r\nclass. We could represent these equivalence clases as follows (similar to what\r\nclasses() would return, but in a simpler format).\r\n\r\n  { {a}, {b}, {c}, {d}, {e} }\r\n\r\nHere, size() returns 5 and class_count() returns 5. Also, in_same_class returns\r\nfalse for any different values (of course a value is always in the same\r\nequivalence class as itself, so in_same_class(a,a) would return true).\r\n\r\nIf we called merge_classes_of(a,b) to merge the equivalence class of a with the\r\nequivalence class of b, we would show the result as\r\n\r\n  { {a,b}, {c}, {d}, {e} }\r\n\r\nHere, size() still returns 5 and class_count() returns 4.\r\n\r\nOf course, that has the same meaning as reversing the order of a and b in the\r\nfirst set.\r\n\r\n  { {b,a}, {c}, {d}, {e} }   which is the same as   { {d}, {c}, {e}, {a,b} } ...\r\n\r\nso the order of the values in any set are irrelevant.\r\n\r\nHere, in_same_class(a,b) would return true; calls with all other different\r\narguments would return false. Likewise, if now called merge_classes_of(d,e) to\r\nmerge the equivalence class of d with the equivalence class of e, we would show\r\nthe result as\r\n\r\n  { {a,b}, {c}, {d,e} }\r\n\r\nHere, size() returns 5 and class_count() returns 3.\r\n\r\nAnd if we did one more merge: merge_classes_of(b,e), the equivalence class of\r\nb would merge with the equivalence class of e, we would show the result as\r\n\r\n  { {a,b,d,e}, {c} }\r\n\r\nHere, size() returns 5 and class_count() returns 2.\r\n\r\nWe could also perform this same merge three other ways: as\r\nmerge_classes_of(a,d), merge_classes_of(a,e), or as merge_classes_of(b,d). Any\r\nof these merges produces the same equivalence classes\r\n\r\n------------------------------------------------------------------------------\r\n\r\nImplementations and Algorithms:\r\n\r\nOne simple implementation of equivalence classes would be a Map from each value\r\nto a POINTER to a Set that contains that value (the Set of all values that are\r\nin the same equivalence class; so all values in the Set would map/point to\r\nthe SAME Set; NOT DIFFERENT Sets with the same values). In this implementation:\r\n\r\n  1) add_singleton(a) creates a Set with just a in it, and puts an association\r\n     in the Map from a to a pointer to that Set.\r\n\r\n  2) in_same_class(a,b) returns whether the pointer to the associated Set for a\r\n     and the pointer to the associated set for b are identical: this means the\r\n     pointers have the same address (very quick to check with == on pointers),\r\n     NOT that the sets store the same values (much slower to check); see below\r\n     for how this  occurs when merging.\r\n\r\n  3) merge_classes_of(a,b) checks whether a and b are already in the same\r\n     equivalence class: if so, do nothing; if not, put every value in the\r\n     smaller-sized Set into the bigger-sized Set, and change the Map so that\r\n     each of the values in the smaller-sized Set now is associated with a\r\n     pointer to the bigger-sized Set. We operate on the  smaller Set because it\r\n     has fewer values to process to do the merging. When done, we delete/destroy\r\n     the smaller set whose values were put in the larger set.\r\n\r\nThe complexity classes for these operations are O(1), O(1), and O(N)\r\nrespectively, where N is the size of the smallest Set, and we are using a\r\nhashing version of sets, where most operations are O(1).\r\n\r\nFor example { {a,b}, {c}, {d,e} } would be represented by the map\r\n\r\n  a-> {a,b}\r\n  b---^\r\n  c-> {c}\r\n  d-> {d,e}\r\n  e---^\r\n\r\nNote that a and b point to the same Set object; and d and e point to the same\r\nSet object (not two copies of this Set). So there are 3 different Set objects\r\nstored and 5 pointers pointing to them. If we merged the set with b with the\r\nset with e, the resulting map is\r\n\r\n  a-> {a,b,d,e}\r\n  b---^\r\n  d---^\r\n  e---^\r\n  c-> {c}\r\n\r\nNote that when merging the equivalence classes for b and d, they are equal\r\nsizes, so we could add the values d and e to the set containing a and b, and\r\nmake d and e (in the Map) refer to this newly-enlarged set, or do it the other\r\nway add the values a and b to the set containing d and e, and make a and b (in\r\nthe Map) refer to this newly-enlarged set. In both cases we add 2 values to the\r\nset and change two associations to the newly enlarged set.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nA Faster (N-ary Tree of Parent Pointers) Implementation of Equivalence Classes:\r\n\r\nA more efficient way to store these values and perform these operations on them\r\ninvolves thinking about the equivalence classes as nodes in trees, where each\r\nnode has only a pointer to its parent (and no pointers from nodes to their\r\nchildren: these are N-ary trees). In this data structure, all the values in the\r\nsame equivalence class appear in the same tree: all will have the same root.\r\nInstead of constructing an actual tree object from a TN class (we discuss this\r\napproach later), we will employ two simple Maps (assume HashMaps) to keep track \r\nof the required information.\r\n\r\n(1) parent map: associate every value with its parent: if a value is the root\r\n      of a tree, map it to ITSELF.\r\n\r\n(2) size map: associate every VALUE THAT IS THE ROOT OF A TREE to the size of\r\n      its tree: the number of values contained in the tree is the number of\r\n      values in the equivalence class that the tree represents.\r\n    Only the ROOTS of trees (values that map to themself in the parent map)\r\n      should appear as keys in the size map; no other nodes should be keys.\r\n\r\nSimple Implementation of Equivalence Class Operations\r\n\r\n (1) add_singleton(a): (1) in the parent map, map the value to itself;\r\n     (2) in the size map, map the value to 1 (it is the root in a size 1\r\n      equivalence class).\r\n\r\n (2) in_same_class(a,b) follow each argument to it root and return whether the\r\n     roots are == (see below for how this occurs).\r\n\r\n (3) merge_classes_of(a,b) follow each argument to its root\r\n       (a) if the roots are the same, do nothing: they are already in the same\r\n           equivalence class.\r\n\r\n       Otherwise, using the size map:\r\n       (b) in the parent map, change the root of the smaller-sized equivalence\r\n           class to map to the root of the larger-sized equivalence class\r\n\r\n       (c) in the size map, update the size for the root of the larger-sized\r\n           equivalence class (to be the sum of the two sizes)\r\n\r\n       (d) remove the key that is the root of the smaller-sized equivalence\r\n           class from the size map, because it is no longer a root.\r\n\r\nThe complexity classes for these operations are O(1), O(H), and O(H), where H\r\nis the Height of highest tree. Again, here we assume that we are using a\r\nhash implementation of the map data type.\r\n\r\nIf we declared the singletons a-h, and merged values that were always in\r\ndifferent equivalence classes, the process might go as follows. To start each\r\nvalue is a root.\r\n\r\n  a   b   c   d   e   f   g   h\r\n\r\nMerge a and b; merge d and e; merge g and h (all roots are themselves; of size 1)\r\n\r\n  a   c   d   f   g\r\n /       /       /\r\nb       e       h\r\n\r\nMerge b and e; merge c and f (b's root is a, e's root is d; equal sizes)\r\n\r\n  a      c   g\r\n / \\    /   /\r\nb   d  f   h\r\n   /\r\n  e\r\n\r\nMerge f and g (f's root is c, g's root is g; equal sizes)\r\n\r\n  a      c \r\n / \\    / \\\r\nb   d  f   g\r\n   /      /\r\n  e      h\r\n\r\nMerge e and h (e's root is a, h's root is c; equal sizes)\r\n\r\n    a    \r\n /  |  \\\r\nb   d   c\r\n   /   / \\\r\n  e   f   g\r\n         /\r\n        h\r\n\r\nIn fact, this is the highest tree possible, gotten by always merging trees of\r\nthe same size. With 2 values we can get a tree of height 1 (by merging 2 height\r\n0 trees); with 4 values we can get a tree of height 2 (by merging 2 height 1\r\ntrees). With 8 values we can get a tree of height 3 (by merging 2 height 2\r\ntrees). With 16 values we can get a tree of height 4 (by merging 2 height 3\r\ntrees): see below.\r\n\r\n          a    \r\n /     /    \\     \\\r\nb     d     c        i\r\n     /     / \\     / | \\\r\n    e     f   g   j  k  m\r\n             /      /  / \\\r\n            h      l  n   o\r\n                         /\r\n                        p\r\n\r\nNotice that the rightmost subtree of a looks exactly like the tree root at a\r\nwithout the right subtree. We need to double the number of nodes to get to the\r\nnext height, so the maximum height of a N node equivalence class tree has\r\nheight Log2 N.\r\n\r\nFor the minimum height tree, merge a and b, then a and c, then a and d, ... a\r\nand h, the tree would look like the following\r\n\r\n                      a\r\n             /  /  /  |  \\  \\  \\\r\n            b   c  d  e   f g   h\r\n\r\nIf we ever merge a tree of height h (built by merging other equivalence trees)\r\nwith a tree of less height (built my merging other equivalence trees), the\r\nresult is sitll a tree of height h.\r\n\r\nSo the work done by each of the (2) and (3) operations is Omega(1) and O(Log N).\r\n\r\nNote that a data structure storing many trees is called a forest.\r\n\r\n\r\nPath Compresssion Heuristic Implementation\r\n\r\nWe can improve the the performance above by generating smaller-height trees.\r\nWe will do this, without doing much extra work, by using the \"path compression\"\r\nHeuristic (a rule of thumb)\r\n\r\nFor this implementation, we also define a private helper method named\r\ncompress_to_root, which operates on a single value: it follows the parent\r\nassociations from that value all the way up to its root (as is required for the\r\nin_same_class and merge_classes_of operation), and makes each of the values\r\nthat it finds on the path, have as its parent the ultimate root that it\r\nreaches; the method finally returns its new parent, which is the root of the\r\ntree for that equivalence class.\r\n\r\nAfter path compression, more values are associated with a parent that is the\r\nroot of of its tree. Because the speed of most operations depends on how fast\r\nwe can traverse from any node to the root of the tree representing its\r\nequivalence class, compression will make such a process faster for subsequent\r\noperations on every node on the path that was compressed, because those nodes\r\nnow directly associate with the tree's root: they no longer have to search\r\nthrough intermediate parents to reach the root.\r\n\r\nWe must search for the root for most operations (2 and 3 below). Doing\r\ncompression does not add much time to finding the root: it requires O(H)\r\noperations, changing O(H) nodes to have a new parent. So now these operations\r\nare.\r\n\r\n  1) add_singleton(a): (1) in the parent map, map the value to itself;\r\n     (2) in the size map, map the value to 1 (it is in a size 1 equivalence\r\n     class).\r\n\r\n  2) in_same_class(a,b) compress_to_root each parameter and return whether the\r\n     returned roots are == (see below for how this occurs).\r\n\r\n  3) merge_classes_of(a,b) compress_to_root each parameter\r\n     (a) if the roots are the same, do nothing: they are already in the same\r\n         equivalence class.\r\n\r\n     Otherwise, using the size map:\r\n     (b) in the parent map, change the root of the smaller-sized equivalence\r\n         class to map to the root of the larger-sized equivalence class,\r\n\r\n     (c) in the size map, update the size for the root of the larger-sized\r\n         equivalence class (to be the sum of the two sizes)\r\n\r\n     (d) remove the key that is the root of the smaller-sized equivalence class,\r\n         because it is no longer a root.\r\n\r\nThe complexity classes for these operations are O(1), a bit more than O(1), and\r\na bit more than O(1) respectively (where \"a bit more than O(1)\" is\r\ncharacterized below). Actually, for the last two operations their complexity\r\nclass is O(height of the highest tree), but we are saying that on average these\r\nheights are very small: almost constant. Again, here we assume that we are\r\nusing a hashing version of maps.\r\n\r\nAnother way to say this is that if we perform each of these operation N times\r\n(adding N singletons, doing N checks/merges), the total complexity is a bit\r\nmore than O(N), so each operation is a bit more than O(1).\r\n\r\nIf we declared the singletons a-h, and merged values that were always in\r\ndifferent equivalence classes, the process might go as follows. To start each\r\nvalue is a root (same as without path compression)\r\n\r\n  a   b   c   d   e   f   g   h\r\n\r\nMerge a and b; merge d and e; merge g and h (same as without path compression)\r\n\r\n  a   c   d   f   g\r\n /       /       /\r\nb       e       h\r\n\r\nMerge b and e; merge c and f (same as without path compression)\r\n\r\n  a      c   g\r\n / \\    /   /\r\nb   d  f   h\r\n   /\r\n  e\r\n\r\nMerge f and g (same as without path compression)\r\n\r\n  a      c \r\n / \\    / \\\r\nb   d  f   g\r\n   /      /\r\n  e      h\r\n\r\nMerge e and h (different with path compression)\r\n\r\n     a    \r\n / / |  \\\r\nb e  d  c\r\n      / | \\\r\n     f g  h\r\n\r\nBecause of path compression, this tree now has height 2, not 3 (and with a\r\nhaving more children: the average depth of a child is lower). If we would have\r\nmerged a and c (or b and c; or ....), the result would have been the same as\r\nwithout path compression.\r\n\r\nWhen we start to discuss graphs and graph algorithms, we will see a few good\r\nuses for storing/manipulating equivalence relations: two nodes in a graph will\r\nbe in the same equivalence class if both are reachable from each other. One of\r\nthe problems we discuss will eventually merge all the values into one\r\nequivalence class, requiring N-1 mergings (and will be complexity class about\r\nO(N)).\r\n\r\n------------------------------------------------------------------------------\r\n\r\nEquivalence Tree Sizes and Heights: Proofs\r\n\r\nWhat can we easily prove about the structure of equivalence trees? Without\r\ncompression (just using the fact that we make the root of the smaller tree\r\nrefer to the root of the larger tree), we will first prove that a tree of height\r\nh contains at least 2^h nodes. So even without compression all the trees are\r\nbushy, not pathological, and cannot be too high. And the complexity class of\r\nin_same_class and merge_class would be at most O(Log2 N).\r\n\r\nWith compression we do better: we can end up with an equivalence class whose\r\ntree is a smaller height: even height 1 (with all nodes referring to the root).\r\nThese are NOT binary trees but are N-ary Trees, represented by nodes pointing\r\nto their PARENTS, not nodes pointing to their CHILDREN.\r\n\r\nFor the following discussion, see the pictures below. \r\n\r\n0) A tree of height 0 requires at least 1 node; that is just a singleton.\r\n\r\n1) A tree of height 1 (the result of merging two singletons) requires at least\r\n2 nodes: by merging the roots of two minimal-sized singletons (trees of height\r\n0) their sizes are the same, one root points to the other; so the height of the\r\nresulting tree is 1 + the height of a singleton). Note that if we added another\r\nsingleton to a tree of height 1, it would remain at height 1, with the root\r\nhaving another child (now 2 children). Adding any number of other singletons\r\nwould leave the height of the resulting tree the same.\r\n\r\n2) A tree of height 2 (the result of merging two minimal-sized trees of height\r\n1) requires 4 nodes: since their sizes are the same, one root points to the\r\nother; again the height of the resulting tree is 1 + the height of one\r\ncomponent tree. Note that if we added another height 1 tree to a tree of height\r\n2, it would remain at height 2, with the root having another child (now 3).\r\nAdding any number of other height 1 tress would leave the height of the\r\nresulting tree the same.\r\n\r\n3) A tree of height 3 (the result of merging two minimal-sized trees of height\r\n2) requires 8 nodes: since their sizes are the same, one root points to the\r\nother; again the height of the resulting tree is 1 + the height of one\r\ncomponent tree. Note that if we added another height 2 tree to a tree of height\r\n3, it would remain at height 3, with the root having another child (now 3).\r\nAdding more height 1 tress would leave the height of the resulting tree the\r\nsame.\r\n\r\nIn the examples below, note that the number of children of the root grows by 1\r\neach time (so by the time we get to h = 3, it isn't a binary tree any more).\r\n\r\n h = 0    h = 1     h = 2         h = 3                 h = 4\r\n   O        O         O             O                     O\r\n           /         / \\          / |  \\           /  /  /         \\  \r\n          O         O   O       O   O   O         O  O   O         O\r\n                       /           /   / \\          /   / \\      / |  \\\r\n                      O           O   O   O        O    O  O    O  O   O\r\n                                         /                /       /   / \\\r\n                                        O                O       O   O  O  \r\n                                                                        /\r\n                                                                       O\r\n \r\nEach minimal tree is built by merging two minimal trees with one less height.\r\nSo, the minimum number of nodes in a tree of heigh h (call it m(h)) is given as\r\nm(0)=1 and m(h) = 2*m(h-1) so\r\n\r\n   m(h) = 2 * m(h-1)\r\n        = 4 * m(h-2)\r\n        = 2^i * m(h-i), and m(0) = 1 (when i = h), so\r\n        = 2^h\r\n\r\nWe can also prove to build a tree of height h requires 2^h - 1 merges. Which\r\nmeans that to build a tree with N nodes requires N-1 merges. First observe that\r\nfor h = 3, for example, we must merge the roots of two trees of h = 2. So if\r\nmerges(h) computes the minimnum number of merges required to build a tree of\r\nheight h, generally we have merges(h) = 1 + 2*merges(h-1). So\r\n\r\n  merges(h) = 2^0 + 2^1*merges(h-1)\r\n            = 2^0 + 2^1 + 2^2*merges(h-2)\r\n            = 2^0 + 2^1 + 2^2 + 2^3*merges(h-3), and m(0) = 0 when i = h\r\n            = 2^0 + 2^1 + 2^2 + ... + 2^(h-1) + 2^h * 0\r\n\r\nGenerally, merges(h) = 1 + 2 + ... 2^(h-1) = 2^h - 1\r\n\r\nOf course, if we merged equivalence classes based on values that were NOT at\r\nthe roots, compression would occur and the trees' heights could be reduced.\r\nAnd, whenever we checked in_same_class on two nodes that were not the roots of\r\ntheir trees, the trees' heights could be reduced.\r\n\r\nSo, what kind of performance can we expect after creating N add_singleton values\r\nand doing N calls to merge_classes_of with RANDOM values (when we account for\r\ndoing compression)? The worst case is merging roots, but as the trees get big, a\r\nRANDOM value merged is not likely to be a tree root (because there are many\r\nvalues inside each tree). The mathematics is too complicated, so I'll just\r\nstate the results here without proof:\r\n\r\n-----------\r\n\r\nDoing N merge_classes_of requires O(N Log2* N) operations: notice the *: it\r\nmeans something different than O(N Log2 N), without the *. Log2* is called the\r\niterated logarithm function.\r\n\r\n-----------\r\n\r\nNow let's explore the Log2* function (again, notice the *)\r\n\r\nThe Log2* function is the inverse of the \"tower-of-2 function\" (just as the\r\nLog2 x function is the inverse of the 2^x function). We define the tower-of-2\r\nfunction on n to be a tower of n twos with the exponentiation operator. Notice\r\nthat ^ is RIGHT associative in mathematics, so 2^2^2 is 2^(2^2)\r\n\r\ntower-of-2(1) = 2               = 2\r\ntower-of-2(2) = 2^2             = 4\r\ntower-of-2(3) = 2^(2^2)         = 16\r\ntower-of-2(4) = 2^(2^(2^2))     = 65,536\r\ntower-of-2(5) = 2^(2^(2^(2^2))) = 2^65,536 or about (2^10)^6,553  = 1000^6,553\r\n                                = 10^19,659\r\n(since 1000^6,553 = (10^3)^6,553 = 10^(3*6,533) = 10^19,659)\r\n\r\ngenerally, we can recursively define: tower-of-2(n) = 2^tower-of-2(n-1)\r\n\r\nSo, for Log2* (the inverse function), we have\r\nLog2*(2) =  1\r\nLog2*(n) <= 2 for 2      < n <=      4\r\nLog2*(n) <= 3 for 4      < n <=     16\r\nLog2*(n) <= 4 for 16     < n <= 65,536\r\nLog2*(n) <= 5 for 65,536 < n <= 10^19,659\r\n\r\nGenerally, Log2* N is the number of times that we need to repeatedly take a\r\nlogarithm base 2 to get to 1. We know Log2 16 = 4, Log2 4 = 2, and Log2 2 = 1.\r\nSo, we need to take a logarithm base 2 of 16 exactly 3 times to get to 1. So\r\nLog2*(16) = 3.\r\n\r\nWe saw that 2^x is a very fast growing function, so its inverse function,\r\nLog2 x grows very slowly. The tower-of-two function grows much more quickly\r\nthan 2^x, so its inverse function, Log2*, is an incredibly slowly growing\r\nfunction (much slower than the Log2 function, which itself grows slowly). In\r\nfact, Log2*(N) <= 5 for all sizes of inputs that we are ever likely to compute\r\n(the number of atoms in the universe is estimated to be between 10^78 to 10^82).\r\nThus, practically speaking, we can think about a bound of the Log2*(N) as\r\napproximately 5: like  a constant function (in this universe of computations).\r\nBut technically it grows without bound, as Log2 does, but Log2* grows even much\r\nmore slowly.\r\n\r\nSo, the actual complexity of doing N operation in the Equivalence class (using\r\nHashMap) is O(N Log2* N), which as we have seen is about O(5N) for all sizes of\r\ninputs that we are ever likely to compute with in this universe, and therefore\r\nwill look very much like O(N), with each operation about O(1).\r\n\r\nThe problem with Equivalence classes is also classically known as the\r\nUNION/FIND problem (in which we union the sets associated with equivalence\r\nclasses and find which equivalence class any value is in). So, the find method\r\nwould return the value that is at the root of a value's tree (and do\r\ncompression). I did not provide a find method (and compression is a helper\r\nmethod), but instead provided an in_same_class method, which computes the\r\n\"find\" of both its arguments and  returns whether they are the same, which is\r\ntypically all that is done with the result of the \"find\" method.\r\n\r\nGoogle the union/find and the real complexity class of Equivalence, which is\r\nknown as the inverse of Ackerman's function: it grows even more slowsly than\r\nLog2* (that is, Ackerman's function grows more quickly that the tower-of-2\r\nfunction). Both Log2* and the inverse of Ackerman's function grow very slowly,\r\nbut they do grow. Is there an Equivalence relation implementation that is truly\r\nO(1). Fredman and Saks proved that the lower bound is not Omega(1) but it is the\r\ninverse of Ackerman's function.\r\n\r\nInstead of using a HashMap for storing parents, I actually once programmed these\r\nreverse trees by having each value stored in a node, and each node storing a\r\npointer to its parent node. But, to do the required operations, I still needed\r\na map from values to the nodes storing them, requiring a HashMap access. After\r\nthat, following nodes to their tree's root is faster by following pointers, but\r\nbecause most nodes are close to their tree root, not much time is saved. Of\r\ncourse the implementation is easier using \"off the shelf\" map implementations.\r\n\r\nFinally, to be fail-safe, the methods implementing Equivalence must sometimes\r\ncheck whether or not the parameter value(s) is in the equivalence (in the\r\nparent map at all). If not, they should raise an exception. Also, we must be\r\ncareful to determine if two values whose equivalence classes must be merged are\r\nalready in the same equivalence class (in which case we do nothing: doing the\r\nmerging operations would mess-up the size map, but not the parent map).\r\n\r\nThis week's quiz will give you a chance to implement the equivalence data type\r\nand investigate its complexity.\r\n\r\n", "encoding": "ascii"}