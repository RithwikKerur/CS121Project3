{"url": "https://www.ics.uci.edu/~eppstein/180a/970424.html", "content": "<HTML>\n<HEAD>\n<TITLE>ICS 180, April 24, 1997</TITLE>\n<META name=\"Owner\" value=\"eppstein\">\n<META name=\"Reply-To\" value=\"eppstein@ics.uci.edu\">\n</HEAD><BODY>\n<IMG SRC=\"icslogo2.gif\" WIDTH=472 HEIGHT=72 ALT=\"\"><P>\n<A HREF=\"index.html\">\n<H1>ICS 180A, Spring 1997:<BR>\nStrategy and board game programming</H1></A>\n\n<H2>Lecture notes for April 24, 1997<BR>\nHashing and Move Ordering</H2>\n\n<P>I didn't really finish describing alpha-beta -- my pseudocode included a \nmysterious \"sort list of moves\" step that I didn't explain.  I'll continue \nto leave that dangling while I talk about hashing; we'll connect it up \nin a little while.\n\n<P>The idea of hashing is very simple.  Many games allow \n<I>transpositions</I> of moves, meaning different sequences of moves that \nend up leading to the same position.  For instance, in chess, the opening \nmoves 1. d4 Nf6 2. c4 and 1. c4 Nf6 2. d4 both give the same position \n(known as an Indian defense).  White's two pawn moves could be made in \neither order without changing the result.  As an example of a more complicated \ntransposition, the moves 1. e4 c6 2. d4 d5 3. ed Qxd5 4. Nc3 Qd6 (Caro-Kann \ndefense), 1. e4 d5 2. ed Qxd5 3. Nc3 Qd6 4. d4 c6 (Scandinavian opening), \nand 1. e4 Nf6 2. e5 Ng8 3. d4 d6 4. ed Qxd6 5. Nc3 c6 (Alekhine defense)\nall lead to the same position, after different numbers of moves.\n\n<P>Because of transpositions, the\nsame positions can show up many places in the alpha-beta search tree.  If \nwe store a data structure that remembers what the results of searching each \nposition were, we can look it up rather than searching it again.  But...we \ndon't have enough memory to store all the positions we search.  And, \nlookups must be very fast to make it save time over just searching.  \nFortunately, we have one advantage: it's ok if we sometimes don't find the \nresults from a position we already searched, and search the same position \nagain, as long as it doesn't happen too often.\n\n<P>The answer: hash tables.  Make a big array: as large as \npossible without blowing out your physical memory (you don't want to eat \ninto virtual memory, it will be slow.)\n\n<PRE>\nstruct {\n    long checksum;\t// or long long might be even better\n    int depth;\n    enum { exact, lower_bound, upper_bound } entry_type;\n    double eval;\n} hashtable[HASH_TABLE_SIZE];\n</PRE>\n\nFor each position you search, compute a \"hash value\" x indexing into the \nhash table and another \"hash value\" y for checking whether you've found the \nright position.\n\n<P>Before searching a position, lookup hashtable[x].\nIf hashtable[x].checksum == y, hashtable[x].entry_type == exact,\nand hashtable[x].depth is at least the depth you are currently searching,\nreturn the eval stored there.\n\n<P>After searching the position, store y, the current depth, and the eval you \njust computed, into hashtable[x].\n\n<H3>How to compute hash values?</H3>\n\nZobrist hashing technique (already mentioned before re repetition \ndetection):\nBefore playing the game (maybe hardcode this in your source code) make an \narray Z[square,piecetype] of random numbers.  Hash(board) is then just sum(Z[s,p]) \nsummed over the pieces currently on the board\ncombined with any extra information you might have such as castling \nability.  Often the sum is replaced by a bitwise exclusive or (uparrow in \nC) which is a little faster and easier to work with, but arithmetic \naddition would probably work just as well.\nWhen you move to a new position, you don't have to recompute the hash from \nscratch; instead you can update the hash really quickly by subtracting \nthe old piece square value from where the moved piece was and and adding \nthe new value for its new location.  Use this technique (with \ndifferent random numbers) both for the hash value x and for the checksum y.\n\n<P>Some further tips for using hashing effectively:\n\n<UL>\n<LI>Don't clean out the array after making a move, it only wastes time and \nsome hashed positions might actually still be useful after the move.\n\n<LI>If the same position occurs at different levels in the tree\n(as in the second transposition example we listed above) this can \nactually give you deeper searches than you originally asked for; that's ok.\n\n<LI>Don't hash the positions very near the leaves of the search tree, there \nare too many of them (they'll take away hash table space from more \nvaluable positions) and you're not saving much time by avoiding searching \nthem.\n</UL>\n\n<H3>How does hashing interact with alpha-beta?</H3>\n\n<P>A large fraction of chess program bugs are related to hashing.\nPartly, because it interacts in confusing ways with alpha-beta search.\nBut, you can't avoid dealing with the issue, because you need both hashing \nand alpha-beta to have an efficient searcher.\n\nRecall that, when we call alphabeta(depth,alpha,beta) on a position, one of \nthree things can happen: a fail high, in which we know the eval is at least \nbeta but not exactly what it is; a fail low, in which we know the eval is \nat most alpha but not exactly what it is; and an exact result, \nalpha&nbsp;&lt;&nbsp;eva&nbsp;&lt;&nbsp;beta.  We can only store an exact \nresult in the hash table if we know the exact result.  But a fail high or \nfail low result could still help us prune later.  So, along with exact \nevals, store two other kinds of eval in hash table: a lower bound stating \nthat the eval is at least beta, and an upper bound stating that the eval is \nat most alpha.  We use the entry_type field of the hash table entry to \nspecify what kind of eval is being stored.  If the hash lookup comes back \nwith one of these, we need to see whether it's useful enough to prune \nimmediately without searching the node.  If so, we return it, and otherwise \nsearch the node again.\n\nHere's some pseudocode for alpha-beta search with hashing.\nWe maintain the hashtable index x and checksum y in global variables,\nthat are updated as part of the process of making and unmaking moves.\n\n<PRE>\ndouble alphabeta(int depth, double alpha, double beta)\n{\n    if (depth &lt;= 0 || game is over) return evaluation();\n    if (hashtable[x].checksum == y && hashtable[x].depth &gt;= depth)\n        switch (hashtable[x].entry_type) {\n            case exact: return hashtable[x].eval;\n            case lower_bound:\n                if (hashtable[x].eval &gt;= beta)\n                    return (hashtable[x].eval);\n                else break;\n            case upper_bound:\n                if (hashtable[x].eval &lt;= alpha)\n                    return (hashtable[x].eval);\n                else break;\n        }\n\n    int eval_is_exact = 0;\n    generate and sort list of moves available in the position\n    for (each move m) {\n        make move m;\n        double val = -alphabeta(depth - 1, -beta, -alpha);\n        unmake move m;\n        if (val &gt;= beta) {\n            hashtable[x].checksum = y;\n            hashtable[x].depth = depth;\n            hashtable[x].entry_type = lower_bound;\n            hashtable[x].eval = val;\n            return val;\n        }\n        if (val &gt; alpha) {\n            alpha = val;\n            eval_is_exact = 1;\n        }\n    }\n\n    hashtable[x].checksum = y;\n    hashtable[x].depth = depth;\n    if (eval_is_exact) hashtable[x].entry_type = exact;\n    else hashtable[x].entry_type = upper_bound;\n    hashtable[x].eval = alpha;\n    return alpha;\n}\n</PRE>\n\n<H3>Alpha-beta and move ordering</H3>\n\n<P>I said we'd return to alpha-beta; here it is. We did an optimistic \nanalysis last time of alpha-beta, showing that it can double your search \ndepth if it prunes whenever it can.  The condition that \"it prunes whenever \nit can\" can be expressed more simply: good moves are searched before bad \nones.  The moves don't have to be completely sorted, but the best one should be \nfirst or at least one of the best should be one of the first.  What happens \nif not?  Then we don't do any pruning and we don't search very deeply.\n\n<P>If we classify nodes into type A (all children get searched) and type B \n(we prune after finding a good child) then move ordering is important in \nboth cases: in type B, you want to start with a child that will let \nyou prune the rest.  In type A, you want to choose a first child that is \ngood enough to let all the other children be type B.\n\n<P>Of course, finding good moves is hard: it's the whole reason we're doing \nthe search in the first place.  But we have some clues: (1) we may have \nhashtable entries from previous iterations of iterated deepening that give \napproximations to search values (same positions searched less deeply). (2) \nwe may have some game-specific information, e.g. in chess captures are \noften good moves, try them first.  (3) the killer heuristic: if move m was \nbest in a sibling, and is valid here too, try it.\n\n<P>So, before searching children, add a step: sort them by expected quality.\nThen do the search in the sorted order.\n(Sometimes you can modify the move generator to output moves in \nroughly-sorted order e.g. captures first, and save doing an explicit sort.)\n\n<P>One additional trick: if you think you're going to prune, you don't need \nto sort everything, you just need to output the first few items in sorted \norder.  So you may want to use a sort that you can take items one by one \nfrom and stop early, e.g.  selection sort or heapsort.\n\n<P><HR>\n<A HREF=\"/~eppstein/\">David Eppstein,\n<A HREF=\"/\">Dept. Information & Computer Science</A>,\n<A HREF=\"http://www.uci.edu/\">UC Irvine</A>,\n<!--#flastmod file=\"970424.html\" -->.\n</BODY></HTML>\n", "encoding": "ascii"}