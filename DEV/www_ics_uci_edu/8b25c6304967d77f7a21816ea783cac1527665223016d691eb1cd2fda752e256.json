{"url": "https://www.ics.uci.edu/~ejw/authoring/requirements/draft-whitehead-http-distreq-00.html", "content": "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML//EN\">\n<html>\n<head>\n<title>Requirements for Distributed Editing</title>\n</head>\n\n<body>\n<pre>\nHTTP Working Group                                 E. J. Whitehead, Jr.\nINTERNET-DRAFT                                     U.C. Irvine\n&lt;draft-whitehead-http-distreq-00.txt&gt;              September 1996\n\nExpires March, 1997\n\nRev. 0.4, September 27, 1996\n</pre>\n<br>\n\n<center>\n<h1>Requirements on HTTP for Distributed Content Editing</h1>\n</center>\n\n<h2>Status of this Memo</h2>\n\n<p> \nThis document is an Internet draft. Internet drafts are working\ndocuments of the Internet Engineering Task Force (IETF), its areas and\nits working groups. Note that other groups may also distribute working\ninformation as Internet drafts.\n</p>\n<p>\nInternet Drafts are draft documents valid for a maximum of six\nmonths and can be updated, replaced or obsoleted by other documents\nat any time. It is inappropriate to use Internet drafts as\nreference material or to cite them as other than as \"work in\nprogress\".\n</p>\n<p>\nTo learn the current status of any Internet draft please check the\n\"lid-abstracts.txt\" listing contained in the Internet drafts shadow\ndirectories on ftp.is.co.za (Africa), nic.nordu.net (Europe),\nmunnari.oz.au (Pacific Rim), ds.internic.net (US East coast) or\nftp.isi.edu (US West coast). Further information about the IETF can be\nfound at URL: <A HREF=\"http://www.ietf/org/\">\nhttp://www.ietf.org/</A>\n</p>\n<p>\nDistribution of this document is unlimited.  Please send comments to\nthe WWW Distributed Authoring and Versioning mailing list, \n&lt;w3c-dist-auth@w3.org&gt;, which may be joined by sending a message \nwith subject \"subscribe\" to\n<A HREF=\"mailto:w3c-dist-auth-request@w3.org\">\n&lt;w3c-dist-auth-request@w3.org&gt;</A>.  \nDiscussions are archived at URL:\n<A HREF=\"http://www.w3.org/pub/WWW/Archives/Public/w3c-dist-auth/\">\nhttp://www.w3.org/pub/WWW/Archives/Public/w3c-dist-auth/</A>.\nThe HTTP working group at \n<A HREF=\"mailto:http-wg@cuckoo.hpl.hp.com\">\n&lt;http-wg@cuckoo.hpl.hp.com&gt;</A> also\ndiscusses the HTTP protocol.  Discussions of the HTTP working group\nare archived at URL:\n<A HREF=\"http://www.ics.uci.edu/pub/ietf/http/\">\nhttp://www.ics.uci.edu/pub/ietf/http/</A>. General discussions\nabout HTTP and the applications which use HTTP should take place on\nthe <A HREF=\"mailto:www-talk@w3.org\">\n&lt;www-talk@w3.org&gt;</A> mailing list.\n</p>\n\n<h2>Abstract</h2>\n\n<p>\nThe HyperText Transfer Protocol, version 1.1 (HTTP/1.1), provides\nsimple support for applications which allow remote editing of typed\ndata.  In practice, the existing capabilities of HTTP/1.1 have proven\ninadequate to support efficient, scalable remote editing free of\noverwriting conflicts.  This document presents a list of features in\nthe form of requirements which, if implemented, would improve the\nefficiency of common remote editing operations, provide a locking\nmechanism to prevent overwrite conflicts, improve relationship\nmanagement support between non-HTML data types, provide a simple\nattribute-value metadata facility, and provide for the creation and\nreading of container data types.  These requirements are also\nsupportive of versioning capability.\n</p>\n\n<h2>1. Introduction</h2>\n\n<p>\nThis document describes functionality which, if provided in the\nHyperText Transfer Protocol (HTTP) [4], would support the\ninteroperability of tools which allow remote loading, editing and\nsaving (publishing) of various media types using HTTP.  As much as\npossible, this functionality is described without suggesting a\nproposed implementation, since there are many ways to\nperform the functionality within the HTTP framework.   It is also\npossible that a single mechanism within HTTP could simultaneously\nsatisfy several requirements.\n</p>\n<p>\nMuch of the functionality described in this document stems from the\nassumption that people performing distributed authoring only have\naccess to the objects they are editing via the HTTP protocol.  This is\nin contrast to the majority of current authoring practice, where there\nis access to the underlying storage media, often with a shell or\ngraphical user interface mediating access to a filesystem.  Authors\nneed more than just remote control over their individual documents:\nthey need remote control over the namespace in which those documents\nreside.  Currently, authors control their namespace by interacting\ndirectly with the underlying storage system, but when performing\ndistributed authoring this access is not available. \n</p>\n\n<h2>2. Requirements</h2> \n<p>\nIn the requirement descriptions below, the\nrequirement will be stated, followed by its rationale.  If any current\ndistributed authoring tools currently implement the requirement,\nthis is also mentioned.  It is assumed that \"server\" means \"a program\nwhich receives and responds to HTTP requests,\" and that\n\"distributed authoring tool\" or \"intranet enabled tool\" means \"a program\nwhich can retrieve a source resource via HTTP, allow editing of this\nresource, and then save/publish this resource to a server using HTTP.\"  A\n\"client\" is \"a program which issues HTTP requests and accepts responses.\"\n</p>\n<ol>\n<li><b>Source Retrieval.</b> The source of any given resource should be\nretrievable via HTTP.<br><br> There are many cases where the source\nresource stored on a server does not correspond to the entity\ntransmitted in response to an HTTP GET.  Current known cases are\nserver side include directives, and Standard Generalized Markup\nLanguage (SGML) source entities which are converted on the fly to HyperText \nMarkup Language (HTML) [2] output entities.\nThere are many possible cases, such as automatic conversion of bitmap\nimages into several variant bitmap media types (e.g. GIF, JPEG), and\nautomatic conversion of an application's native media type into HTML.\nAs an example of this last case, a word processor could store its\nnative media type on a server which automatically converts it to HTML.\nA GET of this resource would retrieve the HTML.  Retrieving the source\nof this resource would result in the transmission of the native word\nprocessor entity.<br>\n<br>\nThis requirement should be met by a general mechanism which can handle\nboth the \"single-step\" source processing described above, where the\nsource is converted into the transmission entity via a single\nconversion step, as well as \"multi-step\" source processing, where\nthere are one or more intermediary processing steps and outputs.  An\nexample of multi-step source processing is the relationship between an\nexecutable binary image, its object files, and its source language\nfiles.  It should be noted that the relationship between source resource and\ntransmission entity could be expressed using the \nfunctionality described below in \"Relationships.\"<br>\n<br>\n<li><b>Relationships.</b>  Via HTTP, it should be possible\nto create, query, list, and delete typed relationships between\nresources of any media type.<br><br>\n\nA hypertext link is a relationship between resources which is browsable\nusing a hypertext style point-and-click user interface.\nRelationships, whether they are browsable hypertext links, or simply a\nmeans of capturing a interrelation between entities, have many\npurposes.  Relationships can support pushbutton printing of a\nmulti-resource document in a prescribed order, jumping to the access\ncontrol page for a resource, and quick browsing of related information,\nsuch as a table of contents, an index, a glossary, help pages, etc.\nWhile relationship support is provided by the HTML \"LINK\" element,\nthis is limited only to HTML entities, and does not support bitmap\nimage types, and other non-HTML media types.<br>\n<A HREF=\"http://www.aolpress.com/press/index.html\">\nAOLpress</A> from America Online [1] currently \"allows\npages to add toolbar buttons on the fly using the HTML 3.2 &lt;LINK\nREL....&gt; tag. For example, your page can add toolbar buttons that link\nto a home page, table of contents, index, glossary, copyright page,\nnext page, previous page, help page, higher level page, or a bookmark\nin the document.\" <br>\n<br>\n\n<li><b>Write Locks.</b>  It should be possible, via HTTP, to restrict\nmodification of a resource to a specific person, or list of persons. \nIt should be possible to set single or multi-person write locks with\na single action.\n<li><b>No-Modify Locks.</b>  It should be possible, via HTTP, to indicate\nto the HTTP server that the contents of a resource should not be modified\nuntil the read lock is released.  It should be possible to assign a\nno-modify lock to a single person or a list of persons with a single\naction.\n<li><b>Read Locks.</b>  It should be possible, via HTTP, to restrict the\nability to read a resource to a specific person, or list of persons.\nIt should be possible to set single or multi-person read locks with\na single action.\n<li><b>Partial-Resource Locking.</b> It should be possible to take\nout a write or a read lock on subsections of a resource.<br>\n<li><b>Lock Query.</b> It should be possible to query for whether a\ngiven resource has any active modification restrictions, and if so, who\ncurrently has modification permission.\n<li><b>Independence of locks.</b>  It should be possible to\nlock a resource without re-reading the resource, and without committing to\nediting the resource.<br>\n<li><b>Multi-Resource Locking.</b>  It should be possible to take\nout a lock on multiple resources in the same action,\nand this locking operation must be atomic across these resources.<br>\n<br>\nAt present, HTTP provides limited support for preventing two or\nmore people from overwriting each other's modifications when they save\nto a given URL.  Furthermore, there is no way for people to discover\nif someone else is currently making modifications to a resource.  This\nis known as the \"lost update problem,\" or the \"overwrite problem.\"\nSince there can be significant cost associated with discovering and\nrepairing lost modifications, preventing this problem is crucial for\nsupporting distributed authoring.  A \"write\" lock ensures that only\none person (or list of persons) may modify an resource, preventing\noverwrites.  Furthermore, locking support is also a key component of\nmany versioning schemes, a desirable capability for distributed\nauthoring. <br>\n<br>\nAn author may wish to lock an entire web of resources even though they\nare editing just a single resource, to keep the other resources from\nchanging.  In this way, an author can ensure that if a local hypertext\nweb is consistent in their distributed authoring tool, it will then be\nconsistent when they write it to the server.  Because of this, it\nshould be possible to take out a lock without also causing\ntransmission of the contents of a resource.  Since it should not be\nassumed that because an resource is locked, that it will necessarily be\nmodified, and since many people may wish to have simultaneous\nguarantees that a resource will not be modified, but still not want to\nmodify the resource themselves, it is desirable to have a \"no-modify\" lock\ncapability.  A no-modify lock, by being less restrictive, provides better\nsupport than a write lock for providing a guarantee that a resource\nwill not be modified.  Since it is prudent to frequently save working\ndrafts of a resource, yet undesirable in many cases for working drafts\nto be readable by persons other than the author, a \"read\" lock allows\na resource to have only a limited set of people (perhaps only the author)\nwho can read the current state of the resource.\nIn summary, a no-modify lock states that \nthe resource is guaranteed not to change for the duration of the lock.\nA read lock guarantees that only the owner of the lock may read the\nresource (but there is no guarantee it will not be modified).\nA write lock states that a resource is guaranteed not to change\nonly if the owner of the lock does not change it, and only\nthe owner of the lock may change it.<br>\n<br>\nIt is often necessary to guarantee that a lock or unlock operation\noccurs at the same time across multiple resources, a feature which is\nsupported by the multiple-resource locking requirement.  This is useful\nfor preventing a collision between two people trying to establish\nlocks on the same set of resources, since with multi-resource locking, one of\nthe two people will get a lock.  If this same multiple-resource locking\nscenario was repeated by using atomic lock operations iterated across\nthe resources, the result would be a splitting of the locks between\nthe two people, based on resource ordering and race conditions.<br>\n<br>\nPartial resource locking provides support for collaborative editing\napplications, where multiple users may be editing the same\nresource simultaneously.  Partial resource locking also allows\nmultiple people to simultaneously work on a database type resource.<br>\n<br>\nWhen more than one types of lock is requested on a resource, it\nresults in either multiple, complimentary locks, or lock collisions.\nAn implementation of the locking functionality must specify how the\nlocks interact, noting which combinations result in collisions, and\nwhich combinations are complimentary.\n<br>\n<li><b>Partial Write.</b> After editing a resource, it should be\npossible, via HTTP, to only write the changes to a resource, rather\nthan retransmitting the entire resource.<br>\n<br>\nDuring distributed editing which occurs over wide geographic\nseparations and/or over low bandwidth connections, it would be\nextremely inefficient (and frustrating) to rewrite a large resource\nafter minor changes, such as a one-character spelling correction.\nIdeally, support will be provided for transmitting \"insert\" (e.g., add\nthis sentence in the middle of a document) and \"delete\" (e.g. remove\nthis paragraph from the middle of a document) style updates. \nThese changes could be as small as a byte, or arbitrarily large (perhaps\neven larger than the original resource), and could result in an\narbitrarily large growth or shrinkage of the resource.  Support for\npartial resource updates will make small edits more efficient, and\nallow distributed authoring tools to scale up for editing of large\ndocuments.<br>\n<br>\n<li><b>Attributes.</b> Via HTTP, it should be possible to create,\nmodify, query, read and delete arbitrary attributes on resources of any\nmedia type.<br>\n<br> \nAttributes can be used to define fields such as author, title,\nsubject, and organization, on resources of any media type.  These\nattributes have many uses, such as supporting searches on attribute\ncontents, and the creation of catalog entries as a placeholder for an\nresource which is not available in electronic form, or which will be\navailable later.<br>\n<br>\n<li><b>List URL Hierarchy Level.</b> A listing of all resources, along\nwith their media type, and last modified date, which are located at a\nspecific URL [3] hierarchy level in an http URL scheme should be\naccessible via HTTP, so long as this operation is meaningful.\n<br>\n<br> \nIn [3] it states that, \"some URL schemes (such as the ftp,\nhttp, and file schemes) contain names that can be considered\nhierarchical.\"  Especially for HTTP servers which directly map all or\npart of their URL name space into a filesystem, it is very useful to\nget a listing of all resources located at a particular hierarchy\nlevel.  This functionality supports \"Save As...\" dialog boxes, which\nprovide a listing of the resources at a current hierarchy level, and\nallow navigation through the hierarchy.  It also supports the creation\nof graphical visualizations (typically as a network) of the hypertext\nstructure among the resources at a hierarchy level, or set of levels.\nIt also supports a tree visualization of the resources and their\nhierarchy levels.<br>\n<br>\nThere are many instances where there is not a strong correlation\nbetween a URL hierarchy level and the notion of a container.  One\nexample is a server in which the URL hierarchy level maps to a\ncomputational process which performs some resolution on the name.  In\nthis case, the contents of the URL hierarchy level can vary depending\non the input to the computation, and the number of resources accessible\nvia the computation can be very large.  It does not make sense to\nimplement a directory feature for such a namespace.  However, the\nutility of listing the contents of those URL hierarchy levels which do\ncorrespond to containers, such as the large number of HTTP servers\nwhich map their namespace to a filesystem, argue for the inclusion of\nthis capability, despite not being meaningful in all cases.  If\nlisting the contents of a URL hierarchy level does not makes sense for\na particular URL, then a \"405 Method Not Allowed\" status code could be\nissued.<br>\n<br>\n<A HREF=\"http://www.aolpress.com/press/index.html\">\nAOLpress</A> from America Online currently supports \"Save As...\" dialog\nboxes, and graphical network visualization of a portion of a site's\nhypertext structure, which they term a \"mini-web.\"  <BR>\n<A HREF=\"http://www.microsoft.com/msoffice/frontpage/productinfo/brochure/front3.htm\">\nFrontPage</A> from Microsoft [5] also currently supports a graphical\nnetwork visualization and additionally supports a tree visualization of\na portion of a site's structure.<br>\n<br>\n<li><b>Make URL Hierarchy Level.</b> Via HTTP, it should be\npossible to create a new URL hierarchy level in an http URL scheme.<br>\n<br>\nThe ability to create containers to hold related resources supports\nmanagement of a name space by packaging its members into small,\nrelated clusters.  The utility of this capability is demonstrated by\nthe broad implementation of directories in recent operating systems.\nThe ability to create a URL hierarchy level also supports the creation\nof \"Save As...\" dialog boxes with \"New Level/Folder/Directory\"\ncapability, common in many applications.<br>\n<A HREF=\"http://www.aolpress.com/press/index.html\">\nAOLpress</A> from America Online, currently supports this capability\nthrough their \"Save As...\" dialog box, and their custom MKDIR\nmethod.<br>\n<br>\n\n<li><b>Copy.</b> Via HTTP, it should be possible to make a\nbyte-for-byte duplicate of a resource  without a client loading, then\nresaving the resource.  This copy should leave an audit trail.<br><br>\n\nThere are many reasons why a resource might need to be duplicated, such\nas change of ownership, a precursor to major modifications, or to make\na backup.  In combination with delete functionality, copy can be used\nto implement rename and move capabilities, by performing a copy to a\nnew name, and a delete of the old name.  Due to network costs\nassociated with loading and saving a resource, it is far preferable to\nhave a server perform a resource copy than a client.  If a copied\nresource records which resource it is a copy of, then it would be possible\nfor a cache to avoid loading the copied resource if it already locally\nstores the original.<br>\nNote that in the case of CGI scripts, or other executable content, the\nintent of the copy operation is to make a byte-for-byte copy of the\nsource of the resource, rather than require the server to guarantee that the\nresource will execute in the same manner in the new location as it\ndid in the old location. It is the responsibility of the user\nto ensure the resource behaves properly in its new location.\n<br>\n<li><b>Move/Rename.</b> Via HTTP, it should be possible to change\nthe URL of a resource without a client loading, then resaving the\nresource under a different name.<br><br>\n\nIt is often necessary to change the name of a resource, for example due\nto adoption of a new naming convention, or if a typing error was made\nentering the name originally.  Due to network costs, it is undesirable\nto perform this operation by loading and resaving the resource under the\nnew name,\nfollowed by a delete of the old resource.  Similarly, a single rename\noperation is more efficient than a copy followed by a delete\noperation.  Ideally an HTTP server should record the move operation,\nand issue a \"301 Moved Permanently\" status code for requests on the\nold URL.  A move operation, if implemented with attribute support,\nshould also preserve most attributes across a move.  Note that moving\na resource is considered the same function as renaming an\nresource.<br><br>\n</ol>\n\n<h2>3. Acknowledgments</h2>\n\n<p>\nMy understanding of these issues has emerged as the result of much\nthoughtful discussion, email, and assistance by many people, who\ndeserve recognition for their effort.\n</p>\n<p>\nMartin Cagan, Continuus Software, Marty_Cagan@continuus.com<br>\nDan Connolly, World Wide Web Consortium, connolly@w3.org<br>\nDavid Durand, Boston University, dgd@cs.bu.edu<br>\nRon Fein, Microsoft, ronfe@microsoft.com<br>\nDavid Fiander, Mortice Kern Systems, davidf@mks.com<br>\nRoy Fielding, U.C. Irvine, fielding@ics.uci.edu<br>\nYaron Goland, Microsoft, yarong@microsoft.com<br>\nPhill Hallam-Baker, MIT, hallam@ai.mit.edu<br>\nDennis Hamilton, Xerox PARC, hamilton@parc.xerox.com<br>\nAndre van der Hoek, University of Colorado, Boulder, andre@bigtime.cs.colorado.edu<br>\nGail Kaiser, Columbia University, kaiser@cs.columbia.edu<br>\nRohit Khare, World Wide Web Consortium, khare@w3.org<br>\nDave Long, America Online, dave@sb.aol.com<br>\nHenrik Frystyk Nielsen, World Wide Web Consortium, frystyk@w3.org<br>\nOra Lassila, Nokia Research Center, ora.lassila@research.nokia.com<br>\nLarry Masinter, Xerox PARC, masinter@parc.xerox.com<br>\nMurray Maloney, SoftQuad, murray@sq.com<br>\nJim Miller, World Wide Web Consortium, jmiller@w3.org<br>\nAndrew Schulert, Microsoft, andyschu@microsoft.com<br>\nChristopher Seiwald, Perforce Software, seiwald@perforce.com<br>\nJudith Slein, Xerox, slein@wrc.xeroc.com<br>\nRichard Taylor, U.C. Irvine, taylor@ics.uci.edu<br>\nRobert Thau, MIT, rst@ai.mit.edu<br>\nFabio Vitali, University of Bologna, Italy, fabio@dm.unibo.it<br>\n</p>\n\n<h2>4. References</h2>\n<p>\n[1] America Online, \"AOL Web Tools -- AOLpress 1.2 Features.\" WWW page.  \n<A HREF=\"http://www.aolpress.com/press/index.html\">\nhttp://www.aolpress.com/press/1.2features.html</A>.\n</p>\n<p>\n[2] T. Berners-Lee, D. Connolly. \"HyperText Markup Language Specification - 2.0.\"\nRFC 1866, MIT/LCS, November 1995.\n</p>\n<p>\n[3] T. Berners-Lee, L. Masinter, M. McCahill. \"Uniform Resource Locators (URL).\"\nRFC 1738, CERN, Xerox PARC, University of Minnesota, December 1994.\n</p>\n<p>\n[4] R. Fielding, J. Gettys, J. C. Mogul, H. Frystyk, and T. Berners-Lee.\n\"Hypertext Transfer Protocol -- HTTP/1.1.\" RFC XXXX, U.C. Irvine,\nDEC, MIT/LCS, August 1996.\n</p>\n<p>\n[5] Microsoft. \"Microsoft FrontPage for Windows Data Sheet.\" WWW page.\n<A HREF=\"http://www.microsoft.com/msoffice/frontpage/productinfo/brochure/default.htm\">\nhttp://www.microsoft.com/msoffice/frontpage/productinfo/brochure/default.htm</A>.\n</p>\n\n<h2>Author's Address</h2>\n\n<p>\n<A HREF=\"http://www.ics.uci.edu/~ejw/\">\nE. James Whitehead, Jr.</A><br>\nDepartment of Information and Computer Science<br>\nUniversity of California<br>\nIrvine, CA 92697-3425<br>\n<br>\nPhone: 714-824-4121<br>\nFax: 714-824-4056<br>\nEMail: <a href=\"mailto:ejw@ics.uci.edu\">ejw@ics.uci.edu</a><br>\n</p>\n</body>\n</html>\n", "encoding": "ascii"}