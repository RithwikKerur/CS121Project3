{"url": "https://www.ics.uci.edu/~theory/269/070518.html", "content": "<!DOCTYPE html PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n<html>\n<head>\n<title>Theory Seminar, May 18, 2007</title>\n</head>\n<body>\n<a href=\"/~theory/\"><img src=\"/~theory/logo/shortTheory.gif\" width=\"\n521\" height=\"82\" border=\"0\" alt=\"ICS Theory Group\"></a>\n\n<h2>CompSci 269S, Spring 2007: Theory Seminar</h2>\n\n<h3>May 18, 2007, in Bren Hall 1423</h3>\n\n<h1>Guaranteed-Accurate Floating-Point Summation</h1>\n\n<h2>Yong-Kang Zhu</h2>\n\n<p>Abstract:</p>\n\n<p>Summation of many floating-point numbers introduces many rounding\nerrors.  When the data are ill-conditioned, the computed sum can be far\nfrom the exact sum, being overwhelmed with roundoff error.  Dekker and\nKnuth independently invented an algorithm called <code>AddTwo</code>\nthat adds two floating-point numbers together while simultaneously\ncomputing the exact roundoff error. Based on <code>AddTwo</code>, we\npresent an algorithm, <code>SimpleSum</code>, which repeatedly calls\n<code>AddTwo</code>. Given an array <i>x</i> of summands we prove that,\nafter finite iterations of the outer loop, <code>SimpleSum</code>\nreaches a steady state in which <i>x</i> is sorted by increasing\nmagnitude, non-overlapping mantissas, and fixed exponents, such that\nfrom <i>x<sub>n</sub></i> to <i>x</i><sub>1</sub> each element contains\na smaller-and smaller component of the roundoff error.  That is, the\nconverged state of the array contains a full, exact and optimally\ncompact representation of the sum of the original array. The algorithm\nworks for any floating-point base.</p>\n\n<p>Then, we will briefly outline a more sophisticated algorithm based\non the same principle, that runs in practice in only two \"for\"\nloops, on average, and a \"hybrid\" that uses some other ideas to\nrun even faster.</p>\n\n</body>\n</html>\n", "encoding": "ascii"}