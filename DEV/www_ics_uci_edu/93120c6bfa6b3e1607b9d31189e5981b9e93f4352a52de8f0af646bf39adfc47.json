{"url": "https://www.ics.uci.edu/~skong2/PAG.html", "content": "<html>\n<head>\n<title>Pixel-wise Attentional Gating for Parsimonious Pixel Labeling - Shu Kong (Aimery) - UC Irvine - Computer Vision</title>\n<link rel=\"icon\" href=\"image/SMMMSG.png\" type=\"img/jpg\">\n<style>\nh1 { padding : 0; margin : 0; }\nbody { padding : 0; font-family : Arial; font-size : 16px; background-color : #EFEFEF; } /* background-image : url('bg.png');}*/\n#container { width : 1024px; margin : 20px auto;  background-color : #fff; padding : 50px; border : 1px solid #ccc; }\n#me { border : 0 solid black; margin-bottom : 0;}\n#sidebar { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0;}\n#content { display : block; margin-right : 260px;}\na { text-decoration : none; }\na:hover { text-decoration : underline; }\na:visited { color : blue; }\na.invisible { color : inherit; text-decoration : inherit; }\n.publogo { margin-right : 10px; height: 50px; width: 50px; float : left; border : 0;}\n.publication { clear : left; padding-bottom : 0px;}\n.publication p { height : 60px; }\n.codelogo { margin-right : 10px; float : left; border : 0;}\n.code { clear : left; padding-bottom : 10px; vertical-align :middle;}\n.code .download a { display : block; margin : 0 15px; float : left;}\n<!-- #simpsons { margin : 5px auto; text-align : center; color : #B7B7B7; } -->\n<!-- \t#erdos { color : #999; text-align : center; font-size : 12px; } -->\n</style>\n<script type=\"text/javascript\">\n\nvar _gaq = _gaq || [];\n    _gaq.push(['_setAccount', 'UA-26193351-1']);\n\t_gaq.push(['_trackPageview']);\n(function() {\nvar ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;\nga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';\nvar s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);\n})();\n\n</script>\n</head>\n\n<body>\n<div id=\"container\">\n<div id=\"sidebar\">\n<figure>\n<img src=\"http://www.ics.uci.edu/~skong2/image/icon_PAG.png\" id=\"me\" width=\"200\">\n<figcaption>parsimonious pixel inference</figcaption>\n</figure>\n<br>\n</div>\n\n<div id=\"content\">\n<h1 align=\"center\">Pixel-wise Attentional Gating for Scene Parsing</h1>\n\n\n<p align=\"center\">\n          <a href=\"http://www.ics.uci.edu/~skong2/\" target=\"_blank\">Shu Kong</a>, \n          <a href=\"http://www.ics.uci.edu/~fowlkes/\" target=\"_blank\">Charless Fowlkes</a>\n</p>\n\n\n<p>\n<font color=\"red\">Last update: June 27, 2018.</font>\n</p>\n\nTo achieve parsimonious inference in per-pixel labeling tasks with a limited computational budget, we propose a Pixel-wise Attentional Gating unit (PAG) that learns to selectively process a subset of spatial locations at each layer of a deep convolutional network. PAG is a generic, architecture-independent, problem-agnostic mechanism that can be readily ``plugged in'' to an existing model with fine-tuning. We utilize PAG in two ways: 1) learning spatially varying pooling fields that improve model performance without the extra computation cost associated with multi-scale pooling, and 2) learning a dynamic computation policy for each pixel to decrease total computation while maintaining accuracy.\n\nWe extensively evaluate PAG on a variety of per-pixel labeling tasks, including semantic segmentation, boundary detection, monocular depth and surface normal estimation. We demonstrate that PAG allows competitive or state-of-the-art performance on these tasks. Our experiments show that PAG learns dynamic spatial allocation of computation over the input image which provides better performance trade-offs compared to related approaches (e.g., truncating deep models or dynamically skipping whole layers). Generally, we observe PAG can reduce computation by 10% without noticeable loss in accuracy and performance degrades gracefully when imposing stronger computational constraints.\n\n\n\n<p>\n<b>keywords</b>: \nspatial Attention, Dynamic Computation, Per-Pixel Labeling, Semantic Segmentation, Monocular Depth, Surface Normal, Boundary Detection.\n\n<ul>\n<li>\n<div class=\"publication\">\n<p> <b>S. Kong</b>, C. Fowlkes, \"<font color=#AF7817>Pixel-wise Attentional Gating for Scene Parsing</font>\", <a href=\"http://wacv19.wacv.net/\">WACV</a>, 2019.\n<br>\n[<a href=\"PAG.html\">project page</a>]\n[<a href=\"https://arxiv.org/abs/1805.01556\">paper</a>]\n[<a href=\"https://github.com/aimerykong/Pixel-Attentional-Gating\">github</a>]\n[<a href=\"https://www.ics.uci.edu/~skong2/slides/20180514_AIML_UCI.pdf\">slides</a>]\n[<a href=\"http://www.robustvision.net/leaderboard.php?benchmark=depth\">ROB Challenge Entry of Depth</a>]\n[<a href=\"http://www.robustvision.net/leaderboard.php?benchmark=semantic\">ROB Challenge Entry of Semantic Segmentation</a>]\n\n<!--[<a href=\"https://github.com/aimerykong/Pixel-Attentional-Gating\">demo</a>]\n[<a href=\"http://www.ics.uci.edu/~skong2/PAG.html\">models</a>]\n[<a href=\"http://www.ics.uci.edu/~skong2/PAG.html\">slides</a>]\n[<a href=\"http://www.ics.uci.edu/~skong2/PAG.html\">slides</a>] -->\n</p>\n</div>\n</li>\n</ul>\n\n<div id=\"content\">\n<br><br>\n\t    <center>\n\t      <img src=\"http://www.ics.uci.edu/~skong2/image/PAG_splashFigure.png\" alt=\"[lng_lat_ecef]\" width=\"1000\" />\n\t    </center>\n<br><br>\n</div>\n</ul>\n\n\n\n<br clear=\"both\">\n</div>\n</div>\n\n\n\n</body>\n</html>\n", "encoding": "ascii"}