{"url": "https://www.ics.uci.edu/~kibler/freshmanSyllabus.html", "content": "<h2> Discussion topics </h2>\r\n  <ol>\r\n    <li> Introduction to class format and informal discussion of intelligence.\r\n    <li> <b>1950</b> <i>Can A Machine Think </i>in Computing Machinery and Intelligence by Alan\r\n    Turing.  Poses the problem of deciding whether an\r\n    artifact can exhibit intelligence.\r\n    <li><b>1950</b> <i>Chess Playing Programs and the Problem of Complexity</i> by\r\n    Allen Newell, J Shaw, and Herbert Simon.  Can programs play difficult games well? Discusses\r\n    approaches to game playing, including minimax, static\r\n    evaluation, quiescence, and goals. Does this demonstrate intelligence? What else might be needed? How hard is chess?\r\n    \r\n    <li> <b>1956</b> <i>Realization of a Geometry-theorem Proving Machine</i>\r\n    by H. Gelernter.  Mathematical ability is often thought of as sign of intelligence. Can programs prove theorems? Presents theorem proving as a search\r\n    through a space of goals and subgoals. Shows how to limit\r\n    search by using models. <b>Assignment question</b>: Assume that you have a program that can prove theorems. Is this sufficient/not sufficient to indicate that you have created an intelligence program. Why or why not? \r\n    \r\n    <li> <b>1961</b> <i>GPS: A Program that simulates Human Thought</i> by\r\n    Allen Newell and Herbert Simon.  Can intelligence be revealed by any one ability? Does it require a host of abilities?  N&S provide a general problem\r\n    solving algorithm that relies on states, goals and operators. <b>Assignment Question</b>: How is this program similar or different from the way you solve problems? \r\n    <li> <b>1977</b> <i>Computers and Thought Lecture</i> by Douglas Lenat. <i>The ubiquity of discovery</i>. Lenat surveys several programs that do scientific discovery, or do they? <b>Assignment question</b>: Are these programs doing scientific discovery? Argue for or against.\r\n    \r\n    <li> <b>1981</b> Rodney Brooks: Brooks argues that intelligence can be achieved without reason or representation, two key assumptions behind most AI research. Darpa issued a million dollar challenge for an autonomous vehicle that would traverse natural environments. Search for Humanoid robots via google. Asimov and Wakamaru are two. Others? <b>Assignment question(s)</b>: Can we build Hal?  Why or why not? What can programs do? Use specifics from readings.\r\n <li> <b>1982</b> Marvin Minsky <i>Why People Think Computers Can't</i>  You may find Minsky's web site interesting. <b>Assignment Questions</b>\r\n Do you agree that his \"web of meaning\" yields meaning? Do you think computers can be conscious?\r\n <li> <b>1999</b> Tom Mitchell <i>Machine Learning and Data Mining</i>  <b>Assignment questions: </b> Are these programs learning? Why or why not?\r\n  <li> Tieing it all together:  <b>Assignment questions</b>: What papers did you find most valuable? Is AI achieving intelligence? \r\n\r\n  </ol>\r\n  <h2> Other Potential Topics/Papers </h2>\r\n  <ul>\r\n        <li> What is Bioinformatics?\r\n        <li> Can Programs do medical diagnosis?\r\n        <li> Practical application of learning\r\n        <li>  <i>AM: A Mathematician</i> by Douglas Lenat. Is proving theorems or solving differential equations an indication of intelligence? A more creative task is discovering theorems. Lenat\r\n    demonstrates a heuristic approach to generate mathematical\r\n    conjectures and definitions by examining examples.\r\n    <li> <i>Some Studies in Machine Learning Using the Game of\r\n    Checkers</i> by Arthur Samuel. (1954) Can programs learn? Demonstrates an effective\r\n    learning algorithm and discusses the problem of\r\n    representation. Does this convince you that programs can be intelligence? Why or Why not? What can programs do?\r\n    <li> <i>The Principle Acts of Conceptual Dependency</i> by Roger Schank. (1969) Provides a\r\n    core conceptual language that he hoped would allow for\r\n    representing the meaning of sentences. Representation is a key problem in AI. \r\n    <li> <i>Mapping Ontologies into Cyc</i> by Douglas Lenat. (2002) An attempt to store everything a child knows by the age of five or common sense knowledge.\r\n    Cyc stores world knowledge in multiple forms, including first and second order logic.\r\n    Inference is handled by special algorithms for efficiency. Currently has several million facts and rules.\r\n    <li><i>Prolog</i> by Kowalski.  Prolog is a programming\r\n    language based on logic. Computation is viewed as logical\r\n    deduction (formally resolution). In this context a program is simply a\r\n    collection of facts and rules. You query the program and it used the facts and rules to generate a proof.\r\n    <\r\n\r\n\r\n        <li> \r\n        </ul>\r\n <h3> Notes </h3>\r\n <ul>\r\n   <li> Complexity: $1,000,000 Clay (mathematics prize) for settling tennis pickup problem.\r\n   Suppose you want pick up N tennis balls and return your spot, with the least amount of work. What is an upper bound on the number of operations you need to figure out the best path?\r\n<li> Lenat on why he went into AI. (1971) <br>\r\nOne was that it was positively reinforcing --- you would be building something like a mental amplifier that would make you smarter, hence would enable you to do even more and better things. \r\n<br>\r\nThe second interesting property was that it was clear researchers in the field didn't know what the hell they were doing. <br>\r\n\r\n\r\n<li> Charlie Brown on Natural Language Processing: <br>\r\n Lucy and Charlie are on the baseball field and it is raining. Lucy is holding an umbrella. <br>\r\nCharlie says: \"You can't catch a baseball holding an umbrella\". <br>\r\nLucy says: \"How did he know that?\"\r\n</ul>\r\n", "encoding": "ascii"}