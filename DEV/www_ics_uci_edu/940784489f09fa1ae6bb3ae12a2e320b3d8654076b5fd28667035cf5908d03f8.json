{"url": "https://www.ics.uci.edu/~pattis/ICS-46/lectures/notes/graphalgorithmsI.txt", "content": "\t\t\tGraph Algorithms I:\r\n\r\n  (Topological Sorting, Connected Components, Minimum Spanning Tree)\r\n\r\nBefore looking at these three algorithms, let's examine the HashGraph class\r\nthat you will write as part of Programming Assignment #5.\r\n\r\nFirst, note that it uses a LocalInfo class which keeps sets of incoming and\r\noutgoing nodes and edges for each node in the graph. This is redundant\r\ninformation (it takes up more space than necessary, and we could reconstruct it\r\nfrom less information) but it allows standard graph operations to all run in\r\nO(1).\r\n\r\nSecond, note that the ArrayGraph classes keeps a map from each node to its\r\nLocalInfo as well as a map from each node-pair to its edge value (of type T) \r\n-if the nodes are connected by an edge.\r\n\r\ntemplate<class T>\r\nclass ArrayGraph {\r\n  //Forward declaration: used in templated typedefs below\r\n  private:\r\n    class LocalInfo;\r\n\r\n  public:\r\n    //Typedefs\r\n    typedef std::string                         NodeName;\r\n    typedef ics::pair<NodeName, NodeName>       Edge;\r\n    typedef ics::pair<NodeName, LocalInfo>      NodeLocalEntry;\r\n    typedef ics::ArrayMap<NodeName, LocalInfo>  NodeMap;\r\n    typedef ics::ArrayMap<Edge, T>              EdgeMap;\r\n    typedef ics::pair<NodeName, LocalInfo>      NodeMapEntry;\r\n    typedef ics::pair<Edge, T>                  EdgeMapEntry;\r\n    typedef ics::ArraySet<NodeName>             NodeSet;\r\n    typedef ics::ArraySet<Edge>                 EdgeSet;\r\n\r\n    static bool LocalInfo_gt(const NodeLocalEntry& a, const NodeLocalEntry& b)\r\n    {return a.first < b.first;}\r\n\r\n\r\n    //Destructor/Constructors\r\n    ~ArrayGraph();\r\n    ArrayGraph();\r\n    ArrayGraph(const ArrayGraph<T>& g);\r\n\r\n    //Queries\r\n    bool empty      ()                                     const;\r\n    int  node_count ()                                     const;\r\n    int  edge_count ()                                     const;\r\n    bool has_node  (std::string node_name)                 const;\r\n    bool has_edge  (NodeName origin, NodeName destination) const;\r\n    T    edge_value(NodeName origin, NodeName destination) const;\r\n    int  in_degree (NodeName node_name)                    const;\r\n    int  out_degree(NodeName node_name)                    const;\r\n    int  degree    (NodeName node_name)                    const;\r\n\r\n    const NodeMap& all_nodes()                   const;\r\n    const EdgeMap& all_edges()                   const;\r\n    const NodeSet& out_nodes(NodeName node_name) const;\r\n    const NodeSet& in_nodes (NodeName node_name) const;\r\n    const EdgeSet& out_edges(NodeName node_name) const;\r\n    const EdgeSet& in_edges (NodeName node_name) const;\r\n\r\n    //Commands\r\n    void add_node   (NodeName node_name);\r\n    void add_edge   (NodeName origin, NodeName destination, T value);\r\n    void remove_node(NodeName node_name);\r\n    void remove_edge(NodeName origin, NodeName destination);\r\n    void clear      ();\r\n    void load       (std::ifstream& in_file,  std::string separator = \";\");\r\n    void store      (std::ofstream& out_file, std::string separator = \";\");\r\n\r\n    //Operators\r\n    ArrayGraph<T>& operator = (const ArrayGraph<T>& rhs);\r\n    bool operator == (const ArrayGraph<T>& rhs) const;\r\n    bool operator != (const ArrayGraph<T>& rhs) const;\r\n\r\n    template<class T2>\r\n    friend std::ostream& operator<<(std::ostream& outs, const ArrayGraph<T2>& g);\r\n\r\n\r\n  private:\r\n    //All methods and operators relating to LocalInfo are defined below, followed by\r\n    //  a friend function for << onto output streams for LocalInfo\r\n    class LocalInfo {\r\n      public:\r\n        LocalInfo() {}\r\n        LocalInfo(ArrayGraph<T>* g) : from_graph(g) {}\r\n        void connect(ArrayGraph<T>* g) {from_graph = g;}\r\n        bool operator == (const LocalInfo& rhs) const {\r\n          //No need to check in_nodes and _out_nodes: redundant information there\r\n          return this->in_edges == rhs.in_edges && this->out_edges == rhs.out_edges;\r\n        }\r\n        bool operator != (const LocalInfo& rhs) const {\r\n          return !(*this == rhs);\r\n        }\r\n\r\n        //LocalInfor instance variables\r\n        //The LocalInfo class is private to code #including this file, but public\r\n        //  instance variables allows ArrayGraph them directly\r\n        //from_graph should point to the ArrayGraph of the LocalInfo it is in, so\r\n        //  LocalInfo methods can access its edge_value map (see <<)\r\n        ArrayGraph<T>* from_graph = nullptr;\r\n        NodeSet       out_nodes;\r\n        NodeSet       in_nodes;\r\n        EdgeSet       out_edges;\r\n        EdgeSet       in_edges;\r\n    };\r\n\r\n\r\n    friend std::ostream& operator<<(std::ostream& outs, const LocalInfo& li) {\r\n      outs << \"LocalInfo[\" << std::endl << \"         out_nodes = \" << li.out_nodes << std::endl;\r\n      outs << \"         out_edges = set[\";\r\n      int printed = 0;\r\n      for (Edge e : li.out_edges)\r\n        outs << (printed++ == 0 ? \"\" : \",\") << \"->\" << e.second << \"(\" << li.from_graph->edge_values[e] << \")\";\r\n      outs << \"]\" << std::endl;\r\n\r\n      outs << \"         in_nodes  = \" << li.in_nodes << std::endl;\r\n      outs << \"         in_edges  = set[\";\r\n      printed = 0;\r\n      for (Edge e : li.in_edges)\r\n        outs << (printed++ == 0 ? \"\" : \",\") << e.first << \"(\" << li.from_graph->edge_values[e] << \")\" << \"->\" ;\r\n\r\n      outs << \"]]\";\r\n      return outs;\r\n    }\r\n\r\n    //ArrayGraph<T> instance variables\r\n    NodeMap node_values;\r\n    EdgeMap edge_values;\r\n};\r\n\r\nIn the following algorithms, we assume a HashGraph for computing complexity\r\nclasses (and HashSets, HashMaps, etc). We also assume a graph has N nodes and\r\nM edges: recall M can be anything from 0 to N^2.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nTopological Sorting\r\n\r\nFirst, we will discuss Topological Sorting. Here the domain is a digraph where\r\nan edge from A to B means node A \"comes before\" node B (or, if you will, node\r\nA is \"less than\" node B). Note that the edge can have a value too, but only the\r\nexistence of an edge is relevant to this algorithm.\r\n\r\nUnlike normal types where the law of trichotomy holds (for any two values, one\r\nis <, =, or > than the other) two values might be \"uncomparable\" meaning their\r\norder is not directly specified: there is no edge from A to B or from B to A.\r\nOf course, if there is a path from A to B that means A is < B (same from B to\r\nA).\r\n\r\nThe edges in the graph supply what mathematicians call a \"partial order\" of the\r\nnodes. A topological sort of a graph is a sequence of nodes such that all the\r\nconstraints (edges saying which nodes come before which  others) are satisified\r\nin the resulting sequence. In the node sequence a, b, c, ... then either there\r\nis an path a->b (a < b) or no path between a and b; there is an path b->c\r\n(b < c) or no path between b and c; ...\r\n\r\nThe original \"make\" program for compiling systems built from many C modules\r\nhad a list of entries of the form c1.c -> c2.c, meaning the C program file c1.c\r\nmust be compiled before the C program file c2.c. the \"make\" program would create\r\na graph whose nodes were program files, with edges indicating the order of\r\ncompilation for any program files for which order was important. The \"make\"\r\nprogram would first topologically sort this graph to determine in what order to\r\ncompile all the program files, and then compile each file according to that\r\norder.\r\n\r\nA simple algorithm for doing topological sorting follows. It produces a queue\r\nof nodes satisfying all the edge constraints (e.g., ArrayQueue<String>). Note\r\nthat this algorithm mutates the graph while running: if the graph must remain\r\nunchanged, we can copy the graph first.\r\n\r\n  while there is a node with in-degree 0\r\n    enqueue it to (put it next in) the answer queue\r\n    remove it from the graph (affecting the degrees of other nodes\r\n                              the refer to it or that it refers to)\r\n\r\nThis process continues until (a) all nodes are removed from graph or (b) some\r\nnodes still remain in the graph, but no node has in-degree = 0. In the latter\r\ncase, the graph is cyclic: there are nodes a, b, c, ... ,x, y, z such that \r\nedges require that a must come before b, b must come before c, ... x must come\r\nbefore y, y must come before z, and z must come before a (which is an impossible\r\nordering). If no node has in-degree 0, then every node is the destination of\r\nanother (only possible if there is a cycle).\r\n\r\nNote that the sequence of nodes may NOT be uniquely determined: if at any time\r\nthere is more than 1 node with in-degree 0, we can arbirarily choose any of\r\nthose nodes to come next in the queue: there are no constraints on which order\r\nthey appear.\r\n\r\nRecall that in graphs, we usually let N denote the number of nodes in the graph\r\nand M denote the number of edges. In sparse graphs M is O(N) and in dense graphs\r\nM is O(N^2).\r\n\r\nWe can characterize this algorithm as O(N^2 + M): finding an in-degree 0 node\r\nis O(N) (iterate through all the nodes), and in a non-cyclic graph this will\r\nhappen N times before the graph is empty. To remove all the nodes requires\r\nremoving all M edges. For dense graphs the complexity is O(N^2 + N^2) = O(N^2).\r\nFor sparse graphs the complexity is O(N^2 + N) = O(N^2).\r\n\r\nWe will apply this algorithm to generate one (of a few different) topological\r\norders (we have lattitude to pick an in-degree 0 node; different picks lead\r\nto different final orders, but all satisifying the required constraints) for\r\nthe graph below (draw a picture of this graph before starting).\r\n\r\nA -> D\r\nA -> E\r\nB -> D\r\nC -> E\r\nC -> H\r\nD -> F\r\nD -> G\r\nD -> H\r\nE -> G\r\n\r\nOne order is: A, B, C, D, E, F, G, H\r\nAnother is  : B, A, C, D, F, H, E, G\r\n\r\nA slightly more complicated but faster algorithm (by Kahn) for a graph G first\r\ncomputes a set of all source nodes and updates this set based on removing edges\r\n(at which time new nodes can become source nodes).\r\n\r\nO = a queue that is empty\r\nS = a set of all source nodes (with in-degree 0)\r\nwhile S is not empty\r\n  n = any node from S (use an iterator to get just the \"first\")\r\n  enqueue n to O\r\n  for each edge e (from n to m)\r\n    remove edge e from the graph\r\n    if in-degree of m is now reduced to 0 by the removal\r\n      add m into S\r\n\r\nif the graph has edges after terminating the loop, then\r\n  the graph is cyclic\r\nelse \r\n  O is a topologically sorted version of all nodes in G\r\n\r\nComputing O and S initially are O(1) and O(N) respectively.\r\n\r\nFor an acyclic graph, the outer loop executes once for each node, so is executed\r\nN times; the inner loop executes once for each edge, so is executed a total of\r\nM times (a bit at a time, some for each outer loop). The other operations are\r\nall O(1) so the running time is O(N+M). Recall that for dense graphs M is\r\nO(N^2), so in the worst case (a dense graph) this algorithm is O(N+N^2) =\r\nO(N^2). But if the graph is sparse (say each node as at most 10 edges), then it\r\nis O(N + 10N) = O(N).\r\n\r\n------------------------------------------------------------------------------\r\n\r\n\r\nConnected Components\r\n\r\nIf an undirected graph is connected, it means that we can reach any node by\r\nfollowing a path from any other node (edges go both ways). If a graph is not\r\nconnected, there are node pairs that are not reachable from each other.\r\nNon-connected graphs contain connected components: subgraphs that are each\r\nconnected. If a graph is connected then there is just one component, which\r\nincludes every node; if it is not connected there will be some number (>1) of\r\nsubgraphs, each of which is connected (all the subgraph's nodes can reach each\r\nother) and in the extreme case -a graph with no edges- every node is in its own\r\nconnected component. \r\n\r\n\"Connected to\" is an equivalence relation in an undirected graph:\r\n  1) Any node is connected to itself\r\n  2) If a is connected to b, then b is connected to a (in an undirected graph)\r\n  3) If a is connected to b, and b is connected to c, then a is connected to c\r\n\r\nSo, we can compute the connected components of a graph using an equivalence\r\nrelation. Each equivalence class represents one connected component: all the\r\nnodes in an equivalence class can reach each other. The algorithm is simply:\r\n\r\n  1) Put every node in the graph into its own equivalence class (as a singleton)\r\n\r\n  2) For every edge in the graph, merge the equivalence classes of its\r\n       origin and destination nodes.\r\n\r\nThe complexity class is O(N+M) since (1) we put each of the N nodes in an\r\nequivalence class N*O(1), and (2) each the loop process every edge exactly\r\nonce and each equivalence relation operation is approximately O(1) for \r\nHashEquivalence using the compression heuristic. So, in a dense graph M is\r\nO(N^2), so this algorithm is also O(N^2); for a sparse graph M is O(N) so this\r\nalgorithm is O(N). Note that this process terminates when all the edges are\r\nprocessed; it could also terminate when the number of classes is 1: at this\r\npoint all nodes are in the same component, so processing more edges is not\r\nnecessary.\r\n\r\nOne application of computing connected components is the \"percolation problem\":\r\nIt asks, given a matrix of values (some open = blank, some closed = X), is\r\nthere a path from any of the open top line cells to the open bottom line cells.\r\nA path must move through only open cells, and each open cell must be connected\r\nto the next by moving up, down, left, or right (not diagonally). An example\r\nmatrix is:\r\n\r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X |   | X | X |   | X | X |   | X | X |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X |   |   |   | X |   |   | X | X | X |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X | X | X |   | X |   |   | X | X | X |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X | X | X |   |   |   |   |   |   | X |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X |   |   | X | X | X | X | X |   |   |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X |   |   | X |   |   |   | X |   |   |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X |   |   | X |   | X |   |   |   |   |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X |   |   | X |   | X | X | X | X | X |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X | X | X |   |   | X | X |   |   | X |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X | X | X |   | X | X | X |   |   | X |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n\r\nHere is a percolation path through this matrix (numbered 1-24). Note the numbers\r\ngenerally go downward (bigger numbers BELOW smaller numbers), but some numbers\r\non the path go upward (bigger numbers ABOVE smaller numbers).\r\n\r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X | 1 | X | X |   | X | X |   | X | X |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X | 2 | 3 | 4 | X |   |   | X | X | X |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X | X | X | 5 | X |   |   | X | X | X |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X | X | X | 6 | 7 | 8 | 9 | 10| 11| X |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X |   |   | X | X | X | X | X | 12|   |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X |   |   | X | 19| 18| 17| X | 13|   |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X |   |   | X | 20| X | 16| 15| 14|   |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X |   |   | X | 21| X | X | X | X | X |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X | X | X | 23| 22| X | X |   |   | X |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n| X | X | X | 24| X | X | X |   |   | X |   \r\n+---+---+---+---+---+---+---+---+---+---+\r\n\r\nTo solve this problem, assume that every matrix cell is a node in graph. Put an\r\nedge in the graph between every two adjacent open nodes (the ones that are next\r\nto each other: either related as top/bottom or left/right). Note that this is a\r\nsparse graph because each node has at most 4 edges. Also, put a node outside\r\nthe matrix on the top and on the bottom: the top one has edges to each open\r\ncell in the first line; the bottom one has edges to each open cells in the\r\nbottom line. Now compute the connected components of this graph. There is a\r\npercolation path if the extra node on top is in the same component as the extra\r\nnode on the bottom.\r\n\r\nNote that running this algorithms says whether or not a percolation exists. It\r\ndoesn't compute the percolation path. To do that you could do a graph search\r\nstarting at the extra node at the top. To find the minimum path would be like a\r\nbreadth first search (finding all nodes reachable in 1 step, 2 steps, etc.\r\nkeeping track of the fastest way to reach each node).\r\n\r\n------------------------------------------------------------------------------\r\n\r\nMinimum Spanning Tree (MST):\r\n\r\nA spanning tree of a undirected graph is a subgraph, such that every node is\r\nreachable from every other node, WITH NO REDUNDANT EDGES. That means in a graph\r\nwith N nodes, will have exactly N-1 edges in its spanning tree. The graph must\r\nbe connected to have a spanning tree. We can prove we need only N-1 edges by\r\ninduction. In all 1 node graphs, we need only 0 edges to have the graph be\r\nconnected (satisfying the N-1 requirement); if we take any connected N node\r\ngraph and add another node, all we must do is add one more edge (from any of\r\nthe N nodes to the new one) to have the graph be connected again.\r\n\r\nNote that spanning trees are acyclic graphs, because any cyclic structure has a\r\nredundant edge: we can remove any edge in the cycle and the graph is still a\r\nspanning tree.\r\n\r\nWe call this graph a spanning \"tree\" because we can look at each graph as\r\na tree: chose any node as the root; all the nodes immediately reachable from it\r\nbecome the root's children; the nodes immediately reachable from these (those\r\nnot already reached) become the grandchildren, etc. Choosing a different root\r\nwill yield a different tree. The height of each tree is the maximum number of\r\nedges that must be followed from the root node to reach the \"farthest away\"\r\nnode.\r\n\r\nA minimum spanning tree (MST) is a spanning tree whose cost (sum of its edges;\r\nassuming they are numbers) is the minimum possible.\r\n\r\nIf we wanted to connect various cities with a phone network, and we knew the\r\ncost of laying the fiber-optic cable between any two cities (it might NOT just\r\nbe proportional to the the linear distance between the cities: this cost is the\r\nvalue on an edge between two cities), finding the MST would solve the problem.\r\n\r\nKruskal's algorithm is one efficient way to find a MST. To run this algorithm,\r\nwe must be able to tell whether an edge connects two nodes that do not yet (in\r\nthe MST we are building) have a path between them. We can easily \"see\" this\r\nproperty on small graphs; we have seen above that connectedness is an\r\nequivalence relation, which we implement efficiently with a HashEquivalence. We\r\nwill use that data type in our algorithm, along with a priority queue.\r\n\r\nKruskal's Algorithm for MST\r\n\r\n  1) Put each node in own equivalence class (add_singleton in Equivalence). \r\n\r\n  2) Put all the edges in a priority queue, such that edges with smaller values\r\n       have higher priorities.\r\n\r\n  3) Start with a MST graph containing all the nodes but no edges. It will\r\n       eventually store these same nodes and only edges that are in the minimum\r\n       spanning tree.\r\n\r\n  4) While T's # edges < N-1 (see above: N node graphs have N-1 edge MSTs)\r\n       a) Dequeue the next edge from the priority queue (the smallest remaining\r\n            edge value).\r\n          If there are no more edges, the graph isn't connected and there is\r\n            no [minimal] spanning tree \r\n       b) If its origin and destination nodes are in the SAME equivalence\r\n            class, do nothing\r\n          If its origin and destination nodes are in two DIFFERENT equivalence\r\n            classes, add the edge to MST and merge the equivalence classes of\r\n            the origin and destination nodes.\r\n\r\nThe complexity of this algorithm is O(N + M Log2 M). The N term comes from\r\nstep 1, the M Log2 M term comes from step 4 - possibly dequeuing all the edges\r\nin the priority queue (in the case of a graph with the longest edge going to a\r\nnode that is connected to no other node).\r\n\r\nIn a sparse graph, with O(N) edges, this algorithm is just O(N Log2 N),\r\ntherefore it is \"fast\" (like fast sorting). In a dense graph, with O(N^2), the\r\nalgorithm is O(N^2 Log2 N^2), which is actually O(N^2 Log2 N) because\r\nLog2 N^2 = 2 * Log2 N (and we remove the constant factor).\r\n\r\nKruskal's algorithm is known as a \"Greedy algorithm\". In a greedy algorithm a \r\nlocally correct choice (here the next smallest edge to process) is guaranteed\r\nto be in the solution. So, once we choose this edge to be part of a MST, we\r\nwill never have to \"unchoose\" it. In Standard backtracking search algorithms\r\nsometimes we make choices that we have to \"unmake\", choosing something else\r\ninstead (so such an algorithm is not greedy). If a problem is solvable by a\r\ngreedy algorithm, the choices the algorithm makes never need to be un-made\r\n(and typically its complexity class will be lower than for a backtracking\r\nsearch, whose complexity class is exponential).\r\n\r\nAn example of a problem where a greedy algorithm fails is making change using\r\nUS currency (where there are a limited number of coins). Normally you'd first\r\nfind the number of quarters needed, then find the number of dimes, then nickels,\r\nthen pennies. But suppose you want to make 30 cents change but in the cash\r\nregister has only 1 quarter, 3 dimes, and no nickels or pennies. A greedy\r\nalgorithm would choose the quarter first, but be unable to choose any dimes,\r\nand fail to solve the problem because there are no nickels. A backtracking\r\nsearch algorithm would undo the choice of 1 quarter, then choose 3 dimes to\r\nsolve the problem.\r\n\r\nApplying Kruskal's algorithm to a graph with unique edge costs will produce a\r\nunique MST. If some edge costs are duplicates, then there might be multiple\r\nMSTs with the same total cost.\r\n\r\nWe applied this algorithm to generate an MST for the graph below. Here\r\nA<-(4)->B means the cost of the undirected edge between A and B is 4.\r\n\r\nA<-(4)->B\r\nA<-(1)->C\r\nA<-(4)->D\r\nB<-(5)->C\r\nB<-(7)->G\r\nB<-(9)->E\r\nB<-(9)->F\r\nC<-(3)->D\r\nD<-(10)->G\r\nD<-(18)->J\r\nE<-(2)->F\r\nE<-(4)->H\r\nE<-(6)->I\r\nF<-(8)->G\r\nF<-(2)->H\r\nG<-(9)->H\r\nG<-(8)->J\r\nH<-(3)->I\r\nH<-(9)->J\r\nI<-(9)->J\r\n\r\nIf we put these values in the priority queue, one order (there are multiple\r\nedges with the same value). Also, initially each node is in its own separate\r\ncluster/equivalence class\r\n\r\nA<-(1)->C\r\nE<-(2)->F\r\nF<-(2)->H\r\nC<-(3)->D\r\nH<-(3)->I\r\nA<-(4)->B\r\nA<-(4)->D\r\nE<-(4)->H\r\nB<-(5)->C\r\nE<-(6)->I\r\nB<-(7)->G\r\nF<-(8)->G\r\nG<-(8)->J\r\nB<-(9)->E\r\nB<-(9)->F\r\nG<-(9)->H\r\nH<-(9)->J\r\nI<-(9)->J\r\nD<-(10)->G\r\nD<-(18)->J\r\n\r\nNote that this graph has 10 nodes so the MST will have 9 edges, so we can\r\nterminate the algorithm when we reach 9 edges.\r\n\r\n 1) We remove A<-(1)->C; A and C are in different clusters, so we put this edge\r\nin the MST (it now has 1 edge) and update the clusters so that now {A,C} are in\r\nthe same cluster.\r\n\r\n 2) We remove E<-(2)->F; E and F are in different clusters, so we put this edge\r\nin the MST (it now has 2 edges) and update the clusters so that now {E,F} are\r\nin the same cluster.\r\n\r\n 3) We remove F<-(2)->H; F and H are in different clusters, so we put this edge\r\nin the MST (it now has 3 edges) and update the clusters so that now {E,F,H} are\r\nin the same cluster.\r\n\r\n 4) We remove C<-(3)->D; C and D are in different clusters, so we put this edge\r\nin the MST (it now has 4 edges) and update the clusters so that now {A,C,D} are\r\nin the same cluster.\r\n\r\n 5) We remove H<-(3)->I; H and I are in different clusters, so we put this edge\r\nin the MST (it now has 5 edges) and update the clusters so that now {E,F,H,I}\r\nare in the same cluster.\r\n\r\n 6) We remove A<-(4)->B; A and B are in different clusters, so we put this edge\r\nin the MST (it now has 6 edges) and update the clusters so that now {A,B,C,D}\r\nare in the same cluster.\r\n\r\n 7) We remove A<-(4)->D; A and D are already in the same cluster (see 6) so we\r\ndon't include this edge in the MST. This is the first time that we are\r\ndiscarding an edge (not using it in the result graph).\r\n\r\n 8) We remove E<-(4)->H; E and H are already in the same cluster (see 5) so we\r\ndon't include this edge in the MST.\r\n\r\n 9) We remove B<-(5)->C; B and C are already in the same cluster (see 6) so we\r\ndon't include this edge in the MST.\r\n\r\n 9) We remove E<-(6)->I; E and I are already in the same cluster (see 5) so we\r\ndon't include this edge in the MST.\r\n\r\n10) We remove B<-(7)->G; B and G are in different clusters, so we put this edge\r\nin the MST (it now has 7 edges) and update the clusters so that now {A,B,C,D,G}\r\nare in the same cluster.\r\n\r\n11) We remove F<-(8)->G; F and G are in different clusters, so we put this edge\r\nin the MST (it now has 8 edges) and update the clusters so that now\r\n{A,B,C,D,E,F,G,H,I} are in the same cluster. This edge connects two formerly\r\nunconnected components.\r\n\r\n11) We remove G<-(8)->J; G and J are in different clusters, so we put this edge\r\nin the MST (it now has 9 edges) and update the clusters so that now\r\n{A,B,C,D,E,F,G,H,I,J} are in the same cluster.\r\n\r\nNote, we now have the needed 9 edges, and we see that all the nodes are in the\r\nsame cluster (all reachable from each other). So, the following nodes are in\r\nthe MST\r\n\r\nA<-(1)->C\r\nE<-(2)->F\r\nF<-(2)->H\r\nC<-(3)->D\r\nH<-(3)->I\r\nA<-(4)->B\r\nB<-(7)->G\r\nF<-(8)->G\r\nG<-(8)->J\r\n\r\nWith a total cost (sum of the edges) of 1+2+2+3+3+4+7+8+8 = 38.\r\n\r\n------------------------------------------------------------------------------\r\n", "encoding": "ascii"}