{"url": "https://www.ics.uci.edu/~kibler/ics171/homeworks/LearningHwk.htm", "content": "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 3.2//EN\">\r\n<HTML>\r\n\r\n<HEAD>\r\n    <META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html;CHARSET=iso-8859-1\">\r\n<META HTTP-EQUIV=\"Content-Type\" CONTENT=\"text/html; charset=windows-1252\">\r\n\r\n    <META NAME=\"GENERATOR\" Content=\"Visual Page 2.0 for Windows\">\r\n    <TITLE>Learning with Weka</TITLE>\r\n</HEAD>\r\n\r\n<BODY>\r\n\r\n<P><FONT SIZE=\"2\">Note: Start this homework early. You may have to use the computers at school but you can download the free open-source Weka software</FONT></P>\r\n<P><FONT SIZE=\"2\">Also read over all the questions before you start, otherwise you may have to repeat some experiments.</FONT></P>\r\n<P>In this homework you will use the Weka software to analyze the iris data set, a standard data set used to evaluated statistical algorithms. This data set is provided with Weka. \r\n<P>For each of the algorithms below, report the accuracies using 2-fold and 10-fold\r\ncross-validation. \r\n<ol>\r\n<li> \r\n<ol>\r\n<li> ZeroR which is the dumbest algorithm of all. It\u2019s the baseline.</P>\r\n<li>k-Nearest-Neighbor (Ibk) with k = 1, k=3, and k = 5. In the IBL folder.</P>\r\n<li> j48: the decision tree algorithm. In the Trees folder.</P>\r\n<li> Part: the algorithm for generating rules. In the Rules folder.</P>\r\n<li> Na&iuml;ve Bayes: a statistical approach using Bayes Rule. In the Bayes folder</P>\r\n</ol>\r\n<li>\r\n<OL Type=\"a\" STYLE=\"List-Style-Type : Lower-Alpha\">\r\n    <LI>Do you expect that 2-fold or 10-fold CV will yield a <B>higher</B> estimate of the accuracy of the algorithm?\r\n    <LI>Why?\r\n    <LI>Does your data support this conclusion? Be specific.\r\n    \r\n</OL>\r\n<li> Which learning methods produced interpretable results?\r\n<li> From the 10-fold CV data, order the algorithms by accuracies. \r\n<li> For the remaining questions, only consider the decision tree algorithm with 10 fold CV. Report the confusion matrix for the decision tree algorithm\r\n    <LI>List, in order, the classes predicted with highest precision, i.e. the probability that the example was\r\n    of class &quot;a&quot; given that the algorithm predicted it was of class &quot;a&quot;. Show how the probabilities were computed.\r\n    <LI>List, in order, the classes predicted with highest recall, i.e. the probability that the example was\r\n    predicted to be of class &quot;a&quot; given that it was of class &quot;a&quot;. Show how the probabilities were computed.\r\n</ol>\r\n</BODY>\r\n\r\n</HTML> ", "encoding": "Windows-1252"}