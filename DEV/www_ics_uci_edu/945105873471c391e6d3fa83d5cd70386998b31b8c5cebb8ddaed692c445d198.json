{"url": "https://www.ics.uci.edu/~goodrich/pubs/io.html", "content": "<!DOCTYPE HTML PUBLIC \"-//IETF//DTD HTML//EN\">\n<HTML> <HEAD>\n<TITLE>ACM Computing Surveys: SDCR Working Group on Storage I/O, \nCormen/Goodrich</TITLE>\n</HEAD>\n\n<BODY bgcolor=\"#ffffff\">\n\n<P>\n<small>\n\n<em><a href=\"http://www.acm.org/\">ACM</a> <a\nhref=\"http://www.cs.jhu.edu/~goodrich/pubs/io.html\">Computing\nSurveys</a></em> <b>28A</b>(4), December 1996,\nhttp://www.cs.jhu.edu/~goodrich/pubs/io.html.  Copyright &#169;\n1996 by the Association for Computing Machinery, Inc.  See the <a\nhref=\"#permissions-statement\">permissions statement</a> below.\n\n</small>\n</P>\n\n\n<BR>\n\n<center>\n<h1><a href=\"http://www.medg.lcs.mit.edu/sdcr/\">\n        Strategic Directions in Computing Research</a></h1>\n<p>\n<h1><a href=\"http://www.cs.duke.edu/~jsv/SDCR96-IO/SDCR96-IO.html \">Working\n        Group on Storage I/O Issues in Large-Scale Computing</a></h1>\n<p>\n<h1>Position statement</h1>\n</center>\n\n<BR>\n\n<P>\n<strong><a href=\"http://www.cs.dartmouth.edu/~thc\">Thomas H. Cormen</a></strong>\n<BR>\n<address>\n<a href=\"http://www.dartmouth.edu/\">Dartmouth College</a>,\n<a href=\"http://www.cs.dartmouth.edu/\">Department of Computer Science</a><BR>\n6211 Sudikoff Laboratory, Hanover, NH 03755-3510, USA<BR>\n<a href=\"mailto:thc@cs.dartmouth.edu\">thc@cs.dartmouth.edu</a>, \n<a\nhref=\"http://www.cs.dartmouth.edu/~thc\"\n>http://www.cs.dartmouth.edu/~thc</a><BR>\n</address>\n\n<BR>\n<strong><a href=\"http://www.cs.jhu.edu/goodrich/home.html\">Michael T. Goodrich</a></strong>\n<BR>\n<address>\n<a href=\"http://www.jhu.edu/\">The Johns Hopkins University</a>,\n<a href=\"http://www.cs.jhu.edu/\">Department of Computer Science</a><BR>\nWhiting School of Engineering, Baltimore, MD 21218<BR>\n<a href=\"http://www.ics.uci.edu/~goodrich/\">http://www.ics.uci.edu/~goodrich/</a><BR>\n</address>\n\n\n<BR>\n<BR>\n\n<blockquote>\n<HR>\n\n<strong>Abstract:</strong>\n\nWe present the challenge of synthesizing a coherent model that\ncombines the best aspects of the Parallel Disk Model and Bulk\nSynchronous Parallel models to develop and analyze algorithms that use\nparallel I/O, computation, and communication.\n\n<small>\n\n<P>\n\nCategories and Subject Descriptors: \nB.3.2 <b>[Memory Structures]</b>: Design Styles - <i>Mass storage\n(e.g., magnetic, optical), Primary memory</i>;\nB.4.4 <b>[Input/Output and Data Communications]</b>:\nPerformance Analysis and Design Aids -\n<i>Formal models, Worst-case analysis</i>;\nD.1.3 <b>[Programming Techniques]</b>: Concurrent Programming - <i>\nParallel programming</i>;\nD.4.2 <b>[Operating Systems]</b>: Storage Management - <i>Secondary\n\t      Storage</i>; \nD.4.4 <b>[Operating Systems]</b>: Communications Management -\n\t  <i>Input/Output; Message sending; Network communication</i>;  \nE.2 <b>[Data Storage Representations]</b>: <i>Contiguous\n\t      representations</i>; \nE.5 <b>[Files]</b>: <i>Sorting/searching</i>;\nF.1.2 <b>[Computation by Abstract Devices]</b>: Modes of Computation -\n<i>Parallelism and concurrency</i>;\nF.2.2 <b>[Analysis of Algorithms and Problem Complexity]</b>:\nNonnumerical Algorithms and Problems - <i>Sorting and searching</i>; \n\n<P>\n\nGeneral Terms: Algorithms, Design, Languages, Performance, Theory.\n\n<P>\n\nAdditional Key Words and Phrases: I/O, external memory, secondary\nmemory, communication, disk drive, parallel disks, sorting, Parallel\nDisk Model, Bulk Synchronous Parallel Model.\n\n</small>\n\n<HR>\n</blockquote>\n\n<BR>\n\n<h2>A Bridging Model for Parallel Computation, Communication, and I/O</h2>\n\n<P>\nThe past decade has seen the introduction of new and useful models for\nanalyzing the computational and communication complexities of parallel\nalgorithms, as well as useful models to measure I/O complexity.  Yet\nno useful model measures all of computational, communication, and I/O\ncomplexity simultaneously.\n\n<P>\nUsefulness of a model implies two characteristics.  First, the model\nshould be realistic in the sense that its prediction for any algorithm\nshould correspond to observed behavior of real systems.  Second, the\nmodel should be simple enough to use and understand that one can\ndesign, analyze, and implement algorithms without having had extensive\nexperience with the model.\n\n<P>\nWe maintain that the Bulk Synchronous Parallel, or BSP, model <a\nhref=\"#Valiant90\">[Valiant 1990]</a> and LogP <a\nhref=\"#CullerKaPaSaScSaSuEi93\">[Culler et al. 1993]</a> models are\nuseful for computational and communication complexities of parallel\nalgorithms.  The Parallel Disk Model, or PDM, <a\nhref=\"#VitterSh94a\">[Vitter Shriver 1994]</a> is useful for I/O\ncomplexity.  The BSP and LogP models, however, ignore I/O, and the PDM\ndoes not account for computation or communication.  Because we think\nof I/O as so much slower than computation or communication, the PDM\napparently captures the most salient factor in the wall-clock time for\nalgorithms that use parallel I/O.\n\n<P>\nWhat is apparent may not be the case, however.\n\n<P>\n<a href=\"#CormenHi96\">Early experiences</a> with algorithms\nimplemented in the PDM indicate that although wall-clock time for a\ngiven algorithm follows the prediction of the model, the algorithms\nthemselves are not I/O bound.  Even with synchronous (i.e., blocking)\nI/O, the time spent waiting for I/O is typically less than 50% of the\ntotal wall-clock time.  This behavior suggests that each parallel disk\naccess gives rise to a given amount of computation and communication\nfor a particular algorithm.\n\n<P>\nA sorting algorithm, for example, might repeatedly process\n\"memoryloads\" of data by performing a large parallel read, an\nin-memory sort across all processors, and a large parallel write.  The\ntime to perform the in-memory sorts might exceed the combined times of\nthe parallel reads and writes, although it is roughly the same among\nthe memoryloads.  Typical algorithms developed for the PDM are similar\nto this hypothetical sorting algorithm in that they make repeated\npasses over the data and each pass repeatedly reads in a large amount\nof data, processes it, and writes out a large amount of data.\nProcessing time (including communication) tends to be about the same\neach time for a given algorithm.  Of course it varies from algorithm\nto algorithm.\n\n<P>\nIf these early observations continue to hold as we gain more\nexperience in implementing algorithms for the PDM, we will draw the\nconclusion that the PDM's predictive power is helpful (for analyzing\nI/O time) but limited (by omitting computation and communication).\n\n<P>\nNote, however, a striking similarity between the BSP model and typical\nPDM algorithms: bulk processing.  In the BSP model, for example,\ncommuncation in a network of processors is considered to be the prime\ncomputational bottleneck; hence, a computation is organized as a\nsequence of rounds, where each round consists of each processor\nperforming computations on its internal memory, followed by the\nsending and receiving of a limited number of messages.  Rounds and\ncommunication in BSP algorithms are like memoryload processing and\nI/O, respectively, in PDM algorithms.\n\n<P>\nThe challenge, therefore, is to synthesize a coherent model that\ncombines the best aspects of the PDM and BSP models to develop and\nanalyze algorithms that use parallel I/O, computation, and\ncommunication.  Along with such a model, we need programming\nprimitives to enable algorithm implementation under the model.  These\nprimitives must be portable and have performance matching the model's\nrequirements.\n\n<P>\nWe view developing such a model as a challenge because we believe that\nit will be difficult to simultaneously satisfy the two requirements\nthat it be realistic yet easy to use.  Our concern is that a realistic\nmodel may have so many parameters as to make it unusable.  The PDM,\nwithout considering processing, has four parameters: problem size,\nmemory size, disk block size, and disk count.  The BSP model also has\nfour parameters: problem size, processor count, latency of the\nnetwork, and the \"gap\" time between consecutive messages in pipelined\ncomputations.  Thus, some natural questions to ask include the\nfollowing:\n<UL>\n<LI>Can all these parameters be merged in some synthesis?  \n\n<LI>Is there a block size notion in BSP that might be consistent with\nthe PDM'S block size?\n\n<LI>What is the right set of at most four or five important parameters?\n</UL>\n\n<P>\nIn summary, we think that it would be valuable to propose a bridging\nparallel computational model that incorporates computation,\ncommunication and I/O in an accurate and easy to use manner.  We hope\nthat discussions at the workshop will lead to such a model.\n\n<h2>References</h2>\n\n<dl>\n  <dt><a name=\"AlpernCaFeSe94\"><b>\n      [Alpern et al. 1994]</b></a></dt>\n  <dd>Alpern, B., Carter, L., Feig, E., and Selker, T., 1994.\n      The Uniform Memory Hierarchy Model of Computation,\n      <em>Algorithmica</em>, 12:2/3, August and September 1994,\n      pages 72-109.\n\n  <p>\n  <dt><a name=\"CormenGo96\"><b>\n      [Cormen Goodrich 1996]</b></a></dt> \n  <dd>Cormen, T. H., and Goodrich, M. T., 1996.\n      <a href=\"http://www.cs.jhu.edu/~goodrich/pubs/io.html\">\n       Position Statement</a>, \n       Strategic Directions in Computing Research:   \n       Working Group on Storage I/O Issues in Large-Scale Computing,\n      <em><a\n      href=\"http://www.acm.org/surveys/\">Computing Surveys</a></em>,\n      <b>28A</b>(4), December 1996,\n      <a href = \"http://www.cs.jhu.edu/~goodrich/pubs/io.html\">\n       http://www.cs.jhu.edu/~goodrich/pubs/io.html</a>.\n\n  <p>\n  <dt><a name=\"CormenHi96\"><b>\n      [Cormen Hirschl 1996]</b></a></dt>\n  <dd>Cormen, T. H., and Hirschl, M., 1996.\n      Early Experiences in Evaluating the Parallel Disk Model with the\n      ViC* Implementation, <em>Parallel Computing</em>, to appear.  Also\n      available as Dartmouth College Computer Science Technical Report\n      TR96-293 at <a href=\"ftp://ftp.cs.dartmouth.edu/TR/TR96-293.ps.Z\">\n      ftp://ftp.cs.dartmouth.edu/TR/TR96-293.ps.Z</a>\n\n  <p>\n  <dt><a name=\"CullerKaPaSaScSaSuEi93\"><b>\n      [Culler et al. 1993]</b></a></dt>\n  <dd>Culler, D., Karp, R., Patterson, D., Sahay, A., Schauser, K. E.,\n      Santos, E., Subramonian, R., and von Eicken, T. 1993.\n      LogP: Towards a Realistic Model of Parallel Computation,\n      <em>Proceedings of the Fourth ACM SIGPLAN Symposium on Principles\n      and Practice of Parallel Programming</em>, May 1993, pages 1-12.\n\n  <p>\n  <dt><a name=\"Valiant90\"><b>\n      [Valiant 1990]</b></a></dt> \n  <dd>Valiant, L. G., 1990.\n      A Bridging Model for Parallel Computation,\n      <em>Communications of the ACM</em>, \n      33:8, August 1990, pages 103-111.\n\n  <p>\n  <dt><a name=\"VitterSh94a\"><b>\n      [Vitter Shriver 1994a]</b></a></dt>\n  <dd>Vitter, J. S., and Shriver, E. A. M., 1994.\n      Algorithms for Parallel Memory I: Two-level Memories,\n      <em>Algorithmica</em>,\n      12:2/3, August and September 1994, pages 110-147.\n\n  <p>\n  <dt><a name=\"VitterSh94b\"><b>\n      [Vitter Shriver 1994b]</b></a></dt>\n  <dd>Vitter, J. S., and Shriver, E. A. M., 1994.\n      Algorithms for Parallel Memory II: Hierarchical Multilevel Memories,\n      <em>Algorithmica</em>,\n      12:2/3, August and September 1994, pages 148-169.\n\n</dl>\n\n\n<P>\n<hr>\n\n<P><a name=\"permissions-statement\"><small>Permission to make digital\nor hard copies of part or all of this work for personal or classroom\nuse is granted without fee provided that copies are not made or\ndistributed for profit or commercial advantage and that copies bear\nthis notice and the full citation on the first page.  Copyrights for\ncomponents of this work owned by others than ACM must be honored.\nAbstracting with credit is permitted.  To copy otherwise, to\nrepublish, to post on servers, or to redistribute to lists, requires\nprior specific permission and/or a fee.  Request permissions from\nPublications Dept, ACM Inc., fax +1 (212) 869-0481, or\n<TT>permissions@acm.org</TT>.</small></P>\n\n\n<P>\n<hr>\n<!-- hhmts start -->\nLast modified: Mon Oct 21 19:18:04 EDT\n<!-- hhmts end -->\n<address><a href=\"http://www.ics.uci.edu/~goodrich/\">Michael T.  Goodrich</a>\n</address>\n\n</BODY> </HTML>\n\n", "encoding": "ascii"}