{"url": "https://www.ics.uci.edu/~dan/pubs/DC-Sec2.html", "content": "<HTML>\n<HEAD>\n<TITLE> Data Compression -- Section 2 </TITLE>\n</HEAD><BODY>\n\n<H1> Data Compression </H1>\n\n<a name=\"Sec_2\">\n<H2> 2.  SEMANTIC DEPENDENT METHODS</H2> </a>\n\n<A HREF=\"DC-Sec1.html\"><IMG SRC=\"prev.gif\" ALT=\"PREV section\"></A>\n<A HREF=\"DC-Sec3.html\"><IMG SRC=\"next.gif\" ALT=\"NEXT section\"></A>\n<P>\n\n\tSemantic dependent data compression techniques are \ndesigned to respond to specific types of local redundancy\noccurring in certain \napplications.  One area in which data compression is \nof great importance is image representation and processing.\nThere are two major reasons for this.  The first is that digitized\nimages contain a large amount of local redundancy.  An image is usually\ncaptured in the form of an array of pixels whereas methods which  \nexploit the tendency for pixels of like color or intensity to cluster\ntogether may be more efficient.  The second reason for the \nabundance of research in this area is volume.  Digital images \nusually require a very large number of bits, and many uses of digital\nimages involve large collections of images.\n<P>\n\tOne technique used for compression of image data is \n<EM>run length encoding</EM>.  In a common version of run length\nencoding, the sequence of image elements along a scan line (row)\nis mapped into a sequence of pairs (<VAR>c</VAR>,<VAR>l</VAR>)\nwhere <VAR>c</VAR> represents an intensity or color and <VAR>l</VAR>\nthe length of the run (sequence of pixels of equal intensity).\nFor pictures such as weather maps, run length encoding can save a\nsignificant number of bits over the image element sequence\n[Gonzalez and Wintz 1977].  Another data compression technique\nspecific to the area of image data is <EM>difference mapping</EM>, in which\nthe image is represented as an array of differences in\nbrightness (or color) between adjacent pixels rather than the\nbrightness values themselves.  Difference mapping was used\nto encode the pictures of Uranus transmitted by <EM>Voyager</EM> 2.  \nThe 8 bits per pixel needed to represent 256 brightness levels\nwas reduced to an average of 3 bits per pixel when difference\nvalues were transmitted [Laeser et al. 1986].  In spacecraft \napplications, image fidelity is a major concern due to the effect\nof the distance from the spacecraft to earth on transmission\nreliability.  Difference mapping was combined with error-correcting \ncodes to provide both compression and data integrity in the \n<EM>Voyager</EM> project.  Another method which takes advantage of the\ntendency for images to contain large areas of constant intensity\nis the use of the quadtree data structure [Samet 1984].\nAdditional examples of coding techniques used in image processing\ncan be found in Wilkins and Wintz and in Cappellini [Wilkins and Wintz 1971; Cappellini 1985].\n<P>\n\tData compression is of interest in business data processing,\nboth because of the cost savings it offers and because of the\nlarge volume of data manipulated in many business applications.\nThe types of local redundancy present in business data files include\nruns of zeros in numeric fields, sequences of blanks in alphanumeric\nfields, and fields which are present in some records and null in\nothers.  Run length encoding can be used to compress sequences of \nzeros or blanks.  Null suppression may be accomplished\nthrough the use of presence bits [Ruth and Kreutzer 1972].  \nAnother class of methods exploits cases\nin which only a limited set of attribute values exist.  <EM>Dictionary\nsubstitution</EM>  entails replacing alphanumeric representations of information\nsuch as bank account type, insurance policy type, sex, month, etc.  \nby the few bits necessary to represent the limited number of possible\nattribute values [Reghbati 1981].\n<P>\n\tCormack describes a data compression system which is\ndesigned for use with database files [Cormack 1985].  \nThe method, which is part of \nIBM's \"Information Management System\" (IMS), compresses\nindividual records and is invoked each time a record\nis stored in the database file; expansion is performed each\ntime a record is retrieved.  Since records may be retrieved\nin any order, context information used by the compression\nroutine is limited to a single record.  In order for\nthe routine to be applicable to any database, it must be able to\nadapt to the format of the record.  The fact that database records\nare usually heterogeneous collections of small fields indicates\nthat the local properties of the data are more important than\nits global characteristics.  The compression routine\nin IMS is a hybrid method which attacks this local redundancy \nby using different coding schemes for different types of fields.\nThe identified field types in IMS are <EM>letters of the alphabet, \nnumeric digits, packed decimal digit pairs, blank,</EM> and <EM>other</EM>.\nWhen compression begins, a default code is used to encode the \nfirst character of the record.  For each subsequent character,\nthe type of the previous character determines the code to be used.\nFor example, if the record <kbd>01870_ABCD__LMN</kbd> were encoded \nwith the <EM>letter</EM> code as default, the leading zero would be\ncoded using the <EM>letter</EM> code; the 1, 8, 7, 0 and the first\nblank (_) would be coded by the <EM>numeric</EM> code.  The <VAR>A</VAR> would be\ncoded by the <EM>blank</EM> code; <VAR>B</VAR>, <VAR>C</VAR>, <VAR>D</VAR>, and the next blank by the\n<EM>letter</EM> code; the next blank and the <VAR>L</VAR> by the <EM>blank</EM>\ncode; and the <VAR>M</VAR> and <VAR>N</VAR> by the <EM>letter</EM> code. \nClearly, each code must define a codeword for every\ncharacter; the <EM>letter</EM> code would assign the shortest codewords\nto letters, the numeric code would favor the digits, etc.  In the system\nCormack describes, the types of the characters are stored in the encode/decode\ndata structures.  When a character <VAR>c</VAR> is received, the decoder checks\n<VAR>type</VAR>(<VAR>c</VAR>) to detect which code table will be used in transmitting the\nnext character.   The compression algorithm might be more efficient if a special\nbit string were used to alert the receiver to a change in code table.\nParticularly if fields were reasonably long,  decoding would be more rapid\nand the extra bits in the transmission would not be excessive.\nCormack reports that the performance of the IMS compression routines \nis very good; at least fifty sites are currently using the system.\nHe cites a case of a database containing student records whose size\nwas reduced by 42.1%, and as a side effect the number of disk operations\nrequired to load the database was reduced by 32.7% [Cormack 1985]. \n<P>\n\tA variety of approaches to data compression designed with\ntext files in mind include use of a dictionary\neither representing  all of the words in the file so that the\nfile itself is coded as a list of pointers to the dictionary\n[Hahn 1974], or representing common words and word endings so that the\nfile consists of pointers to the dictionary and encodings\nof the less common words [Tropper 1982].  Hand-selection of\ncommon phrases [Wagner 1973], programmed selection of prefixes \nand suffixes [Fraenkel et al. 1983] and programmed selection of\ncommon character pairs [Snyderman and Hunt 1970; Cortesi 1982] \nhave also been investigated.\n<P>\n\tThis discussion of semantic dependent data compression\ntechniques represents a limited sample of a very large body of\nresearch.  These methods and others of a like nature are interesting\nand of great value in their intended domains.  Their obvious\ndrawback lies in their limited utility.  It should be noted, however,\nthat much of the efficiency gained through the use of semantic dependent\ntechniques can be achieved through more general methods, albeit to\na lesser degree.  For example, the dictionary approaches can be implemented\nthrough either Huffman coding (\n<a href=\"DC-Sec3.html#Sec_3.2\">Section 3.2</a>, <a href=\"DC-Sec4.html#Sec_4\">Section 4</a>) or Lempel-Ziv\ncodes (<a href=\"DC-Sec5.html#Sec_5.1\">Section 5.1</a>).  Cormack's database scheme is a special case of\nthe codebook approach (<a href=\"DC-Sec3.html#Sec_3.2\">Section 3.2</a>), and run length encoding is one\nof the effects of Lempel-Ziv codes. \n\n<P>\n<A HREF=\"DC-Sec1.html\"><IMG SRC=\"prev.gif\" ALT=\"PREV section\"></A>\n<A HREF=\"DC-Sec3.html\"><IMG SRC=\"next.gif\" ALT=\"NEXT section\"></A>\n<P>\n</BODY></HTML>\n", "encoding": "ascii"}