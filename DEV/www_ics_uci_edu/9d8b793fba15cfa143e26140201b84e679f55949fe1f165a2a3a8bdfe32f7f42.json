{"url": "https://www.ics.uci.edu/~eppstein/161/960130.html", "content": "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 3.2//EN\">\n<html>\n<head>\n<title>Deterministic selection</title>\n<meta name=\"Owner\" value=\"eppstein\">\n<meta name=\"Reply-To\" value=\"eppstein@ics.uci.edu\">\n</head>\n<body>\n<h1>ICS 161: Design and Analysis of Algorithms<br>\nLecture notes for January 30, 1996</h1>\n\n<!--#config timefmt=\"%d %h %Y, %T %Z\" -->\n<hr>\n<p></p>\n\n<h1>Deterministic selection</h1>\n\nLast time we saw quick select, a very practical randomized linear\nexpected time algorithm for selection and median finding. In\npractice, this is all you need to use. But for theoretical\npurposes, it's unsatisfying to have only a randomized algorithm,\nand in some rare circumstances it may more important to be\npredictable than to be fast. So can we get a linear worst case time\nalgorithm? We'll describe a solution invented by five people: <a\nhref=\"people.html#blum\">Blum</a>, <a href=\"people.html#floyd\">\nFloyd</a>, <a href=\"people.html#pratt\">Pratt</a>, <a href= \n\"people.html#rivest\">Rivest</a>, and <a href=\"people.html#tarjan\">\nTarjan</a>. \n\n<p>Recall that quickselect chooses a random \"pivot\" x, partitions\nthe list into elements less than and greater than x, and calls\nitself recursively in one of the two sublists. The even quicker\nselection method I outlined does something similar, but chooses the\npivot in a complicated way, by calling itself recursively in a\nrandom sample of the input. Our deterministic algorithm will use\nthe same idea of choosing x by performing a recursive call.</p>\n\n<p>If we could do so quickly, one good choice would simply be to\nlet x be the median of the values. Then each recursive call would\nonly be on a subset of half the values. But of course if we knew\nhow to find the median, we'd be done, so finding the median is too\ngood to hope for. Instead let's just try to get something close to\nthe median (say within n/4 positions of it). Then each recursive\ncall would be on a larger fraction of the input (3n/4) but this\nstill might be good enough.</p>\n\n<h2>Median of medians</h2>\n\nHow can we get something close to the median, reasonably quickly?\nJust like the \"quicker selection\", Instead of finding the median of\nthe whole set, find a median of a sample. How do we choose the\nsample? Medians again! \n\n<p>Median-of-medians algorithm:</p>\n\n<ul>\n<li>Line up elements in groups of five (this number 5 is not\nimportant, it could be e.g. 7 without changing the algorithm much).\nCall each group S[i], with i ranging from 1 to n/5.</li>\n\n<li>Find the median of each group. (Call this x[i]). This takes 6\ncomparisons per group, so 6n/5 total (it is linear time because we\nare taking medians of very small subsets).</li>\n\n<li>Find the median of the x[i], using a recursive call to the\nalgorithm. If we write a recurrence in which T(n) is the time to\nrun the algorithm on a list of n items, this step takes time\nT(n/5). Let M be this median of medians.</li>\n\n<li>Use M to partition the input and call the algorithm recursively\non one of the partitions, just like in quickselect.</li>\n</ul>\n\nCan we say anything about how many items are included in this last\nrecursive call? It's easier to talk about this in terms of the\nelements thrown away (not included in the call). \n\n<blockquote>We always throw away either L3 (the values greater than\nM) or L1 (the values less than M). Suppose we throw away L3. \n\n<p>Among the n/5 values x[i], n/10 are larger than M (since M was\ndefined to be the median of these values).</p>\n\n<p>For each i such that x[i] is larger than M, two other values in\nS[i] are also larger than x[i] (since x[i] is the median of\nS[i]).</p>\n\n<p>So L3 has at least 3 elements in each of at least n/10 groups\nS[i], for a total of at least 3n/10 elements. By a symmetric\nargument, L1 has at least 3n/10 elements.</p>\n\n<p>Therefore the final recursive call is on a list of at most 7n/10\nelements and takes time at most T(7n/10).</p>\n</blockquote>\n\nThis algorithm has the property we want, that each recursive call\nonly involves a constant fraction of the input. \n\n<h2>Deterministic selection algorithm</h2>\n\nBefore we analyze our algorithm, let's write it out more carefully\nin pseudocode. Also, instead of using a special algorithm to find\nthe median in each subset S[i], let's just call the method\nrecursively again. To prevent infinite recursion, we have to stop\nwhen L is so small that there aren't enough x[i] values to find\nmedians of. \n\n<pre>\n    select(L,k)\n    {\n    if (L has 10 or fewer elements)\n    {\n        sort L\n        return the element in the kth position\n    }\n\n    partition L into subsets S[i] of five elements each\n        (there will be n/5 subsets total).\n\n    for (i = 1 to n/5) do\n        x[i] = select(S[i],3)\n\n    M = select({x[i]}, n/10)\n\n    partition L into L1&lt;M, L2=M, L3&gt;M\n    if (k &lt;= length(L1))\n        return select(L1,k)\n    else if (k &gt; length(L1)+length(L2))\n        return select(L3,k-length(L1)-length(L2))\n    else return M\n    }\n</pre>\n\n<h2>Analysis</h2>\n\nThe pseudo-code above gives us a number of comparisons that can be\nfound by solving the recurrence \n\n<pre>\n    T(n) &lt;= 12n/5 + T(n/5) + T(7n/10)\n</pre>\n\nThe 12n/5 term comes from two places: we can sort each of the sets\nS[i] with seven comparisons (homework 2.31), so the step in which\nwe compute the x[i] values takes 7n/5 comparisons total. And then\nthe step in which we partition L takes n-1 more comparisons. The\nother two terms come from the two recursive calls, in which we find\nM and then the overall return value. As we discussed earlier, the\nsecond recursive call is on a list of at most 7n/10 elements hence\nits T(7n/10) bound. \n\n<p>Actually with some more care we can do a little better: we don't\nreally need to sort the sets S[i], just find their medians, which\nonly requires 6n/5 comparisons. The resulting information, together\nwith the computation of M, should already be enough to eliminate\n3n/10 elements from L. So we could get a recurrence with 6n/5 in\nplace of the 12n/5 above, and save a factor of two in the total\ncomparisons. But since this result is mainly of theoretical\ninterest, I've left it in the simpler and easier to understand form\nabove.</p>\n\n<p>This recurrence looks like one coming from a divide and conquer\nalgorithm, but one which splits the problem unequal parts. But in\nthis case the important fact is that the parts add up to less than\nthe whole, when this happens it doesn't matter as much how equal or\nunequal they are.</p>\n\n<p>There are two ways to analyze a problem like this. The first is\nthe method I showed for quickselect, in which we try to form an\ninductive proof that something is O(n) by assuming it's cn for some\nspecific c, expanding the right side of the recurrence, and working\nthrough the math to determine what c should be. In our case we\nhave</p>\n\n<pre>\n    T(n) &lt;= 12n/5 + T(n/5) + T(7n/10)\n\n     = 12n/5 + cn/5 + 7cn/10\n\n     = n (12/5 + 9c/10)\n</pre>\n\nIf this is to be at most cn, so that the induction proof goes\nthrough, we need it to be true that \n\n<pre>\n    n (12/5 + 9c/10) &lt;= cn\n\n    12/5 + 9c/10 &lt;= c\n\n    12/5 &lt;= c/10\n\n    c &lt;= 24\n</pre>\n\nWhich tells us that we can prove by induction that T(n) &lt;= 24n\n(or any larger constant times n). We also need to deal with the\nbase case but that is easy. \n\n<p>The second method to analyze a recurrence like this one is to\ndraw a tree showing the sizes of the problems in each recursive\ncall, and analyze the total size of problems on each level of the\ntree. The total number of comparisons can then be found by\nmultiplying this total subproblem size by the 12/5 factor of\ncomparisons per element in each call. The tree starts with a root\nproblem of size n, and then each node has two subproblems, one of\nsize 1/5 its parent, and the other of size 7/10 its parent.</p>\n\n<pre>\n          n\n        /   \\\n       n/5        7n/10\n      /   \\       /   \\\n    n/25 7n/50 7n/50 49n/100\n    / \\   / \\   / \\   / \\\n</pre>\n\nEach problem on one level is replaced by two problems on the next\nlevel down, of sizes 1/5 and 7/10 the parent. So the total size on\nthe next level is 1/5+7/10=9/10 that of the previous level\n(sometimes even less when a subproblem reaches a base case and\ndoesn't make more recursive calls). \n\n<p>Therefore the total number of comparisons is</p>\n\n<pre>\n    12/5 (n + 9n/10 + 81n/100 + ...)\n\n    = 12/5 n (1 + 9/10 + (9/10)^2 + (9/10)^3 + ...)\n\n    = 12/5 n 1/(1-(9/10))\n\n    = 24n\n</pre>\n\n<a name=\"geom\">As a general rule, the <i>geometric series</i>\nsum(x^i) (for i from 0 to n-1) solves to (1-x^n)/(1-x), and\nwhenever x is less than 1 the limit of the sum as n goes to\ninfinity becomes 1/(1-x). The sum above is just a case of this\nformula in which x=9/10. The same tree-expansion method then shows\nthat, more generally, if T(n) &lt;= cn + T(an) + T(bn), where\na+b&lt;1, the total time is c(1/(1-a-b))n.</a> \n\n<p>So our deterministic selection algorithm uses at most 24n\ncomparisons and takes O(n) time.</p>\n\n<p>With a lot of work one can reduce the number of comparisons to\n2.95n [see <a href=\"http://www.netlib.org/confdb/soda95/DZ.html\">D.\nDor and U. Zwick, \"Selecting the Median\", 6th SODA, 1995</a>] which\nis a little less than twice as much as randomized selection, but\nmuch more complicated and less practical.</p>\n\n<hr>\n<p><a href=\"/~eppstein/161/\">ICS 161</a> -- <a href=\"/\">Dept.\nInformation &amp; Computer Science</a> -- <a href= \n\"http://www.uci.edu/\">UC Irvine</a><br>\n<small>Last update: \n<!--#flastmod file=\"960130.html\" --></small></p>\n</body>\n</html>\n\n", "encoding": "ascii"}