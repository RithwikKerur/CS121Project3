{"url": "https://www.ics.uci.edu/~majumder/VC/211HW3/vlfeat/doc/overview/plots-rank.html", "content": "<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\n   <html xmlns=\"http://www.w3.org/1999/xhtml\">\n <head>\n  <!-- IE Standards Mode -->\n  <meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"></meta>\n\n  <!-- Favicon -->\n  <link href=\"../images/vl_blue.ico\" type=\"image/x-icon\" rel=\"icon\"></link>\n  <link href=\"../images/vl_blue.ico\" type=\"image/x-icon\" rel=\"shortcut icon\"></link>\n\n  <!-- Page title -->\n  <title>VLFeat - Tutorials > Plotting AP and ROC curves</title>\n\n  <!-- Stylesheets -->\n  <link href=\"../vlfeat.css\" type=\"text/css\" rel=\"stylesheet\"></link>\n  <link href=\"../pygmentize.css\" type=\"text/css\" rel=\"stylesheet\"></link>\n  <style xml:space=\"preserve\">\n    /* fixes a conflict between Pygmentize and MathJax */\n    .MathJax .mo, .MathJax .mi {color: inherit ! important}\n  </style>\n  \n\n  <!-- Scripts-->\n  \n\n  <!-- MathJax -->\n  <script xml:space=\"preserve\" type=\"text/x-mathjax-config\">\n    MathJax.Hub.Config({\n    tex2jax: {\n      inlineMath: [ ['$','$'], ['\\\\(','\\\\)'] ],\n      processEscapes: true,\n    },\n    TeX: {\n      Macros: {\n        balpha: '\\\\boldsymbol{\\\\alpha}',\n        bc: '\\\\mathbf{c}',\n        be: '\\\\mathbf{e}',\n        bg: '\\\\mathbf{g}',\n        bq: '\\\\mathbf{q}',\n        bu: '\\\\mathbf{u}',\n        bv: '\\\\mathbf{v}',\n        bw: '\\\\mathbf{w}',\n        bx: '\\\\mathbf{x}',\n        by: '\\\\mathbf{y}',\n        bz: '\\\\mathbf{z}',\n        bsigma: '\\\\mathbf{\\\\sigma}',\n        sign: '\\\\operatorname{sign}',\n        diag: '\\\\operatorname{diag}',\n        real: '\\\\mathbb{R}',\n      },\n      equationNumbers: { autoNumber: 'AMS' }\n      }\n    });\n  </script>\n  <script src=\"http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\" xml:space=\"preserve\" type=\"text/javascript\"></script>\n\n  <!-- Google Custom Search -->\n  <script xml:space=\"preserve\">\n    (function() {\n    var cx = '003215582122030917471:oq23albfeam';\n    var gcse = document.createElement('script'); gcse.type = 'text/javascript'; gcse.async = true;\n    gcse.src = (document.location.protocol == 'https' ? 'https:' : 'http:') +\n    '//www.google.com/cse/cse.js?cx=' + cx;\n    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(gcse, s);\n    })();\n  </script>\n\n  <!-- Google Analytics -->\n  <script xml:space=\"preserve\" type=\"text/javascript\">\n    var _gaq = _gaq || [];\n    _gaq.push(['_setAccount', 'UA-4936091-2']);\n    _gaq.push(['_trackPageview']);\n    (function() {\n    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;\n    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';\n    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);\n    })();\n  </script>\n </head>\n\n <!-- Body Start -->\n <body>\n  <div id=\"header-section\">\n    <div id=\"header\">\n      <!-- Google CSE Search Box -->\n      <div class=\"searchbox\">\n        <gcse:searchbox-only autoCompleteMaxCompletions=\"5\" autoCompleteMatchType=\"any\" resultsUrl=\"http://www.vlfeat.org/search.html\"></gcse:searchbox-only>\n      </div>\n      <h1 id=\"id-16\"><a shape=\"rect\" href=\"../index.html\" class=\"plain\"><span id=\"vlfeat\">VLFeat</span><span id=\"dotorg\">.org</span></a></h1>\n    </div>\n    <div id=\"sidebar\"> <!-- Navigation Start -->\n      <ul>\n<li><a href=\"../index.html\">Home</a>\n<ul>\n<li><a href=\"../about.html\">About</a>\n</li>\n<li><a href=\"../license.html\">License</a>\n</li>\n</ul></li>\n<li><a href=\"../download.html\">Download</a>\n<ul>\n<li><a href=\"../install-matlab.html\">Using from MATLAB</a>\n</li>\n<li><a href=\"../install-octave.html\">Using from Octave</a>\n</li>\n<li><a href=\"../install-shell.html\">Using from the command line</a>\n</li>\n<li><a href=\"../install-c.html\">Using from C</a>\n<ul>\n<li><a href=\"../xcode.html\">Xcode</a>\n</li>\n<li><a href=\"../vsexpress.html\">Visual C++</a>\n</li>\n<li><a href=\"../gcc.html\">g++</a>\n</li>\n</ul></li>\n<li><a href=\"../compiling.html\">Compiling</a>\n<ul>\n<li><a href=\"../compiling-unix.html\">Compiling on UNIX-like platforms</a>\n</li>\n<li><a href=\"../compiling-windows.html\">Compiling on Windows</a>\n</li>\n</ul></li>\n</ul></li>\n<li class='active'><a href=\"tut.html\">Tutorials</a>\n<ul>\n<li><a href=\"frame.html\">Local feature frames</a>\n</li>\n<li><a href=\"covdet.html\">Covariant feature detectors</a>\n</li>\n<li><a href=\"hog.html\">HOG features</a>\n</li>\n<li><a href=\"sift.html\">SIFT detector and descriptor</a>\n</li>\n<li><a href=\"dsift.html\">Dense SIFT</a>\n</li>\n<li><a href=\"liop.html\">LIOP local descriptor</a>\n</li>\n<li><a href=\"mser.html\">MSER feature detector</a>\n</li>\n<li><a href=\"imdisttf.html\">Distance transform</a>\n</li>\n<li><a href=\"encodings.html\">Fisher Vector and VLAD</a>\n</li>\n<li><a href=\"gmm.html\">Gaussian Mixture Models</a>\n</li>\n<li><a href=\"kmeans.html\">K-means clustering</a>\n</li>\n<li><a href=\"aib.html\">Agglomerative Infromation Bottleneck</a>\n</li>\n<li><a href=\"quickshift.html\">Quick shift superpixels</a>\n</li>\n<li><a href=\"slic.html\">SLIC superpixels</a>\n</li>\n<li><a href=\"svm.html#tut.svm\">Support Vector Machines (SVMs)</a>\n</li>\n<li><a href=\"kdtree.html\">KD-trees and forests</a>\n</li>\n<li class='active' class='activeLeaf'><a href=\"plots-rank.html\">Plotting AP and ROC curves</a>\n</li>\n<li><a href=\"utils.html\">Miscellaneous utilities</a>\n</li>\n<li><a href=\"ikm.html\">Integer K-means</a>\n</li>\n<li><a href=\"hikm.html\">Hierarchical integer k-means</a>\n</li>\n</ul></li>\n<li><a href=\"../applications/apps.html\">Applications</a>\n</li>\n<li><a href=\"../doc.html\">Documentation</a>\n<ul>\n<li><a href=\"../matlab/matlab.html\">MATLAB API</a>\n</li>\n<li><a href=\"../api/index.html\">C API</a>\n</li>\n<li><a href=\"../man/man.html\">Man pages</a>\n<ul>\n<li><a href=\"../man/mser.html\">mser</a>\n</li>\n<li><a href=\"../man/sift.html\">sift</a>\n</li>\n<li><a href=\"../man/vlfeat.html\">vlfeat</a>\n</li>\n</ul></li>\n</ul></li>\n</ul>\n\n    </div> <!-- sidebar -->\n  </div>\n  <div id=\"headbanner-section\">\n    <div id=\"headbanner\">\n      <span class='page'><a href=\"tut.html\">Tutorials</a></span><span class='separator'>></span><span class='page'><a href=\"plots-rank.html\">Plotting AP and ROC curves</a></span>\n    </div>\n  </div>\n  <div id=\"content-section\">\n    <div id=\"content-wrapper\">\n      <div id=\"content\">\n        \n    \n\n<p><em>This tutorial illustrates the use of the functions\n<code/><a href=../matlab/vl_roc.html>vl_roc</a></code>,\n<code/><a href=../matlab/vl_det.html>vl_det</a></code>, and\n<code/><a href=../matlab/vl_pr.html>vl_pr</a></code> to generate ROC, DET, and precision-recall\ncurves.</em></p>\n\n<p>VLFeat includes support for plotting starndard information\nretrieval curves such as the <em>Receiver Operating Characteristic\n(ROC)</em> and the <em>Precision-Recall (PR)</em> curves.</p>\n\n<p>Consider a set of samples with labels <code/>labels</code> and\nscore <code/>scores</code>. <code/>scores</code> is typically the output\nof a classifier, with higher scores corresponding to positive\nlabels. Ideally, sorting the data by decreasing scores should leave\nall the positive samples first and the negative samples last.  In\npractice, a classifier is not perfect and the ranking is not ideal.\nThe tools discussed in this tutorial allow to evaluate and visualize\nthe quality of the ranking.</p>\n\n<p>For the sake of the illustration generate some data randomly as\nfollows:</p>\n\n<div class=\"highlight\"><pre><span class=\"n\">numPos</span> <span class=\"p\">=</span> <span class=\"mi\">20</span> <span class=\"p\">;</span>\n<span class=\"n\">numNeg</span> <span class=\"p\">=</span> <span class=\"mi\">100</span> <span class=\"p\">;</span>\n<span class=\"n\">labels</span> <span class=\"p\">=</span> <span class=\"p\">[</span><span class=\"nb\">ones</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span> <span class=\"n\">numPos</span><span class=\"p\">)</span> <span class=\"o\">-</span><span class=\"nb\">ones</span><span class=\"p\">(</span><span class=\"mi\">1</span><span class=\"p\">,</span><span class=\"n\">numNeg</span><span class=\"p\">)]</span> <span class=\"p\">;</span>\n<span class=\"n\">scores</span> <span class=\"p\">=</span> <span class=\"nb\">randn</span><span class=\"p\">(</span><span class=\"nb\">size</span><span class=\"p\">(</span><span class=\"n\">labels</span><span class=\"p\">))</span> <span class=\"o\">+</span> <span class=\"n\">labels</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p>In this case, there have five times more negative samples than\npositive ones. The scores are correlated to the labels as expected,\nbut do not allow for a perfect separation of the two classes.</p>\n\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n<h1 id=\"plots-rank.roc\">ROC and DET curves</h1>\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n\n<p>To visualize the quality of the ranking, one can plot the ROC curve\nby using the <code/><a href=../matlab/vl_roc.html><a shape=\"rect\" href=\"../matlab/vl_roc.html\">vl_roc</a></a></code>\nfunction:</p>\n\n<div class=\"highlight\"><pre><span class=\"n\">vl_roc</span><span class=\"p\">(</span><span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"n\">scores</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p>This produces the figure</p>\n\n<div class=\"figure\">\n<img src=\"../demo/plots_rank_roc.jpg\"></img>\n<div class=\"caption\">An example ROC curve.</div>\n</div>\n\n<p>The ROC curve is the parametric curve given by the true positve\nrate (TPR) against the true negative rate (TNR). These two quantities\ncan be obtained from <code/><a href=../matlab/vl_roc.html>vl_roc</a></code> as follows:</p>\n\n<div class=\"highlight\"><pre><span class=\"p\">[</span><span class=\"n\">tpr</span><span class=\"p\">,</span> <span class=\"n\">tnr</span><span class=\"p\">]</span> <span class=\"p\">=</span> <span class=\"n\">vl_roc</span><span class=\"p\">(</span><span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"n\">scores</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p>The TPR value <code/>tpr(k)</code> is the percentage of positive\nsamples that have rank smaller or equal than <code/>k</code> (where\nranks are assigned by decreasing scores). <code/>tnr(k)</code> is\ninstead the percentage of negative samples that have rank larger\nthan <code/>k</code>. Therefore, if one classifies the samples with\nrank smaller or equal than <code/>k</code> to be positive and the rest\nto be negative, <code/>tpr(k)</code> and <code/>tnr(k)</code> are\nrepsectively the probability that a positive/negative sample is\nclassified correctly.</p>\n\n<p>Moving from rank <code/>k</code> to rank <code/>k+1</code>, if the\nsample of rank <code/>k+1</code> is positive then <code/>tpr</code>\nincreases; otherwise <code/>tnr</code> decreases. An ideal classifier\nhas all the positive samples first, and the corresponding ROC curve is\none that describes two sides of the unit square.</p>\n\n<p>The <em>Area Under the Curve (AUC)</em> is an indicator of the\noverall quality of a ROC curve. For example, the ROC of the ideal\nclassifier has AUC equal to 1. Another indicator is the <em>Equal\nError Rate (EER)</em>, the point on the ROC curve that corresponds to\nhave an equal probability of miss-classifying a positive or negative\nsample. This point is obtained by intersecting the ROC curve with a\ndiagonal of the unit square. Both AUC and EER can be computed\nby <code/><a href=../matlab/vl_roc.html>vl_roc</a></code>:</p>\n\n<div class=\"highlight\"><pre><span class=\"p\">[</span><span class=\"n\">tpr</span><span class=\"p\">,</span> <span class=\"n\">tnr</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"p\">]</span> <span class=\"p\">=</span> <span class=\"n\">vl_roc</span><span class=\"p\">(</span><span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"n\">scores</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n<span class=\"nb\">disp</span><span class=\"p\">(</span><span class=\"n\">info</span><span class=\"p\">.</span><span class=\"n\">auc</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n<span class=\"nb\">disp</span><span class=\"p\">(</span><span class=\"n\">info</span><span class=\"p\">.</span><span class=\"n\">eer</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p><code/><a href=../matlab/vl_roc.html>vl_roc</a></code> has a couple of useful functionalities:</p>\n\n<ul class=\"text\">\n<li>Any sample with label equal to zero is effecitvely ignored in the\nevaluation.</li>\n\n<li>Samples with scores equal to <code/>-inf</code> are assumed to be\nnever retrieved by the classifier. For these, the TNR is\nconventionally set to be equal to zero.</li>\n\n<li>Additional negative and positive samples with <code/>-inf</code>\nscore can be added to the evaluation by means of\nthe <code/>numNegatives</code> and <code/>numPositives</code>\noptions. For example,\n<code/>vl_roc(labels,scores,'numNegatives',1e4)</code> sets the number\nof negative samples to 10,000. This can be useful when evaluating\nlarge retrieval systems, for which one may want to record\nin <code/>labels</code> and <code/>scores</code> only the top ranked\nresults from a classifier.</li>\n\n<li>Different variants of the ROC plot can be produced. For example\n<code/>vl_roc(labels,scores,'plot','tptn')</code> swaps the two axis,\nplotting the TNR against the TPR.  Since the TPR is also the recall\n(i.e., the percentage of positive samples retrieved up to a certain\nrank), this makes the plot more directly comparable to\na <a shape=\"rect\" href=\"plots-rank.pr\">precision-recall plot</a>.\n<div class=\"figure\">\n<img src=\"../demo/plots_rank_roc_variants.jpg\"></img>\n<div class=\"caption\">Variants of the ROC plot.</div>\n</div>\n</li>\n</ul>\n\n<p>A limitation of the ROC curves in evaluating a typical retrieval\nsystem is that they put equal emphasis on false positive and false\nnegative errors. In a tipical retrieval application, however, the vast\nmajority of the samples are negative, so the false negative rate is\ntypically very small for any operating point of interest. Therefore\nthe emphasis is usually on the very first portion of the rank, where\nthe few positive samples should concentrate. This can be emphasized by\nusing either <a shape=\"rect\" href=\"plots-rank.pr\">precision-recall plot</a> or a\nvariant of the ROC curves called <em>Detection Error Tradeoff (DET)\ncurves</em>.</p>\n\n<p>A DET curve plots the FNR (also called <em>false alarm rate</em>)\nagainst teh FPR (also called <em>miss rate</em>) in logarithmic\ncoordiantes.  It can be generated\nby <code/><a href=../matlab/vl_det.html><a shape=\"rect\" href=\"../matlab/vl_det.html\">vl_det</a></a></code> function\ncall:</p>\n\n<div class=\"figure\">\n<img src=\"../demo/plots_rank_det.jpg\"></img>\n<div class=\"caption\">An example DET curve.</div>\n</div>\n\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n<h1 id=\"plots-rank.pr\">Precision-recall curves</h1>\n<!-- ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ -->\n\n<p>Both ROC and DET curves normalize out the relative proportions of\npositive and negative samples. By contrast, a <em>Precision-Recall\n(PR)</em> curve reflects this directly. One can plot the PR curve by\nusing the <code/><a href=../matlab/vl_pr.html><a shape=\"rect\" href=\"../matlab/vl_pr.html\">vl_pr</a></a></code>\nfunction:</p>\n\n<div class=\"highlight\"><pre><span class=\"n\">vl_pr</span><span class=\"p\">(</span><span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"n\">scores</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p>This produces the figure</p>\n\n<div class=\"figure\">\n<img src=\"../demo/plots_rank_pr.jpg\"></img>\n<div class=\"caption\">An example precision-recall curve.</div>\n</div>\n\n<p>The PR curve is the parametric curve given by precision and\nrecall. These two quantities can be obtained from <code/><a href=../matlab/vl_roc.html>vl_roc</a></code>\nas follows:</p>\n\n<div class=\"highlight\"><pre><span class=\"p\">[</span><span class=\"n\">recall</span><span class=\"p\">,</span> <span class=\"n\">precision</span><span class=\"p\">]</span> <span class=\"p\">=</span> <span class=\"n\">vl_roc</span><span class=\"p\">(</span><span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"n\">scores</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p>The precision value <code/>precision(k)</code> is the proportion of\nsamples with rank smaller or equal than <code/>k-1</code> that are\npositive(where ranks are assigned by decreasing\nscores). <code/>recall(k)</code> is instead the percentage of positive\nsamples that have rank smaller or equal than <code/>k-1</code>. For\nexample, if the first two samples are one positive and one\nnegative, <code/>precision(3)</code> is 1/2. If there are in total 5\npositive samples, then <code/>recall(3)</code> is 1/5.</p>\n\n<p>Moving from rank <code/>k</code> to rank <code/>k+1</code>, if the\nsample of rank <code/>k+1</code> is positive then\nboth <code/>precision</code> and <code/>recall</code> increase;\notherwise <code/>precision</code> decreases and <code/>recall</code>\nstays constant. This gives the PR curve a characteristic\nsaw-shape. For aan ideal classifier that ranks all the positive\nsamples first the PR curve is one that describes two sides of the unit\nsquare.</p>\n\n<p>Similar to the ROC curves, the <em>Area Under the Curve (AUC)</em>\ncan be used to summarize the quality of a ranking in term of precision\nand recall. This can be obtained as <code/>info.auc</code> by</p>\n\n<div class=\"highlight\"><pre><span class=\"p\">[</span><span class=\"n\">rc</span><span class=\"p\">,</span> <span class=\"n\">pr</span><span class=\"p\">,</span> <span class=\"n\">info</span><span class=\"p\">]</span> <span class=\"p\">=</span> <span class=\"n\">vl_pr</span><span class=\"p\">(</span><span class=\"n\">labels</span><span class=\"p\">,</span> <span class=\"n\">scores</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n<span class=\"nb\">disp</span><span class=\"p\">(</span><span class=\"n\">info</span><span class=\"p\">.</span><span class=\"n\">auc</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n<span class=\"nb\">disp</span><span class=\"p\">(</span><span class=\"n\">info</span><span class=\"p\">.</span><span class=\"n\">ap</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n<span class=\"nb\">disp</span><span class=\"p\">(</span><span class=\"n\">info</span><span class=\"p\">.</span><span class=\"n\">ap_interp_11</span><span class=\"p\">)</span> <span class=\"p\">;</span>\n</pre></div>\n\n\n<p>The AUC is obtained by trapezoidal interpolation of the precision.\nAn alternative and usually almost equivalent metric is the <em>Average\nPrecision (AP)</em>, returned as <code/>info.ap</code>. This is the\naverage of the precision obtained every time a new positive sample is\nrecalled. It is the same as the AUC if precision is interpolated by\nconstant segments and is the definition used by TREC most\noften. Finally, the <em>11 points interpolated average precision</em>,\nreturned as <code/>info.ap_interp_11</code>. This is an older TREC\ndefinition and is obtained by taking the average of eleven precision\nvalues, obtained as the maximum precision for recalls largerer than\n0.0, 0.1, ..., 1.0. This particular metric was used, for example, in\nthe PASCAL VOC challenge until the 2008 edition.</p>\n\n\n  \n      </div>\n      <div class=\"clear\">&nbsp;</div>\n    </div>\n  </div> <!-- content-section -->\n  <div id=\"footer-section\">\n    <div id=\"footer\">\n      &copy; 2007-13 The authors of VLFeat\n    </div> <!-- footer -->\n  </div> <!-- footer section -->\n </body>\n <!-- Body ends -->\n</html>\n ", "encoding": "ascii"}