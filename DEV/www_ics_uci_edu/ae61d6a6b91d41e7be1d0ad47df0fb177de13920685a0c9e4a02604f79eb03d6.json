{"url": "https://www.ics.uci.edu/~dechter/courses/ics-295/winter-2018/", "content": "<html>\r\n<head>\r\n  <title>Dr. Rina Dechter @ UCI</title>\r\n  <link rel=Stylesheet href=\"/~dechter/basic.css\">\r\n</head>\r\n<body style=\"background-color: rgb(255, 255, 255);\" alink=\"#00aaaa\" link=\"#008080\" vlink=\"#008080\">\r\n<center>\n   <table width=\"95%\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\n      <tr>\n         <td class=\"title\" valign=\"bottom\">\n            <nobr>Dr. Rina Dechter - University of California at Irvine</nobr>\n         </td>\n         <td><img alt=\"ZOT!\" align=\"right\" valign=\"bottom\" src=\"/~dechter/images/anteater-ics.gif\"></td>\n      </tr>\n      <!--\n\t  <tr>\n         <td colspan=\"2\"><img height=\"2\" src=\"/~dechter/images/transp-fill.gif\"></td>\n      </tr>\n\t  -->\n\t  <!--\n      <tr>\n         <td colspan=\"2\"><img width=\"100%\" height=\"2\"  src=\"/~dechter/images/black-fill.gif\"></td>\n      </tr>\n\t  -->\n      <tr valign=top>\n         <td>\n\t\t    <!--<font color=\"ffaa00\" size=\"3\">-->\n\t\t    <a href=\"/~dechter/index.html\">home</a> |\n            <a href=\"/~dechter/publications.html\">publications</a> |\n            <a href=\"/~dechter/books/\">book</a> |\n            <a href=\"/~dechter/courses.html\">courses</a> |\n            <a href=\"/~dechter/research.html\">research</a>\n\t\t\t<!--</font>-->\n         </td>\n         <td align=right>\n            <!--<font color=#008080>-->\n               Revised on\n               \n               Mar. 22, 2018\n            </font>\n         </td>\n      </tr>\n   </table>\n</center>\r\n<br>\r\n<br>\r\n<center>\r\n<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"90%\">\r\n  <tbody>\r\n    <tr>\r\n      <td><img src=\"/%7Edechter/images/transp-fill.gif\" height=\"4\"></td>\r\n    </tr>\r\n    <tr>\r\n      <td class=\"title\">\r\n      <h3><span style=\"font-weight: bold;\">CompSci 295 Reinforcement Learning, Winter 2018<br>\r\n      </span></h3>\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td><img src=\"/%7Edechter/images/black-fill.gif\" height=\"2\"\r\n width=\"100%\"></td>\r\n    </tr>\r\n    <tr>\r\n      <td align=\"right\"> <a href=\"resources.htm\"><span\r\n style=\"text-decoration: underline;\"></span></a><span\r\n style=\"text-decoration: underline;\"></span><a href=\"slides.html\"></a><a\r\n style=\"font-weight: bold;\" href=\"resources.html\"><span\r\n style=\"text-decoration: underline;\"></span></a> </td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n<p>\r\n<span style=\"font-weight: bold;\"></span><br>\r\n<table style=\"width: 1076px; height: 430px;\" border=\"0\" cellpadding=\"0\"\r\n cellspacing=\"0\">\r\n  <tbody>\r\n    <tr>\r\n      <td colspan=\"2\">\r\n      <ul>\r\n        <li>Classroom: DBH 1429<br>\r\n        </li>\r\n        <li>Day: Monday </li>\r\n        <li>Time: 4:00 - 6:30 pm </li>\r\n        <li>Instructor: Rina Dechter - <a\r\n href=\"mailto:dechter@ics.uci.edu\">dechter@ics.uci.edu</a> </li>\r\n      </ul>\r\n      <hr noshade=\"noshade\">\r\n      <p> </p>\r\n      <p> The class will cover topics in Reinforcement Learning and in Planning Under Uncertainty. The class will run as a seminar.  I will give the  first few introductory classes. Then students will be required to read and present papers from the literature or chapters in books to the class and do a project which can be based on their selected papers.There may also be some home-works assigned.\r\nThe class is  intended  for PhD students in the area of AI and Machine Learning, with  271 and 273 courses as prerequisite.  If you are a second year master student that already took 271 and 273 you should talk to me to get an approval.<br>\r\n<br>\r\n\t<h2><a href=\"https://docs.google.com/spreadsheets/d/18IfXZxgVKYbe5-5IsfgJIG8FU94OIbOk64Pjb3RmJn4/edit#gid=0\">Project Spreadsheet</a></h2>\r\n\t\r\n      <h2><span style=\"font-weight: bold;\">Relevant sources (books or classes):</span></h2>\r\n\r\n\t  <ul>\r\n\r\n\t  <li><a href=\"https://sites.ualberta.ca/~szepesva/RLBook.html\">Algorithms for Reinforcement Learning</a><br>\r\n\t  Csaba Szepesv\u00e1ri\r\n\t <li><a href=\"http://incompleteideas.net/book/bookdraft2017nov5.pdf\">Reinforcement Learning: An Introduction</a><br>\r\n\t  Richard S. Sutton and Andrew G. Barto\r\n\t  <li><a href=\"http://cs.brown.edu/courses/cs2951f/\">Learning and Sequential Decision Making</a><br>\r\n\t  Michael L. Littman\r\n\t  <li><a href=\"http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html\">UCL Course on Reinforcement Learning</a><br>\r\n\t  David Silver\t  \r\n\t  <li><a href=\"http://www.morganclaypool.com/doi/abs/10.2200/S00426ED1V01Y201206AIM017?journalCode=aim\">Planning with Markov Decision Processes: An AI Perspective</a><br>\r\n\t  Mausam, Andrey Kolobov\r\n\t  <li><a href=\"http://www.morganclaypool.com/doi/abs/10.2200/S00513ED1V01Y201306AIM022\">A Concise Introduction to Models and Methods for Automated Planning</a><br>\r\n\t  Hector Geffner and Blai Bonet\r\n\t  <li><a href=\"https://en.wikipedia.org/wiki/Reinforcement_learning#Research\">Reinforcement Learning: Wikipedia</a><br>\r\n\t  </ul>\r\n\t  \r\n<h2><span style=\"font-weight: bold;\">Papers:</span></h2>\r\n\t  \r\n<ul>\r\n\t  \r\n\t\t<li> <font class=\"papertitle\"> <a name=\"Sutton-td\"> </a>Learning to Predict by the Methods of Temporal Differences</font> [<a href=\"papers/Sutton-td.pdf\">pdf</a>]\r\n\r\n\t\t<br> Richard S. Sutton\r\n\r\n\t\t<br> <font class=\"journalname\">Machine Learning</font>, volume 3, pp  9-44, 1988. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"1994-singh-yee\"> </a>An Upper Bound on the Loss from Approximate Optimal-Value Functions</font> [<a href=\"papers/1994-singh-yee.pdf\">pdf</a>]\r\n\r\n\t\t<br> Satinder P. Singh and Richard C. Yee\r\n\r\n\t\t<br> <font class=\"journalname\">Machine Learning</font>, volume 16, pp 227-233, 1994. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"littman1\"> </a>Algorithms for Sequential Decision Making</font> [<a href=\"papers/littman1.pdf\">pdf</a>]\r\n\r\n\t\t<br> Michael L. Littman\r\n\r\n\t\t<br> <font class=\"journalname\">Ph.D. Dissertation</font>, Brown University, Providence, RI, USA, March 1996. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"rl-survey-jair\"> </a>Reinforcement Learning: A Survey</font> [<a href=\"papers/rl-survey-jair.pdf\">pdf</a>]\r\n\r\n\t\t<br> Leslie Pack Kaelbling, Michael L. Littman and Andrew W. Moore\r\n\r\n\t\t<br> <font class=\"journalname\">Journal of Artificial Intelligence Research</font>, volume 4, pp  237-285, 1996.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"Boutilier-Dean-hanks-jair\"> </a>Decision-Theoretic Planning: Structural Assumptions and\r\nComputational Leverage</font> [<a href=\"papers/Boutilier-Dean-hanks-jair.pdf\">pdf</a>]\r\n\r\n\t\t<br> Craig Boutilier, Thomas Dean and Steve Hanks\r\n\r\n\t\t<br> <font class=\"journalname\">Journal of Artificial Intelligence Research</font>, volume 11, pp  1-94, 1999.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"craig-abstraction\"> </a>SPUDD: Stochastic Planning using Decision Diagrams</font> [<a href=\"papers/craig-abstraction.pdf\">pdf</a>]\r\n\r\n\t\t<br> Jesse Hoey, Robert St-Aubin, Alan Hu and Craig Boutilier\r\n\r\n\t\t<br> <font class=\"confname\">UAI-99</font>. <i>15th Conference on Uncertainty in Artificial Intelligence</i>, Stockholm, Sweden, July 1999. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2000-nips12-sutton-mcallester-policy-gradient-methods-for-reinforcement-learning-with-function-approximation\"> </a>Policy gradient methods for reinforcement learning with function approximation </font> [<a href=\"papers/2000-nips12-sutton-mcallester-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf\">pdf</a>]\r\n\r\n\t\t<br> Richard S. Sutton, David McAllester, Satinder Singh and Yishay Mansour\r\n\t\t\r\n\t\t<br> <font class=\"confname\">NIPS-99</font>. <i>12th International Conference on Neural Information Processing Systems</i>, Denver, Colorado, USA, December 1999. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2000-singh-littmansingh98convergence\"> </a>Convergence Results for Single-Step On-Policy Reinforcement-Learning Algorithms</font> [<a href=\"papers/2000-singh-littmansingh98convergence.pdf\">pdf</a>]\r\n\r\n\t\t<br> Satinder Singh, Tommi Jaakkola, Michael L. Littman and Csaba Szepesv\u00e1ri\r\n\r\n\t\t<br> <font class=\"journalname\">Machine Learning</font>, volume 39, pp 287\u2013308, 2000. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"KearnsSinghE3\"> </a>Near-Optimal Reinforcement Learning in Polynomial Time</font> [<a href=\"papers/KearnsSinghE3.pdf\">pdf</a>]\r\n\r\n\t\t<br> Michael Kearns and Satinder Singh\r\n\r\n\t\t<br> <font class=\"journalname\">Machine Learning</font>, volume 49, pp  209-232, 2002. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2002-brafman02a\"> </a>R-MAX - A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning</font> [<a href=\"papers/2002-brafman02a.pdf\">pdf</a>]\r\n\r\n\t\t<br> Ronen I. Brafman and Moshe Tennenholtz\r\n\r\n\t\t<br> <font class=\"journalname\">Journal of Machine Learning Research</font>, volume 3, pp 213-231, 2002. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"givan-dean-greig\"> </a>Equivalence notions and model minimization in Markov decision processes</font> [<a href=\"papers/givan-dean-greig.pdf\">pdf</a>]\r\n\r\n\t\t<br> Robert Givan, Thomas Dean and Matthew Greig\r\n\r\n\t\t<br> <font class=\"journalname\">Artificial Intelligence</font>, volume 147, pp  163-223, 2003. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2003-LSPIjmlr03.pd\"> </a>Least-Squares Policy Iteration</font> [<a href=\"papers/2003-LSPIjmlr03.pd.pdf\">pdf</a>]\r\n\r\n\t\t<br> Michail G. Lagoudakis and Ronald Parr\r\n\r\n\t\t<br> <font class=\"journalname\">Journal of Machine Learning Research</font>, volume 4, pp 1107-1149, 2003. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2005-Ernst-JLMRernst05a\"> </a>Tree-Based Batch Mode Reinforcement Learning</font> [<a href=\"papers/2005-Ernst-JLMRernst05a.pdf\">pdf</a>]\r\n\r\n\t\t<br> Damien Ernst, Pierre Geurts and Louis Wehenkel\r\n\r\n\t\t<br> <font class=\"journalname\">Journal of Machine Learning Research</font>, volume 6, pp 503-556, 2005. \r\n\t\t<p>\r\n\t  \r\n\t\t<li> <font class=\"papertitle\"> <a name=\"icml-brl\"> </a>An Analytic Solution to Discrete Bayesian Reinforcement Learning</font> [<a href=\"papers/icml-brl-8pages.pd.pdf\">pdf</a>]\r\n\r\n\t\t<br> Pascal Poupart, Nikos Vlassis, Jesse Hoey, Kevin Regan\r\n\r\n\t\t<br> <font class=\"confname\">ICML-06</font>. <i>23rd International Conference on Machine Learning</i>, Pittsburgh, PA, USA, June 2006. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2006-csaba\"> </a>Bandit based monte-carlo planning</font> [<a href=\"papers/2006-csaba.pdf\">pdf</a>]\r\n\r\n\t\t<br> Levente Kocsis, Csaba Szepesv\u00e1ri\r\n\r\n\t\t<br> <font class=\"confname\">ECML-06</font>. <i>17th European Conference on Machine Learning</i>, Berlin, Germany, September 2006. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"littman-2008627\"> </a>Knows What It Knows: A Framework For Self-Aware Learning</font> [<a href=\"papers/littman-2008627.pdf\">pdf</a>]\r\n\r\n\t\t<br> Lihong Li, Michael L. Littman, Thomas J. Walsh\r\n\r\n\t\t<br> <font class=\"confname\">ICML-08</font>. <i>25th International Conference on Machine Learning</i>, Helsinki, Finland, July 2008. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2007-parr-icml08.pd\"> </a>An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning</font> [<a href=\"papers/2007-parr-icml08.pd.pdf\">pdf</a>]\r\n\r\n\t\t<br> Ronald Parr, Lihong Li, Gavin Taylor, Christopher Painter-Wakefield, Michael L. Littman\r\n\r\n\t\t<br> <font class=\"confname\">ICML-08</font>. <i>25th International Conference on Machine Learning</i>, Helsinki, Finland, July 2008. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2008-littman-aij-main\"> </a>An analysis of model-based Interval Estimation for Markov Decision Processes</font> [<a href=\"papers/2008-littman-aij-main.pdf\">pdf</a>]\r\n\r\n\t\t<br> Alexander L.Strehl and Michael L.Littman\r\n\r\n\t\t<br> <font class=\"journalname\">Journal of Computer and System Sciences</font>, volume 74, pp 1309-1331, 2008. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2009-littman1205.2664.pd\"> </a>A Bayesian sampling approach to exploration in reinforcement learning</font> [<a href=\"papers/2009-littman1205.2664.pd.pdf\">pdf</a>]\r\n\r\n\t\t<br> John Asmuth, Lihong Li, Michael L. Littman, Ali Nouri, David Wingate\r\n\r\n\t\t<br> <font class=\"confname\">UAI-09</font>. <i>25th Conference on Uncertainty in Artificial Intelligence</i>, Montreal, Quebec, Canada, June 2009. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2009-sutton-Fast_gradient-descent\"> </a>Fast gradient-descent methods for temporal-difference learning with linear function approximation</font> [<a href=\"papers/2009-sutton-Fast_gradient-descent.pdf\">pdf</a>]\r\n\r\n\t\t<br> Richard S. Sutton, Hamid Reza Maei, Doina Precup, Shalabh Bhatnagar, David Silver, Csaba Szepesv\u00e1ri, Eric Wiewiora\r\n\r\n\t\t<br> <font class=\"confname\">ICML-09</font>. <i>26th International Conference on Machine Learning</i>, Montreal, Quebec, Canada, June 2009. \r\n\t\t<p>\t\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2009-silver-paper_thesis\"> </a>Reinforcement Learning and Simulation-Based Search in Computer Go</font> [<a href=\"papers/2009-silver-paper_thesis.pdf\">pdf</a>]\r\n\r\n\t\t<br> David Silver\r\n\r\n\t\t<br> <font class=\"journalname\">Ph.D. Dissertation</font>, University of Alberta, Edmonton, Alberta, Canada, 2009. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2009-Stone-JMLRtaylor09a\"> </a>Transfer Learning for Reinforcement Learning Domains: A Survey</font> [<a href=\"papers/2009-Stone-JMLRtaylor09a.pdf\">pdf</a>]\r\n\r\n\t\t<br> Matthew E. Taylor and Peter Stone\r\n\r\n\t\t<br> <font class=\"journalname\">Journal of Machine Learning Research</font>, volume 10, pp 1633-1685, 2009. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2010-sutton-ICML10_controlGQ\"> </a>Toward Off-Policy Learning Control with Function Approximation</font> [<a href=\"papers/2010-sutton-ICML10_controlGQ.pdf\">pdf</a>]\r\n\r\n\t\t<br> Hamid Reza Maei, Csaba Szepesv\u00e1ri, Shalabh Bhatnagar, Richard S. Sutton\r\n\r\n\t\t<br> <font class=\"confname\">ICML-10</font>. <i>27th International Conference on Machine Learning</i>, Haifa, Israel, June 2010. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2010-mtc-aij\"> </a>Monte Carlo tree search in Kriegspiel</font> [<a href=\"papers/2010-mtc-aij.pdf\">pdf</a>]\r\n\r\n\t\t<br> Paolo Ciancarini and Gian Piero Favini\r\n\r\n\t\t<br> <font class=\"journalname\">Artificial Intelligence</font>, volume 174, pp 670-684, 2010. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"mcts-gelly-silver\"> </a>Monte-Carlo tree search and rapid action value estimation in computer Go</font> [<a href=\"papers/mcts-gelly-silver.pdf\">pdf</a>]\r\n\r\n\t\t<br> Sylvain Gelly and David Silver\r\n\r\n\t\t<br> <font class=\"journalname\">Artificial Intelligence</font>, volume 175, pp  1856-1875, 2011. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2012-parr-icml2012-full\"> </a>Greedy Algorithms for Sparse Reinforcement Learning</font> [<a href=\"papers/2012-parr-icml2012-full.pdf\">pdf</a>]\r\n\r\n\t\t<br> Christopher Painter-Wakefield, Ronald Parr\r\n\r\n\t\t<br> <font class=\"confname\">ICML-12</font>. <i>29th International Conference on Machine Learning</i>, Edinburgh, Scotland, UK, July 2012. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"mcts-survey\"> </a>A Survey of Monte Carlo Tree Search Methods</font> [<a href=\"papers/mcts-survey.pdf\">pdf</a>]\r\n\r\n\t\t<br> Cameron Browne, Edward Powley, Daniel Whitehouse, Simon Lucas, Peter I. Cowling, Philipp Rohlfshagen, Stephen Tavener, Diego Perez, Spyridon Samothrakis and Simon Colton\r\n\r\n\t\t<br> <font class=\"journalname\">IEEE Transactions on Computational Intelligence and AI in Games</font>, volume 4, pp  1-43, 2012. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2013-UAI-BatchiFDD\"> </a>Batch-iFDD for representation expansion in large MDPs</font> [<a href=\"papers/2013-UAI-BatchiFDD.pdf\">pdf</a>]\r\n\r\n\t\t<br> Alborz Geramifard, Thomas J. Walsh, Nicholas Roy, Jonathan P. How\r\n\r\n\t\t<br> <font class=\"confname\">UAI-13</font>. <i>29th Conference on Uncertainty in Artificial Intelligence</i>, Bellevue, Washington, USA, August 2013. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2014-emma\"> </a>Offline policy evaluation across representations with applications to educational games</font> [<a href=\"papers/2014-emma.pdf\">pdf</a>]\r\n\r\n\t\t<br> Travis Mandel, Yun-En Liu, Sergey Levine, Emma Brunskill, Zoran Popovic\r\n\r\n\t\t<br> <font class=\"confname\">AAMAS-14</font>. <i>2014 International Conference on Autonomous Agents and Multi-agent Systems</i>, Paris, France, May 2014. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2015Thomas2015\"> </a>High-Confidence Off-Policy Evaluation </font> [<a href=\"papers/2015Thomas2015.pdf\">pdf</a>]\r\n\r\n\t\t<br> Philip S. Thomas, Georgios Theocharous, Mohammad Ghavamzadeh\r\n\r\n\t\t<br> <font class=\"confname\">AAAI-15</font>. <i>29th AAAI Conference on Artificial Intelligence</i>, Austin, Texas, USA, January 2015. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"thomas-nips-15\"> </a>Policy evaluation using the \u03a9-return </font> [<a href=\"papers/thomas-nips-15.pdf\">pdf</a>]\r\n\r\n\t\t<br> Philip S. Thomas, Scott Niekum, Georgios Theocharous, George Konidaris\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-15</font>. <i>28th International Conference on Neural Information Processing Systems</i>, Montreal, Canada, December 2015. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nature-go\"> </a>Mastering the game of Go without human knowledge</font> [<a href=\"papers/nature-go.pdf\">pdf</a>]\r\n\r\n\t\t<br> David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, Yutian Chen, Timothy Lillicrap, Fan Hui, Laurent Sifre, George van den Driessche, Thore Graepel and Demis Hassabis\r\n\r\n\t\t<br> <font class=\"journalname\">Nature</font>, volume 550, pp  354\u2013359, 2017. \r\n\t\t<p>\r\n\t\t\r\n</ul>\r\n\t  \r\n<h2><span style=\"font-weight: bold;\">NIPS 2017 Papers:</span></h2>\r\n\r\n<ul>\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-1\"> </a>Optimistic posterior sampling for reinforcement learning: worst-case regret bounds</font> [<a href=\"papers/nips/6718-optimistic-posterior-sampling-for-reinforcement-learning-worst-case-regret-bounds.pdf\">pdf</a>]\r\n\r\n\t\t<br> Shipra Agrawal, Randy Jia\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\t\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-2\"> </a>Regret Analysis for Continuous Dueling Bandit</font> [<a href=\"papers/nips/6747-regret-analysis-for-continuous-dueling-bandit.pdf\">pdf</a>]\r\n\r\n\t\t<br> Wataru Kumagai\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n\t\t\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-3\"> </a>Minimal Exploration in Structured Stochastic Bandits</font> [<a href=\"papers/nips/6773-minimal-exploration-in-structured-stochastic-bandits.pdf\">pdf</a>]\r\n\r\n\t\t<br> Richard Combes, Stefan Magureanu, Alexandre Proutiere\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-4\"> </a>Shallow Updates for Deep Reinforcement Learning</font> [<a href=\"papers/nips/6906-shallow-updates-for-deep-reinforcement-learning.pdf\">pdf</a>]\r\n\r\n\t\t<br> Nir Levine, Tom Zahavy, Daniel J. Mankowitz, Aviv Tamar\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-5\"> </a>Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning</font> [<a href=\"papers/nips/6974-interpolated-policy-gradient-merging-on-policy-and-off-policy-gradient-estimation-for-deep-reinforcement-learning.pdf\">pdf</a>]\r\n\r\n\t\t<br> Shixiang Gu, Timothy Lillicrap, Zoubin Ghahramani, Richard E. Turner, Bernhard Sch\u00f6lkopf, Sergey Levine\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-6\"> </a>Monte-Carlo Tree Search by Best Arm Identification</font> [<a href=\"papers/nips/7075-monte-carlo-tree-search-by-best-arm-identification.pdf\">pdf</a>]\r\n\r\n\t\t<br> Emilie Kaufmann, Wouter M. Koolen\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-7\"> </a>Hybrid Reward Architecture for Reinforcement Learning</font> [<a href=\"papers/nips/7123-hybrid-reward-architecture-for-reinforcement-learning.pdf\">pdf</a>]\r\n\r\n\t\t<br> Harm van Seijen, Mehdi Fatemi, Joshua Romoff, Romain Laroche, Tavian Barnes, Jeffrey Tsang\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\t\r\n\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-8\"> </a>Robust and Efficient Transfer Learning with Hidden Parameter Markov Decision Processes</font> [<a href=\"papers/nips/7205-robust-and-efficient-transfer-learning-with-hidden-parameter-markov-decision-processes.pdf\">pdf</a>]\r\n\r\n\t\t<br> Taylor Killian, Samuel Daulton, George Konidaris, Finale Doshi-Velez\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-9\"> </a>Towards Generalization and Simplicity in Continuous Control</font> [<a href=\"papers/nips/7233-towards-generalization-and-simplicity-in-continuous-control.pdf\">pdf</a>]\r\n\r\n\t\t<br> Aravind Rajeswaran, Kendall Lowrey, Emanuel Todorov, Sham Kakade\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\t\r\n\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-10\"> </a>Inverse Reward Design</font> [<a href=\"papers/nips/7253-inverse-reward-design.pdf\">pdf</a>]\r\n\r\n\t\t<br> Dylan Hadfield-Menell, Smitha Milli, Pieter Abbeel, Stuart Russell, Anca Dragan\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\t\r\n\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-11\"> </a>Learning Combinatorial Optimization Algorithms over Graphs</font> [<a href=\"papers/nips/comb-opt_rl_combopt.pd.pdf\">pdf</a>]\r\n\r\n\t\t<br> Hanjun Dai, Elias B. Khalil, Yuyu Zhang, Bistra Dilkina, Le Song\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\t\t\t\r\n\r\n\r\n\r\n</ul>\r\n\r\n<h2><span style=\"font-weight: bold;\">Reinforcement Learning Symposium (NIPS 2017) Papers:</span></h2>\r\n\r\n<ul>\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"drls-1\"> </a>Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning</font> [<a href=\"papers/nips/2017_NIPS_MIMe - ANUSHA NAGABANDI.pdf\">pdf</a>]\r\n\r\n\t\t<br> Anusha Nagabandi, Gregory Kahn, Ronald S. Fearing, Sergey Levine\r\n\r\n\t\t<br> <font class=\"confname\">DRLS-17</font>. <i>Deep Reinforcement Learning Symposium, NIPS 2017</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\t\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"drls-2\"> </a>Parameter Space Noise for Exploration</font> [<a href=\"papers/nips/param-noise-final - Matthias Plappert.pdf\">pdf</a>]\r\n\r\n\t\t<br> Matthias Plappertyz, Rein Houthoofty, Prafulla Dhariwaly, Szymon Sidory, Richard Y. Cheny, Xi Chen, Tamim Asfourz, Pieter Abbeel, Marcin Andrychowiczy\r\n\r\n\t\t<br> <font class=\"confname\">DRLS-17</font>. <i>Deep Reinforcement Learning Symposium, NIPS 2017</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\t\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"drls-3\"> </a>Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor</font> [<a href=\"papers/nips/soft-actor-critic-nips-2017.pdf\">pdf</a>]\r\n\r\n\t\t<br> Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, Sergey Levine\r\n\r\n\t\t<br> <font class=\"confname\">DRLS-17</font>. <i>Deep Reinforcement Learning Symposium, NIPS 2017</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"drls-4\"> </a>Time-Contrastive Networks: Self-Supervised Learning from Pixels</font> [<a href=\"papers/nips/TCN_NIPS17_DeepRL_final - Yevgen Chebotar.pdf\">pdf</a>]\r\n\r\n\t\t<br> Pierre Sermanet, Corey Lynch, Yevgen Chebotar, Jasmine Hsu, Eric Jang, Stefan Schaal, Sergey Levine\r\n\r\n\t\t<br> <font class=\"confname\">DRLS-17</font>. <i>Deep Reinforcement Learning Symposium, NIPS 2017</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n\t\t\r\n\t\t\r\n\r\n</ul>\r\n\t  \r\n<h2><span style=\"font-weight: bold;\">Conferences, Symposia, Workshops:</span></h2>\r\n<ul>\r\n\t\t<li>\r\n\t\t<a href=\"https://sites.google.com/view/deeprl-symposium-nips2017/\"><font class=\"confname\">DRLS-17</font></a>. <i>Deep Reinforcement Learning Symposium, NIPS 2017</i>, Long Beach, USA, December 2017.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li>\r\n\t\t<a href=\"https://nips.cc/Conferences/2017/Schedule?type=Poster\"><font class=\"confname\">NIPS-17</font></a>. <i>Advances in Neural Information Processing Systems, NIPS 2017</i>, Long Beach, USA, December 2017.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li>\r\n\t\t<a href=\"https://sites.google.com/site/deeprlnips2016/\"><font class=\"confname\">DRLW-16</font></a>. <i>Deep Reinforcement Learning Workshop, NIPS 2016</i>, Barcelona, Spain, December 2016.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li><a href=\"https://ewrl.wordpress.com/ewrl13-2016/\"><font class=\"confname\">EWRL-16</font></a>. <i>The 13th European Workshop on Reinforcement Learning</i>, Barcelona, Spain, December 2016. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li>\r\n\t\t<a href=\"http://rll.berkeley.edu/deeprlworkshop/\"><font class=\"confname\">DRLW-15</font></a>. <i>Deep Reinforcement Learning Workshop, NIPS 2015</i>, Montreal, Canada, December 2015.\r\n\t\t<p>\r\n\t\t\r\n\t\t\r\n\r\n</ul>\r\n\r\n\t \r\n<!--\t  <li><a href=\"http://arxiv.org/pdf/1105.5460.pdf\">Decision-Theoretic Planning: Structural Assumptions and Computational Leverage</a><br>\r\n\t  Craig Boutilier, Thomas Dean, and Steve Hanks<br>\r\n\t  <i>Journal of Artificial Intelligence Research, 1999</i>\r\n\t  <li><a href=\"http://icaps13.icaps-conference.org/technical-program/accepted-papers/#FullMain\">List of Accepted Papers at ICAPS 2013</a>\r\n\t  <li><a href=\"http://www.aiconferences.org/ICAPS/icaps.html\">ICAPS Proceedings</a>\r\n\t  <li><a href=\"http://ie.technion.ac.il/~dcarmel/publications.html\">Papers by Carmel Domshlak</a>\r\n \r\n\t  <ul>\r\n\r\n<li> <font class=\"papertitle\"> <a name=\"positionUCT\"> </a>To UCT, or not to UCT? (Position Paper)</font> \r\n[<a href=\"http://iew3.technion.ac.il/~dcarmel/Papers/Sources/socs13.pdf\">pdf</a>]\r\n\r\n<br> Carmel Domshlak, Zohar Feldman\r\n\r\n<br> <font class=\"confname\">SOCS-13</font>. <i>6th Annual Symposium on Combinatorial Search</i>, Leavenworth, WA, USA, July 2013. \r\n<p>\r\n\r\n\r\n<li> <font class=\"papertitle\"> <a name=\"brueIS\"> </a>Monte-Carlo Planning: Theoretically Fast Convergence Meets Practical Efficiency</font> \r\n[<a href=\"http://iew3.technion.ac.il/~dcarmel/Papers/Sources/uai13.pdf\">pdf</a>]\r\n\r\n<br> Zohar Feldman, Carmel Domshlak\r\n\r\n<br> <font class=\"confname\">UAI-13</font>. <i>29th Conference on Uncertainty in Artificial Intelligence</i>, Bellevue, WA, USA, July 2013. \r\n<p>\r\n\r\n\r\n\r\n <li> <font class=\"papertitle\"> <a name=\"ftC\"> </a>Fault tolerant contingent planning: Complexity and compilation</font> \r\n [<a href=\"http://iew3.technion.ac.il/~dcarmel/Papers/Sources/icaps13c.pdf\">pdf</a>]\r\n\r\n <br> Carmel Domshlak\r\n\r\n <br> <font class=\"confname\">ICAPS-13</font>. <i>23nd International Conference on Automated Planning and Scheduling</i>, Rome, Italy, June 2013. \r\n <p>\r\n  \r\n  <li> <font class=\"papertitle\"> <a name=\"controlMDPs\">Planning for Operational Control Systems with Predictable Exogenous Events</a></font> \r\n  <br> Ronen Brafman, Carmel Domshlak, Yagil Engel, and Zohar Feldman\r\n  <br> <font class=\"confname\">AAAI-11</font>, <i>25th AAAI Conference on\r\n     Artificial Intelligence</i>, San-Francisco, CA, USA, August 2010.\r\n     <p>\r\n\r\n     <li> <font class=\"papertitle\"><a name=\"pffJ\"></a>Probabilistic Planning via Heuristic Forward Search and Weighted Model Counting</font>\r\n\r\n     [</a><a href=\"http://www.jair.org/papers/paper2289.html\">abstract</a>,\r\n      <a href=\"http://www.jair.org/media/2289/live-2289-3600-jair.pdf\">pdf</a>]\r\n\r\n      <br> Carmel Domshlak, Joerg Hoffmann\r\n\r\n      <br> <font class=\"journalname\">Journal of Artificial Intelligence Research</font>, \r\n      volume 30, pp  565-620, 2007.\r\n      <p>\r\n\r\n      <ul> \r\n        <li> <font class=\"papertitle\"> Fast Probabilistic Planning Through Weighted Model Counting </font>\r\n\r\n\t     [<a href=\"http://iew3.technion.ac.il/~dcarmel/Papers/Sources/icaps06b.pdf\">pdf</a>,\r\n\t           <a href=\"Presentations/icaps06-pff.pdf\">slides</a>]\r\n\r\n\t\t       <br> Carmel Domshlak, Joerg Hoffmann\r\n\r\n\t\t           <br> <font class=\"confname\">ICAPS-06</font>. <i>16th International Conference on Automated Planning and Scheduling</i>, pp 243-252, The English Lake District, U.K., September 2006.\r\n\r\n\t\t\t      <p>\r\n\t\t\t      </ul>\r\n\r\n\r\n</ul>\r\n\t  <li> Marc Toussaint Papers\r\n\t  <p>\r\n\t  <ul>\r\n\t\t<p>\r\n\t  \t<li>Probabilistic inference for solving (PO)MDPs [<a href=\"papers/toussaint-probinf-pomdp.pdf\">pdf</a>]<br>\r\n\t\tMarc Toussaint, Stefan Harmeling, and Amos Storkey<br>\r\n\t\t<i>Technical Report EDI-INF-RR-0934</i>, University of Edinburgh, School of Informatics, 2006.\r\n\t\t<p>\r\n\t\t<li>Nice applications that demonstrate efficiency in challenging domains are:\r\n\t\t<ul>\r\n\t\t<p>\r\n\t\t<li>Hierarchical POMDP Controller Optimization by Likelihood Maximization [<a href=\"papers/toussaint-hier-pomdp.pdf\">pdf</a>]<br>\r\n\t\tMarc Toussaint, Laurent Charlin, and Pascal Poupart<br>\r\n\t\tIn <i>Uncertainty in Artificial Intelligence (UAI 2008)</i>, 562-570, AUAI Press, 2008.\r\n\t\t<p>\r\n\t\t<li>Scalable Multiagent Planning Using Probabilistic Inference [<a href=\"papers/toussaint-multiagent-planning.pdf\">pdf</a>]<br>\r\n\t\tAkshat Kumar, Shlomo Zilberstein, and Marc Toussaint<br>\r\n\t\tIn <i>Proc. of the 22nd Int. Joint Conf. on Artificial Intelligence (IJCAI 2011),</i>2011.\r\n\t  </ul>\r\n\t  </ul>\r\n\r\n      </ul>\r\n      <p>\r\n      <br>\r\n-->\r\n\r\n\t \r\n      <h2><span style=\"font-weight: bold;\">Schedule</span></h2>\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td><img src=\"/%7Edechter/images/black-fill.gif\" height=\"2\"\r\n width=\"100%\"></td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n<table style=\"width: 1079px; height: 369px;\" border=\"3\" cellpadding=\"5\"\r\n cellspacing=\"1\">\r\n  <tbody>\r\n    <tr>\r\n      <td><b>Week\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b> </td>\r\n      <td> <b>Date</b> </td>\r\n      <td> <b>Topic</b> </td>\r\n      <td> <b>Readings and Files</b> </td>\r\n    </tr>\r\n    <tr>\r\n      <td> Week 1 </td>\r\n      <td> 1/8 </td>\r\n      <td>\r\n      <ul>\r\n        \r\n      </ul>\r\n      </td>\r\n      <td style=\"text-align: left; vertical-align: top;\">\r\n\t\t\t<a href=\"homework/hwk1-295.pdf\">Homework 1</a><br>\r\n\t\t\t<a href=\"slides/class1.pdf\">Slides 1</a><br>\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 2 </td>\r\n      <td> 1/15 </td>\r\n      <td>\r\n      Martin Luther King, Jr. Day - No class\r\n      </td>\r\n      <td> <br>\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td> Week 3 </td>\r\n      <td> 1/22 </td>\r\n      <td>\r\n      <ul>\r\n      </ul>\r\n      </td>\r\n      <td style=\"text-align: left; vertical-align: top;\">\r\n\t\t\t<a href=\"homework/hwk2-295.pdf\">Homework 2</a><br>\r\n\t\t\t<a href=\"slides/class2.pdf\">Slides 2</a><br>\r\n\t</td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 4<br>\r\n      </td>\r\n      <td> 1/29 </td>\r\n      <td>\r\n      <ul>\r\n      </ul>\r\n      </td>\r\n     <td style=\"text-align: left; vertical-align: top;\">\r\n\t\t\t<a href=\"homework/hwk3-295.pdf\">Homework 3</a><br>\r\n\t\t\t<a href=\"slides/class3.pdf\">Slides 3</a><br>\r\n\t</td>\r\n    </tr>\r\n    <tr>\r\n      <td> Week 5 </td>\r\n      <td> 2/5 </td>\r\n      <td>\r\n      No class\r\n      </td>\r\n      <td> <br> </td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 6 </td>\r\n      <td> 2/12 </td>\r\n      <td>\r\n      <ul>\r\n      </ul>\r\n      </td>\r\n\t  <td style=\"text-align: left; vertical-align: top;\">\r\n\t\t\t<a href=\"slides/class4.pdf\">Slides 4</a><br>\r\n\t\t\tPezeshki <a href=\"presentations/Pezeshki.pdf\">Slides</a> | <a href=\"papers/mcts-survey.pdf\">Paper</a><br>\r\n\t\t\tBroka <a href=\"presentations/Broka.pdf\">Slides</a> | <a href=\"papers/2009-sutton-Fast_gradient-descent.pdf\">Paper</a><br>\r\n\t\t\tZou <a href=\"presentations/Zou.pdf\">Slides</a> | <a href=\"papers/2005-poupart-icml-brl-8pages.pd.pdf\">Paper</a><br>\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 7 </td>\r\n      <td> 2/19 </td>\r\n      <td>\r\n      Presidents' Day - No class\r\n      </td>\r\n      <td style=\"text-align: left; vertical-align: top;\">\r\n\t\t\t<a href=\"homework/hwk4-295.pdf\">Homework 4</a><br>\t\t\t\r\n\t</td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 8 </td>\r\n      <td> 2/26 </td>\r\n      <td>\r\n      <ul>\r\n      </ul>\r\n      </td>\r\n\t  <td style=\"text-align: left; vertical-align: top;\">\r\n\t\t\t<a href=\"homework/hwk5-295.pdf\">Homework 5</a><br>\t\r\n\t\t\tXu <a href=\"presentations/Xu.pdf\">Slides</a> | <a href=\"papers/2000-nips12-sutton-mcallester-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf\">Paper</a><br>\r\n\t\t\tPraveen <a href=\"presentations/Praveen.pdf\">Slides</a>  | <a href=\"papers/littman-2008627.pdf\">Paper</a><br>\r\n\t\t\tPandey <a href=\"presentations/Pandey.pdf\">Slides</a> | <a href=\"papers/2007-parr-icml08.pd.pdf\">Paper</a><br>\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 9<br>\r\n      </td>\r\n      <td>3/5<br>\r\n      </td>\r\n      <td>\r\n      <ul>\r\n      </ul>\r\n      </td>\r\n      \t  <td style=\"text-align: left; vertical-align: top;\">\r\n\t\t\t<a href=\"homework/hwk6-295.pdf\">Homework 6</a><br>\r\n\t\t\t<a href=\"https://www.alexirpan.com/2018/02/14/rl-hard.html\">Blog Post</a><br>\r\n\t\t\tMcAleer Slides| <a href=\"papers/nature-go.pdf\">Paper</a><br>\r\n\t\t\tDheeru <a href=\"presentations/Dheeru.pdf\">Slides</a> | <a href=\"papers/icml04-apprentice.pdf\">Paper</a><br>\r\n\t\t\tLanier & Takashi <a href=\"presentations/Lanier-Takashi.pdf\">Slides</a> | <a href=\"papers/2009-Stone-JMLRtaylor09a.pdf\">Paper</a><br>\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 10<br>\r\n      </td>\r\n      <td>3/12<br>\r\n      </td>\r\n      <td>\r\n      <ul>\r\n       \r\n      </ul>\r\n      </td>\r\n      <td>\t\r\n\t\t\t<a href=\"homework/hwk7-295.pdf\">Homework 7</a><br>\r\n\t\t\tLogan <a href=\"presentations/Logan.pdf\">Slides</a>| <a href=\"papers/2015Thomas2015.pdf\">Paper</a><br>\r\n\t\t\tLaCroix <a href=\"presentations/LaCroix.pdf\">Slides</a> | <a href=\"papers/nips/7123-hybrid-reward-architecture-for-reinforcement-learning.pdf\">Paper</a><br>\r\n\t\t\tLee <a href=\"presentations/Lee.pdf\">Slides</a> | <a href=\"papers/2013-UAI-BatchiFDD.pdf\">Paper</a><br>\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 11<br>\r\n      </td>\r\n      <td>3/19 4-6:30p<br>\r\n      </td>\r\n      <td>\r\n      Lecture to be held in the usual classroom.\r\n      </td>\r\n      <td>\tNelson <a href=\"presentations/Nelson.pdf\">Slides</a>| <a href=\"papers/mcts-gelly-silver.pdf\">Paper</a><br>\r\n\t\t\tChen <a href=\"presentations/Chen.pdf\">Slides</a> | <a href=\"papers/nips/7253-inverse-reward-design.pdf\">Paper</a><br>\r\n\t\t\tMoskvichev <a href=\"presentations/Moskvichev.pdf\">Slides</a> | <a href=\"papers/Sutton-Precup-Singh-AIJ99.pdf\">Paper</a><br>\r\n      </td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n<br>\r\n</p>\r\n<br>\r\n\r\n\r\n</center>\r\n<div id=\"footer\"><centeR>\r\n<A HREF=\"http://www.ics.uci.edu\">School of Information and Computer Science</A>\r\n<A HREF=\"http://www.uci.edu\">University of California, Irvine, CA 92697-3435</a>\r\n<A HREF=\"http://www.ics.uci.edu/~dechter\">Dr. Rina Dechter</A>\n\r\n<A HREF=\"mailto:dechter_at_ics.uci.edu\">dechter at ics.uci.edu</A>\r\n\n</center></div>\r\n</body>\r\n</html>\r\n", "encoding": "utf-8"}