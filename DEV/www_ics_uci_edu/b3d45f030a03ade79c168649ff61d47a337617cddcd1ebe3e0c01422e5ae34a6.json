{"url": "https://www.ics.uci.edu/~dechter/courses/ics-275a/fall-99/sazhin-275a-project.html", "content": "<HTML>\r\n<HEAD>\r\n<TITLE>\r\nDr. Rina Dechter @ UCI\r\n</TITLE>\r\n<LINK REL=\"Stylesheet\" HREF=\"/~dechter/basic.css\">\t\t\r\n</HEAD>\r\n\r\n<BODY bgcolor=\"#ffffff\" alink=\"00aaaa\" link=\"008080\" vlink=\"008080\">\r\n\r\n<!-- Begin Header -->\r\n  [an error occurred while processing this directive]\r\n<!-- End Header -->\r\n\t\t\r\n<br><br>\r\n<center>\r\n<TABLE width=\"90%\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\r\n<tr><td>\r\n<p class=\"title\">Correlation between parameters of the constraint graphs and the solution\r\ntime spent by different search algorithms<br>\r\nCourse project ICS 275A<br>\r\nAnton Sazhin</p>\r\n\r\n<p ALIGN=\"CENTER\"><a HREF=\"mailto:sazhin@ics.uci.edu\">sazhin@ics.uci.edu</a></font><font\r\nFACE=\"Arial\"> </p>\r\n</font><font FACE=\"Arial\" SIZE=\"3\">\r\n\r\n<p ALIGN=\"CENTER\">This project is based on the research done by Rina Dechter and Daniel\r\nFrost.</p>\r\n</font><font FACE=\"Arial\"><b>\r\n\r\n<p>1. Introduction</p>\r\n</b></font><font FACE=\"Arial\" SIZE=\"3\">\r\n\r\n<p ALIGN=\"JUSTIFY\">Constraint Satisfaction Problems were in the focus of the theoretical\r\nand experimental research over the last two decades [1-5]. As the result of this research\r\nthere is a verity of different algorithms, which are efficient for solving some classes of\r\nCSP. A lot of work is done to provide a theoretical guarantee of the worst case\r\nperformance. But in practice a lot of problems do not belong to any class of CSP where we\r\nhave a reasonable guarantee of the worst case performance. Nevertheless even for these\r\ncases existing algorithms often are able to provide a solution much faster then the\r\nestimated worst case time. </p>\r\n\r\n<p ALIGN=\"JUSTIFY\">This project provides a statistical analysis of an average case\r\nperformance of five different CSP algorithms for some classes of CSP problems where the\r\nworst case analysis provides guarantees, which are far behind of any computational\r\nresources available nowadays. </p>\r\n\r\n<p ALIGN=\"JUSTIFY\">The project addresses two main questions. Are some instances\r\n&quot;naturally&quot; more difficult then other even if they have the same number of\r\nvariables, constraints, and values in each domain? If there are some &quot;naturally&quot;\r\ndifficult instances then what makes them difficult? </p>\r\n</font><font FACE=\"Arial\"><b>\r\n\r\n<p ALIGN=\"JUSTIFY\">2. Method</p>\r\n</b></font><font FACE=\"Arial\" SIZE=\"3\">\r\n\r\n<p ALIGN=\"JUSTIFY\">The behavior of the five search algorithms is investigated in this\r\nproject (BJ means conflict-directed backjumping, FC means forward checking, AC3X means\r\nfull arc-consistency checking, DVO means dynamic variable ordering, VMC means maximum\r\ncardinality variable ordering, VFA means fixed arbitrary variable ordering):</p>\r\n\r\n<p ALIGN=\"JUSTIFY\">1. BJ-AC3X-DVO</p>\r\n\r\n<p ALIGN=\"JUSTIFY\">2. BJ-AC3X-VMC</p>\r\n\r\n<p ALIGN=\"JUSTIFY\">3. BJ-AC3X-VFA</p>\r\n\r\n<p ALIGN=\"JUSTIFY\">4. BJ-FC-DVO</p>\r\n\r\n<p ALIGN=\"JUSTIFY\">5. BJ-FC-VMC</p>\r\n\r\n<p ALIGN=\"JUSTIFY\">The choice of the set of CSP to test the algorithm performance is\r\nreally crucial. For one type of CSP problems algorithm A can overperform algorithm B while\r\nfor another type of CSP A overperforms B. The choice of the testing set of CSP is very\r\nsubjective. It has been shown [1,3] that there are set of parameters (so called cross-over\r\npoints) which make CSP very difficult to solve. In this project only sets nearby\r\ncross-over points are investigated. </p>\r\n\r\n<p ALIGN=\"JUSTIFY\">Eight sets of CSP problems are chosen (see table 1). Each set contains\r\n10000 parameterized, randomly generated, binary CSP instances. Four generation parameters\r\ndetermines the each set of CSP: N is the number of variables, D is the size of each\r\nvariable&#146;s domain, C is the number of constraints, T is an indicator of the tightness\r\nof each constraint. The short notation is used everywhere below: N_D_C_T. For example the\r\ntype 50_3_164_2 means N = 50, D = 3, C = 164, T = 2. </p>\r\n\r\n<p ALIGN=\"JUSTIFY\">All possible constraints could be enumerated using a simple rule:\r\nconstraint 1--2 has number 1, constraint 1--3 has number 2, ..., constraint 1--N has\r\nnumber N - 1, ..., constraint (N-1)--N has number N*(N-1)/2. Four sets contain the\r\ninstances where constraints are uniformly distributed over all variables (these sets\r\ndenoted as &quot;uniform&quot;). In the uniform case the distribution function of a binary\r\nrandom variable &quot;Constraint x is chosen&quot; is linear, so its derivative (the\r\nprobability density function) is constant. Four sets contain the instances where\r\nconstraints are distributed non-uniformly (these sets denoted as &quot;non-uniform&quot;).\r\nIn the non-uniform case the distribution function is polynomial with randomly chosen power\r\nbetween 1 and 2, so its derivative (the probability density function) is polynomial with\r\nrandomly chosen power between 0 and 1. </p>\r\n\r\n<p ALIGN=\"JUSTIFY\">To make the performance estimation simpler only one parameter is used\r\nto judge how good a particular algorithms solves a particular CSP instance. This parameter\r\nis the number of consistency checks made by the algorithm while solving the instance. The\r\nnumber of consistency checks for all algorithms under investigation is strongly correlated\r\nwith CPU time spent by these algorithms at some particular computer. And the number of\r\nconsistence checks is implementation independent and will be the same for computers with\r\ndifferent performance.</p>\r\n\r\n<p ALIGN=\"JUSTIFY\">Eight different graph parameters are used as in advance estimators of\r\nthe difficulty of some particular instance of CSP. Four of them deal with the original\r\nconstraint graph and the corresponding set of four graph parameters is calculated for the\r\ninduced constraint graph. Minimum induced width algorithm is used to build the induced\r\nwidth graph. These parameters for original and induced graphs respectively are width,\r\nnumber of variables in the core, hyperwidth of the core, and relative density of\r\nconstraints in the core. The definition of the core is the set of variables in the graph\r\n(original or induced respectively) with width at least 80% of the width of the\r\ncorresponding graph. For example, if the induced width is equal to 50 then the core of the\r\ninduced graph contains all variables with induced width 40 or bigger. The hyperwidth of\r\nthe core is defined as the sum over widths of all variables in the core. The definition of\r\nthe relative density of constraints in the core is a little bit cumbersome: it is the\r\nratio of the actual number of constraints between variables in the core (both variables\r\nshould be in the core) to the expected number of constraints between variables in the\r\ncore. The actual number of constraints between variables in the core could be easily\r\ncounted for the particular graph. The expected number of constrains between variables in\r\nthe core is equal to C*N<sub>C</sub>*( N<sub>C</sub> -1)/( N*( N -1) ), where C is the\r\nnumber of constraints, N is the number of variables, and N<sub>C </sub>is the number of\r\nvariables in the core.</p>\r\n</font><font FACE=\"Arial\"><b>\r\n\r\n<p ALIGN=\"JUSTIFY\">3. Results and discussion </p>\r\n</b></font><font FACE=\"Arial\" SIZE=\"3\">\r\n\r\n<p ALIGN=\"JUSTIFY\">The average numbers of consistency checks over 10000 instances for each\r\nalgorithm and each set of generation parameters of CSP is shown in the table 1. The graph\r\n1 represents the same information (results for BJ-FC-VMC are omitted because they are way\r\nbigger then other). We can see that the algorithms BJ-AC3X-DVO, BJ-AC3X-VMC and\r\nBJ-AC3X-VFA give almost the same performance for simple (less time consuming for all\r\nalgorithms) types of CSP: 50_3_164_2 and 50_3_92_3. In the case of more difficult types of\r\nCSP (50_3_380_1 and 30_6_151_10) the choice of the &quot;right&quot; variable ordering\r\nbecomes more important so BJ-AC3X-DVO and BJ-AC3X-VMC perform better than BJ-AC3X-VFA.\r\nOnly the BJ-AC3X-VFA algorithm shows the significant (about three times) difference\r\nbetween performance for &quot;uniform&quot; and &quot;non-uniform&quot; types of CSP. This\r\nresult seems counterintuitive because one can expect that the algorithm that use\r\n&quot;smart&quot; variable ordering will take bigger advantage of the information about\r\nnon-uniformity of the constraint distribution.</p>\r\n\r\n<p ALIGN=\"JUSTIFY\">The main focus of this project is the analysis of the set of\r\ncorrelation matrixes. This set is presented in tables 2 &#150; 25. In these tables\r\n&quot;all&quot; means correlation matrixes over all instances, &quot;zeros&quot; means\r\ncorrelation matrixes over instances which are proved to have no solution and\r\n&quot;ones&quot; means correlation matrixes over instances which have at least one\r\nsolution. Remember that algorithms stop after the first solution is found or the absence\r\nof the solution is proved.</p>\r\n\r\n<p ALIGN=\"JUSTIFY\">Let&#146;s first address the question about the &quot;natural&quot;\r\ndifficulty of some instances inside the same type of CSP. There are some interesting\r\ntrends here. </p>\r\n\r\n<p ALIGN=\"JUSTIFY\">The first one is that for &quot;difficult&quot; types of CSP\r\n(50_3_380_1 and 30_6_151_10) the performance of all algorithms, except BJ-AC3X-VFA, is\r\nhighly correlated. One should not make the conclusion that for this type of CSP the\r\nvariable ordering is fully responsible for the performance. We can see that FC algorithms\r\nperform significantly worse than AC3X algorithms in these types of CSP. I would suggest\r\nthe interpretation that for these types of CSP there is a significant amount of instances\r\nwhere the &quot;smart&quot; variable ordering can detect a &quot;good&quot; ordering,\r\nwhich simultaneously improves performance of all nontrivial ordering algorithms.</p>\r\n\r\n<p ALIGN=\"JUSTIFY\">Another very interesting trend is that the correlation between\r\nBJ-AC3X-VFA and other AC3X algorithms is higher in the cases of non-uniformly distributed\r\nconstraints. For &quot;difficult&quot; types of CSP (50_3_380_1 and 30_6_151_10) the\r\ngrowth of the correlation is minimal. But for &quot;easy&quot; types of CSP (50_3_164_2\r\nand especially 50_3_92_2) the difference is very high. Maybe this type of correlation is\r\nconnected with the fact that BJ-AC3X-VFA for &quot;difficult&quot; types of CSP performs\r\nsignificantly better when constraints are distributed non-uniformly.</p>\r\n\r\n<p ALIGN=\"JUSTIFY\">Surprisingly enough, there is not so much difference between the set of\r\ncorrelation matrixes for problems where solution exists only, for problems where the\r\nabsence of the solution is proven only and for mixture of those problems. One interesting\r\nobservation can be made here. For difficult types of CSP, instances where no solution is\r\nproved are more time consuming for all algorithms (negative correlation between -0.2 and\r\n&#150;0.5). But for easy types of CSP the situation is more complicated. FC algorithms\r\nperform approximately the same way in solvable instance and in instances where no solution\r\nis proved. BJ-AC3X-DVO and BJ-AC3X-VMC perform significantly better in instances where no\r\nsolution is proved. While BJ-AC3X-VFA performs significantly better in instances where no\r\nsolution is proved only if constraints are distributed non-uniformly. In the case of\r\nuniformly distributed constraints there is no correlation between performance of\r\nBJ-AC3X-VFA and the existence of the solution.</p>\r\n\r\n<p ALIGN=\"JUSTIFY\">The last part of the statistical analysis deals with the correlation\r\nbetween the performance and different graph parameters. It would be really nice to be able\r\nto predict how difficult is each particular instance of CSP simply by analyzing the\r\nconstraint graph. Unfortunately, at least for the chosen set of graph parameters there is\r\nno significant correlation between any graph parameter and any algorithm. There is a small\r\ncorrelation between induced width and the performance of algorithms that use VMC (the\r\nmaximum cardinality variable ordering) at least for some types of CSP. One should expect\r\nit because VMC is closely connected with induced graph. But even this correlation is too\r\nsmall (non bigger than 0.3) to be used on practice. </p>\r\n</font><font FACE=\"Arial\"><b>\r\n\r\n<p ALIGN=\"JUSTIFY\">4. Conclusion </p>\r\n</b></font><font FACE=\"Arial\" SIZE=\"3\">\r\n\r\n<p ALIGN=\"JUSTIFY\">The obvious observation is that for these particular types of CSP the\r\nbest choice would be BJ_AC3X_VMC.</p>\r\n\r\n<p ALIGN=\"JUSTIFY\">Less trivial observation is that there are strong dependencies between\r\nperformance of different algorithms applied to the same CSP instances. And these\r\ndependencies change significantly when we change the set of generation parameters.</p>\r\n\r\n<p ALIGN=\"JUSTIFY\">The set of graph parameters introduced in this project is not suitable\r\nfor an advance prediction of the difficulty of some particular CSP instance inside the\r\nsame generation type. Three possible reasons could explain this fact. The first possible\r\nreason is that the author of this project is not lucky (or smart) enough to guess the\r\nright set of graph parameters. The second explanation is that the pairwise correlation\r\nbetween each particular parameter and performance is not enough and one should\r\nstatistically analyze the performance vs. the whole set of graph parameters\r\nsimultaneously. For example, the parity function could not be detected using pairwise\r\ncorrelation matrix. The last possible reason could be that it is impossible in principal\r\nto predict the &quot;hardness&quot; of some particular instance inside the same type of\r\nCSP before we solve it or prove the absence of the solution by some algorithm. </p>\r\n\r\n<p ALIGN=\"JUSTIFY\">&nbsp;</p>\r\n\r\n<p ALIGN=\"JUSTIFY\">&nbsp;</p>\r\n</font><font FACE=\"Arial\"><b>\r\n\r\n<p ALIGN=\"JUSTIFY\">5. References</p>\r\n\r\n<dir>\r\n  </b></font><font FACE=\"Arial\" SIZE=\"3\"><p ALIGN=\"JUSTIFY\">1. Daniel Frost, <a\r\n  HREF=\"http://www.ics.uci.edu/~csp/R69.ps\">&quot;Algorithms and\r\n  Heuristics for Constraint Satisfaction Problems.&quot;</a> Ph.D. thesis, ICS, UCI, October\r\n  1997.</p>\r\n  <p ALIGN=\"JUSTIFY\">2. Rina Dechter, &quot;Enhancement Schemes for Constraints Proceedings:\r\n  Backjumping, Learning and Cutset Decomposition&quot;, <i>Artificial Intelligence</i>\r\n  41:273-312. 1990</p>\r\n  <p ALIGN=\"JUSTIFY\">3. Peter Cheeseman, Bob Kanefsky, and William M. Taylor, &quot;Where\r\n  the <i>really</i> hard problems are&quot;, In <i>Proceedings of the International Joint\r\n  Conference on Artificial Intelligence, </i>pages 331-337, 1991</p>\r\n  <p ALIGN=\"JUSTIFY\">4. John G. Gaschnig, &quot;Performance Measurement and Analysis of\r\n  Certain Search Algorithms&quot;, Ph.D. thesis, Carnegie Mellon University, Pittsburgh, PA\r\n  15213, May 1979.</p>\r\n  <p ALIGN=\"JUSTIFY\">5. Daniel Frost and Rina Dechter, &quot;In search of the best\r\n  constraint satisfaction search&quot;, In <i>Proceedings of the Twelfth National Conference\r\n  on Artificial Intelligence, </i>pages 291-300, 1991</p>\r\n</dir>\r\n</font>\r\n\r\n<p ALIGN=\"JUSTIFY\"><font FACE=\"Arial\"><b>6. Appendix</b></font></p>\r\n\r\n<p ALIGN=\"JUSTIFY\"><a href=\"sazhin-275a-project-tables.html\">The set of tables 1-25 is\r\navailable in HTML format (It could be really slow)</a></p>\r\n\r\n<p ALIGN=\"JUSTIFY\">This project report is also available in MS Office (Word and Excel)\r\nformat. The tables look much better. Also printing is easy.<a\r\nhref=\"proj_report_sazhin_275A.zip\"> Download zip archive (42K)</a></p>\r\n</td></tr>\r\n</table>\r\n</center>\r\n\r\n<p>\r\n\r\n<!--- Begin Footer -->\r\n     <div id=\"footer\"><centeR>\r\n<A HREF=\"http://www.ics.uci.edu\">School of Information and Computer Science</A>\r\n<A HREF=\"http://www.uci.edu\">University of California, Irvine, CA 92697-3435</a>\r\n<A HREF=\"http://www.ics.uci.edu/~dechter\">Dr. Rina Dechter</A>\n\r\n<A HREF=\"mailto:dechter_at_ics.uci.edu\">dechter at ics.uci.edu</A>\r\n\n</center></div>\r\n<!--- End Footer -->\r\n\r\n\r\n</body>\r\n</html>\r\n", "encoding": "ascii"}