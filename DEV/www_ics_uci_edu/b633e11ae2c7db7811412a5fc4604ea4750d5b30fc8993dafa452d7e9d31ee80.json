{"url": "https://www.ics.uci.edu/~eppstein/161/960208.html", "content": "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 3.2//EN\">\n<html>\n<head>\n<title>Shortest paths and topological ordering</title>\n<meta name=\"Owner\" value=\"eppstein\">\n<meta name=\"Reply-To\" value=\"eppstein@ics.uci.edu\">\n</head>\n<body>\n<h1>ICS 161: Design and Analysis of Algorithms<br>\nLecture notes for February 8, 1996</h1>\n\n<!--#config timefmt=\"%d %h %Y, %T %Z\" -->\n<hr>\n<p></p>\n\n<h1>Shortest Paths</h1>\n\nThe basic problem: Find the \"best\" way of getting from s to t where\ns and t are vertices in a graph. We measure \"best\" simply as the\nsum of edge lengths of a path. For instance the graph could be a\nmap representing intersections as vertices, road segments as edges;\nyou want to find either the shortest or fastest route from your\nhouse to ICS. Although both of these problems have different\nsolutions, they are both shortest path problems; in one the length\nof an edge represents the actual mileage of a segment of road,\nwhile in the other it represents the time it would take to drive\nit, but in both cases the important fact is that the total length\nof a path is measured by adding the lengths of individual edges.\nFor another example, which I mentioned in my first lecture on graph\nalgorithms, the graph might have vertices representing airports,\nwith edges representing possible flights, and the \"length\" of an\nedge measuring the cost of taking that flight; your problem would\nthen be to find the cheapest flight from e.g. SNA to JFK. Note that\nthese graphs may be directed; e.g. there may be a one-way road, or\nflights in one direction might have different costs than those the\nother way. \n\n<p>We are going to make a big assumption: that all the edges have\nlengths that are positive numbers. This is often but not always the\ncase; it makes sense in the examples above, but it is conceivable\nthat an airline could pay people to take certain routes, so that\nthe lengths of those edges in the airport graph might be negative.\nWe'll pretend this never happens. It makes the algorithms a lot\neasier. Later we'll see some special cases where we can handle\nnegative weights.</p>\n\n<p><a name=\"sssp\">Rather than computing one distance d(s,t), we'll\ncompute d(s,x) for all vertices x. This is known as the <i>single\nsource shortest path problem</i> (s is the <i>source</i>). It turns\nout that computing this extra information makes things easier,\nbecause then we can put together information about paths with fewer\nedges to get paths with more edges.</a></p>\n\n<h2>Paths from distances</h2>\n\nSuppose we already know the distances d(s,x) from s to every other\nvertices. This isn't a solution to the shortest path problem,\nbecause we want to know actual paths having those distances. How\ncan we find those paths? That there are two kinds of shortest\npaths: those formed by a single edge (s,t), and those in which the\npath from s to t goes through some other vertices; let's say x is\nthe last vertex the path goes through before t. Then in the second\ncase, the overall path must be formed by concatenating a path from\ns to x with edge (x,t). (We can view both types of shortest path as\nbeing similar if we think of the shortest path from s to s as being\none with no edges in it.) Further, the path from s to x must itself\nbe a shortest path (since otherwise concatenating the shortest path\nwith (x,t) would decrease the length of the overall path). A final\nobservation is that d(s,x) must be less than d(s,t), since\nd(s,x)=d(s,t)+length(x,t) and we are assuming all edges have\npositive length. \n\n<p>Therefore if we only know the correct value of x we can find a\nshortest path:</p>\n\n<p><b>Algorithm 1:</b></p>\n\n<pre>\n    for each vertex y in sorted order by d(s,y)\n    let (x,y) be an edge with d(s,x)+length(x,y)=d(s,y)\n    path(s,y) = path(s,x) + edge (x,y)\n</pre>\n\nWe will want to use something like this idea to compute shortest\npaths without already knowing their lengths. When we get to y in\nthe loop, it will still be ok to use terms like d(s,x) if this is\nless than d(s,y), because we will have already processed x in a\nprevious iteration. But the pseudo-code above uses d(s,y) itself\ntwice, and this will not work as well. \n\n<p>To get rid of the second use of d(s,y), in which we test to\ndetermine which edge to use, we can notice that (because we are\ncomputing a shortest path) d(s,x)+length(x,y) will be less than any\nsimilar expression, so instead of testing it for equality with\nd(s,y) we can just find a minimum:</p>\n\n<p><b>Algorithm 2:</b></p>\n\n<pre>\n    for each vertex y in sorted order by d(s,y)\n    let (x,y) be an edge with x already processed,\n        minimizing d(s,x)+length(x,y)\n    path(s,y) = path(s,x) + edge (x,y)\n    d(s,y) = d(s,x) + length(x,y)\n</pre>\n\n<h2>Dijkstra's algorithm</h2>\n\nThe only remaining use of d(s,y) in this algorithm is to determine\nwhat order to process the vertices in. <i><a href= \n\"people.html#dijkstra\">Dijkstra</a>'s algorithm</i> for shortest\npaths does this almost exactly like <a href=\"960206.html#prim\">\nPrim's algorithm</a>. Remember that in Prim's algorithm, we add\nvertices and edges one a a time to a tree, at each step choosing\nthe shortest possible edge to add. Dijkstra's algorithm does the\nsame thing, only choosing the edge to add at each step to be the\none minimizing d(s,x)+length(x,y). \n\n<p><b>Algorithm 3:</b> (Dijkstra, basic outline)</p>\n\n<pre>\n    let T be a single vertex s\n    while (T has fewer than n vertices)\n    {\n    find edge (x,y)\n        with x in T and y not in T\n        minimizing d(s,x)+length(x,y)\n    add (x,y) to T\n    d(s,y)=d(s,x)+length(x,y)\n    }\n</pre>\n\n<p>The actual shortest paths can be found by following the path in\nT from s to t. This defines a structure known as a \"shortest path\ntree\". In practice it may sometimes faster to build two trees, one\nfrom s and one from t, and stop when they run into each other (this\nusually ends up visiting less of the graph).</p>\n\n<p>Just like with Prim's algorithm, we can use heaps to perform the\nhard part of each iteration (finding the best edge) in logarithmic\ntime.</p>\n\n<p><b>Algorithm 4:</b> (Dijkstra with heaps)</p>\n\n<pre>\n    make a heap of values (vertex,edge,distance)\n    initially (v,-,infinity) for each vertex\n    let tree T be empty\n    while (T has fewer than n vertices)\n    {\n    let (v,e,d(v)) have the smallest weight in the heap\n    remove (v,e,d(v)) from the heap\n    add v and e to T\n    set distance(s,v) to d(v)\n    for each edge f=(v,u)\n        if u is not already in T\n        find value (u,g,d(u)) in heap\n        if d(v)+length(f) &lt; d(g)\n            replace (u,g,d(g)) with (u,f,d(v)+length(f))\n    }\n</pre>\n\nJust as in Prim's algorithm, this runs in time O(m log n) if you\nuse binary heaps, or O(m + n log n) if you use Fibonacci heaps. \n\n<h2>Dijkstra and negative lengths</h2>\n\nDijkstra's algorithm does not work with negative edge weights. For\ninstance, consider the following graph (assume the edges are all\ndirected from left to right): \n\n<pre>\n       2\n    A-----B\n     \\   /\n    3 \\ / -2\n       C\n</pre>\n\nIf we start with A, Dijkstra's algorithm will choose the edge (A,x)\nminimizing d(A,A)+length(edge), namely (A,B). It then sets d(A,B)=2\nand chooses another edge (y,C) minimizing d(A,y)+d(y,C); the only\nchoice is (A,C) and it sets d(A,C)=3. But it never finds the\nshortest path from A to B, via C, with total length 1. \n\n<h2>Topological ordering and shortest paths</h2>\n\nThere is an important class of graphs in which shortest paths can\nbe computed more quickly, in linear time. The idea is to go back to\nalgorithms 1 and 2, which required you to visit the vertices in\nsome order. In those algorithms we defined the order to be sorted\nby distance from s, which as we have seen works for positive weight\nedges, but not if there are negative weights. <a name=\"topo\">Here's\nanother ordering that always works: define a <i>topological\nordering</i> of a directed graph to be one in which, whenever we\nhave an edge from x to y, the ordering visits x before y.</a> If we\ncan define such an ordering, then we can do something like\nalgorithm 2, and be sure that the predecessor of a vertex x is\nalways processed before we process x itself. \n\n<p><b>Algorithm 5:</b> (shortest paths from topological order)</p>\n\n<pre>\n    for each vertex y in a topological ordering of G\n    choose edge (x,y) minimizing d(s,x)+length(x,y)\n    path(s,y) = path(s,x) + edge (x,y)\n    d(s,y) = d(s,x) + length(x,y)\n</pre>\n\n<a name=\"long\">This runs in linear time (with the possible\nexception of finding the ordering), and works even when the graph\nhas negative length edges. You can even use it to find longest\npaths: just negate the lengths of all the edges. The only catch is\nthat it only works when we can find a topological ordering.</a> \n\n<h2>Topological ordering and acyclic graphs</h2>\n\nDefine a <i>directed acyclic graph</i> (often known as a DAG for\nshort) to be a directed graph, containing no cycle (a cycle is a\nset of edges forming a loop, and all pointing the same way around\nthe loop). \n\n<p>Theorem: a graph has a topological ordering if and only if it is\na directed acyclic graph.</p>\n\n<p>One direction of the proof is simple: suppose G is not a DAG, so\nit has a cycle. In any ordering of G, one vertex of the cycle has\nto come first, but then one of the two cycle edges at that vertex\nwould point the wrong way for the ordering to be topological. In\nthe other direction, we have to prove that every graph without a\ntopological ordering contains a cycle. We'll prove this by finding\nan algorithm for constructing topological orderings; if the\nalgorithm ever gets stuck we'll be able to use that information to\nfind a cycle.</p>\n\n<p><b>Algorithm 6:</b> (topological ordering)</p>\n\n<pre>\n    list L = empty\n    while (G is not empty)\n    find a vertex v with no incoming edges\n    delete v from G\n    add v to L\n</pre>\n\nIf this algorithm terminates, L is a topological ordering, since we\nonly add a vertex v when all its incoming edges have been deleted,\nat which point we know its predecessors are already all in the\nlist. \n\n<p>What if it doesn't terminate? The only thing that could go wrong\nis that we could be unable to find a vertex with no incoming edges.\nIn this case all vertices have some incoming edge. We want to prove\nthat in this case, G has a cycle. Start with any vertex s, follow\nits incoming edge backwards to another vertex t, follow its\nincoming edge backwards again, and so on, building a chain of\nvertices ...w-&gt;v-&gt;u-&gt;t-&gt;s.</p>\n\n<p>We can keep stepping backwards like this forever, but there's\nonly a finite number of vertices in the graph. Therefore, we'll\neventually run into a vertex we've seen before:\nu-&gt;w-&gt;v-&gt;u-&gt;t-&gt;s. In this case, u-&gt;w-&gt;v-&gt;u\nis a directed cycle. This procedure always finds a directed cycle\nwhenever algorithm 6 gets stuck, completing the proof of the\ntheorem that a graph has a topological ordering if and only if it\nis a DAG. Incidentally this also proves that algorithm 6 finds a\ntopological ordering whenever one exists, and that we can use\nalgorithm 6 to test whether a graph is a DAG. Putting algorithm 6\ntogether with the \"stepping backwards\" procedure provides a fast\nmethod of finding cycles in graphs that are not DAGs.</p>\n\n<p>Finally, let's analyze the topological ordering algorithm. The\nkey step (finding a vertex without incoming edges) seems to require\nscanning the whole graph, but we can speed it up with some really\nsimple data structures: a count I[v] of the number of edges\nincoming to v, and a list K of vertices without incoming edges.</p>\n\n<p><b>Algorithm 7:</b> (topological ordering, detailed\nimplementation)</p>\n\n<pre>\n    list K = empty\n    list L = empty\n    for each vertex v in G\n    let I[v] = number of incoming edges to v\n    if (I[v] = 0) add v to K\n    while (G is not empty)\n    remove a vertex v from K\n    for each outgoing edge (v,w)\n    decrement I[w]\n    if (I[w] = 0) add w to K\n    add v to L\n</pre>\n\nIt is not hard to see that this algorithm runs in linear time, so\ncombining it with algorithm 5 we see that we can find shortest\npaths in DAGs in linear time. \n\n<hr>\n<p><a href=\"/~eppstein/161/\">ICS 161</a> -- <a href=\"/\">Dept.\nInformation &amp; Computer Science</a> -- <a href= \n\"http://www.uci.edu/\">UC Irvine</a><br>\n<small>Last update: \n<!--#flastmod file=\"960208.html\" --></small></p>\n</body>\n</html>\n\n", "encoding": "ascii"}