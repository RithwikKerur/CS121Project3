{"url": "https://www.ics.uci.edu/~theory/269/980515.html", "content": "<!DOCTYPE html PUBLIC \"-//IETF//DTD HTML 2.0//EN\">\n<html>\n<head>\n<title>Theory Seminar, 15 May 1998</title>\n<meta name=\"Owner\" value=\"eppstein\">\n<meta name=\"Reply-To\" value=\"eppstein@ics.uci.edu\">\n</head>\n<body>\n<a href=\"/~theory/\"><img src=\"/~theory/logo/shortTheory.gif\" width= \n\"521\" height=\"82\" border=\"0\" alt=\"ICS Theory Group\"></a> \n\n<h1>ICS 269, Spring 1998: Theory Seminar</h1>\n\n<hr>\n<h2>15 May 1998:<br>\nMachine Learning of Classifications via Generalized Linear\nModels<br>\nKent Martin, ICS, UC Irvine</h2>\n\n<p>We describe a general-purpose classification learning algorithm\nbased on Generalized Linear Models, and evaluate that algorithm\n(GLOREAL, the Generalized Logistic Regression Algorithmic Learner)\nas a competitor to ordinary decision tree learners such as C4.5.\nGLOREAL is based on a generalization of logistic regression and it\nalso uses some non-conventional methods for model selection that\nare adapted from other work at the interface of machine learning\nand statistics. Empirical results show that GLOREAL is 4-5% more\naccurate than C4.5 on the average. GLOREAL's success is due in part\nto learning and aggregating multiple classifiers for a problem,\nwhich is more effective in GLOREAL than it is in bagging decision\ntrees. Another important factor in GLOREAL's success is that it has\na richer and more effective representation language than ordinary\ndecision tree learners, particularly with regard to numeric\nattributes.</p>\n</body>\n</html>\n\n", "encoding": "ascii"}