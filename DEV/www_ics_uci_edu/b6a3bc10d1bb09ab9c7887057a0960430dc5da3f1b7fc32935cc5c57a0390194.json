{"url": "https://www.ics.uci.edu/~yamingy/bayesD_cocktail.r", "content": "#    paper:  On a multiplicative algorithm for computing Bayesian D-optimal designs\n#  contact:  Yaming Yu, Department of Statistics, UC Irvine \n#  \n#  w=bayesD(A, prior, maxiter, small, alpha, alg)\n#  \n#  required input\n#    A: r by n by m by m array of information matrices\n#    (r: number of support points of the prior pi(theta) \n#    (n: number of design points)\n#    (m: dimension of parameter)\n#    prior: 1 by r, weights on the information matrices \n#  \n#  optional input \n#    maxiter: maximum number of iterations (default=1000)\n#    small: convergence threshold (default=1e-5)\n#    alpha: overrelaxation parameter (default=0, no overrelaxation) \n#    alg: choice of algorithm (default=1, cocktail algorithm) \n#  \n#  output\n#    w: optimal weights (1 by n)\n\nderi=function(d, M, diff, prior, ord=1){\n  ## calculating derivatives needed in the Newton line search \n  r=dim(M)[1];\n  output=c(0,0); \n  for(i in 1:r){\n    P=solve(as.matrix(M[i,,]+d*diff[i,,]));\n    mat=P%*%as.matrix(diff[i,,]);\n    output[1]=output[1] + sum(diag(mat))*prior[i]; \n    if(ord==2)\n      output[2]=output[2] + sum(diag(mat%*%mat))*prior[i]; \n  }\n  output; \n} \n\nbayesD=function(A, prior, maxiter=1000, small=1e-5, alpha=0, alg=1){\n  if(alg==0)\n    print(\"Using the multiplicative algorithm only\");\n  if(alg==1){\n    print(\"Using the cocktail algorithm:\"); \n    print(\"VDM + nearest neighbor exchange + multiplicative algorithm\"); \n  }\n  r=dim(A)[1];\n  n=dim(A)[2];\n  m=dim(A)[3];\n  w=1:n; \n  if(alg>=1){\n    w[]=0;\n    w[floor(runif(m*2, 0, 1)*n)+1]=1;\n  }\n  w[w>0]=1/sum(w>0); ## starting design\n  index=1:n;\n  M=array(dim=c(r, m, m));\n\n  for(k in 1:maxiter){\n    ind=index[w>0];\n    for(i in 1:r){\n      M[i,,]=0\n      for(j in 1:length(ind))  \n        M[i,,]=M[i,,]+w[ind[j]]*A[i,ind[j],,];\n    }\n    lam=rep(0, n);\n    for(i in 1:r){ \n      P=solve(as.matrix(M[i,,])); \n      for(j in 1:n)\n        lam[j]=lam[j]+sum(diag(P%*%as.matrix(A[i,j,,])))*prior[i]; \n    }\n    tmp=max(lam);\n    if(tmp<m+small) ## testing convergence\n      break; \n\n    if(alg>=1){ ## VDM step\n      j2=max(index[tmp==lam]);\n      diff=A[,j2,,]-M[,,]; \n      out=deri(0, M, diff, prior, 2); \n      d=out[1]/(out[2]+1e-100);\n      d=min(1, max(0, d)); \n      while(deri(d, M, diff, prior)[1]<0)\n        d=0.5*d; \n      w=(1-d)*w;\n      w[j2]=w[j2]+d;\n      M=M+d*diff; \n\n      ind=index[w>0];\n      for(j in 1:(length(ind)-1)){ ## nearest neighbor exchanges\n        j1=ind[j];\n        j2=ind[j+1];\n        diff=A[,j1,,]-A[,j2,,];\n        out=deri(0, M, diff, prior, 2);\n        d=out[1]/(out[2]+1e-100);\n        d=min(w[j2], max(-w[j1], d));\n        while(d*deri(d, M, diff, prior)[1]<0)\n          d=0.5*d;\n        w[j1]=w[j1]+d;\n        w[j2]=w[j2]-d;\n        M=M+d*diff; \n      }\n    } \n\n    if(alg==0){ ## multiplicative step\n      a=alpha*min(lam[ind])/2;\n      w[ind]=w[ind]*(lam[ind]-a)/(m-a);\n    }\n    if(alg>=1){ ## multiplicative step\n      ind=index[w>0];\n      lam=rep(0,length(ind));\n      for(i in 1:r){ \n        P=solve(as.matrix(M[i,,]));\n        for(j in 1:length(ind))\n          lam[j]=lam[j]+sum(diag(P%*%as.matrix(A[i,ind[j],,])))*prior[i]; \n      }\n      a=alpha*min(lam)/2; \n      w[ind]=w[ind]*(lam-a)/(m-a); \n    }\n    w[ind]=w[ind]/sum(w[ind]); ## redundant (numerical safeguard)\n  } ## end for\n\n  if(k==maxiter){\n    print(\"No convergence in\");\n    print(maxiter);\n    print(\"iterations\");\n  }else{\n    print(\"Convergence in\");\n    print(k);\n    print(\"iterations\");\n  } \n  w; ## optimal weights (output)\n} \n\n", "encoding": "ascii"}