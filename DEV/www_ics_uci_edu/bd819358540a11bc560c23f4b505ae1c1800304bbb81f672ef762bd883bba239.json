{"url": "https://www.ics.uci.edu/~pattis/ICS-46/lectures/notes/ProblemSolving2.txt", "content": "\t\tProblem Solving with State-Space Seaching\r\n\r\n\r\nIntroduction: \r\n\r\nIn the this lecture as in the previous one, we will look at how to think about\r\nsolving certain kinds of problems on computers, by thinking about finding their\r\nsolutions as the process of searching through trees. In this lecture we will\r\nlook at problem solving using \"breadth-first search\" and a new variant of\r\n\"depth first search\" (i.e, not pre-/in-post-order) called \"best-first search\".\r\nThe queue and priority queue collections respectively play major roles in each\r\nof these search orders. They don't use recursion/stacks but do use queues and\r\npriority queues, which can add/remove values from the type, and check whether\r\na variable of that type is empty.\r\n\r\nAgain, no tree gets constructed explicitly (no new TN() statements will appear\r\nin any code), but the order in which the nodes are examined can be nicely\r\nvisualized as a tree, whose nodes are searched until a solution is found (or\r\nuntil the code discovers that no solution is possible).\r\n\r\n\r\nWater Jug Problems:\r\n\r\nTo be concrete, we will start by describing a schema for Water Jug problems, to\r\nhelp us learn the right terminology. One example of a Water Jug problem is as\r\nfollows.\r\n\r\n  We have three jugs (call them j1, j2, and j3) with capacities 3, 5, and 8\r\n  gallons respectively. At the start, j1 and j2 are empty and j3 is filled\r\n  (with 8 gallons). We can pour liquid from one jug into another according to\r\n  the following rules: once we start pouring, we must empty the jug we are\r\n  pouring FROM, except we can never overflow the jug we are pouring INTO (so we\r\n  stop either when the FROM jug is empty or the TO jug is filled, whichever\r\n  comes first). We want to discover a sequence of pouring operations (from\r\n  various jugs into other various jugs, according the pouring rules) such that\r\n  eventually j1 is empty and j2 and j3 each contain 4 gallons.\r\n\r\nSo, the rules say that if we start pouring from j3 to j1, we must stop when\r\nj1 has 3 gallons (it cannot overflow) so j3 has 5 gallons remaining. If we then\r\nstart pouring j1 into j2 we must pour all 3 gallons, so j1 will contain 0\r\ngallons and j2 will contain 3 gallons. If we then start pouring j3 into j2 we\r\nmust stop when j2 has 5 gallons (it cannot overflow) so j3 has 3 gallons\r\nremaining.\r\n\r\nIn this formulation of the Water Jugs problem, water is conserved: we can \r\nneither pour water onto the ground (removing it from the system) or put water\r\ninto a jug from the tap (adding it to the system). In other versions of this\r\nproblem we can empty a jug onto the ground or fill a jug from the tap.\r\n\r\nNote: Students have been telling me for a few quarters that one of of the Die\r\nHard movies involved a water jugs problem (2 jugs, 3 and 5, where the solution\r\nrequires one jug with 4 gallons; this is a non-conserved problem: the water\r\njugs are empty and can be filled from a tap and emptied on the ground). Here is\r\na link to the the video:\r\n\r\n  https://www.youtube.com/watch?v=6cAbgAaEOVE\r\n\r\n\r\nGeneral State-Space Search Problems:\r\n\r\nNow let's describe this problem as a general state-space search problem.\r\n\r\nFirst, the salient information about the current state of the problem is how\r\nmany gallons of water each jug currently holds. We call such a description a\r\nSTATE and can think of describing a state simply as a triple of numbers:\r\n(j1,j2,j3). So (2,4,2) represents the state where j1 contains 2 gallons, j2\r\ncontains 4 gallons, and j3 contains 2 gallons. \r\n\r\nBesides calling (2,4,2) a state, we can also call it a point in the space of\r\nall possible states. We can think of this space as a subset of points in\r\n3-dimensional space: first, it includes only those points whose coordinates are\r\nintegers; second the sum of the values of the coordinates must always be 8\r\n(because water is conserved). Together, these points specify all possible\r\nstates for the JUGS and are collectively called the STATE-SPACE of the problem. \r\n\r\nWe also specified a START and STOP state (point in state-space): in the\r\nproblem above, the start state is (0,0,8) and the stop state is (0,4,4).\r\nSometimes we want to allow more than one stop state: in such cases we can\r\neither specify them individually as a set, or via a boolean function:\r\nis_stop_state would take a state as a parameter and it returns whether or not\r\nit is a stop state.\r\n\r\nFinally, we described OPERATORS that we can apply to any state, each of which\r\ntransforms one state into another state (or think of an operator moving us from\r\none point to another point in the state-space). We saw that the \"pour j3 into\r\nj1\" operator, when applied to state (0,0,8) transforms it into state (3,0,5).\r\nLikewise, if we applied the \"pour j3 into j1\" operator to state (2,3,3) it\r\nwould transform it to the state (3,3,2), because j1 already holds 2 gallons\r\nand can hold a maximum of 3 gallons, so j3 is reduced by exactly 1 gallon.\r\n\r\nGenerally, a solution to a state-space search problem is a sequence of\r\noperators that transforms the start state into the stop state by applying\r\none operator at a time, hopping from state to state (point to point in\r\nstate-space) in the order specified by the sequence. We would like to find\r\nthe shortest solution (measured by number of operators) and we would like to\r\nfind that solution quickly (examining few operators not on the solution path).\r\n\r\n\r\nSolving a State-Space problem as Tree Searching:\r\n\r\nWe will label every node in a tree with some state, and label every edge from a\r\nparent to a child with an operator that transforms the parent state into the\r\nchild state.\r\n\r\nPicture the start state as the root of a tree. Each node (including the root)\r\nhas a child for each operator. The state at the child is the state resulting\r\nfrom the operator tranforming the parent state into the child state. So, the\r\nsolution to a state-space problem is a path from the root of the tree downward\r\nto the stop state: the result of applying that sequence of operators on the\r\nstart state, leading to the stop state.\r\n\r\nAgain, we use the term \"combinatorial searching\" to characterize this approach\r\nto solving these problems, because we search through all possible combinations\r\nof operators. If we drew out complete search trees, we would generate a\r\ntremendous number of nodes (this is called the \"combinatorial explosion\"). If\r\nthe tree represents the result of C operators for each node/state, and it\r\ntakes N operators to solve the problem (the stop state is at a depth of N) the\r\ntree can  have up to C^N nodes at depth N. So even if C is small, say 2, a\r\nproblem that requires 10 operators can lead to a search tree with 1,000 leaf\r\nnodes; a problem requiring a solution with twice as many operators (20) can\r\nlead to a search tree with 1,000,000 leaf nodes.\r\n\r\nSo, in the case of the water jugs problem above. The root of the tree is the\r\nstart state (0,0,8). There are 6 operators available at each state: j1->j2\r\n(which abbreviates \"pour j1 into j2\"), j2->j1, j1->j3, j3->j1, j2->j3, and\r\nj3->j2; note that for each operators ja->jb there is also the reverse operator\r\njb->ja, so there are always an even number of operators.\r\n\r\nSo, we will show all the states at depth 1 reachable from the start state (at\r\ndepth 0) by applying one operator as\r\n\t\t\t\t(0,0,8)\r\n      /             /           /          \\             \\           \\\r\n   j1->j2       j2->j1       j1->j3      j3->j1        j2->j3       j3->j2  \r\n  (0,0,8)       (0,0,8)      (0,0,8)     (3,0,5)       (0,0,8)     (0,5,3)\r\n\r\nNow, the searching algorithm implemented in code at the end of this lecture\r\nkeeps track of which states have already been reached (think of this for now\r\nas a set; it is really a map where the value associated with each reached state\r\nis the sequence of operators it takes to get there, where the sequence is empty\r\nfor the root). Lots of operators, when applied to this start state, transform\r\nthe start state into the same start state (pouring from j1 to j2 does nothing\r\nbecause j1 has not water in it) so we don't have to continue exploring the\r\nsubtrees of those states: only the operators labelled j3->j1 and j3->j2 change\r\nthe state. For simplicity we will redraw the tree below, omitting any node\r\nwhose state is the same as the start (root's) state.\r\n\r\n\t\t\t\t   (0,0,8)\r\n                    /                                    \\\r\n                 j3->j1                                j3->j2  \r\n                (3,0,5)                                (0,5,3)\r\n\r\nSo, we can get to the new states (3,0,5) and (0,5,3) from the start state by\r\napplying one operator.\r\n\r\nNext, we will show all the states at depth 2 reachable from the new states (at\r\ndepth 1) by applying one operator. Here again we don't show any operators that\r\nlead to states that are already in the tree.\r\n\r\n\t\t\t\t   (0,0,8)\r\n                    /                                    \\\r\n                 j3->j1                                j3->j2  \r\n                (3,0,5)                                (0,5,3)\r\n           /              \\                               |\r\n        j1->j2           j3->j2p                       j2->j1\r\n        (0,3,5)          (3,5,0)                       (3,2,3)\r\n\r\nNote in the subtree of the (3,0,5) node, j2->j1 transforms to (3,0,5) which is\r\nthe same as its parent state (because j2 is empty); j1->j3 transforms to(0,0,8)\r\nwhich we already saw at depth 0; j3->j1 transforms to (3,0,5) which is the same\r\nas its parent state (because j1 is already filled); j2->j3 is (3,0,5) which is\r\nthe same as its parent state (because j2 is empty). So only j1->j2 and j3->j2\r\ntransform the parent node (3,0,5) to a state tht does not already label a node\r\nin the tree.\r\n\r\nWe can likewise discover that only j2->j1 transforms the parent node (0,5,3) to\r\na state that does not already label a node in the tree: j3->j2 in the right\r\nsubtree transforms (0,5,3) to (3,5,0) which already is the leftmost node at\r\ndepth 2\r\n\r\nSo, we can get to the new states (0,3,5), (3,5,0), and (3,2,3) from the start\r\nstate by applying two operators.\r\n\r\nNext, we will show all the states at depth 3 reachable from the new states (at\r\ndepth 2) by applying one operator. Here again we don't show any operators that\r\nlead to states that are already in the tree.\r\n\r\n\t\t\t\t   (0,0,8)\r\n                    /                                    \\\r\n                 j3->j1                                j3->j2  \r\n                (3,0,5)                                (0,5,3)\r\n           /              \\                               |\r\n        j1->j2           j3->j2p                       j2->j1\r\n        (0,3,5)          (3,5,0)                       (3,2,3)\r\n          |                                               |\r\n        j3->j1     no operators lead to                j1->j3           \r\n        (3,3,2)  any new states: noltans               (0,2,6)\r\n\r\nSo, we can get to the new states (3,3,2) and (0,2,6) from the start state by\r\napplying three operators.\r\n\r\nNext, we will show all the states at depth 4 reachable from the new states (at\r\ndepth 3) by applying one operator. Here again we don't show any operators that\r\nlead to states that are already in the tree.\r\n\r\n\t\t\t\t   (0,0,8)\r\n                    /                                    \\\r\n                 j3->j1                                j3->j2  \r\n                (3,0,5)                                (0,5,3)\r\n           /              \\                               |\r\n        j1->j2           j3->j2p                       j2->j1\r\n        (0,3,5)          (3,5,0)                       (3,2,3)\r\n          |                                               |\r\n        j3->j1      no operators lead                  j1->j3           \r\n        (3,3,2)     to any new states                  (0,2,6)\r\n          |                                               |\r\n        j1->j2                                         j2->j1\r\n        (1,5,2)                                        (2,0,6)\r\n\r\nSo, we can get to the new states (1,5,2) and (2,0,6) from the start state by\r\napplying four operators.\r\n\r\nNext, we will show all the states at depth 5 reachable from the new states (at\r\ndepth 4) by applying one operator. Here again we don't show any operators that\r\nlead to states that are already in the tree.\r\n\r\n\t\t\t\t   (0,0,8)\r\n                    /                                    \\\r\n                 j3->j1                                j3->j2  \r\n                (3,0,5)                                (0,5,3)\r\n           /              \\                               |\r\n        j1->j2           j3->j2p                       j2->j1\r\n        (0,3,5)          (3,5,0)                       (3,2,3)\r\n          |                                               |\r\n        j3->j1      no operators lead                  j1->j3           \r\n        (3,3,2)     to any new states                  (0,2,6)\r\n          |                                               |\r\n        j1->j2                                         j2->j1\r\n        (1,5,2)                                        (2,0,6)\r\n       /      \\                                           |\r\n    j1->j3   j2->j3                                    j3->j2    \r\n   (0,5,3)  (1,0,7)                                    (2,5,1)\r\n\r\nSo, we can get to the new states (0,5,3), (1,0,7), and (2,5,1) from the start\r\nstate by applying five operators.\r\n\r\nNext, we will show all the states at depth 6 reachable from the new states (at\r\ndepth 5) by applying one operator. Here again we don't show any operators that\r\nlead to states that are already in the tree.\r\n\r\n\t\t\t\t   (0,0,8)\r\n                    /                                    \\\r\n                 j3->j1                                j3->j2  \r\n                (3,0,5)                                (0,5,3)\r\n           /              \\                               |\r\n        j1->j2           j3->j2p                       j2->j1\r\n        (0,3,5)          (3,5,0)                       (3,2,3)\r\n          |                                               |\r\n        j3->j1      no operators lead                  j1->j3           \r\n        (3,3,2)     to any new states                  (0,2,6)\r\n          |           (noltans)                           |\r\n        j1->j2                                         j2->j1\r\n        (1,5,2)                                        (2,0,6)\r\n      /        \\                                          |\r\n   j1->j3    j2->j3                                   j3->j2    \r\n  (0,5,3)   (1,0,7)                                   (2,5,1)\r\n               |                                         |\r\n  noltans   j1->j2                                    j2->j1   \r\n            (0,1,7)                                   (3,4,1)  \r\n\r\nSo, we can get to the new states (0,1,7) and (3,4,1) from the start state by\r\napplying six operators.\r\n\r\nNext, we will show all the states at depth 7 reachable from the new states (at\r\ndepth 6) by applying one operator as. Here we don't show any operators that\r\nlead to states that are already in the tree.\r\n\r\n\t\t\t\t   (0,0,8)\r\n                    /                                    \\\r\n                 j3->j1                                j3->j2  \r\n                (3,0,5)                                (0,5,3)\r\n           /              \\                               |\r\n        j1->j2           j3->j2p                       j2->j1\r\n        (0,3,5)          (3,5,0)                       (3,2,3)\r\n          |                                               |\r\n        j3->j1      no operators lead                  j1->j3           \r\n        (3,3,2)     to any new states                  (0,2,6)\r\n          |           (noltans)                           |\r\n        j1->j2                                         j2->j1\r\n        (1,5,2)                                        (2,0,6)\r\n      /        \\                                          |\r\n   j1->j3    j2->j3                                    j3->j2    \r\n  (0,5,3)   (1,0,7)                                    (2,5,1)\r\n               |                                          |\r\n  noltans   j1->j2                                     j2->j1   \r\n            (0,1,7)                                    (3,4,1)  \r\n               |                                         |\r\n            j3->j1                                     j1->j3\r\n            (3,1,4)                                    (0,4,4)\r\n\r\nSo, we can get to the new states (3,1,4) and (0,4,4) from the start state by\r\napplying seven operators.\r\n\r\nBut (0,4,4) is the stop state! We have solved the problem as illustrated below\r\n(this output is what my program produces, listing all the operators from the\r\nroot to the solution leaft in order (and showing the state at every depth).\r\n\r\n  Jugs[0,0,8]: Starting State\r\n  Jugs[0,5,3]: Transfer from jug 3 to jug 2\r\n  Jugs[3,2,3]: Transfer from jug 2 to jug 1\r\n  Jugs[0,2,6]: Transfer from jug 1 to jug 3\r\n  Jugs[2,0,6]: Transfer from jug 2 to jug 1\r\n  Jugs[2,5,1]: Transfer from jug 3 to jug 2\r\n  Jugs[3,4,1]: Transfer from jug 2 to jug 1\r\n  Jugs[0,4,4]: Transfer from jug 1 to jug 3\r\n  Jugs[0,4,4]: Final State\r\n\r\nSo, by doing a breadth-first search of the tree, we examined all the states we\r\ncould reach by applying 1 operator, then by applying 2 operators, etc. until we\r\nreached the stop state. Thus, if a solution exist we will always find the\r\nshortest sequence of operators that lead to it (before examining any nodes at\r\ndepth n, we have examined all nodes at depth n-1).\r\n\r\nWe use a queue to perform this breadth-first search. Initially we add the start\r\nstate to the queue, and whenever we remove a state from the queue, we apply\r\nall the operators to it (generating more states) and put those states back in\r\nthe queue (if we have not already put them in the queue: every state that is\r\nadded to the queue also is put into a map -its associated value is the sequence\r\nof operators that were applied to the start state to get to the key state-\r\nwhich we can get to see if it is present.\r\n\r\nIf a solution doesn't exist at all (imagine what would happen if the stop state\r\nwere (0,4,5)) this process would eventually lead to leaf nodes that are all\r\nlabelled noltans: operators transform their states only to states already in\r\nthe tree, so there are no new states to examine, and the program realizes\r\nthere is no solution. Because the state-space is finite, this process will\r\neventually yield and answer or realize that no answer is possible.\r\n\r\n\r\nThe 15s Puzzle:\r\n\r\nAnother problem solvable by state-space searching is the 15s puzzle (really\r\na generalization of the N^2-1 puzzle). The puzzle's state is given by a 4x4\r\nmatrix, in which the numbers 1-15 appear on tiles, with one square \"empty\".\r\nFor example\r\n     0   1   2   3\r\n   +---+---+---+---+\r\n 0 | 5 | 3 | 1 | 2 |\r\n   +---+---+---+---+\r\n 1 | 15| 8 | 12| 14|\r\n   +---+---+---+---+\r\n 2 | 6 | 7 |   | 9 |\r\n   +---+---+---+---+\r\n 3 | 4 | 13| 11| 10|\r\n   +---+---+---+---+\r\n\r\nThere are four operators:\r\n  1) move the tile above the empty square down\r\n  2) move the tile below the empty square up\r\n  3) move the tile to the right of the empty square to the left\r\n  4) move the tile to the left of the empty square to the right\r\n\r\nAn easier way to think about these four operations as to move the empty\r\nsquare up, down, to the left, and to the right.\r\n\r\nSo, given a start and stop state (two matrices), a solution to the problem is\r\nthe sequence of operators (chosen from these four) needed to transform the\r\nstart state into the stop state.\r\n\r\n\r\nAs a quick side note, let's examine how many states there are in the search\r\nspace for the 15s puzzle and use big-O and big-Omega notation to bound this\r\nnumber by simpler functions both from above and below.\r\n\r\nThere are 16! different possible states. First let's look at an upper bound\r\nfor n! using big-O notation.\r\n\r\nn! = 1 x 2 x 3 x ... x n-1 x n; if we replace each value by a bigger one, n,\r\nn! < n^n; this isn't a great (tight) upper bound (it is way too big) but it is\r\nan upper bound so n! is O(n^n)\r\n\r\nnote 16^16 = (2^4)^16 = 2^64 = 2^4 x (2^10)^6 ~ 16 x (10^3)^6 = 16x10^18\r\n\r\nNext let's look at a lower bound for n! using big-Omega notation.\r\n\r\nn! = 1 x 2 x 3 x ... n/2 x n/2+1 x ... x n\r\n\r\n  1) replace the first n/2 terms by a smaller number: 2\r\n    (OK, so 2 isn't smaller than 1, but so long as n>8, the product of the\r\n     first 1/2 of the terms is bigger than 2^(n/2) because 4 is 2^2)\r\n  2) replace the last n/2 terms by a smaller number: n/2\r\n\r\nn! > 2^(n/2) x (n/2)^(n/2) = (2*n/2)^(n/2) = n^(n/2) = (n^n)^(1/2) = sqrt(n^n)\r\nso n! is Omega(sqrt(n^n))\r\n\r\nnote thatr when n is 16, sqrt (n^n) ~ sqrt (16x10^18) = 4x10^9\r\n\r\nso 4x10^9 < n! < 16x10^18\r\n\r\nThe bigger approximation is bigger by a factor of 4 billion than the smaller\r\napproximation, so the bounds here are not very tight. The actual value of 16!\r\nis about 2.1x 10^13 (about the square root of the product of these two\r\napproximations).\r\n\r\nStirlings formula for approximating n!, which is very accurate for large n, has\r\nn! ~ sqrt(2*pi*n)*(n/e)^n.\r\n\r\nRubik's cube is another problem that is solvable by state-space search (but\r\nwith many more operations and a much larger state-space).\r\n\r\n\r\nBest-First Search and the A* Algorithm\r\n\r\nBest-First search is another way to search a state-space tree. The goal of this\r\nform of search is to find a good solution (maybe not the optimal one found by\r\nbreadth first searching), but by examining fewer nodes (applying fewer\r\noperators throughout the searching process).\r\n\r\nTo implement best-first searching we need a simple but rough way to determine\r\nwhich of two states is \"closer\" to the stop state: a closer state would require\r\nfewer operators to transform it into the stop state. If we could perfectly\r\ncompute this information, we could always find an optimal length sequence of\r\noperators with no real searching, by (a) applying all operators to the start\r\nstate and finding the new state closest to the stop state; (b) applying all\r\noperators to that new state and finding a newer state closest to the stop\r\nstate, ... and continuing until we reach the stop state.\r\n\r\nBut it is very hard in practice to compute how close a state really is to the \r\nstop state (without actually doing a breadth-first search from that state to\r\nthe stop state; that would defeat the whole purpose of best-first searching\r\nbecause the closeness function itself would require extensive searching).\r\nSo, we will always end up with a simple closeness method that is very\r\nappoximate.\r\n\r\nIn the water jugs problem, we can approximate closeness to a solution in two\r\nsimple ways. In the first, we compute how close a state is to the stop state\r\nby computing  the sum of the absolute values of the differences between the\r\namount of water in a jug and the amount that is supposed to be there. Like all\r\ncloseness methods, the answer should be non-negative, with 0 at the stop state\r\nitself, and bigger numbers otherwise (think of it as a \"distance\" to the\r\nsolution; then the closesness function -how close is state A to state B- is\r\nalso called a \"metric\").\r\n\r\nSo, if the current state is (2,5,1) and the stop state is (0,4,4), we'd compute\r\nthis metric as |2-0| + |5-4| + |1-4| = 6.\r\n\r\nWe can use an even simpler metric to compute how close a state is to the stop\r\nstate, by computing the sum of a \"chracteristic function\" for each jug: 0 if\r\nit contains the right amount of water, 1 if it doesn't. This just computes how\r\nmany jugs contain the incorrect amount of water. So it has less information, but\r\nit is not obvious whether the extra informatin is actually usefule. Note that\r\nthese metrics are easily extendable to problems with any number of jugs.\r\n\r\nOnce we have such a metric, we can create a priority queue for all the examined\r\nstates, such that the highest priority state is the one that is closest to the\r\nstop state. As before, we use our operators to determine which states to add\r\nto this priority queue, but when we remove a state to examine next, it is\r\nwhatever state that is closest (by our approximation) to the stop state. The\r\nalgorithm is the same as breadth-first searching, but using a priority queue,\r\ninstead of a straight queue, means we examine states in a different order.\r\n\r\nIt might seem like the first metric would be better because it is more\r\ndetailed, but at least for the one water jug problem I ran my code on (see the\r\nnext section), the second metric was better. The problem was using jugs with\r\nsizes 5, 11, 13, and 24; a start state of (0,0,0,24); and a stop state of\r\n(0,8,8,8)\r\n\r\nCollected Information: Breadth-First, Best-First (two heuristics), A*\r\n\r\nWhen solving the problem in water_jugs_application (where water is conserved)\r\nthe breadth-first solution is found after examining 889 nodes, and has a\r\nsolution length of 6 (a sequence of 6 operators solves the problem).\r\n\r\nThe best-first solution is found using the first metric after examining 413\r\nnodes, but its solution length is 15. So, it runs about twice as fast but finds\r\na solution that is over two times a long.\r\n\r\nUsing the second metric, the best-first solution is found after examining 101\r\nnodes, and its solution length is 9. So, it runs about 9 times as fast, but\r\nfinds a solution that is 50% longer.\r\n\r\nFinally, the A* algorithm sums the number of operators needed to reach the\r\ncurrent state and the metric (think of it as estimating the number of operators\r\nexpected to reach the stop state). So it prefers searching from nodes that are\r\nclose to the start state and close to the stop state. If the metric NEVER\r\n\"overestimates\" the number of operators needed, then using the A* algorithm is\r\nguaranteed to produce the optimal solution. Using the second metric, the A*\r\nsolution is found after examining 337 nodes, and its solution length is 6. So,\r\nit runs about 3 times faster than breadth-first search (and 3 times slower than\r\nbest-first search) but produces an optimal solution.\r\n\r\n\r\nOne General Algorithm to solve Breadth-First and Best-First Searching:\r\n\r\nThere is a rather compact algorithm for implementing general state-space\r\nsearching. We start by getting from the problem the \"start\" state, the \"stop\"\r\nstate, and a set of all the \"operators\" that can be applied to get from one\r\nstate in the problem to another state in the problem, adding the \"start\" state\r\ninto the previously empty \"exploring\" collection.\r\n\r\nGenerally, each loop removes from the \"exploring\" collection (it is a queue for\r\nbreadth-first search and a priority queue for best-first and A* search) the\r\nnext state to explore when trying to find a solution. One by one we apply all\r\nknown operators to this state to generate all the other states that we can\r\nreach from it; for each new state (that we have not already reached; we check\r\nwhether the new state is already in the solutions map), we check whether it is\r\na solution (is the \"stop\" state) and if so, return the operators needed to \r\nreach it; otherwise we put how to reach that state (the list of operators need\r\nto get to that state from the \"start\" state) in solutions and add that state to\r\nthe \"exploring\" collection.\r\n\r\nEventually we will have found/returned a solution or \"exploring\" will be empty\r\n(there are no more new states to explore: we've already reached every state that\r\nis reachable) and we will return an empty queue of opertors (signalling there\r\nis no list of operators allowing us to reach the \"stop\" state from the \"start\" \r\nstate.\r\n\r\n\r\n//Find a to a problem and return it.\r\n//The actual data type that matches the abstract Queue parameter \"exploring\" might be a queue\r\n//  (see breadth_first_solution) or a priority queue (best_first_solution): the algorithm for\r\n//  the solution is the same, but depends on how dequeue is implemented.\r\nics::ArrayQueue<ics::Operator> solve_it (ics::Problem& problem,\r\n                                         ics::Queue<ics::State>&& exploring) {\r\n  int operator_count = 0;\r\n  ics::State start   = problem.get_start_state();\r\n  ics::State stop    = problem.get_stop_state();\r\n\r\n  //Trivial solutions: no operators needed\r\n  if (stop == start) {\r\n    std::cout << \"Found Solution: Operator applications = 0 (start state = stop state)\" << std::endl;\r\n    return ics::ArrayQueue<ics::Operator>();\r\n  }\r\n\r\n  ics::ArraySet<ics::Operator> operators(problem.get_all_operators());\r\n\r\n//  ics::ArrayMap<ics::State,ics::ArrayQueue<ics::Operator>> solutions;            //state -> ics::ArrayQueue[Operator]\r\n  ics::ArrayMap<ics::State,ics::ArrayQueue<ics::Operator>>& solutions = problem.solutions;              //state -> ics::ArrayQueue[Operator]\r\n  solutions.clear();\r\n\r\n  exploring.enqueue(start);\r\n  solutions[start] = ics::ArrayQueue<ics::Operator>();                             //initial state -> no operations\r\n\r\n  //Are there still states to explore\r\n  while(!exploring.empty()) {\r\n    ics::State current_state = exploring.dequeue();                                //state to explore next\r\n\r\n    //Try all operators and examine the state they lead to for uniqueness\r\n    for (ics::Operator op : operators) {\r\n      operator_count++;\r\n\r\n      try {\r\n        ics::State new_state = op.apply(current_state);\r\n\r\n        if (!solutions.has_key(new_state)) {\r\n          //extend solution to include this operator\r\n          ics::ArrayQueue<ics::Operator> current_solution = solutions[current_state];  //operators to get to this state\r\n          ics::ArrayQueue<ics::Operator> new_solution(current_solution);\r\n          new_solution.enqueue(op);\r\n\r\n          //if stop state, return solution\r\n          if (new_state == stop) {\r\n            std::cout << \"Found Solution: Operator applications = \" << operator_count << std::endl;\r\n            return new_solution;\r\n          }\r\n\r\n          //update solutions map and exploring queue\r\n          solutions[new_state] = new_solution;\r\n          exploring.enqueue(new_state);\r\n        }\r\n      } catch (const std::exception& e) {\r\n        //Just apply next operator if this one fails to work; i.e., skip it\r\n      }\r\n\r\n    }\r\n  }\r\n\r\n  //Failed to find solution; return an empty queue of operators.\r\n  //Note that this is the same result as the trivial solution (above).\r\n  std::cout << \"No Solution: Operator applications = \" << operator_count << std::endl;\r\n  return ics::ArrayQueue<ics::Operator>();\r\n}\r\n\r\nOn the page that lists sample programs, there is a download for \"State Space\r\nSearch\" which include a few classes comprising this general problem solver,\r\nas well as the classes Operator, State, and Problem to represent the Water Jugs\r\nproblem. When run, the application prints all the operators and then performs\r\nboth a breadth-first and best-first search for a solution, printing both the\r\nnumber of nodes explored and the solution. As we discussed, breadth-first\r\nsearching will typically explore more nodes but come up with a shorter solution\r\nthan best-first searching. If the how_close method starts with the number of\r\noperators needed to reach the current state, then the searching will be using\r\nthe A* algorithm.\r\n\r\nHere is the actual code that calls solve_it for each kind of search. Note that\r\nyou can speed-up best-first searching by using a HeapPriorityQueue instead of\r\nan ArrayPriorityQueue. The how_close function in the State class determines\r\nan integer metric of how close one state is to an other.\r\n\r\n\r\n\r\n//Use breadth-first searching to find an \"optimal\" solution (the one\r\n//  with the minimum number of operators needed to transform the initial\r\n//  state to the final state).\r\nics::ArrayQueue<ics::Operator> breadth_first_solution (ics::Problem& problem) {\r\n  return solve_it(problem, ics::ArrayQueue<ics::State>());\r\n}\r\n\r\n\r\n//Use the gt function (state i has higher priority than state j if i is heuristically closer to\r\n//  the stop state) to try to find a solution faster (search the tree, looking at fewer internal\r\n//  states), but typically not find an optimal solution.\r\n//The above is a pure best-first algorithm. If the gt function computes its result by adding\r\n//  (a) teh number of operators it takes to get to a state, and\r\n//  (b) the heuristic does not over-estimate how many operators it takes to reach the next state\r\n//  then the result will be an \"optimal\" solution, typically found by examining more operators\r\n//  than a pure best-first search but fewer than a breadth-first search.\r\nics::ArrayQueue<ics::Operator> best_first_solution (ics::Problem& problem,\r\n                                                    bool (*gt)(const ics::State& a, const ics::State& b)) {\r\n  return solve_it(problem, ics::ArrayPriorityQueue<ics::State>(gt));\r\n}\r\n", "encoding": "ascii"}