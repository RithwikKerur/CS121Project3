{"url": "https://www.ics.uci.edu/~theory/269/180413.html", "content": "<!DOCTYPE html>\n<html>\n<head>\n<title>Theory Seminar, March 9, 2018</title>\n<link rel=\"stylesheet\" href=\"../stylesheet.css\" type=\"text/css\">\n<script type=\"text/x-mathjax-config\">\nMathJax.Hub.Config({\n  tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']]}\n});\n</script>\n<script src=\"//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML\">\n</script>\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n</head>\n<body>\n<a href=\"/~theory/\"><img src=\"http://www.ics.uci.edu/~theory/logo/CATOC2.jpg\"\nalt=\"Center for Algorithms and Theory of Computation\"></a>\n<h2><a href=\"/~theory/269/\">CS 269S, Spring 2018: Theory Seminar</a><br>\nBren Hall, Room 1423, 1pm</h2>\n<hr />\n<h2>April 13, 2018:</h2>\n<h1>(Optimistic) Gradient for Min-max optimization: Limit points, Convergence\nand Learning</h1>\n<h2>Ioannis Panageas, MIT</h2>\n\n<p>\nMotivated by applications in Optimization, Game Theory, and the training of\nGenerative Adversarial Networks, the convergence properties of first order\nmethods in both unconstrained and constrained min-max problems have received\nextensive study. It has been recognized that they may cycle, but there is no\ngood understanding of their limit points when they do not. When they\nconverge, do they converge to local min-max solutions? In this talk we will\nprovide a characterization of the limit points of two basic first order\nmethods, namely Gradient Descent/Ascent (GDA) and Optimistic \nMirror Descent (OMD) for unconstrained min-max optimization. Finally we will\ndiscuss recent progress towards the convergence properties of OMD for the\ncase of 2-player zero-sum games (instance of constrained min-max\noptimization). \n</p>\n\n<p>\nJoint work with Costis Daskalakis\n</p>\n\n</body></html>\n\n", "encoding": "ascii"}