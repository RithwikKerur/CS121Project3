{"url": "https://www.ics.uci.edu/~rickl/rickl-patent-5526281.html", "content": "<HTML>\n<HEAD>\n<BASE TARGET=\"_top\">\n<TITLE>United States Patent: 5,526,281</TITLE></HEAD>\n<BODY BGCOLOR=\"#FFFFFF\">\n<a name=\"top\"></a>\n<center>\n<IMG SRC=\"rickl-patent-patfthdr.gif\">\n</center>  \n<p>\n<TABLE border=0>\n<TR><TD VALIGN=TOP ALIGN=LEFT width=40>\n&nbsp;\n</TD>\n<TD VALIGN=TOP ALIGN=LEFT width=40>\n&nbsp;\n</TD>\n<TD VALIGN=TOP ALIGN=RIGHT WIDTH=50>\n</TD><TD ALIGN=RIGHT VALIGN=BOTTOM WIDTH=500><FONT SIZE=-1>( <STRONG>1</STRONG></FONT> <FONT SIZE=-2>of</FONT> <STRONG><FONT SIZE=-1>1</STRONG> )</FONT></TD></TR></TABLE>\n<HR>\n<TABLE WIDTH=\"100%\">\n<TR>\t<TD ALIGN=\"LEFT\" WIDTH=\"50%\"><B>United States Patent </B></TD>\n\t<TD ALIGN=\"RIGHT\" WIDTH=\"50%\"><B> <A Name=h2 HREF=#h1></A><A  HREF=#h3></A><B><I>5,526,281</I></B>\n</B></TD>\n</TR>\n<TR><TD ALIGN=\"LEFT\" WIDTH=\"50%\"><b>\nChapman\n, &nbsp et al.</B>\n</TD><TD ALIGN=\"RIGHT\" WIDTH=\"50%\"> <B>\nJune 11, 1996\n</B></TD>\n</TR>\n</TABLE><HR>\n<font size=\"+1\"> Machine-learning approach to modeling biological activity for molecular\n     design and to modeling other characteristics\n</font><BR>\n<BR><CENTER><B>Abstract</B></CENTER>\n<P>Explicit representation of molecular shape of molecules is combined with\n     neural network learning methods to provide models with high predictive\n     ability that generalize to different chemical classes where structurally\n     diverse molecules exhibiting similar surface characteristics are treated\n     as similar. A new machine-learning methodology that can accept multiple\n     representations of objects and construct models that predict\n     characteristics of those objects. An extension of this methodology can be\n     applied in cases where the representations of the objects are determined\n     by a set of adjustable parameters. An iterative process applies\n     intermediate models to generate new representations of the objects by\n     adjusting said parameters and repeatedly retrains the models to obtain\n     better predictive models. This method can be applied to molecules because\n     each molecule can have many orientations and conformations\n     (representations) that are determined by a set of translation, rotation\n     and torsion angle parameters.\n</P>\n<HR>\n  <TABLE WIDTH=\"100%\">\n  <TR><TD VALIGN=\"TOP\" ALIGN=\"LEFT\" WIDTH=\"10%\">Inventors:\n  </TD><TD ALIGN=\"LEFT\" WIDTH=\"90%\">\n  <B>Chapman; David</B> (San Francisco, CA);\n<B>Critchlow; Roger</B> (San Francisco, CA);\n<B>Jain; Ajay N.</B> (San Carlos, CA);\n<B>Lathrop; Rick</B> (Cambridge, MA);\n<B>Perez; Tomas L.</B> (Cambridge, MA);\n<B>Dietterich; Tom</B> (Corvalis, OR)\n  </TD></TR>\n  <TR><TD VALIGN=\"TOP\" ALIGN=\"LEFT\" WIDTH=\"10%\">Assignee:\n  </TD><TD ALIGN=\"LEFT\" WIDTH=\"90%\">\n  <B>Arris Pharmaceutical Corporation</B> (South San Francisco, CA)\n  </TD></TR>\n<TR><TD VALIGN=\"TOP\" ALIGN=\"LEFT\" WIDTH=\"10%\" NOWRAP>Appl. No.:\n</TD><TD ALIGN=\"LEFT\" WIDTH=\"90%\">                    \n<B> 382990</B></TD></TR>\n  <TR><TD VALIGN=\"TOP\" ALIGN=\"LEFT\" WIDTH=\"10%\">Filed:\n  </TD><TD ALIGN=\"LEFT\" WIDTH=\"90%\">                    \n  <B>October 28, 1994</B></TD></TR>\n</TABLE>\n<p>\n<TABLE WIDTH=\"100%\">\n  <TR><TD VALIGN=TOP ALIGN=\"LEFT\" WIDTH=\"40%\"><B>U.S. Class:</B></TD>\n  <TD VALIGN=TOP ALIGN=\"RIGHT\" WIDTH=\"60%\"><B>364/496</B>; 364/578; 395/920  </TD></TR>\n  <TR><TD VALIGN=TOP ALIGN=\"LEFT\" WIDTH=\"40%\"><B>Intern'l Class: </B></TD>\n  <TD VALIGN=TOP ALIGN=\"RIGHT\" WIDTH=\"60%\">G06F 017/00; G06F 015/18</TD></TR>\n  <TR><TD VALIGN=TOP ALIGN=\"LEFT\" WIDTH=\"40%\"><B>Field of Search: </B></TD>\n  <TD ALIGN=\"RIGHT\" VALIGN=\"TOP\" WIDTH=\"60%\">\n  364/496,497,578\n395/920,924,21,22,23\n  </TD></TR>\n</TABLE>\n<HR><CENTER><B>References Cited   </B></CENTER><HR>\n<CENTER><B>U.S. Patent Documents</B></CENTER>\n<TABLE WIDTH=\"100%\"><TR><TD WIDTH=\"25%\">5025388</TD><TD WIDTH=\"25%\">Jun., 1991</TD><TD WIDTH=\"25%\" ALIGN=\"LEFT\">Cramer, III et al.</TD><TD WIDTH=\"25%\" ALIGN=\"RIGHT\">364/496.\n</TD></TR>\n<TR><TD WIDTH=\"25%\">5167009</TD><TD WIDTH=\"25%\">Nov., 1992</TD><TD WIDTH=\"25%\" ALIGN=\"LEFT\">Skeririk</TD><TD WIDTH=\"25%\" ALIGN=\"RIGHT\">395/27.\n</TD></TR>\n<TR><TD WIDTH=\"25%\">5260882</TD><TD WIDTH=\"25%\">Nov., 1993</TD><TD WIDTH=\"25%\" ALIGN=\"LEFT\">Blanco et al.</TD><TD WIDTH=\"25%\" ALIGN=\"RIGHT\">364/499.\n</TD></TR>\n<TR><TD WIDTH=\"25%\">5265030</TD><TD WIDTH=\"25%\">Nov., 1993</TD><TD WIDTH=\"25%\" ALIGN=\"LEFT\">Skolnick et al.</TD><TD WIDTH=\"25%\" ALIGN=\"RIGHT\">364/496.\n</TD></TR>\n</TABLE>\n\n<BR>\n  <TABLE WIDTH=\"90%\">\n  <BR>\n  <CENTER><B>Other References</B></CENTER>\n  <TD ALIGN=LEFT><br>T. A. Andrea, et al., Applications of Neural Networks in Quantitative\n     Structure-Activity Relationship of Dihydrofolate Reductase Inhibitors,\n     Journal of Medicinal Chemistry, vol. 34, No, 9, 1991, pp. 2824-2836.\n<br>Good, et al., Structure-Activity Relationships from Molecular Similarity\n     Matrices, Journal of Medicinal Chemistry, vol. 36, No. 4, Feb. 19, 1993,\n     pp. 433-438.\n<br>Aoyama, et al., Neural Networks Applied to Quantitative Structure-Activity\n     Relationship Analysis, Journal of Medicinal Chemistry, 1990, vol. 33, No.\n     9, pp. 2583-2590.\n<br>Aoyama, et al., Obtaining the Correlation Indices Between Drug Activity and\n     Structural Parameters Using a Neural Network, Chemical Pharmaceutical\n     Bulletin, vol. 39, No. 2, pp. 372-378, 1991.\n<br>Oinuma, et al., Neural Networks Applied to Structure-Activity\n     Relationships, Journal of Medicinal Chemistry, vol. 33, No. 3, 1990, pp.\n     905-908.\n<br>Viswanadhan, et al., Mapping the Binding Site of the Nucleoside Transporter\n     Protein: A 3D-QSAR Study, Biochemica et Biophysica Acta., 1039 (1990)\n     356-366.\n<br>Ghose, et al., Use of Physicochemical Parameters in Distance Geometry and\n     Related Three-Dimensional Quantitative Structure-Activity Relationships: A\n     Demonstration Using Escherichia coli Dihydrofolate Reductase Inhibitors,\n     Journal of Medical Chemistry, vol. 28, No. 3, 1985, pp. 333-346.\n<br>Smellie, et al., Fast Drug-Receptor Mapping by Site-Directed Distances: A\n     Novel Method of Predicting New Pharmacological Leads, J. Chem. Inf.\n     Comput. Sci., vol. 31, No. 3, 1991, pp. 386-392.\n<br>Cramer, III, et al., Comparative Molecular Field Analysis (COMFA), J. Am.\n     Chem. Soc., vol. 110, No. 18, 1988, pp. 5959-5967.\n<br>Crippen, et al., Distance Geometry and Molecular Conformation, Research\n     Studies Press Ltd., 8, Ligand Binding, pp. 361-429.\n<br>Hopfinger, A QSAR Investigation of Dihydrofolate Reductase Inhibition By\n     Baker Triazines Based Upon Molecular Shape Analysis, J. Am. Chem. Soc.,\n     1980, 102, 7196-7206.\n<br>Doweyko, The Hypothetical Active Site Lattice. An Approach to Modelling\n     Active Sites from Data on Inhibitor Molecules, Journal of American\n     Chemistry, 1988, 31 (7), pp. 1396-1406.\n<br>Simon, et al., Mapping of Dihydrofolate-Reductase Receptor Site by\n     Correlation with Minimal Topological (Steric) Differences, J. Theor.\n     Biol., 1977, 66, pp. 485-495.\n<br>Crippen, Deduction of Binding Site Structure from Ligand Binding Data,\n     Annals New York Academy of Sciences, vol. 439, 1984, pp. 1-11.\n<br>Boulu, et al., Voronoi Binding Site Models: Calculation of Binding Modes\n     and Influence of Drug Binding Data Accuracy, Journal of Computational\n     Chemistry, 10 (5), 673-632 (1989).\n<br>Crippen, Voronoi Binding Site Models, Journal of Computational Chemistry 8\n     (7), 943-955 (1987).\n<br>Boulu, et al., Voronoi Binding Site Model of a Polycyclic Aromatic\n     Hydrocarbon Binding Protein, J. Med. Chem., 1990, 33, 771-775.\n<br>Blankley, Introduction: A Review of QSAR Methodology, Academic Press, Inc.,\n     1983, pp. 1-17.\n<br>Nicklaus, et al., QSAR of Conformationally Flexible Molecules: Comparative\n     Molecular Field Analysis of Protein-Tyrosine Kinase Inhibitors, Journal of\n     Computer-Aided Molecular Design, 6 (1992) 487-504.\n </TD></TABLE>\n  <BR>\n  <I>Primary Examiner:</I>  Voeltz; Emmanuel T.\n<BR>\n  <I>Assistant Examiner:</I>  Kemper; M.\n<BR>\n  <I>Attorney, Agent or Firm:</I> D'Alessandro & Ritchie\n<BR>\n<HR>\n<CENTER><B><I>Parent Case Text</B></I></CENTER>\n<HR>\n<BR><BR>CROSS-REFERENCE TO RELATED APPLICATION\n<BR><BR>This is a file-wrapper continuation of patent application Ser. No.\n     08/066,389, filed May 21, 1993 now abandoned.\n<HR>\n<CENTER><B><I>Claims</B></I></CENTER>\n<HR>\n<BR><BR>1. A method in a computer for predicting activity of molecules with respect\n     to a chemical function based on known activities of a plurality of\n     molecules, said molecules each having one or more conformations and\n     orientations, each combination of a conformation and an orientation\n     defining a pose of a molecule, said method comprising:\n<BR><BR>(a) operating a computer to define one or more poses of each molecule as\n     the initial poses of an initial training set;\n<BR><BR>(b) operating a computer to construct a model in said computer with\n     parameters for predicting activity of poses with respect to said chemical\n     function and setting model parameter values;\n<BR><BR>(c) operating a computer to predict the activities of at least some of said\n     initial poses in the initial training set using the model and said model\n     parameter values and comparing the predicted activities of initial poses\n     of molecules to results of a set of actual tests for such activities of\n     such molecules;\n<BR><BR>(d) modifying said model parameter values in a computer based on a prior\n     comparison between predicted activities of poses in the initial or an\n     updated training set and said results of a set of actual tests for such\n     activities to minimize the differences between the predicted activities of\n     said at least some of the poses of molecules in such set and said results\n     of a set of actual tests for such activities of such molecules, and\n     modifying or selecting poses of the molecules to obtain an updated\n     training set of enhanced poses with higher predictive value than poses\n     prior to the modifying step;\n<BR><BR>(e) operating said computer to use the model and modified model parameters\n     values to predict the activity of a molecule not in the training set, and\n     having unknown activity; and\n<BR><BR>(f) visually displaying using computer graphics, in response to said\n     conditionally modified model, a representation of a second new molecule\n     not in the training set, and having unknown activity.\n<BR><BR>2. The method of claim 1, further comprising:\n<BR><BR>(f) predicting the activities of at least some of said enhanced poses in\n     the updated set using the modified parameter values and comparing the\n     predicted activities of enhanced poses of molecules to the known\n     activities of such molecules; and\n<BR><BR>(g) repeating steps (d) and (f) prior to step (e), wherein step (d) is\n     repeated based on a prior comparison between predicted activities of poses\n     in the updated set and their known activities.\n<BR><BR>3. The method of claim 2, wherein step (g) is carried out until there is no\n     substantial change in the model parameter values and the enhanced poses.\n<BR><BR>4. The method of claim 1, wherein said modifying step employs gradient\n     descent in modifying the poses and the model parameter values.\n<BR><BR>5. The method of claim 1, wherein said modifying step in (d) first\n     iteratively modifies the model parameter values until the differences\n     between the predicted activities of said at least some of the enhanced\n     poses of molecules and the known activities of such molecules are\n     minimized to arrive at a set of modified model parameter values and then\n     iteratively modifies the poses to maximize their activities and to obtain\n     enhanced poses.\n<BR><BR>6. The method of claim 5, wherein each time after poses of molecules in the\n     training set have been modified, said modifying step in (d) iteratively\n     modifies the model parameter values until the differences between the\n     predicted activities of said at least some of the enhanced poses of\n     molecules and the known activities of such molecules are minimized to\n     obtain a set of modified parameter values, so that any pose modification\n     thereafter will be in accordance with said set of modified parameter\n     values.\n<BR><BR>7. The method of claim 1, wherein the pose of each molecule in the set that\n     has higher predicted activity than other poses in the set of the same\n     molecule defines the best pose of such molecule, and wherein said model\n     parameter values are modified in step (d) based on a prior comparison\n     between predicted activities of the best poses in the set and their known\n     activities to minimize the differences between the predicted activities of\n     said at least some of the best poses of molecules in the set and the known\n     activities of such molecules.\n<BR><BR>8. The method of claim 1, said model constructing step including extracting\n     a set of feature values from each of said initial poses related to said\n     activity and setting an initial value for each of the features to be some\n     of the model parameter values.\n<BR><BR>9. The method of claim 8, said model constructing step further including\n     setting initial mean and standard deviations of a feature value and a\n     Gaussian-like function representing a contribution to predicted activity\n     of a pose as a function of said feature value in relation to its initial\n     mean and standard deviations.\n<BR><BR>10. The method of claim 9, wherein said model constructing step further\n     includes setting a positive or negative weighting factor for said Gaussian\n     function.\n<BR><BR>11. The method of claim 1, wherein an error function is defined for each\n     pose, said function being a difference between the predicted activity of\n     such pose of a molecule and the known activity of such molecule, wherein\n     said modifying step includes deriving a total error function indicating\n     the sum of the individual error functions of each of some of the poses and\n     changing the model parameter values to minimize the total error function.\n<BR><BR>12. The method of claim 11, wherein said modifying step employs gradient\n     based steps to minimize the error function.\n<BR><BR>13. The method of claim 1, wherein said pose modifying step in step (d)\n     modifies the poses as functions of parameters including orientation and\n     conformation parameters.\n<BR><BR>14. The method of claim 13, wherein said functions are differentiable and\n     said pose modifying step includes differentiating the functions with\n     respect to orientation and conformation parameters.\n<BR><BR>15. The method of claim 1, further comprising setting a set of ordered\n     numerical values according to a preset order to represent the known\n     activities of said plurality of molecules, wherein said modifying step (d)\n     also includes adjusting the set of ordered numerical values while\n     retaining the preset order to reduce the differences between the predicted\n     activities of said at least some poses of molecules in the initial or an\n     updated training set and the known activities of such molecules.\n<BR><BR>16. The method of claim 1, further comprising, prior to the selecting step,\n     searching for conformers of the molecules in the training set and aligning\n     the conformers relative to one another to form possible poses.\n<BR><BR>17. The method of claim 1, wherein said using step (e) also indicates which\n     conformer of said molecule not in the training set would have the highest\n     predicted activity with respect to said chemical function.\n<BR><BR>18. The method of claim 1, wherein said using step also indicates which\n     properties of said molecule not in the training set would have effects on\n     its predicted activity with respect to said chemical function.\n<BR><BR>19. The method of claim 1, further comprising visually displaying\n     relationship between poses of molecules and model parameter values using\n     computer graphics.\n<BR><BR>20. The method of claim 19, further comprising modifying said poses with\n     respect to the model parameter values displayed to modify the predicted\n     activities of the poses.\n<BR><BR>21. The method of claim 1, wherein said using step includes searching a\n     database of molecules with unknown activities and predicting their\n     activities.\n<BR><BR>22. The method of claim 1, wherein said model constructing step includes\n     setting a sigmoid function representing a contribution to predicted\n     activity of a pose as a sum of the weighted Gaussians of one or more\n     individual feature values.\n<BR><BR>23. The method of claim 22, wherein said model constructing step further\n     includes setting another sigmoid function representing the overall\n     predicted activity of a pose as a weighted sum of the sigmoid functions.\n<BR><BR>24. A method of operating a computer for predicting activity of molecules\n     with respect to a chemical function based on known activities of a\n     training set of molecules, said molecules in the set each having one or\n     more conformations and orientations, each combination of a conformation\n     and an orientation defining a pose of a molecule, said method comprising:\n<BR><BR>operating a computer to extract a set of feature values from each a set of\n     results from actual tests performed for each of said poses of molecules in\n     the training set, said feature values related to said activity, said\n     extracting step including the following steps:\n<BR><BR>(a) creating a surface representation in said computer of each of the poses\n     of molecules in the training set; and\n<BR><BR>(b) obtaining a feature value between at least one sampling point and a\n     point on said surface representation in said computer of each of the poses\n     constructing a model for predicting activity of poses with respect to said\n     chemical function using said feature values and using the model to predict\n     the activity of a molecule not in the training set.\n<BR><BR>25. The method of claim 24, wherein said creating step creates said\n     representations by finding van der Waals surface representations of atoms\n     on the surface of each of the poses.\n<BR><BR>26. The method of claim 25, wherein said finding step includes:\n<BR><BR>finding a first atom of the molecule with its center at a minimum distance\n     to a sampling point using a squared distance function;\n<BR><BR>finding a set of atoms in the vicinity of the first atom whose van der\n     Waals radii are larger than that of the first atom, if any; and\n<BR><BR>determining from a square root function which of the atoms in the set has a\n     van der Waals surface closer to the sampling point than that of the first\n     atom, if any.\n<BR><BR>27. The method of claim 24, wherein said creating step creates said\n     representations by summing Gaussian surface representations of atoms on\n     the surface of each of the poses.\n<BR><BR>28. The method of claim 24, said obtaining step including determining the\n     distances between said at least one point and the surface representations\n     along predetermined directions.\n<BR><BR>29. The method of claim 24, said obtaining step including:\n<BR><BR>determining the minimum distance between said at least one point and the\n     surface representations of the poses.\n<BR><BR>30. The method of claim 29, further comprising:\n<BR><BR>selecting a plurality of points around said surface representations; and\n<BR><BR>determining the minimum distance between each of said points and the\n     surface representations of the poses.\n<BR><BR>31. The method of claim 30, wherein said points selecting step includes:\n<BR><BR>forming an average surface representation of substantially all the poses;\n     and\n<BR><BR>selecting a plurality of points around said average surface representation.\n<BR><BR>32. The method of claim 24, said feature values including a steric or\n     electrostatic value.\n<BR><BR>33. The method of claim 24, further comprising visually displaying\n     relationship between poses of molecules and said model using computer\n     graphics.\n<BR><BR>34. The method of claim 33, further comprising modifying said poses with\n     respect to the model displayed to modify the predicted activities of the\n     poses.\n<BR><BR>35. A method in a computer for arriving at a model for predicting activity\n     of molecules with respect to a chemical function based on known activities\n     of a training set of molecules, said molecules in the set each having one\n     or more conformations and orientations, each combination of a conformation\n     and an orientation defining a pose of a molecule, said method comprising:\n<BR><BR>(a) operating a computer to define one or more poses from possible poses of\n     each molecule as the initial poses of a training set;\n<BR><BR>(b) operating a computer to construct a model in said computer with\n     parameters for predicting activity of poses with respect to said chemical\n     function and setting model parameter values;\n<BR><BR>(c) operating a computer to predict the activities of at least some of said\n     initial poses in the training set using the model and said model parameter\n     values and comparing the predicted activities of initial poses of\n     molecules to a set of results from actual tests performed for activities\n     of such molecules;\n<BR><BR>(d) modifying said model parameter values in said computer based on a prior\n     comparison between predicted activities of poses in the set and said set\n     of results from actual tests performed for activities to minimize the\n     differences between the predicted activities of said at least some of the\n     poses of molecules in the set and said set of results from actual tests\n     performed for activities of such molecules, and also modifying or\n     selecting poses of the molecules to obtain an updated training set of\n     enhanced poses with greater predicted activities than poses in the set\n     prior to the modifying step; and\n<BR><BR>(e) visually displaying using computer graphics, in response to said\n     modified model, a representation of a new molecule not in the training\n     set, and having unknown activity.\n<BR><BR>36. A method of operating a computer for predicting characteristics of an\n     object based on known characteristics of a plurality of other objects,\n     said other objects each having one or more representations, said method\n     comprising:\n<BR><BR>(a) operating a computer to define one or more representations from\n     possible representations of each of said other objects as the initial\n     representations;\n<BR><BR>(b) operating a computer to construct a model in said computer for\n     predicting characteristics of the representations;\n<BR><BR>(c) operating a computer to predict the characteristics of at least some of\n     said initial representations or an updated set of representations using\n     the model and comparing the predicted characteristics of initial\n     representations of said other objects to a set of results from actual\n     tests performed for characteristics of such other objects, wherein for\n     each of said other objects, the representation that has better\n     characteristics than other representations of the same object defines the\n     best representation of such object;\n<BR><BR>(d) modifying said model in said computer based on a prior comparison\n     between predicted characteristics of the best representations of said\n     other objects and said set of results from actual tests performed for\n     characteristics to minimize the differences between the predicted\n     characteristics of said best representations of the other objects and said\n     set of results from actual tests performed for characteristics of such\n     objects;\n<BR><BR>(e) operating said computer to use the modified model to predict the\n     characteristics of an object, said object not being one of said other\n     objects for which possible representations were chosen as the initial\n     representations.\n<BR><BR>37. The method of claim 36, further comprising:\n<BR><BR>(f) repeating steps (c) and (d) prior to step (e), wherein step (c) is\n     repeated based on a prior comparison between predicted characteristics of\n     at least some of the representations of each object and the known\n     characteristics of those objects.\n<BR><BR>38. A method of operating a computer for predicting characteristics of an\n     object based on known characteristics of a plurality of other objects,\n     said other objects each having many representations, each representation\n     called a pose and being defined by the object and values of one or more\n     parameters defining pose parameters, said method comprising:\n<BR><BR>operating a computer to define one or more poses from the possible\n     representations of each of said other objects as the initial poses;\n<BR><BR>(b) operating a computer to construct a model in said computer for\n     predicting characteristics of the objects from one or more poses of the\n     objects;\n<BR><BR>(c) operating a computer to predict characteristics of at least some of\n     said initial poses or enhanced poses using the model and comparing the\n     predicted characteristics of the initial poses of said other objects to a\n     set of results from actual tests performed for characteristics of such\n     other objects, wherein for each of said other objects the pose that has\n     better predicted characteristics than other poses of the same object\n     defines the best pose of such object;\n<BR><BR>(d) modifying said model in said computer based on a prior comparison\n     between predicted characteristics of the best poses of said other objects\n     and said set of results from actual tests performed for characteristics to\n     minimize the differences between the predicted characteristics of said\n     best poses of the other objects and said set of results from actual tests\n     performed for characteristics of such objects;\n<BR><BR>(e) operating a computer to define an updated set of enhanced poses by\n     computing new pose parameters for each object such that the resulting pose\n     is predicted by said model to have improved characteristics;\n<BR><BR>(f) repeating steps (c), (d), and (e) one or more times; and\n<BR><BR>(g) operating a computer to apply the modified model to predict the\n     characteristics of an object, said object not being one of said other\n     objects for which possible representations were chosen as the initial\n     poses.\n<BR><BR>39. A method for predicting activity of molecules with respect to a\n     chemical function based on activities of a plurality of molecules, said\n     method comprising\n<BR><BR>operating a computer to define a plurality of molecules, each one of said\n     molecules having at least one pose;\n<BR><BR>operating a computer to define a training set having at least one pose for\n     each one of said molecules;\n<BR><BR>operating a computer to construct a model in a memory for predicting a\n     result of an assay for a measure of activity relating to a set of desired\n     physical properties for said molecule;\n<BR><BR>operating a computer using said model to produce a prediction for a first\n     pose of a first molecule in said training set;\n<BR><BR>operating a computer using said model to produce a prediction for a second\n     pose of said first molecule;\n<BR><BR>conditionally modifying said model in said memory in response to a\n     difference between said prediction and a result of an actual said assay\n     conducted for said first pose;\n<BR><BR>conditionally modifying said training set in said memory to replace said\n     first pose with said second pose in response to a difference between said\n     prediction for said first pose and said prediction for said second pose;\n<BR><BR>repeating said steps of operating a computer using said model for said\n     first and second poses, and conditionally modifying said model and said\n     training set in memory, until a predetermined condition is reached;\n<BR><BR>operating a computer using said model to produce a prediction for a pose of\n     a new molecule, said new molecule not being in said training set;\n<BR><BR>conducting an actual said assay for said new molecule;\n<BR><BR>comparing said prediction for said pose of said new molecule with a result\n     of said actual assay for said new molecule; and\n<BR><BR>repeating said steps of operating a computer using said model for said pose\n     of said new molecule, conducting an actual said assay for said new\n     molecule, and said prediction, until a predetermined condition is reached.\n<BR><BR>40. A method as in claim 39, comprising conditionally modifying said model\n     in response to a difference between said prediction for said pose of said\n     new molecule and said result of said actual assay for said new molecule.\n<BR><BR>41. A method as in claim 39, comprising conditionally modifying said\n     training set in response to a difference between said prediction for said\n     pose of said new molecule and said result of said actual assay for said\n     new molecule.\n<BR><BR>42. A method as in claim 39, comprising\n<BR><BR>operating said model for at least one pose for each one of a plurality of\n     new molecules, said plurality of new molecules not being in said training\n     set, to produce a prediction for each one of said plurality of new\n     molecules;\n<BR><BR>selecting a choice one of said plurality of new molecules in response to\n     said prediction for each one of said plurality of new molecules;\n<BR><BR>conducting an actual said assay for said choice one of said plurality of\n     new molecules;\n<BR><BR>comparing a result of said actual assay for said choice one of said\n     plurality of new molecules with at least a part of said prediction for\n     each one said plurality of new molecules; and\n<BR><BR>repeating said steps of selecting a choice one, conducting an actual said\n     assay for said choice one, and comparing a result of said actual assay for\n     said choice one, until a predetermined condition is reached.\n<BR><BR>43. A method as in claim 42, comprising\n<BR><BR>conditionally modifying said model in response to a difference between said\n     prediction for said choice one of said plurality of new molecules and said\n     result of said actual assay for said choice one of said plurality of new\n     molecules.\n<BR><BR>44. A method as in claim 42, comprising\n<BR><BR>conditionally modifying said training set in response to a difference\n     between said prediction for said choice one of said plurality of new\n     molecules and said result of said actual assay for said choice one of said\n     plurality of new molecules.\n<BR><BR>45. A method as in claim 39, wherein said model comprises a neural network,\n     said neural network comprising\n<BR><BR>a plurality of layers each having at least one node;\n<BR><BR>said plurality of layers including a first layer having at least one node\n     coupled to an input value;\n<BR><BR>a second layer having at least one node coupled to a plurality of nodes of\n     said first layer;\n<BR><BR>said first layer having at least one node with a first transfer function,\n     said first transfer function comprising a Gaussian function with\n     parameters m, s, and z, said parameters being modifiable; and\n<BR><BR>said second layer having at least one node with a second transfer function,\n     said second transfer function comprising a sigmoid function with\n     parameters, said parameters being modifiable.\n<BR><BR>46. A method as in claim 39, wherein said new molecule is designed in\n     response to said model.\n<BR><BR>47. A method as in claim 39, wherein said new molecule is a catalyst, a\n     carbohydrate, a coating agent, a cosmetic, an explosive, an industrial\n     chemical, a paint, a perfuming agent, a petroleum derivative, a polymer,\n     or a polypeptide.\n<BR><BR>48. A method as in claim 39, wherein said new molecule is a pharmaceutical.\n<HR>\n<CENTER><B><I> Description</B></I></CENTER>\n<HR>\n<BR><BR>BACKGROUND OF THE INVENTION\n<BR><BR>This invention relates in general to a machine-learning approach to\n     modeling biological activities or other characteristics and, in\n     particular, to a machine-learning approach to modeling biological activity\n     for molecular design or other characteristics. In modeling biological\n     activity, the approach is preferably shaped-based.\n<BR><BR>The shape that a molecule adopts when bound to a biological target, the\n     bioactive shape, is an essential component of its biological activity.\n     This shape, and any specific interactions such as hydrogen bonds, can be\n     exploited to derive predictive models used in rational drug design. These\n     can be used to optimize lead compounds, design de novo compounds, and\n     search databases of existing compounds for novel structures possessing the\n     desired biological activity. In order to aid the drug discovery process,\n     these models must make useful predictions, relate chemical substructures\n     to activity, and confidently extrapolate to chemical classes beyond those\n     used for model derivation.\n<BR><BR>Physical data such as X-ray crystal structures of drug-target complexes\n     provide a shape model directly and have led to recent successes in\n     structure-based drug-design. However, in the absence of such data,\n     rational drug design must rely upon predictive models derived solely from\n     observed biological activity. Several methods exist that produce\n     predictive models relying, in part, on molecular shape.\n<BR><BR>Existing methods for constructing predictive models are unable to model\n     steric interactions accurately, particularly when these interactions\n     involve large regions of the molecular surface. Existing quantitative\n     structure-activity relationship (QSAR) models are severely limited by the\n     types of molecular properties they consider. Methods that employ\n     properties of substituents assume that the molecules share a common\n     structural skeleton, and hence cannot be extrapolated to molecules with\n     different skeletons. Many methods employ ad hoc features that make it\n     difficult to interpret the models as a guide for drug design.\n     Pharmacophore models (e.g., BioCAD) model activity in terms of the\n     positions of a small number of atoms of functional groups. This overcomes\n     many of the problems of traditional QSAR methods, but it has difficulty\n     addressing steric interactions.\n<BR><BR>In U.S. Pat. No. 5,025,388 to Cramer, III, et al., a comparative molecular\n     field analysis (COMFA) methodology is proposed. In this methodology, the\n     three-dimensional structure for each molecule is placed within a\n     three-dimensional lattice and a probe atom is chosen, placed successively\n     at each lattice intersection, and the steric and electrostatic interaction\n     energies between the probe atom and the molecule calculated for all\n     lattice intersections. Such energies are listed in a 3D-QSAR table. A\n     field fit procedure is applied by choosing the molecule with the greatest\n     biological activity as the reference in conforming the remaining molecules\n     to it. In determining which conformation of the molecule to use in the\n     analysis, COMFA proposes using averaging or Boltzman distribution\n     weighting to determine a most representative conformer. After the 3D-QSAR\n     table is formed, a partial least squares analysis and cross-validation are\n     performed. The outcome is a set of values of coefficients, one for each\n     column in the data table, which when used in a linear equation relating\n     column values to measured biological values, would tend to predict the\n     observed biological properties in terms of differences in the energy\n     fields among the molecules in the data set, at every one of the sampled\n     lattice points.\n<BR><BR>The COMFA method is disadvantageous since it requires that the chemist\n     guess the alignment and active conformation of each molecule or,\n     alternatively, compute the average or a weighted distribution of the\n     steric and electrostatic fields for all conformations. This can undermine\n     the applicability and accuracy of the method.\n<BR><BR>The COMFA method is also disadvantageous because it constructs a linear\n     model to predict activity as a function of the properties measured at the\n     grid points. Biological activity is an inherently non-linear function of\n     molecular surface properties (such as electrostatic, weak polar, and van\n     der Waals interactions). In COMFA these nonlinearities must be captured in\n     the field values measured at the grid points.\n<BR><BR>None of the above-described approaches is entirely satisfactory. It is\n     therefore desirable to provide an improved approach for modeling\n     biological activity in which the above-described difficulties are\n     alleviated.\n<BR><BR>SUMMARY OF THE INVENTION\n<BR><BR>An important advantage of the approach of this application over COMFA is\n     that a non-linear mathematical model is employed. This permits a surface\n     representation that is easier to understand and more efficient to compute.\n     The non-linearity is handled by a mathematical model.\n<BR><BR>This invention is based on the observation that it is difficult for a\n     scientist to provide good guesses about the best bioactive pose for each\n     molecule and that it is desirable to provide a method where the model can\n     be refined to generate new molecular orientations and conformations even\n     though the initial guesses may be mediocre. This invention is also based\n     on the observation that almost all of the chemical interactions between\n     molecules of interest to biochemistry and medicinal chemistry are based\n     entirely on surface interactions so that the predictive model would best\n     utilize a surface-based representation of molecular shape.\n<BR><BR>One aspect of the invention is directed towards an iterative process that\n     produces better models. In many binding interactions between molecules,\n     not all of the characteristics of the molecule considered are of equal\n     importance. Using a modeling approach permits the user to focus on the\n     salient features of the molecules. This aspect of the invention is\n     directed towards a method for predicting activity of molecules with\n     respect to a chemical function based on known activities of a plurality of\n     molecules. Each molecule has one or more conformations and orientations,\n     and each combination of a conformation and an orientation defines a pose\n     of a molecule. The method comprises selecting one or more poses from\n     possible poses of each molecule as the initial poses of a training set. A\n     model is then constructed with model parameters for predicting activity of\n     poses with respect to said chemical function and model parameter values\n     are then set. The activities of at least some of the initial poses in the\n     training set are predicted using the model and the model parameter values.\n     The predicted activities of at least some of the initial poses of\n     molecules are then compared to the known activities of such molecules. The\n     model parameter values are then modified based on a prior comparison\n     between predicted activities of poses in the set and their known\n     activities to minimize the differences between the predicted activities of\n     said at least some of the poses of molecules in the set and the known\n     activities of such molecules. The poses of the molecules are also modified\n     or re-selected so as to obtain an updated training set of enhanced poses\n     with higher predictive value than poses in the set prior to the modifying\n     step. The model and modified model parameter values are then used to\n     predict the activity of additional molecules whose activity is unknown.\n<BR><BR>In the preferred embodiment, the model parameter values and poses are\n     modified iteratively until the model parameter values as well as the poses\n     both converge before the model and the modified model parameter values are\n     used to predict the activity of the molecules whose activity is unknown.\n     For each molecule, the pose having the highest predicted activity is the\n     best pose of the molecule, Preferably, the model parameter values are\n     modified based on a prior comparison between predicted activities of only\n     the best pose or poses for each molecule in the set and their known\n     activities.\n<BR><BR>Another aspect of the invention is directed toward a shape-based approach\n     to modeling biological activity. This aspect is directed towards a method\n     for predicting activity of molecules with respect to a chemical function\n     based on known activities of a training set of molecules. Each molecule in\n     the set has one or more poses as defined above. The method comprises\n     extracting a set of feature values from each of the poses of molecules in\n     the training set, said feature values related to said activity. The\n     extracting step includes the following two steps: creating a surface\n     representation of each of the poses of each of the molecules in the\n     training set and obtaining a feature value between at least one sampling\n     point and a point on the surface representation of each of the poses. A\n     model is then constructed for predicting activity of poses with respect to\n     the chemical function using the feature values and the model is then used\n     to predict the activity of a molecule not in the training set. In the\n     preferred embodiment, the feature value is obtained by determining the\n     minimum distance between said at least one point and the surface\n     representations of the poses.\n<BR><BR>Yet another aspect of the invention is directed towards a general\n     machine-learning method for predicting characteristics of an object based\n     on known characteristics of a plurality of other objects. Each object has\n     one or more representations. The method comprises selecting one or more\n     representations from possible representations of each of the other objects\n     as the initial representations, constructing a model for predicting\n     characteristics of the representations, and predicting the characteristics\n     of at least some of the initial representations using the model and\n     comparing the predicted characteristics of initial representations of the\n     other objects to their known characteristics. For each of the other\n     objects, the representation that has better characteristics than other\n     representations of the same object defines the best representation of the\n     object. The method further comprises modifying the model based on a prior\n     comparison between predicted characteristics of the best representations\n     of the other objects and their known characteristics to minimize the\n     differences between the predicted characteristics of said best\n     representations of the other objects and their known characteristics. The\n     last step involves using the modified model to predict characteristics of\n     an object not in the training set.\n<BR><BR>BRIEF DESCRIPTION OF THE DRAWINGS\n<BR><BR>The file of this patent contains at least one drawing executed in color.\n     Copies of this patent with color drawing(s) will be provided by the Patent\n     and Trademark Office upon request and payment of the necessary fee.\n<BR><BR>FIG. 1 is a flow diagram of a molecular shape learning system to illustrate\n     the invention.\n<BR><BR>FIG. 2 is a schematic illustration of four different molecules, each with\n     one or more different orientations and conformations or poses to\n     illustrate the bootstrap procedure of FIG. 1.\n<BR><BR>FIG. 3 is a schematic view of the van der Waals surface representations of\n     atoms on a surface of a pose.\n<BR><BR>FIG. 4 is a schematic illustration of a pose of a molecule and a number of\n     points around the surface representation to illustrate a point based\n     system for feature extraction.\n<BR><BR>FIG. 5A is a schematic view of a ray-based feature extraction system to\n     illustrate the invention.\n<BR><BR>FIG. 5B is a schematic view of a pose of a molecule and a ray-based feature\n     extraction system to illustrate such system.\n<BR><BR>FIG. 5C is a schematic view of one or more poses of four different\n     molecules to illustrate the ray-based feature extraction system.\n<BR><BR>FIG. 6A is a graphical illustration of a Gaussian function to illustrate\n     the invention.\n<BR><BR>FIG. 6B is a schematic view of a ray-based feature extraction system and\n     tolerance boxes to illustrate the relationship between activity of the\n     molecule and its feature values along the rays of the ray-based system.\n<BR><BR>FIG. 6C is a schematic view of the ray-based feature extraction system and\n     tolerance boxes in relation to a pose to illustrate the invention.\n<BR><BR>FIG. 7 is a flow chart illustrating iterative model parameter modification\n     and reposing of molecules in order to illustrate the preferred embodiment\n     of the invention.\n<BR><BR>FIGS. 8A-8C and 9A-9C are two sets of figures each set showing a molecule\n     undergoing re-orientation and re-conformation to illustrate the preferred\n     embodiment of the invention.\n<BR><BR>FIG. 10 is a schematic view illustrating a method for finding the minimum\n     distance between the sampling point and the van der Waals surfaces of\n     atoms of a molecule to illustrate the invention.\n<BR><BR>FIG. 11 is a crude diagram of learned requirements for musk odor activity\n     to illustrate an example applying the invention of this application.\n<BR><BR>FIGS. 12A-12F are graphical illustrations of six different molecules\n     showing the relations between their structures and activities to\n     illustrate the invention.\n<BR><BR>FIG. 13 is a schematic view of a portion of a 16.times.16 grid to\n     illustrate a machine-learning method for predicting characteristics of\n     objects to illustrate another aspect of the invention.\n<BR><BR>FIG. 14 is a flow chart to illustrate the aspect of the invention of FIG.\n     13.\n<BR><BR>GENERAL DESCRIPTION OF THE PREFERRED EMBODIMENT\n<BR><BR>A novel modeling approach is proposed using a surface-based representation\n     of molecular shape that employs neural network learning techniques to\n     derive robust predictive models. Trained models predict the bioactive\n     shape of molecules and can be readily interpreted to guide the design of\n     new active compounds. The method is demonstrated on musk odor perception,\n     a problem believed to be determined by subtle steric interactions.\n<BR><BR>This approach combines three advances: a representation that characterizes\n     surface shape such that structurally diverse molecules exhibiting similar\n     surface characteristics are treated as similar; a new machine learning\n     methodology that can accept multiple orientations and conformations of\n     both active and inactive molecules; and an iterative process that applies\n     intermediate models to generate new molecular orientations to produce\n     better predictive models. The method is first outlined, then predictive\n     results are presented, and lastly the details of the method are described.\n<BR><BR>The procedure begins by conducting a search for low energy conformations of\n     the training molecules. This provides a pool of energetically accessible\n     shapes for each molecule. They are then placed into a set of initial\n     orientations that coarsely align the gross shape and electrostatically\n     important regions of the molecules. From these starting poses, we extract\n     feature values using either the point-based or ray-based feature\n     extraction method. These feature values (along with the known activities\n     of the corresponding molecules) are then provided as input to a neural\n     network, which is trained to construct an initial model of activity. To\n     improve predictive performance, we apply the learned model to\n     automatically compute additional discriminative molecular poses. The model\n     is refined using the new poses, and the process iterates until it\n     converges on a best model and a best pose for each molecule. Activity\n     predictions for new molecules are then obtained by applying the final\n     model. As in the training process, the model automatically computes the\n     best conformation and orientation for each molecule--the predicted\n     bioactive pose. It can be visualized in three dimensions to identify\n     required, allowed and disallowed regions of space around a candidate\n     molecule.\n<BR><BR>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT\n<BR><BR>The invention will now be described in detail by reference to figures. FIG.\n     1 is a flow chart showing the overall structure of the system. In order to\n     predict the activity of molecules not yet synthesized or for which not\n     much is known with respect to a particular chemical function, such as\n     binding to a particular receptor, one would first start with molecular\n     structures and assay values of known molecules with known activities with\n     respect to such chemical function. This is accomplished in the first step\n     20 in FIG. 1 by gathering the training data. Such data is subsequently\n     used in a learning model which is refined to generate consistent\n     hypotheses to explain the training data. However, in order to make the\n     learning process more efficient, it is desirable to employ a bootstrap\n     procedure 22. This procedure is illustrated in FIG. 2 in three steps:\n     finding the conformers, posing the conformers and selecting initial poses\n     from the poses to form an initial training set. After the training set is\n     formed, the set is used in a learning step 24 to refine a system which is\n     then used to predict (26) the activity of a molecule not in the training\n     set.\n<BR><BR>As shown in FIG. 2, the training data includes data on four different\n     molecules, where molecules 1 and 2 are active with respect to a particular\n     chemical function and molecules 3 and 4 are inactive with respect to such\n     function. As known to those skilled in the art, biologically active\n     molecules can take on different shapes known as conformers or\n     conformations defined by the internal torsion angles of the rotatable\n     bonds in the molecule. As shown in FIG. 2, molecules 1 and 4 each have\n     only one conformer, molecule 2 two conformers and molecule 3 three\n     conformers. In order to increase the computational efficiency in learning,\n     it is desirable to choose only the conformations that are best in\n     confirming or refuting the learning model.\n<BR><BR>The first step in this selection involves posing the molecule. A pose of a\n     molecule is defined by its conformation (internal torsion angles of the\n     rotatable bonds) and orientation (three rigid rotations and translations).\n     This mathematically defines the pose of the molecule. First, a conformer\n     of an active molecule is chosen and its pose is first fixed. As shown in\n     FIG. 2, molecule 1 is chosen and its pose 30 is fixed. Then the conformers\n     of the other molecules are realigned to match pose 30, such as in the\n     realignment of conformer 32 along arrow 34. Conformer 36 of molecule 3 is\n     moved along all three dimensions until it overlaps as much as possible\n     pose 30 as shown in FIG. 2. In chemical terms, this is analogous to\n     permitting the molecule to rotate, translate and alter its conformation to\n     achieve its best possible fit to the binding site. The rotation,\n     translation and alteration in the internal torsion angles of the rotatable\n     bonds in a molecule is referred to herein as reposing of the molecule.\n<BR><BR>In other words, since the fixed pose of molecule 1 known to have high\n     activity is used as the reference for reposing the remaining molecules,\n     this crudely simulates the process of reposing the other molecules to\n     achieve the best possible fit to the binding site. The reposed conformers\n     of molecules 2, 3 and 4 are shown in FIG. 2 in the category labeled\n     \"posed\". The above-described process can be performed using a number of\n     software packages available commercially, such as Catalyst from BioCAD,\n     Foster City, Calif., and Batchmin available from Columbia University, New\n     York City, N.Y.\n<BR><BR>The learning process 24 now begins with a selection of only some of the\n     poses to be in the training set. In other words, poor matches are dropped\n     for computational efficiency in the subsequent learning process. For\n     example, two of the poses of molecule 3 have been dropped to arrive at a\n     training set of five selected poses as shown in FIG. 2. In making the\n     selection, various properties of the four molecules known to chemists may\n     be used, including physical and chemical properties such as shape,\n     electrostatic interaction, solvation and biophysical properties.\n<BR><BR>Before the selected poses may be used for training, the relevant features\n     of these poses are first extracted. The COMFA methodology described in\n     U.S. Pat. No. 5,025,388, for example, employs a three-dimensional lattice\n     structure and extracts the relevant features by calculating the steric and\n     electrostatic interaction energies between a probe atom placed at each of\n     the lattice intersections and the molecule. As indicated above, the\n     receptor site in a binding interaction \"sees\" only the surfaces and not\n     the interior of a molecule. By choosing a three-dimensional lattice and\n     modeling the learning process based on the interaction energies between\n     these lattice points and the molecule, the COMFA methodology has failed to\n     focus in on the critical portion of the molecule, namely its surface.\n     Consequently, extraneous data not particularly relevant to binding\n     interactions may be included and may compromise the subsequent learning\n     process and cause it to give incorrect weight to critical surface\n     features. The feature extraction methods of this invention overcome such\n     defects.\n<BR><BR>Surface Representation\n<BR><BR>This invention envisions creating a surface representation of each of the\n     poses and then obtaining a feature value between at least one sampling\n     point and a point on the surface representation of each of the poses. FIG.\n     3 is a schematic illustration of a portion of a surface of a molecule with\n     five atoms whose nuclei are at 42-50 at such surface portion. The van der\n     Waals surface of each of the five atoms is first found. The van der Waals\n     surfaces of adjacent atoms would intersect; thus, the van der Waals\n     surface 42' of atom with nucleus at 42 intersects surface 44' of atom with\n     nucleus at 44 at ridge 52. The portions of surfaces 42', 44' that extend\n     outwards from ridge 52 are then taken as a surface representation of the\n     molecule around atoms with nuclei at 42 and 44. Thus, the curved surface\n     60, having a number of ridges such as ridge 52 at the intersections of\n     adjacent van der Waals surfaces, is a surface representation of the\n     portion of the molecule shown in FIG. 3.\n<BR><BR>As known to those skilled in the art, the electron density around each atom\n     can be represented as a Gaussian function of distance from the nucleus of\n     the atom where the peak of such Gaussians would more or less coincide with\n     the van der Waals radius of the atom. A surface representation of the\n     portion of the molecule shown in FIG. 3 can then be obtained by summing\n     the Gaussian functions for all the five atoms with nuclei at 42-50 where\n     the sum function also has a peak surface that would more or less coincide\n     with surface 60. The surface representation arrived at using the van der\n     Waals surfaces of the atom has been found to be adequate and easy to find\n     for most purposes for modeling biological and chemical activity whereas\n     the sum of the Gaussian approach gives a scientifically more rigorous\n     representation of such surface. The details of finding the van der Waals\n     surfaces of atoms and calculations involving a surface such as surface 60\n     are known to those skilled in the art and will not be explained in detail\n     here; although an improved method of calculating the minimum distance\n     between such surface and a sampling point is discussed below. Similarly,\n     the Gaussian distributions for the atoms and method for summing them are\n     also known to those skilled in the art and will not be explained in detail\n     here. Other than van der Waals and Gaussian surface representations, other\n     types of surface representation are possible, such as a Connolly surface.\n     See, M. J. Connolly, J. Appl. Cryst., 16, 548 (1983).\n<BR><BR>Feature Extraction\n<BR><BR>The feature values, including steric, electrostatic or other feature values\n     may be extracted by first specifying at least one sampling point and then\n     obtaining a feature value between such sampling point and a point on the\n     surface representation of each of the poses. In the preferred embodiment,\n     the point is outside but near the molecular surface and the feature value\n     is extracted by determining, for example, the minimum distance between\n     such sampling point and the surface representation of the pose. For\n     simplicity, a surface representation of a pose determined in the manner\n     above will be referred to simply as the surface of the pose. An\n     electrostatic feature value may be extracted as the electrostatic\n     interaction between a probe atom placed at such sampling point and the\n     pose. Alternatively, the electrostatic feature value may be the sum of the\n     Coulomb force interactions between the probe atom and atoms of the pose\n     surface. The abovedescribed approach will be referred to herein as the\n     point-based feature extraction approach. Preferably, a number of sampling\n     points are chosen surrounding the poses. In other words, the same sampling\n     points are used to extract features from each of the poses in the training\n     set. To arrive at a common set of sampling points, one may select the\n     points by reference to the averaged position of the poses in the training\n     set.\n<BR><BR>FIG. 4 is a schematic illustration of a number of sampling points 62\n     surrounding the surface of a pose 64, which may be an averaged position of\n     the poses in the set. If the fine features of portion 64' of the pose are\n     deemed to be particularly important for the activity of the pose, the\n     density of sampling points 62 may be increased surrounding such portion as\n     illustrated in FIG. 4. Point based feature extraction has the advantage\n     that the feature values (minimum distances, electrostatic interaction, . .\n     . ) will not change abruptly upon changing the orientation or conformation\n     of the pose. Also, when differentiability of the feature values with\n     respect to orientation and conformational parameters is important, point\n     based feature extraction gives rise to feature values which are\n     differentiable functions of the orientation and conformational parameters.\n     The steric feature values may simply comprise the minimum distance between\n     each of the sampling points and the surface representation of the\n     molecule, such as a', b', c', d', e' as shown in FIG. 4 The electro-static\n     feature values may comprise the electrostatic interaction energies or sums\n     of Coulomb forces between a probe atom placed at each of the sampling\n     points and the molecule. Other feature values may be extracted in a\n     similar manner.\n<BR><BR>Another possible feature extraction method is a ray-based method as\n     illustrated in FIGS. 5A-5C. In ray-based feature extraction, first one or\n     more points are chosen, such as point 72, preferably located inside the\n     molecular surface, and a number of rays with fixed directions are chosen,\n     such as rays 74a, 74b, 74c, 74d diverging from point 72. The points at\n     which the surface representation of the molecule intersects these rays\n     would yield the steric feature values a, b, c, d as illustrated in FIG.\n     5B. Thus, the four rays intersecting the surface of pose 76 intersect the\n     pose surface at distances a, b, c, d from point 72 so that the set of\n     feature values representing pose 76 is [a, b, c, d, . . . ], a, b, c, d\n     being the steric feature values. As shown in FIGS. 5B, 5C, pose 76 of\n     molecule 1 has feature values [a, b, c, d, . . . ]. The two poses of\n     molecule 2 and the single pose of each of molecules 3 and 4 each has a set\n     of feature values representing it as illustrated in FIG. 5C.\n<BR><BR>Form of the Model\n<BR><BR>Once features have been extracted for each initial pose in the initial\n     training set, these features are input to a parameterized mathematical\n     model (neural network) to produce an activity prediction. Let V (M, P) be\n     the vector of n features extracted to represent molecule M in pose P. Let\n     the kth component of this vector be denoted V (M, P).sub.k.\n<BR><BR>During training, the optimal values for the model parameters are\n     determined. It will be understood that the scope of this invention\n     includes a wide range of mathematical models, including linear models and\n     nonlinear models. In the preferred embodiment, the model has the form:\n     ##EQU1##\n     where m is the number of weights\n<BR><BR>Sigmoid (x)=1/(1+exp(-x))\n<BR><BR>exp is the exponential function (whose base e is the base of the natural\n     logarithm)\n<BR><BR>u.sub.j is a real-valued weight and\n     ##EQU2##\n     .mu..sub.i a real-valued location parameter .sigma..sub.i is a real-valued\n     width parameter\n<BR><BR>The parameters of this model are:\n<BR><BR>u.sub.j (j=1 . . . n)\n<BR><BR>v.sub.ji (j=1 . . . n, i=1 . . . m)\n<BR><BR>.mu..sub.i (i=1 . . . m)\n<BR><BR>.sigma..sub.i (i=1 . . . m).\n<BR><BR>n\n<BR><BR>In this embodiment, the function G is a Gaussian-like function that will\n     produce large values when the measured feature V (M, P).sub.i is near to\n     .mu..sub.i and smaller values when the measured feature is distant from\n     .mu..sub.i. The value of .sigma..sub.i controls how rapidly the value of G\n     decreases as V (M, P).sub.i moves away from .mu..sub.i. FIG. 6A shows a\n     sketch of the shape of the G function.\n<BR><BR>Given an initial set of training poses, the training process is initialized\n     by providing starting values for each of the parameters. In the preferred\n     embodiment, the values of u.sub.j and v.sub.ji are set to small random\n     positive values in the range from 0.0 to 0.2; .mu..sub.i is initialized to\n     be a small amount (1.0) less than the mean of the values of V (M, P).sub.i\n     for all molecules and poses in the training data set. The value of\n     .sigma..sub.i is initially set to a value of 0.25. The value of n, the\n     number of intermediate sigmoids, is initialized to 1. If inadequate\n     predictions are obtained, n can be increased and the model re-trained\n     until a sufficient value of n is found.\n<BR><BR>FIG. 6B provides a graphical interpretation of the model applied to\n     ray-based features. Each Gaussian G (V (M,P).sub.j, .mu..sub.i,\n     .sigma..sub.i) can be approximately viewed as a box lying along the ray at\n     a location determined by .mu..sub.i. The size (length) of the box is\n     determined by .sigma..sub.i. If the values of v.sub.ji are positive (for\n     each value of j), then this indicates that in order to exhibit activity,\n     it is desirable that the molecular surface pass through this box. For\n     example, box 82 lies at a position .mu..sub.1 along ray 74a. The size of\n     the box is determined by .sigma..sub.1. As shown in FIG. 6C, molecule 1\n     falls inside all of the boxes 82, 84, 86 and 88, so (assuming the v.sub.ji\n     are all positive), it will have very high predicted activity. If the\n     values of v.sub.ji are negative for some ray i, then the box represents a\n     region where the molecular surface should not be located. This is how the\n     model represents excluded regions for the molecular surface.\n<BR><BR>Because contributions are weighted and summed by the sigmoid functions, a\n     molecule can still have fairly high predicted activity even if its surface\n     does not pass through all of the desirable boxes. Notice that the\n     predicted activity of a molecule will vary as the pose of the molecule\n     varies. For each pose, the molecular surface can intersect the various\n     rays at different points, and hence produce different feature values. The\n     final predicted activity of each molecule is determined by the pose that\n     gives the highest predicted activity among all poses considered for that\n     molecule according to the final learned model.\n<BR><BR>The discussion in the preceding paragraphs has focused on steric features,\n     but the same mathematical model applied equally well to electrostatic\n     features. The values of .mu..sub.i and .sigma..sub.i for an electrostatic\n     feature i describe an interval (\"Box\") of desirable or undesirable values\n     for the feature (depending on the values of v.sub.ji). In fact, the same\n     mathematical model is applicable to other biological activity types\n     including but not limited to affinity, agonism, potency, receptor\n     selectivity and tissue selectivity.\n<BR><BR>Training the Model\n<BR><BR>The training of the model will now be described in reference to FIG. 7.\n     FIG. 7 is a flow chart illustrating in more detail the learning step 24\n     and prediction step 26 of FIG. 1.\n<BR><BR>In the preferred embodiment, the sampling points 62 are chosen by reference\n     to an average surface representation obtained by averaging the surface\n     representations of the poses in the training set. Thus, if surface\n     representation 64 is an averaged surface representation of all the poses,\n     then the sampling points 62 are chosen by reference to such surface. The\n     averaging process to obtain the average representation of a set of poses\n     is known to those skilled in the art.\n<BR><BR>As explained above in reference to FIG. 2, an initial set of poses is\n     selected to form the training set in order to train the model (block 100).\n     Then the initial values for the parameters n, .mu..sub.i, .sigma..sub.i,\n     v.sub.ji, and u.sub.j are chosen (block 102). The feature values of the\n     poses in the training set are extracted as described above. However, it\n     will be understood that the training system of the invention is not\n     limited to the point-based or ray-based feature extraction methods above.\n     Then the predicted activity of each of the poses in the training set is\n     calculated using the model and the parameter values set initially by\n     using, for example, the equations above. For each molecule, the pose with\n     the highest predicted activity is chosen as the best pose of the molecule\n     (block 106). Then the parameter values set initially for feature i are\n     modified to minimize the differences between the predicted and actual\n     activities of preferably only the best poses of the molecules.\n<BR><BR>When receptor sites are present in the vicinity of the molecules used for\n     training, it is known that the presence of such sites would influence the\n     orientation and conformations of molecules present so that in actual fact,\n     the molecules would repose under such influence to attempt to conform to\n     the pose with the highest activity. Therefore, the above-described step in\n     block 108 of training the model by reference to only the best poses of\n     molecules resembles the physical process. It is of course possible to\n     modify the parameter values in reference to poses in addition to or other\n     than the best poses; all such variations are within the scope of the\n     invention.\n<BR><BR>If p.sub.j is the predicted activity of a particular pose j and a.sub.j its\n     actual activity, then an error function for the training set of poses can\n     be formed by the following equation:\n     ##EQU3##\n     where m is the total number of poses (preferably only the best poses) in\n     the set in reference to which the parameter values are to be modified. A\n     wide variety of computational methods may be applied to minimize the error\n     function with respect to the parameters of the model (e.g., u.sub.j,\n     v.sub.ji, .mu..sub.i, .sigma..sub.i, n). Such methods are known to those\n     skilled in the art and will not be described here. In the preferred\n     embodiment, the gradient of the error function with respect to these\n     parameters (except for n) is computed, and gradient descent methods are\n     applied. Other methods such as conjugate gradient, Newton methods,\n     simulated annealing, and genetic algorithms may also be used and are\n     within the scope of the invention.\n<BR><BR>After the differences between predicted and actual activities of poses\n     (e.g., best poses) have been minimized, such as by minimizing the above\n     error function, such differences are compared to preset thresholds\n     (diamond 110). If the differences are below the preset threshold or\n     thresholds, one concludes that the process has converged and proceeds to\n     the step in block 112. If not, then one returns to block 106 to calculate\n     the predicted activities of poses in the training set by reference to the\n     modified parameter values and again choose the best pose for each molecule\n     having the highest predicted activity. The parameter values are again\n     modified to minimize differences between predicted and actual activities\n     of best poses. This loop is repeated until the differences are found to be\n     below preset threshold or thresholds and the same best poses are chosen\n     every time.\n<BR><BR>Then the molecules are reposed to maximize their activities and from the\n     possible poses after the reposing, poses are chosen to form a new training\n     set (block 112), a process such as that illustrated in FIG. 2 above.\n     Instead of reposing the molecules, it is possible to simply re-select from\n     the initial set of poses to form the training set of poses, as illustrated\n     in FIG. 2. However, it is believed to be preferable to repose the\n     molecules in order to form a new training set. The new training set is\n     compared to the prior training set to see whether the changes to the poses\n     are below certain set threshold or thresholds (diamond 114). If the\n     changes are found to be below the threshold(s), then the process of\n     training the model is completed and one proceeds to the prediction step in\n     block 116. If the changes to the poses are not below the threshold or\n     thresholds, (diamond 114), then one returns to block 104. Since the\n     orientation and conformation of the poses may have changed, these new\n     poses will have different feature values from those in the original\n     training set. Therefore, the feature extraction step needs to be repeated.\n     The process of reposing is illustrated in FIGS. 8A-8C and 9A-9C by\n     reference to a ray-based system. As shown in FIGS. 8A, 8B, molecule 3 is\n     reposed by first re-orienting the molecule with respect to the sampling\n     points (or to the rays in the ray-based system). When the parameter values\n     of the model are modified, the positions of the boxes in FIG. 8 have been\n     modified so that they are not the same as the positions of the boxes in\n     the prior application of the model to the molecule. Therefore, molecule 3\n     has been re-oriented to best fit its surface portions within the tolerance\n     boxes with positive weighting factors and to avoid boxes with negative\n     weighting factors as shown in FIG. 8B. Then the internal torsion angles of\n     the rotatable bonds are altered to re-conform the molecule to again best\n     fit the surface portions of the molecule within the modified boxes as\n     shown in FIG. 8C. Molecule 3 is known to have low activity. As illustrated\n     in FIG. 8C, the molecule cannot be maneuvered to fit into one of the\n     tolerance boxes. This may cause the calculated predicted activity of\n     molecule 3 to be low as well so that the model is confirmed. Molecule 4 is\n     re-oriented and re-conformed in a manner similar to that for molecule 3.\n     As shown in FIG. 9C, molecule 4 can be reposed so that its surface\n     portions fit within all the tolerance boxes of the model. This may cause\n     molecule 4 to have a high predicted activity, contrary to the known low\n     activity of the molecule. If this happens, this may cause the error\n     function to exceed the preset threshold(s) so that the parameter values\n     would have to be modified again as described above for the inner loop in\n     blocks 106, 108 and diamond 110.\n<BR><BR>The above-described process makes good use of the salient feature of poses\n     of inactive as well as active molecules. The above-described reposing\n     process with aligned and conformed poses of active molecules to maximize\n     the activities and to repose the inactive molecules to be in the best\n     position to refute the model. Thus, in order for the model to pass the\n     abovedescribed testing process, it will predict the inactivity of poses of\n     inactive molecules even though these have been realigned and reconfirmed\n     to be in the best position to \"fool\" the model, while at the same time\n     confirming the activity of the active molecules.\n<BR><BR>In the preferred embodiment, gradient search methods are also used for\n     reposing the training molecules to maximize their predicted activities as\n     functions of the orientation and conformational parameters.\n<BR><BR>For both the point-based and ray-based feature extraction methods used in\n     conjunction with either the van der Waals or Conholly surfaces, the\n     extracted features are differentiable functions of the orientation and\n     conformational parameters. Furthermore, the model (as represented by the\n     equations above) is a differentiable function of the values of the\n     extracted features. Hence, by applying the chain rule, it is possible to\n     compute the gradient of the predicted activity with respect to the\n     orientation and conformational parameters and apply gradient-based search\n     to find poses that maximize predicted activity. However, other kinds of\n     models and other methods of feature extraction may not satisfy this\n     property, in which case other computational methods (e.g., simulated\n     annealing, linear programming) could be applied to find poses that\n     maximize predicted activity. It is understood that the scope of the\n     invention includes all methods for finding such poses.\n<BR><BR>Instead of reposing the molecules, it is possible to simply re-select the\n     best poses from the original set of poses formed prior to the selection\n     step in block 100. It is found, however, that reposing the molecules\n     rather than re-selecting from existing poses greatly reduces the error of\n     prediction as indicated in Table 1 below in regard to a musk model.\n<BR><BR>The trained model and the ultimate parameter values may then be used to\n     predict the activity of a new molecule with unknown activity (block 116).\n     Thus, again, feature values are extracted from the poses of the molecule\n     and the predicted activities of the poses are calculated to find the best\n     pose with the highest activity. Thus, the model not only enables the user\n     to predict the activity of the molecule not in the training set but also\n     predict its best poses. Its feature values in comparison with the\n     parameter values would indicate which surface portions have the desirable\n     properties in regard to a chemical function and which surface portions\n     have undesirable properties in regard to such function. This is\n     illustrated in more detail in FIGS. 12A-12F and the accompanying\n     description below. In fact, the model may be used to search a database of\n     molecules with unknown activity and predict the activities of their poses.\n     Poses of these molecules may be modified to alter their predicted\n     activities.\n<BR><BR>In FIG. 7 above, the model parameter values are optimized in an inner loop\n     before the molecules are reposed or poses reselected in an outer loop.\n     Such embodiment is efficient because reposing molecules requires large\n     numbers of calculations. It will be understood, however, that the\n     optimization can be performed in ways different from that described above\n     and are within the scope of the invention. For example, it is possible to\n     maximize the activity by reposing in an inner loop before the model\n     parameter values are optimized to minimize the differences between\n     predicted and actual activities of best poses in an outer loop. The two\n     optimization processes may also be intertwined.\n<BR><BR>In the above-described point based feature extraction using a van der Waals\n     surface representation of atoms, it will be simpler not to have to first\n     calculate the surface representations of the entire molecule but simply to\n     determine the closest distance between a particular sampling point and\n     find the atom whose van der Waals surface will be at the closest distance\n     to such sampling point. In order to determine the nearest atomic surface\n     to a sampling point, one way requires computing the distance between the\n     sampling point and the van der Waals sphere computed for each atom in the\n     molecule separately. For each atom in the molecule, the distance d between\n     a sampling point p with coordinates (px, py, pz) and the van der Waals\n     sphere of radius r for an atom with a center at c with coordinates (cx,\n     cy, cz) is:\n<BR><BR>d=sqrt((px-cx).sup.2 +(py-cy).sup.2 +(pz--cz).sup.2)-r\n<BR><BR>This requires computing a square root, for each possible atom, which is\n     very expensive. Another aspect of the invention provides a much more\n     efficient way to compute this distance d, based on the observation that it\n     is cheaper to compute the square of the distance than to compute the\n     distance itself. The nearest-atom computation operates in two passes on\n     each feature. In the first pass, we find the minimum distance squared to\n     atomic centers. The atom with the minimum distance to atomic center is not\n     necessarily the atom with the minimum distance to the van der Waals\n     surface, however. Therefore, in the second pass, the distance to the van\n     der Waals surface distance is determined only for atoms that are \"close\"\n     to the minimum distance squared. It is noted here that the distance to the\n     van der Waals surface distance cannot be computed in distance squared\n     space, because of the subtraction of the van der Waals radius. In the\n     second pass, \"close\" is computed in terms of the difference between the\n     radius of the atom with the minimum distance squared to center and the\n     maximum possible atomic radius.\n<BR><BR>Specifically, in reference to FIG. 10, suppose the atom with the minimum\n     distance squared to its center 130 has distance d' to the sampling point\n     134 and radius r. Suppose the atom in the molecule centered at 132 with\n     the maximum radius has radius r.sub.max. Then an atom center (e.g. 132) of\n     another atom could in principle be up to d'+r.sub.max -r away and have the\n     same distance to the van der Waals shell viewed from point 134 as the atom\n     centered at 130. So we want to look at all atoms close to center 130 but\n     whose distance squared to atomic center is within (d'+r.sub.max -r).sup.2\n     away. Thus, in the second pass, we look at atoms in the vicinity of 130\n     with van der Waals radii between r and r.sub.max using a square root\n     calculation.\n<BR><BR>EXAMPLE\n<BR><BR>The relationship between the model parameter values and the poses of the\n     molecules may be displayed visually using computer graphics to aid\n     biochemical design as in the musk odor prediction problem described below.\n     Thus, the parameter values .mu..sub.i, .sigma..sub.i and weighting factor\n     v.sub.ji discussed above may be displayed on a screen of a monitor as well\n     as a surface of a molecule. The model parameter values may be illustrated\n     by octagonal patches near the surface of the molecule where each feature\n     was measured. Each patch is colored according to whether the measurement\n     found the surface to be too close, too far, or about right. These three\n     values are computed by thresholding the Gaussian corresponding to each\n     feature. Clearly, a Gaussian with a wide G will allow a broader range of\n     distance measurements to count as \"about right.\"\n<BR><BR>When the surface is too far from the measurement point, there may be room\n     to modify the molecule to add additional bulk to the molecule. When the\n     surface is too close to the measurement point, there may be need to modify\n     the molecule to trim bulk from the molecule.\n<BR><BR>Thus, the pattern of colored patches may guide the medicinal chemist in\n     choosing the parts of the molecule which should be made larger or smaller\n     to improve the activity of the molecule.\n<BR><BR>The problem of musk odor prediction has been the focus of many modeling\n     efforts. Musk odor is a specific and clearly identifiable sensation,\n     although the mechanisms underlying it are poorly understood. These\n     molecules typically have a single hydrogen-bond acceptor on a roughly\n     ellipsoidal hydrocarbon. Musk odor is determined almost entirely by steric\n     effects. A single methyl group change can account for a significant change\n     in musk odor.\n<BR><BR>To test the invention's ability to predict subtle steric interactions, we\n     studied a set of 102 diverse structures in several chemical classes\n     collected from published studies. Only those compounds for which published\n     assay values agreed were used. The data set contained 39 aromatic,\n     oxygen-containing molecules with musk odor and 63 homologs that lacked\n     musk odor. Each molecule was conformationally searched using a Monte Carlo\n     procedure. Some molecules possessed flexible sidechains and exhibited a\n     sizeable number of conformations (ranging from 2 to over 250), many of\n     which significantly changed the overall shape of the molecule. Because all\n     molecules were assayed as racemic mixtures, all stereoisomers of each\n     molecule were likewise searched and included in the data set. The final\n     dataset contained 6,953 conformathons of the 102 molecules.\n<BR><BR><PRE>\n                  TABLE 1\n    ______________________________________\n    Predictive accuracy of musk model in a 20-fold cross-validation\n    hold-out test (standard error is in brackets).\n              True False   True   False\n              Pos. Neg.    Neg.   Pos.  % Correct\n    ______________________________________\n    Adaptive alignment\n                36     3       57    6    91[2.8]\n    Fixed alignment\n                36     3       47   16    81[3.9]\n    ______________________________________\n</PRE>\n<BR><BR>We performed a 20-fold cross-validation test of predictive performance. The\n     molecules in the data set were partitioned into twenty random subsets.\n     Twenty models were trained, with one of these subsets excluded from the\n     training data during each execution. The model constructed in each\n     execution was then tested to see how well it could predict the withheld\n     molecules, and the results were totalled. Overall predictive performance\n     using is 91% (see Table 1). In Table 1, \"True Pos.\" means that a molecule\n     which is active is confirmed to be active, \"False Neg.\" means that an\n     active molecule is erroneously predicted to be inactive, \"True Neg.\" means\n     that an inactive molecule is predicted to be inactive, and \"False Pos.\"\n     means that inactive molecules are erroneously predicted to be active. A\n     model constructed using fixed molecular alignments results in predictive\n     performance of 81%--the model-directed realignment (i.e., reposing) aspect\n     of the invention substantially improves performance. The primary\n     requirements of musk activity discovered by applying the invention are\n     crudely illustrated in FIG. 11 (the actual learned models are sensitive to\n     approximately fifty specific surface regions). Molecules must have a\n     hydrogen bond acceptor at the appropriate geometry (positions 1 or 2), and\n     the right amount of hydrophobic bulk at positions A, B and C. This model\n     is consistent with other models of musk odor activity, but it was learned\n     exclusively from a general surface-based representation of shape.\n<BR><BR>Predictive models must be able to extrapolate beyond the structural classes\n     analyzed during model generation to be useful for molecular design. Random\n     hold-out tests, such as cross-validation, do not test this ability because\n     they mix all structural classes in both the training and test data. To\n     test extrapolation ability, we conducted a series of class-holdout\n     experiments in which all molecules of a given structural class were\n     withheld during training and then evaluated during testing. This simulates\n     the situation in which chemists wish to apply a learned model to guide the\n     synthesis of a new class of compounds. Table 2 shows four classes, the\n     largest of which is class 2. Class 1 has a substantially different\n     arrangement of hydrophobic bulk. Classes 2 and 4 have molecules with\n     different hydrogen-bonding geometries. Each class represents a structural\n     type that a chemist might choose as a synthetic target.\n<BR><BR>Cross-class predictive performance ranges from 71% to 100% and in all cases\n     benefit substantially by using adaptive alignment (i.e., iterative\n     reposing and model parameter value modification)--the error-rate drops by\n     more than half. A more useful criterion in assessing performance than\n     percent correctly predicted above or below a fixed threshold is the\n     quality of the ranking of the molecules as measured by the number of\n     molecules that are misranked. The neural-network produces a value on the\n     interval [0,1], and test molecules are ranked by this score. A ranked list\n     is perfect if all active molecules are ranked higher than all inactive\n     molecules. The number of misranked molecules is the minimum number of\n     molecules that need to be eliminated from the ranked list to produce a\n     list with a perfect ranking. This is different from other rank scores\n     because the musk data contains only binary assay values but the invention\n     makes real-valued predictions. By this measure, with adaptive alignment,\n     predictive performance is very high, ranging from 86% to 100%. Performance\n     on class 4 is the poorest and seems to be related to the non-planar\n     geometry of the ether component of these molecules.\n<BR><BR><PRE>\n                                      TABLE 2\n    __________________________________________________________________________\n    Predictive accuracy of musk model across structural classes. Numbers in\n    brackets\n    are standard error. The counts reported in rows 2-4 are for adaptive\n    alignment.\n    Structural (1)4-substituted\n                       (2)1- (3)6-substituted\n    Class:     dihydroindanes\n                       indanones\n                             tetrahydronapthalenes\n                                        (4) benzopyrans\n    __________________________________________________________________________\n    Number of molecules\n                13      21    27         14\n    True positives\n                7       6     9          4\n    False negatives\n                0       0     4          3\n    True negatives\n                6       13    13         5\n    False positives\n                0       2     0          1\n    Percent correct\n               100[0.0]\n                        90[6.5]\n                              85[6.8]    71[12.1]\n    (adaptive alignment)\n    Percent correct\n                85[9.9]\n                        76[9.3]\n                              74[8.4]    57[13.2]\n    (fixed alignment)\n    Number misranked\n                0       1     1          2\n    Percent correct\n               100[0.0]\n                        95[4.8]\n                              96[3.8]    86[9.3]\n    (by ranking)\n    __________________________________________________________________________\n</PRE>\n<BR><BR>Previous studies of musk odor on similar molecules using atom-based\n     approaches have produced similar levels of predictive accuracy in\n     cross-validated predictive tests, ranging from 90% (std. err. 6.7) to 93%\n     (std. err. 6.4). However, none of these studies has reported predictive\n     results across chemical classes or has employed molecular properties that\n     could easily be interpreted to guide design of new compounds.\n<BR><BR>To illustrate the system's ability to provide detailed guidance in\n     molecular design, additional models were trained while withholding\n     specific pairs, triplets, and quadruplets of molecules that differed by\n     single methyl group additions and deletions. FIG. 12A-12F depicts six\n     molecules, each processed by a model. The molecules are displayed in their\n     most active predicted poses (chosen by the model) with a Connolly surface.\n     M. J. Connolly, J. Appl. Cryst., 16, 548 (1983). The patches on each\n     surface correspond to the set of features selected by the model. The\n     surface has an acceptable steric interaction if it has a gray patch at\n     that location. White patches indicate areas that should be increased in\n     size, and black patches indicate areas whose size should be decreased.\n<BR><BR>The method's ability to provide detailed guidance in molecular design is\n     demonstrated in FIGS. 12A-12F. Only black, gray and white patches are\n     shown in these figures since color patches cannot be reproduced in patent\n     drawings. FIGS. 12A-12D display four molecules in their predicted poses as\n     chosen by a model trained on the remaining ninety-eight molecules. Each\n     molecule is displayed as a Connolly surface. The relative musk odor\n     strength of these four hold-out molecules is known. The patches on each\n     surface correspond to the features selected by the model during training.\n     The surface has a good steric interaction if it has a gray patch at that\n     location. White patches indicate areas that should be increased in size,\n     and black patches indicate areas whose size should be decreased. FIG. 12A\n     displays a correctly predicted inactive molecule, and the white patches\n     suggest that activity could be increased by adding bulk near the arrow\n     (corresponding to area A in FIG. 11). FIG. 12B shows the molecule\n     resulting from the addition of a methyl group at this point, correctly\n     predicted to have musk odor. From this molecule, which has only moderate\n     musk odor intensity, the indicated region (corresponding to area B of FIG.\n     11) is predicted to benefit from additional bulk. Either adding a methyl\n     group to the aromatic ring, shown in FIG. 12C, or changing the methyl\n     group added to FIG. 12A to an ethyl, achieves this result. Both the\n     molecules in FIGS. 12C, 12D have greater musk odor than molecule in FIG.\n     12B, as predicted.\n<BR><BR>FIGS. 12E, 12F show the application of another model, constructed by\n     withholding the pair of molecules shown. FIG. 12A, the black patches\n     suggest an unfavorable interaction (indicated by the arrow). This can be\n     directly remedied by removal of the corresponding methyl group. The result\n     is a correctly predicted molecule with strong musk odor, shown in FIG.\n     12B. Another approach is to remove the methyl substituent on the aromatic\n     ring that is responsible for the ketone's unfavorable orientation. This\n     results in a molecule of medium musk strength (not shown). Several other\n     examples of guided design on molecules from different structural classes\n     in this data set were observed.\n<BR><BR>What follows is a detailed description of predictive model generation from\n     a set of molecules and assay values. We first discussed the surface\n     representation, then the neural-network learning algorithm, then the\n     adaptive alignment procedure. Consider a molecule in a particular\n     conformation at a particular location and orientation in space. This\n     situation is defined by the internal torsion angles of the rotatable\n     bonds, and the three rigid rotations and translations. This mathematically\n     defines the pose of the molecule. From each pose p of a molecule m, we\n     generate a high-dimensional vector of features V(m,p) for purposes of\n     activity prediction. Each element of the feature vector characterizes a\n     portion of the smoothed van der Wall's surface of the molecule.\n<BR><BR>Our goal is to predict the activity of a molecule as a function of the\n     feature vector. However, because there are infinitely many poses of\n     molecule, there are infinitely many feature vectors. Let A(V(m,p) denote\n     the predicted activity of molecule m in pose p. The predicted activity for\n     m is defined to be the maximum of these predictions over all possible (low\n     energy) poses: Max.sub.low energy p A(V(m,p)). In chemical terms, this is\n     analogous to permitting the molecule to rotate, translate and alter its\n     conformation to achieve the best possible fit to the binding site.\n<BR><BR>To achieve this maximization, we conduct a conformational search for each\n     molecule to identify its low-energy conformations. Each of these\n     conformers is placed in a starting pose, and the learning algorithm is\n     applied to construct a model A(V(m,p)). For the application reported here,\n     initial poses were chosen such that their aromatic rings were tightly\n     aligned and their oxygens were properly positioned to form a hydrogen bond\n     with an assumed H-bond donor atom (34, 35). This produced an acceptable\n     coarse alignment of the molecules. The model computes a weighted sum of\n     non-linear functions, which can be cascaded, whose parameters can be\n     estimated to achieve a mapping from input molecular features to an output\n     activity value. The activity of musks was encoded as 0.982 and the\n     activity of non-musks was encoded as 0.018. A molecule was predicted to be\n     a musk if the model computed its activity to be greater than 0.5. Such\n     models are called neural networks because of the analogy to biological\n     neural networks where the \"neurons\" compute non-linear functions based on\n     weighted and summed input (\"synaptic connections\") from other neurons. Our\n     model is of the form:\n     ##EQU4##\n     where F, G are non-linear functions. The vectors v.sub.j, j=0 . . . m and\n     w.sub.k, k=l . . . n are vectors of adjustable weights. The set P is the\n     set of poses generated thus far. The model is trained by an iterative\n     weight adjustment procedure that seeks to minimize error using\n     gradient-based search, called error back-propagation. D. E. Rumelhart, G.\n     E. Hinton, R. J. Williams, in \"Parallel Distributed Processing:\n     Explorations in the Microstructure of Cognition,\" D. E. Rumelhart, J. L.\n     McClelland, and the PDP Research Group, Eds. (MIT Press/Bradford,\n     Cambridge, Mass. 1986), Vol. 1: Foundations. For each molecule, only the\n     pose giving the highest predicted activity (using the current model) is\n     used to update the weight vectors.\n<BR><BR>In each iteration, after the neural network model has been trained, it is\n     applied to each molecule m.sub.i to find the pose p.sub.i that maximizes\n     the predicted activity of m.sub.i by performing rigid rotations and\n     translations. This is accomplished by computing the gradient of the\n     predicted activity with respect to the pose and employing gradient search\n     methods. The poses computed in this fashion for the active molecules are\n     precisely those poses that serve to confirm the model--they cause the\n     active molecules to align more tightly with each other along those\n     portions of the molecular surface that are important for activity\n     prediction. The poses computed for inactive molecules are precisely those\n     poses that best refute the model. Hence, we see that this algorithm\n     applies a simple form of the scientific method of conjecture and\n     refutation until a model is found that cannot be refuted. To attain\n     convergence, at most five iterations of model-building and pose generation\n     were required. The advantage of this approach is that only a small\n     fraction of the infinite space of possible poses needs to be explicitly\n     considered, and yet the resulting model is robust with respect to a much\n     wider range of poses of the molecules. It also makes good use of negative\n     data.\n<BR><BR>This adaptive approach to posing molecules is a major departure from\n     previous methods. Any method that attempts to measure subtle shape\n     differences among molecules must measure molecular properties (e.g.,\n     interatomic distances, occupancy of binding sites) that vary with pose.\n     Previous methods assume that the correct poses of molecules can be\n     selected before a predictive model is constructed. Models constructed from\n     standard fixed poses may not give accurate predictions for new molecules.\n     New molecules must be placed in the appropriate pose based on intuition or\n     ad hoc procedures that may behave poorly, especially with molecules from\n     novel structural classes. Our approach, in contrast, uses the constructed\n     model to guide the generation of the correct poses, so that molecules are\n     aligned along those surface regions that are most predictive of activity\n     differences.\n<BR><BR>We have demonstrated a new method for activity prediction and molecular\n     design using a surface-based representation of molecular shape that\n     exhibits high predictivity and extrapolates well across structural\n     classes. Automatic selection of conformations and adaptive alignment of\n     molecules was shown to substantially improve predictive performance.\n     Three-dimensional visualization of models guided structural changes of\n     molecules that enhanced biological activity. The surface-based molecular\n     representation yielded excellent cross-class predictive performance, a\n     capability which is critical for advancing drug design into new structural\n     classes. The model was able to resolve the effects of very subtle surface\n     changes.\n<BR><BR>Where the known activities of the molecules are expressed in quantitative\n     terms, the above-described model can be readily applied using the\n     quantitative known activities. Where the activities are non-numerical,\n     such as in the musk study above, musk strength prediction is somewhat\n     complicated. The reported strengths are discrete non-numerical values; for\n     example, \"extremely strong\" and \"fairly weak.\" There are about ten such\n     values. How do we map \"medium strength\" to a number?\n<BR><BR>We could use an arbitrary mapping, like \"odorless\" is 0.1 and \"very weak\"\n     is 0.2 and \"weak\" is 0.3, and so on. But there is a potential problem.\n     There is, in some sense, a \"right\" answer. Assuming no hidden units, the\n     output is essentially a linear sum of the feature inputs. There may not be\n     any linear weighting that gets very close to an arbitrary assignment of\n     numbers to strengths. The curve is kinked. The system will devote a lot of\n     effort to trying to unkink it.\n<BR><BR>As an alternative, we let the system figure out what the true assignment of\n     discrete categories to numerical values is. The target value for each\n     category is initialized arbitrarily, with correct ordering, as above. But\n     then it can float. We backpropagate the error term for each category into\n     the target value for the category. So, during training, we periodically\n     look at the output of the model for all the \"medium\" musks and take the\n     average, say 0.56. Then we adjust the target for \"medium\" molecules from\n     its current value (say 0.52) in the direction of the average. This reduces\n     the error for all the medium molecules (since the error is computed as the\n     difference between the actual and target values).\n<BR><BR>The learning rate parameter for this backpropagation has to be set low, so\n     that the system does not thrash trying to fix gross errors in the model by\n     adjusting the target values.\n<BR><BR>It may be necessary to permanently wire the extreme values (\"odorless\" and\n     \"extremely strong\") to 0.1 and 0.9 to avoid having the system reduce error\n     by collapsing the scale.\n<BR><BR>It is possible that for various reasons (e.g., bad assays), even with a low\n     learning rate the targets could cross (so that, e.g., \"medium\" got to be\n     higher than \"fairly strong\"). We could fix this by adding a 1/r.sup.2\n     \"repulsive force\" to the targets, so that in the target update phase as\n     two targets got close to each other, they would be held apart. (This would\n     also have the side effect of preventing scale collapse.)\n<BR><BR>This level of indirection between the reported assay values and the\n     system's target values can also be used to make assay values reported from\n     different sources commensurable. This applies to both numerical and\n     non-numerical assays. Commonly, one paper in the literature will report\n     assay values for one set of molecules and another paper will report assay\n     values for another set. Particularly, if the sets are disjoint, these\n     values may not be commensurable, since the assays typically were performed\n     under somewhat different conditions. Now, we have the correct ordering for\n     the assay values on a per-source basis (and also the within-source\n     relative magnitudes, in the case of numerical data). The target-score\n     adjustment code will respect that, but between papers, one can let the\n     system do as it pleases and decide, for example, that one paper is 0.05 is\n     equivalent to other's 2.7.\n<BR><BR>Generality of the Invention\n<BR><BR>Two aspects of the invention described above, the method of iterative\n     reposing objects to produce better models and the method of training a\n     model when each object has multiple representations, are applicable not\n     only to biological activity modeling but also to many other problems\n     including handwriting recognition. We illustrate this with the task of\n     handwritten character recognition.\n<BR><BR>Computer methods for automatically recognizing handwritten characters would\n     be extremely useful in several fields including the reading of zip codes\n     on envelopes, dollar amounts on personal checks, and handwritten\n     characters on pen-based computers. An accepted way of representing\n     handwritten letters for automated recognition is to take a digital picture\n     of each letter. The picture represented in the computer by, for example, a\n     16.times.16 grid of binary values (a part of which is shown in FIG. 13).\n     These two hundred fifty-six values become the features that can be input\n     into a general purpose classification algorithm, such as a neural network.\n     As with the molecules discussed above, each character can be defined to\n     have a \"pose.\" For example, a character can rotate or translate in two\n     dimensions as well as be scaled larger or smaller. The pose of a character\n     can be defined by a set of parameters (e.g., two rotational parameters,\n     two translational parameters, and one scale parameter).\n<BR><BR>Let us first consider how the general machine learning method of learning\n     from multiple representations could be applied to this task. Suppose we\n     wish to automatically recognize instances of the letter `A.` A training\n     set could be constructed consisting of a large number of digitized\n     handwritten `A`s as well as a large number of other characters and symbols\n     from which the `A`s need to be discriminated. Then the general procedure\n     shown in FIG. 14 could be applied.\n<BR><BR>First (block 200), a neural network model for `A` could be initialized.\n     Each of the N different characters and symbols forms a training object.\n     Then (block 202), for each object in the training set, a set of poses\n     could be generated by computing several different combinations of\n     rotations, translations, and scalings of each character (set 1, . . . ,\n     set N). Features (e.g. 256 values in a 16 by 16 grid) would be extracted\n     (block 204) and then the neural network model would be applied to predict\n     whether each of the representative poses was an instance of the letter `A`\n     (block 206). Based on the predicted scores, one or more best\n     representative poses of each object in the training set would be selected,\n     and the neural network model would be trained to predict correctly whether\n     each pose was an instance of the letter `A..degree. If the model and the\n     choices of best representations do not change substantially from previous\n     iterations (block 21), then the process terminates. Otherwise, the current\n     model is applied to all of the poses of each object in the training set\n     (block 206) to again select one or more best representations for each\n     object.\n<BR><BR>Once the model and the choice of representations converges, the learned\n     model can be applied to predict whether or not new objects are instances\n     of the letter `A` (block 212). The same procedure could be applied to\n     construct recognizers for each of the other letters of the alphabet, the\n     digits, punctuation symbols, and so on.\n<BR><BR>Now that we have described how the general machine learning method could be\n     applied to character recognition, let us consider how the method of\n     dynamic reposing (not shown in FIG. 14) could also be applied to this\n     problem. The method is exactly analogous to FIG. 7. As above, we begin\n     with a training set consisting of a large number of digitized handwritten\n     `A`s as well as a large number of other characters and symbols from which\n     the `A`s need to be discriminated. Rather than generating many different\n     poses of each character, we would compute initial poses by rotating,\n     translating, and scaling the characters in the training set so that they\n     all had approximately the same orientation and size. This corresponds to\n     block 100 of FIG. 7. Then a neural network training procedure is carried\n     out (blocks 108, 110). After training the model, the key component of this\n     aspect of the invention would be applied. The current trained model would\n     be used to guide the reposing of each of the training set characters\n     (block 112) in an attempt to maximize the predicted output of the neural\n     network (i.e., to maximize the likelihood that the network would predict\n     that each character was an `A`). The resulting poses would then be used as\n     input for another iteration of retraining the model. This process would be\n     repeated until the model and the poses ceased to change significantly.\n<BR><BR>To apply the learned model to determine whether a new character is an\n     instance of the letter `A` (block 16), the new character would be reposed\n     to maximize the predicted output of the neural network. If this predicted\n     output exceeded a preset threshold, the character would be classified as\n     an `A,` otherwise it would be not be classified as an `A.` If several\n     models had been learned (e.g., one for each letter), then the new\n     character would be reposed separately for each model, and the model that\n     gave the highest predicted output would be applied to classify the new\n     character.\n<BR><BR>As with molecules, the advantage of this aspect of the invention over prior\n     methods is that rather than attempting to classify the characters in their\n     starting poses (which are somewhat arbitrary), the invention reposes the\n     characters so that they adopt poses most informative for recognition\n     (i.e., poses that accentuate those aspects of the letter `A` that are\n     shared among all instances of `A`s and not shared by instances of other\n     characters).\n<BR><BR>It will be understood that these two aspects of the invention do not\n     require that a neural network learning procedure be employed. They can be\n     applied with any procedure that constructs predictive models. It will also\n     be understood that these two aspects of the invention are not limited to\n     problems of assigning objects into a discrete set of classes (e.g., active\n     vs. inactive, `A` vs. `B` vs. `C` etc.). The methods can also be applied\n     to tasks, such as drug activity prediction, in which the model must\n     predict a real-valued property of the objects.\n<BR><BR>The invention has been described by reference to various embodiments. It\n     will be understood that various modifications and changes may be made\n     without departing from the scope of the invention which is to be limited\n     only by the appended claims.\n<BR><BR><CENTER><B>* * * * *</B></CENTER>\n<HR>\n</BODY>\n</HTML>", "encoding": "ascii"}