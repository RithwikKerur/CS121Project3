{"url": "https://www.ics.uci.edu/~eppstein/161/960220.html", "content": "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 3.2//EN\">\n<html>\n<head>\n<title>Strong connectivity</title>\n<meta name=\"Owner\" value=\"eppstein\">\n<meta name=\"Reply-To\" value=\"eppstein@ics.uci.edu\">\n</head>\n<body>\n<h1>ICS 161: Design and Analysis of Algorithms<br>\nLecture notes for February 20, 1996</h1>\n\n<!--#config timefmt=\"%d %h %Y, %T %Z\" -->\n<hr>\n<p></p>\n\n<h1>Strongly connected components</h1>\n\n<h2>Strong connectivity and equivalence relations</h2>\n\nIn undirected graphs, two vertices are connected if they have a\npath connecting them. How should we define connected in a directed\ngraph? \n\n<blockquote>We say that a vertex a is <i>strongly connected</i> to\nb if there exist two paths, one from a to b and another from b to\na.</blockquote>\n\nNote that we allow the two paths to share vertices or even to share\nedges. We will use a ~ b as shorthand for \"a is strongly connected\nto b\". We will allow very short paths, with one vertex and no\nedges, so that any vertex is strongly connected to itself. \n\n<p><a name=\"rel\">Recall that a <i>relation</i> is another word for\na collection of pairs of objects (if you like, you can think of a\nrelation as being a directed graph, but not the same one we're\nusing to define connectivity). An <i>equivalence relation</i> a # b\nis a relation that satisfies three simple properties:</a></p>\n\n<ul>\n<li style=\"list-style: none\"><a name=\"ref\"></a></li>\n\n<li><b>Reflexive property</b>: For all a, a # a. Any vertex is\nstrongly connected to itself, by definition. <a name=\"sym\">\n</a></li>\n\n<li><b>Symmetric property</b>: If a # b, then b # a. For strong\nconnectivity, this follows from the symmetry of the definition. The\nsame two paths (one from a to b and another from b to a) that show\nthat a ~ b, looked at in the other order (one from b to a and\nanother from a to b) show that b ~ a. <a name=\"trans\"></a></li>\n\n<li><b>Transitive property</b>: If a # b and b # c, then a # c.\nLet's expand this out for strong connectivity: if a ~ b and b ~ c,\nwe have four paths: a-b, b-a, b-c, and c-b. Concatenating them in\npairs a-b-c and c-b-a produces two paths connecting a-c and c-a, so\na ~ c, showing that the transitive property holds for strong\nconnectivity.</li>\n</ul>\n\nSince all three properties are true of strong connectivity, strong\nconnectivity is an equivalence relation. \n\n<p>Note that it was critical for our definition that we allowed the\npaths a-b and b-a to overlap. If we made a small change such as\ndefining two vertices to be connected if they are part of a\ndirected cycle, we wouldn't be able to concatenate the paths and\nshow that the transitive property holds.</p>\n\n<h2>Equivalence classes and strongly connected components</h2>\n\nFor any equivalence relation a # b, we can define <i>equivalence\nclasses</i> by the formula \n\n<pre>\n    [a] = { b | a # b }\n</pre>\n\n(in English, the equivalence class of a, which we call \"[a]\", is\ndefined to be simply the set of things related to a). The\nequivalence classes for strong connectivity are called <i>strongly\nconnected components</i>. \n\n<p>These sets have the property that they partition the space of\nall vertices into disjoint subsets.</p>\n\n<p>(This is not hard to prove. First, any vertex a is a member of\n[a] by reflexivity, so the equivalence classes cover all of the\ninput. And second, if b is in [a] then [a]=[b] (by symmetry and\ntransitivity, any element of one is an element of the other) so any\ntwo different equivalence classes must be disjoint.)</p>\n\n<p>If we can find all the strongly connected components of a graph,\nit would be easy to test whether any two vertices are strongly\nconnected: just see if they're in the same component.</p>\n\n<h2>Component graph and weak connectivity</h2>\n\nStrongly connected components also have a use in other graph\nalgorithms: if you replace every strongly connected component by a\nsingle vertex, you get a smaller directed acyclic graph, known as\nthe <i>component graph</i> or <i>condensation</i> (Baase ex. 4.42\nasks you to prove this fact.) \n\n<p>For some graph problems, you can use this idea to get an\nalgorithm that reduces the problem to subproblems on each\ncomponent, plus one more subproblem on the component graph. Here's\nan example (this problem isn't in Baase, and I didn't get to this\nin my lecture, so I won't test you on it):</p>\n\n<p>Suppose we define two vertices a and b to be <i>weakly\nconnected</i> (also known as <i>semiconnected</i>) if there's\neither a path from a to b or one from b to a (but not necessarily\nboth). We say the graph is weakly connected if this is true for\nevery pair of vertices. Then it's not hard to show that a graph is\nweakly connected if and only if its component graph is a path. So\nby computing the strongly connected components, we can also test\nweak connectivity.</p>\n\n<h2>Computing a single component</h2>\n\nFrom the definition above, it is easy to find a single strongly\nconnected component [x]. Simply use BFS, DFS, or any other similar\nalgorithm to find a set S of all vertices reachable from x by a\npath. Do the same thing in the graph formed by reversing all the\nedges of our original graph, to find a set T of all vertices that\ncan reach x by a path. According to the definition above, [x] is\njust the intersection of S and T. \n\n<p>So in O(m) time we can find a single component. Since there are\nO(n) components, we can find them all in time O(mn). But this\nslower than necessary. The point of today's lecture is to show how\nto solve the problem in linear time. (The solution we describe,\nbased on depth first search, was invented by <a href= \n\"people.html#tarjan\">Bob Tarjan</a> in 1972. Baase ex. 4.50\noutlines an alternative linear time algorithm.)</p>\n\n<h2>Depth first search again</h2>\n\nA tangent on pseudo-code: I haven't been writing the same\npseudocode as in the book for the same reason I haven't been\nspeaking the same sentences in the book. The ideas matter, the\nexact pseudocode doesn't. So if you're asking which should I\nmemorize, the book or the lecture the answer is neither, you should\nget to understand them to the point where they seem like the same\nidea and remember that idea. With that in mind, here's pseudocode\nfor DFS (directed graph version) that looks a little different from\nwhat we did last time. \n\n<p>One complication (that I forgot to mention in lecture) is that\nwe want to build a DFS tree that involves all the vertices of the\ngraph. If we just start somewhere in the graph, not all vertices\nmight be reachable, and the DFS will not get to them. One solution\nwould be to restart the DFS every time this happens, but to make\nthings a little simpler, I'm going to modify the graph by adding a\nnew vertex connected by outward-going edges to everything else.\nThis doesn't change the strongly connected components (except to\nadd one new component for the one new vertex) but keeps the rest of\nthe algorithm simpler.</p>\n\n<pre>\n    DFS(G)\n    {\n    make a new vertex x with edges x-&gt;v for all v\n    build directed tree T, initially a single vertex {x}\n    visit(x)\n    }\n\n    visit(p)\n    {\n    for each edge p-&gt;q\n        if q is not already in T\n        {\n        add p-&gt;q to T\n        visit(q)\n        }\n    }\n</pre>\n\n<a name=\"edges\">This version of the pseudo-code makes it obvious\nthat only certain edges can occur: if q is not already in T,\np-&gt;q gets added, so if p-&gt;q does not end up in tree, q must\nbe already in tree. There are three possible places q could be: an\nancestor of p (in which case we call p-&gt;q a <i>back edge</i>), a\ndescendant of p (in which case we call p-&gt;q a <i>forward\nedge</i>), or in a previous branch of the tree (in which case we\ncall p-&gt;q a <i>cross edge</i>). The one case that's ruled out is\nthat q can not be in a later branch of the tree.</a> \n\n<h2>DFS trees and strongly connected components</h2>\n\nThe key property, that relates DFS to strong connectivity, is that\nstrongly connected components form subtrees of the DFS tree. (In\nother words, a component can not be in two separate parts of the\ntree.) \n\n<p>Why?</p>\n\n<p>Note that if we have paths a-b and b-a, any two intermediate\nvertices of those paths would have to be also in the same component\n(since e.g. if we have a-c-b then we already have a path a-c and by\nconcatenating c-b-a we also get a path c-a).</p>\n\n<p>So suppose one component ended up in two parts of the tree. Then\nit would have to have edges from one part to the other (the\ndefinition of strong connectivity tells us there must be paths, but\nthe observation above about intermediate vertices being part of the\nsame component tells us they would actually just be edges).</p>\n\n<p>The two parts couldn't be in side by side branches of the tree,\nbecause there would be no edges in one of the two directions. But\non the other hand, if one part contains an ancestor x of a vertex y\nin the other part, we can use the argument above about intermediate\nvertices to show that the path in the tree from x to y is also in\nthe same component, contradicting the assumption that x and y are\nin different parts of the tree. So it is not possible to have a\ncomponent in two separate parts of the DFS tree, which is what we\nwanted to prove.</p>\n\n<h2>Heads of components</h2>\n\nSince the components of the graph are just subtrees of the DFS\ntree, to find components, we just have to break tree at certain\nedges, and the components will be formed by what's left of the\ntree. We'll say a vertex is a \"head\" of a component if it's the\ntopmost (i.e. if we should break the edge coming into it). By the\nobservations above, the problem has turned into one of determining\nwhether a given vertex v is a head. \n\n<p>To test this, look at the subtree of the DFS tree, rooted at v.\nSuppose this subtree does not have any back or cross edges going\nout of it. Then clearly, v must be the head of [v], since there are\nno paths from v to any vertex higher in the tree.</p>\n\n<p>Just as clearly, if there is a back edge u-w from this subtree\nto an ancestor of v, v is not a head. In this case, the edge u-w\ntogether with the paths in the DFS tree from w to v and from v to u\nform a cycle, which must all be part of the same component [v]. But\nw is higher in the tree than v, so v can not be the head of this\ncomponent.</p>\n\n<p>The complicated case happens when the only edges going out of\nthe subtree rooted at v are cross edges to other branches of the\nDFS tree. To make this complicated case a little easier, we'll set\nup our algorithm so that as soon as the DFS finishes visiting a\nvertex, if it is a head, we delete it and its component from the\ngraph. We can show that if our algorithm does this, then whenever\nwe see a cross edge out of the subtree from v, v is not a head.</p>\n\n<blockquote>Proof: This is where we use the fact that DFS trees\nhave cross edges only to previously visited branches of the tree,\nnot to later branches. Suppose we see a cross edge u-w. Let z be\nthe head of [w], then z is visited no later than w. If z were in a\nseparate branch of the tree, we'd have finished visiting it and\ndeleted both it and w, contradicting the assumption that we're\nseeing edge u-w. So z is an ancestor of v, and putting edge u-w\ntogether with the paths w-z (by assumption that z is the head of\n[w]), z-v (since z is an ancestor of v) and v-u (since v is an\nancestor of u) gives us a cycle, showing that v is in [z] and\ntherefore v is not a head.</blockquote>\n\nSummarizing, we see that we can test whether a vertex is a head by\nlooking for the existence of back or cross edges out of its\nsubtree. \n\n<h2>Strong connectivity algorithm</h2>\n\nDefine the <i>DFS numbering</i> dfsnum(v) to be the number of\nvertices visited before v in the DFS. Then if there is a back or\ncross edge out of the subtree of v, it's to something visited\nbefore v and therefore with a smaller dfsnum. We use this by\ndefining the <i>low value</i> low(v) to be the smallest dfsnum of a\nvertex reachable by a back or cross edge from the subtree of v. If\nthere is no such edge, low(v)=dfsnum(v). Then rephrasing what we've\nseen so far, v is a head of a component exactly when\nlow(v)=dfsnum(v). The advantage of using these definitions is that\ndfsnum(v) is trivial to calculate as we perform the DFS, and low(v)\nis easily computed by combining the low values from the children of\nv with the values coming from back or cross edges out of v itself. \n\n<p>We use one more simple data structure, a stack L (represented as\na list) which we use to identify the subtree rooted at a vertex. We\nsimply push each new vertex onto L as we visit it; then when we\nhave finished visiting a vertex, its subtree will be everything\npushed after it onto L. If v is a head, and we've already deleted\nthe other heads in that subtree, the remaining vertices left on L\nwill be exactly the component [v].</p>\n\n<p>We are now ready to describe the actual algorithm. It simply\nperforms a DFS, keeping track of the low and dfsnum values defined\nabove, using them to identify heads of components, and when finding\na head deleting the whole component from the graph, using L to find\nthe vertices of the component.</p>\n\n<pre>\n    DFS(G)\n    {\n    make a new vertex x with edges x-&gt;v for all v\n    initialize a counter N to zero\n    initialize list L to empty\n    build directed tree T, initially a single vertex {x}\n    visit(x)\n    }\n\n    visit(p)\n    {\n    add p to L\n    dfsnum(p) = N\n    increment N\n    low(p) = dfsnum(p)\n    for each edge p-&gt;q\n        if q is not already in T\n        {\n        add p-&gt;q to T\n        visit(q)\n        low(p) = min(low(p), low(q))\n        } else low(p) = min(low(p), dfsnum(q))\n\n    if low(p)=dfsnum(p)\n    {\n        output \"component:\"\n        repeat\n        remove last element v from L\n        output v\n        remove v from G\n        until v=p\n    }\n    }\n</pre>\n\nWe have already seen an explanation for why this algorithm works.\nIt only remains to point out that it takes linear time -- the basic\nframework is just DFS, and the added manipulations of low, dfsnum,\nand L do not slow this down at all. So we can find strongly\nconnected components in linear time. \n\n<hr>\n<p><a href=\"/~eppstein/161/\">ICS 161</a> -- <a href=\"/\">Dept.\nInformation &amp; Computer Science</a> -- <a href= \n\"http://www.uci.edu/\">UC Irvine</a><br>\n<small>Last update: \n<!--#flastmod file=\"960220.html\" --></small></p>\n</body>\n</html>\n\n", "encoding": "ascii"}