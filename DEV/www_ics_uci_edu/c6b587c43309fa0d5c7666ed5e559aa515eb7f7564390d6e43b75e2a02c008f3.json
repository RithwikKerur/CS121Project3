{"url": "https://www.ics.uci.edu/~pattis/ICS-33/lectures/functionalprogramming.txt", "content": "\t\t\tFunctional Programming\r\n\r\nFunctional programming is a style of programming that uses the simplicity and\r\npower of functions to accomplish programming tasks. Some talk about the\r\nfunctional programming paradigm. They contrast it with the more standard\r\nimperative paradigm (which includes both the procedural and object-oriented\r\nstyles). Functional programs fundamentally evaluate expressions to compute\r\ntheir results; imperative programs fundamentally execute statements to compute\r\nresults (which often mutate data structures and rebind the values of names\r\n-which purely functional programming prohibits).\r\n\r\nIn a purely functional solution to a problem, there will be no mutation to data\r\nstructures (instead of mutating one, a new one is built/returned, with the\r\nrequired changes: just as we have seen with strings, which are immutable), and\r\nrecursion (not looping) is the primary control structure. Functions are called\r\n\"referentially transparent\": given the same inputs, they always produce the same\r\nresult; we can always replace a function call with its ultimately returned\r\nresult. Whether or not a computation occurs doesn't affect later computations\r\n(it has no side-effects, just a returned result; it examines/sets no global\r\ndata, just is arguments). \r\n\r\nA certain class of functions, called tail-recursive (we will illustrate them\r\nin more detail below), can be automatically translated into non-recursive\r\nfunctions that run a bit faster and do not use extra memory space for call\r\nframes: each recursive function call occupies space for its parameter. Most\r\npurely functional languages recognize and implement tail-recursive functions by\r\ndoing this translation; Python does NOT (at least not yet; but then again in\r\nPython we can write our own iterative solution).\r\n\r\nFunctional languages easily support and frequently use the passing of functions\r\nas arguments to other functions (these other functions are called \"higher-order\"\r\nfunctions or functionals) and functions being returned from other functions as\r\ntheir values; we have seen both of these features used in Python, which does\r\nsupport these features well (better than C++ and Java), and we will see more\r\nuses of these features in this lecture.\r\n\r\nThere are programming languages that are purely function (Haskell), others that\r\nare mostly functional (ML -whose major implementations are SML and OCaml; the\r\nScheme dialect of Lisp; and Erlang), and still others that at least support a\r\nfunctional style of programming (some better, some worse) when it is useful.\r\nPython is in this latter category, although features like comprehensions in\r\nin Python emphasize its functional programming aspects (generators and even\r\nlambdas fall into this category too).\r\n\r\nGenerally, functional programming is characterized as using immutable objects\r\nand no state changes (we bind names only once, allowing us to repeatedly refer\r\nto a data structure, but do not rebind them). Ints, strings, tuples, and\r\nfrozensets are all immutable objects in Python (which means we can use their\r\nvalues as keys in dicts and values in sets), but lists, sets, dicts, and\r\ndefaultdicts are all mutable (and therefore cannot be used these ways in sets\r\nand dicts). Note i = i + 1 mutates no objects: it  does rebind i to an int\r\nobject storing a value that is one bigger.\r\n\r\nIn functional programming, we don't change data structures, but instead produce\r\nnew ones that are variants of the old ones. For example, if we want to \"change\"\r\nthe first value (at index 0) of a tupel t to 1, we instead create a new tuple\r\nwhose first values is 1 and whose other values are all the other values\r\noriginally in the tuple, using the concatenation operator. The new tuple is\r\nconstructed as (1,)+t[1:]; note that we need the comma in (1,) to distinguish\r\nit from (1): the former is a tuple containing the value 1, the later is just a\r\nparenthesized int.\r\n\r\nFunctional programming creates lots of objects and must do so in a time and\r\nspace efficient way, and for the most part, functional languages achieve parity\r\nin time/space efficiency with imperative programming languages (functional\r\nprograms can be a bit slower, but they are often clearer/simpler/easier to both\r\nunderstand and modify). Mixed paradigm languages like Python tend not to be as\r\nefficient when used functionally as true functional languages. Emerging\r\nmulti-paradigm languages like Scala and Clojure are closing the gap. Also,\r\nbecause of the simplicity of the semantics of functional programming, it is\r\neasier to automatically transform functional programs to run more efficiently\r\nin parallel, on cluster or multi-core computers.\r\n\r\nMost functional programming languages are also statically type-safe. Before\r\nprograms are executed they are compiled (staticaly type-checked). If they\r\ntype-check correctly, the system executing them can be guaranteed that all\r\noperators and functions will be applied to the correct number and type of\r\narguments; if not the compiler will report where errors like these are\r\ndetected -the same errors that Python would find only when it runs the code:\r\nstatic type-checking occurs before any code runs. Contrast this with Python,\r\nwhich often discovers inappropriate argument types while running programs\r\n(at runtime), not before running them. For example, a relational operator may\r\nfind it cannot compare two values: a Python program containing 1 < \"1\" will\r\nrun in Python, until Python gets to that code; in statically type-checked \r\nlanguage (including Java and C++), such an error would be reported BEFORE a\r\nprogram is run. Of course there can still be other kinds of errors (not\r\ntype-related) in functional programs: e.g., using a + operator where a * is\r\nneeded; same for Python.\r\n\r\nFunctional programming languages are still not as widely used as imperative\r\nlanguages, but they continue to find many uses in industry, and in some\r\nindustries (telecommunications) they have achieved dominance (at least with\r\nsome companies within the industries). Programmers who are trained to use\r\nfunctional languages think about problems and solve problems differently. All\r\nCS students should be exposed to functional programming as part of their\r\neducation (and I mean an exposure longer than one day, or even a few weeks).\r\nSome schools use functional programming languages in their introduction to\r\nprogramming courses.\r\n\r\nTo learn more about Python's use of functional programming, read section 10\r\n(Functional Programming Modules) in Python's Library documentation, discussing\r\nthe itertools, functools, and the operator modules. Some of this material is\r\ndiscussed in more detail below.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nMap/Transform, Filter, Reduce/Accumulate:\r\n\r\nWe start this lecture by looking at just three important higher-order functions\r\nused repeatedly in functional programming: map (aka transform), filter, and\r\nreduce (aka accumulate). In Python, each operates on a function and an iterable,\r\nwhich means they can operate on lists and tuples easily (because they are\r\niterable), but also on iterables that don't store all their values and just\r\nproduce values as necessary (e.g., the ints and primes generators).\r\n\r\nWe will write recursive and generator versions of each, with the recursive\r\nversions having list parameters and returning list results, because many\r\nfunctional programing languages use only lists, not tuples, but lists that are\r\nimmutable in these languages: a base case for both lists and tuple is\r\nlen(x) == 0: instead of x == []  or x == ().\r\n\r\n(1) map/transform: this function takes a unary function and some list/iterable\r\n    of values and produces a list/iterable of mapped/transformed values based on\r\n    substituting each value with the result of calling the parameter function\r\n    on that value. For example, calling\r\n\r\n   map_l(lambda x : x**2, [i for i in irange(0,5)])\r\n\r\ntakes a list as a second argument and produces a list as a result: a list of\r\nthe squares of the values of the numbers 0 to 5: [0,1,4,9,16,25]. Calling\r\n\r\n   map_i(lambda x : x**2, irange(0,5))\r\n\r\ntakes a more general iterable as a second argument and produces an iterable as\r\na result: an iterable of the squares of the values of the numbers 0 to 5.\r\n\r\nSo, the value produced is a generator that we can iterate over. If we wrote\r\nlist(map_i(lambda x : x**2, irange(0,5))) Python would return the same result\r\nas for map_l because it would construct a list by iterating over the iterable\r\nthat map_i returned. But if we wrote\r\n\r\n    for i in map_i(lambda x : x**2, irange(0,5)):\r\n        do something with i\r\n\r\nNo list would ever be produced when executing the for loop (just as no list\r\nwould be produced with executing: for i in range(0,5): ...).\r\n\r\nNote that lambdas are frequently (but not exclusively) used in calls to the map\r\nfunction: often we need to use a small, simple function once, which we can most\r\neasily write as a lambda. But, we can pass it any object that is callable,\r\nincluding function objects and class objects that implement __call__.\r\n\r\nHere are simple implementations of the list/iterator versions of this map. For\r\nmap_l we define a recursive verion; map_i is a generator\r\n\r\ndef map_l(f,alist):\r\n    if alist == []:\r\n        return []\r\n    else:\r\n        return [f(alist[0])] + map_l(f,alist[1:])\r\n\r\nNote: no local variables and no mutation: the + operator builds a new list from\r\ntwo existing ones. In languages that do not have comprehensions, this is the\r\nstandard definition. In Python, which has powerful comprehensions, we could\r\nalso write it more simply as\r\n\r\ndef map_l(f,alist):\r\n    return [f(i) for i in alist]\r\n\r\nHere is the map_i function, which is a simple generator.\r\n    \r\ndef map_i(f,iterable):\r\n    for i in iterable:\r\n        yield f(i)\r\n\r\nNote that Python actually defines its map implementation to be a generator (so\r\nit is closer to map_i than map_l):\r\n\r\n y = map(lambda x : x**2, irange(0,5))\r\n print(y)\r\n\r\nprints\r\n\r\n <map object at 0x02C42BF0>\r\n\r\nThis result is similar to printing the result of calling a generator function\r\n(which produces a generator object). It returns an object that we can iterate\r\nover.\r\n\r\nAgain, we can use a list/tuple/set constructor to turn such a map object into an\r\nactual list/tuple/set: it iterates through the values produced by map and\r\ncollects these values in a list/tuple/set.\r\n\r\n print(list(y))\r\n\r\nprints\r\n\r\n  [0, 1, 4, 9, 16, 25]\r\n\r\nIn fact, the real map defined in Python is generalized to work on any number of\r\nlists/iterables. If there are n iterables, then the function f must have n\r\nparameters. So, if we called the real map function in Python (which as we've\r\nseen, produces an iterable) as\r\n\r\n  print(   list( map(lambda x,y: x*y, 'abcde', irange(1,5)) )   )\r\n\r\nprints\r\n\r\n  ['a', 'bb', 'ccc', 'dddd', 'eeeee']\r\n\r\nHow does Python define map for these arbitrary number of arguments? It uses zip,\r\nwhich is actually a generator itself (returning something that is iterable). So\r\nwe can define Python's map function as a version of map_i generalized to\r\narguments with multiple iterables.\r\n\r\ndef map(f,*iterables):\r\n    for args in zip(*iterables):\r\n        yield f(*args)\r\n\r\nRecall that writing *iterables/*args INSIDE the body of a function/generator\r\ncall separates all the tuple components into positional arguments; writiing\r\n*iterables in map's header combines any number of positional arguments into a\r\nsingle tuple.\r\n\r\nagain, print( map(lambda x,y: x*y, 'abcde', irange(1,5)) )\r\n\r\nprints like <map object at 0x02C36EF0>.\r\n\r\n\r\n(2) filter: this function takes a predicate (a unary function returning a bool,\r\nalthough in Python most values have a bool interpretation: recall the __bool__\r\nmethod) and some list/iterable of values and produces a list/iterable with only\r\nthose values for which the predicate returns True (or a value that is\r\ninterpreted as True by the __bool__ method defined in its class). For example,\r\ncalling\r\n\r\n   import predicate\r\n   filter_l(predicate.is_prime, [i for i in irange(2,50)])\r\n\r\nproduces a list of the values between 2 and 50 inclusive that are prime:\r\n[2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47].\r\n\r\nHere are simple implementations of the list/iterator versions of this function.\r\nAgain for filter_l we define a recursive verion; filter_i is a generator.\r\n\r\ndef filter_l(p,alist):\r\n    if alist == []:\r\n        return []\r\n    else:\r\n        if p(alist[0]):\r\n            return [alist[0]] + filter_l(p,alist[1:])\r\n        else:\r\n            return filter_l(p,alist[1:])\r\n\r\nNote: no local variables and no mutation: + build a new list from existing ones.\r\nWe can simplify a bit, by using a conditional expression and noting that\r\n[] + alist = alist\r\n\r\ndef filter_l(p,alist):\r\n    if alist == []:\r\n        return []\r\n    else:\r\n        return ([alist[0]] if p(alist[0]) else [])   +   filter_l(p,alist[1:])\r\n\r\nIn languages that do not have comprehensions, this is the standard definition.\r\nIn Python, which has comprehensions, we could also write it as\r\n\r\ndef filter_l(p,alist):\r\n    return [i for i in alist if p(i)]\r\n\r\nHere is the filter_i function, which is a simple genrator.\r\n\r\ndef filter_i(p,iterable):\r\n    for i in iterable:\r\n        if p(i):\r\n            yield i\r\n\r\nNote that Python defines its filter like filter_i: it produces a generator when\r\ncalled.\r\n\r\ny = filter(predicate.is_prime, irange(2,50))\r\nprint(y)\r\n\r\nprints like <filter object at 0x02C42BF0>.\r\n\r\nAgain, we can use a list/tuple/set constructor to turn such a map object into an\r\nactual list/tuple/set: it iterates through the values produced by filter and\r\n\r\nprint(list(y))\r\n\r\nprints\r\n\r\n  [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47]\r\n\r\n\r\n(3) reduce/accumulate: this function is different than the previous two: it\r\ntakes a binary function and some list/iterable of values and typically produces\r\na single value: it REDUCES or ACCUMULATES its arguments into a single value. \r\n\r\nUnlike map and filter (which are defined and automatically imported from the\r\nbuiltins module) we must import reduce from the functools module explicitly.\r\n\r\nOnce we write \r\n\r\nfrom functools import reduce\r\n\r\ncalling\r\n\r\n  reduce(lambda x,y : x+y, irange(1,100))\r\n\r\nreturns the sum of all the values in the irange iterable. Here is a more\r\ninteresting call, because uses a non-commutative operator (subtraction).\r\n\r\n  reduce(lambda x,y : x-y, [1,2,3])\r\n\r\nwhich returns -4: or 1 - 2 - 3 or (1-2)-3. Technically, this is called LEFT\r\nreduction/accumulation because the operators are applied left to right. If\r\nthey had been applied right to left (right reduction), the result would have\r\nbeen 1-(2-3) = 1 - (-1) = 2. For all commutative operators, the association\r\norder doesn't make a difference. That is, (1+2)+3 is the same as 1+(2+3). So\r\nfor 5 values, the reduce is equivalent to (((1+2)+3)+4)+5.\r\n\r\nNote that Python's operator module defines a variety of functions like add\r\n(which has the same meaning as lambda x,y: x+y) so we could also call this\r\nfunction as reduce(operator.add, irange(1,100)), if we had imported operator.\r\nOther standard Python operators appear in this module as well. See Section 10.3\r\nof the Python documentation for more details.\r\n\r\nLikewise, we can also call reduce(boolean.__and__, iterable) to compute the same\r\nvalue as all(iterable) and reduce(boolean.__or__, iterable) to compute the same\r\nvalues as any(iterable). In fact, we can also use the operator module to name\r\nthese functions: operator.and_/operator.or_ (notice the trailing underscore,\r\nbecause the words or/and already have meaning as logical operators in Python).\r\n\r\nThe operator module also includes itemgetter, which is a function that takes any\r\nnumber of arguments and returns a function that can be called on any object\r\nimplementing __getitem__: for example, operator.itemgetter(n) returns a function\r\nthat can select the nth item in a list: operator.itemgetter(1)([1,2,3]) returns\r\n2, like [1,2,3][1] or [1,2,3].__getitem__(1). Likewise,\r\noperator.itemgetter(0,2) returns a function that can select both the 1st and 3rd\r\nitem in a list: operator.itemgetter(0,2)([1,2,3]) returns (1,3); note that it\r\nreturns a tuple. So itemgetter is useful when sorting on data using multiple\r\nkeys: instead of writing sorted(iterable, key = lambda x : (x[1],x[0]}) we can\r\nwrite it more simply as sorted(iterable, key = itemgetter(1,0)).\r\n\r\nThe function attrgetter does the same thing with attributes instead of items:\r\noperator.attrgetter(attr)(object) returns the same value as either\r\neval('object.'+attr) or object.__dict__[attr]. If c refers to an object with\r\nattributes a and b, then calling operator.attrgettr('a','b')(c) returns a tuple\r\nequivalent to (c.a, c.b).\r\n\r\nWe have seen code examples where sum all the 0 indexes of a list (l) of\r\n2-tuples:\r\n\r\nsum( x for x,_ in l )\r\n\r\nThis code is very compact because if uses a Python tuple comprehension. We can\r\nalso write this code functionally (without Python's tuple comprehension) as\r\n\r\nsum ( map( operator.itemgetter(0), l) )\r\n\r\nwhich maps each 2-tuple in l to the value at its 0 index, and then sums them.\r\n\r\nHere is another interesting example. Assume that we define a simple max\r\nfunction to return the bigger of its two values.\r\n\r\ndef max(x,y):\r\n    return x if x > y else y    # if x == y returns y, the same as returning x\r\n\r\nThen, calling\r\n\r\n  reduce(max, [4,2,-3,8,6])\r\n\r\nis equivalent to max(max(max(max(4,2),-3),8),6) which evaluates (left to right)\r\nas follows, to compute the maximum of the entire list of values.\r\n\r\nmax(max(max(max(4,2),-3),8),6) -> max(max(max(4,-3),8),6) ->\r\nmax(max(4,8),6) -> max(8,6) -> 8\r\n\r\nHere is a simplified definition of reduce that illustrates its typical behavior\r\non good arguments: it assumes that iterable has at least one value (which it\r\nreturns, if there are no more values in the iterable).\r\n\r\ndef reduce(f,iterable):\r\n    i = iter(iterable)\t\t  # create iterator\r\n    a = next(i)\t\t\t  # get its first value\r\n    while True:\t\t\t  # while (to process more values in iterator)\r\n        try:\t\t\t  #   try (to determine if more values)\r\n            a = f(a,next(i))\t  #     get next:f combines with previous result\r\n        except StopIteration:\t  #   when no more values in iterator\r\n            return a\t\t  #     return reduced/accumulated result\r\n\r\nIt is also possible to write this function more simply as follows, since a call\r\nto iter(i) returns i when i is already an iterator. Here, the loop \"for j in i:\"\r\nbinds j, one at a time, to all the REMAINING VALUES FROM i (all values after\r\nthe first, which is explicitly stored in a).\r\n\r\ndef reduce(f,iterable):\r\n    i = iter(iterable)\t\t  # create iterator\r\n    a = next(i)\t\t\t  # get first value\r\n    for j in i:\t\t\t  # iterate over all remaining valuse in i\r\n        a = f(a,j)\t          #   using j/f combines with previous result\r\n    return a\t\t\t  # return reduced/accumulated result\r\n\r\nHand simulate calls to reduce(max,[1]), reduce(max,[2,1]), reduce(max,[1,2]), \r\netc. to ensure you understand how this code works for 1/2-list, how the loop\r\neventually stops, and how the function computes the correct value. Note that\r\nthis function raises a StopIteration exception if the iterable is empty: the\r\nfirst call to next(i) will raise a StopException which is not handled (because\r\nit is not in the nested try/except). \r\n\r\nThe actual implementation of reduce allows the programmer to specify what value\r\nto return for an empty iterable, and is a bit more complicated: e.g., it\r\nrequires two nested try/except statements. It allows either 2 or 3 arguments:\r\nthe first must be a binary function (which we will still call f), the second\r\nmust be an iterable (which we will still call iterable), and the third (if\r\npresent) is called the UNIT (aka initializer for the reduction/accumulation).\r\n\r\nIf the iterable has no values, the unit is returned if it is supplied,\r\notherwise map raises a special TypeError (not StopIteration) exception. Also,\r\nif the unit is specified, it is considered to be the implicit first value in\r\nthe iterable. All these semantics are captured in the following function, which\r\nhas the core of the previous reduce, but allows for this new behavior based on\r\nthe optional third argument.\r\n\r\ndef reduce(f,*args):\r\n    if not (1 <= len(args) <= 2): # if undecodedable arguments\r\n        if len(args) < 1:\r\n            raise TypeError('reduce expected at least 2 arguments, got '+str(len(args)))\r\n        else:\r\n            raise TypeError('reduce expected at most 3 arguments, got '+str(len(args)))\r\n\r\n    iterable = args[0]\r\n\r\n    i = iter(iterable)            # create iterator\r\n    try:                          # try (to handle empty iterator if no unit)\r\n        a = args[1] if len(args) == 2 else next(i)\r\n                                  # use unit or get first value\r\n        while True:               # while (to process more values in iterator)\r\n            try:                  #   try (to determine if more values)\r\n                a = f(a,next(i))  #     get next/f combines with previous result\r\n            except StopIteration: #   when no more values in iterator\r\n                return a          #     return reduced/accumulated result\r\n    except StopIteration:         # empty iterator (with no unit): raise exception\r\n        raise TypeError('reduce() of empty sequence with no initial value') from None\r\n        \r\nNote that\r\n  reduce(operator.add, [])     raises a TypeError Exception\r\n    TypeError: reduce() of empty sequence with no initial value\r\n  reduce(operator.add, [],  0) returns  0 (the unit)\r\n  reduce(operator.add, [5])    returns  5\r\n  reduce(operator.add, [5], 0) returns  5 (the unit, 0, + the first value)\r\n  reduce(operator.add, [5], 5) returns 10 (the unit, 5, + the first value)\r\n\r\nNote the \"from None\" in the last line. If we raise an exception while handling\r\nan exception in Python, both exceptions appear in the trace. But the TypeError\r\nexception is what we want to communicate (the StopIteration exception was just\r\nhow we know there is a problem) so by including \"from None\" it instructs Python\r\nto remove the StopIteration exception from the trace.\r\n\r\nThere is only one verion of this function, because it produces a single answer,\r\nso we don't need separate list/iterable versions. There is a simple recursive\r\ndefinition of the reduce function operating on lists (here shown with a mandated\r\nunit to keep this function simple), but it uses RIGHT reduction/accumulation,\r\nwhich as we saw for commutative operators produces the same result. \r\n\r\ndef right_reduce_l(f,alist,unit):\r\n    if alist = []:\r\n        return unit\r\n    else:\r\n        return f( alist[0], right_reduce(f,alist[1:],unit) )\r\n\r\nHere are three concrete examples of a functional style of programming, using\r\nmap, filter, and reduce. The first expression computes the length of the longest\r\nline in a file. \r\n\r\nreduce(max,\t\t\t\t\t# reduce uses max on...\r\n       map(lambda l : len(l.rstrip()),\t\t# map uses lambda (length of stipped line) on ...\r\n           open('file')))\t\t\t# an open file\r\n\r\nSo, we use open('file') as the iterable to map, which maps each line to its\r\nlength; the result of this call is used as the iterable to reduce, which reduces\r\nall these line lengths to the single maximum length.\r\n\r\nThe second example returns the longest line, not the length of the longest line,\r\nwe could alter the computation slightly, as follows.\r\n\r\nreduce(lambda x,y: x if len(x) >= len(y) else y,\r\n       map(lambda l : l.rstrip(),\r\n           open('file')))\r\n\r\nHere we still use open('file) as the iterable to map, but the lambda to map now\r\njust strips spaces off the right end, but doesn't map lines to their lengths.\r\nThe lambda for reduce (whose arguments will be two lines from the file) returns\r\nthe longer of the two lines by computing and comparing the len of each; when\r\nreduced over all lines in the file, the final result is the longest line in the\r\nfile. If multiple lines are longest, the one appearling earliest will be the\r\nresult (because of >=).\r\n\r\nThe third example returns a list of all the lines that were the longest. For\r\nthis we need to define a more complex reduction function, which would be\r\nconfusing as a lambda:\r\n\r\ndef list_of_lines_reduce(lofl : [str], l :  str) -> [str]:\r\n    if len(l) > len(lofl[0]):\r\n        return [l]\r\n    elif len(l) == len(lofl[0]):\r\n        return lofl+[l]\r\n    else:\r\n        return lofl\r\n\r\nThis function assumes that lofl is a list of lines; it looks at the new line\r\nand either returns a list with just that line (if th new line is longer);\r\nreturns a list of the previously computed lines concatenated with a list of\r\nthat line (if the new line is as long as the longest); returns a list of the\r\npreviously computed lines (if the new line is the smaller).\r\n\r\nWe would call that function as \r\n\r\nreduce(list_of_lines_reduce,\r\n       map(lambda l : l.rstrip(),\r\n           open('file')),\r\n       [''])\r\n\r\nHere [''] is the 3rd/unit argument: a list with the smallest line in it. If\r\nthe file had no lines, this would be the returned result.\r\n\r\nFinally, we could further enhance this example by using filter to discard some\r\nlines: lines that are comments starting with the # character. We would call\r\nthis function as\r\n\r\nreduce(list_of_list_reduce,\r\n       filter(lambda l : len(l) == 0 or l[0] != '#',\r\n              map(lambda l : l.rstrip(),\r\n                  open('file'))),\r\n       [''])\r\n\r\nHere lines of length 0 are allowed, as are lines with more than 0 characters\r\nthat don't start with a '#' (we have to check the length to ensure the indexing\r\nis legal). This function is equivalent to one that filters before maps:\r\n\r\nreduce(list_of_list_reduce,\r\n       map(lambda l : l.rstrip(),\r\n          filter(lambda l : l[0] != '#',\r\n                 open('file'))),\r\n       [''])\r\n\r\nBy doing the filter before rstrip, we know every line has it least one\r\ncharacter: even the empty line has a '\\n' in it.\r\n\r\nOften the form of such a function combines all aspects; one example is:\r\n\r\n  reduce(r_func, map(m_func, filter(f_func, iterable)))\r\n\r\nwhich reduces all the mapped values that make it through filter. The\r\nfunctional programming idiom of mapping the result of a filter is already\r\nmore easily captured in Python's comprehension, so we could rewrite this code\r\nas\r\n\r\n  reduce(r_func, (m_func(i) for i in iterable if f_func(i)))\r\n\r\nFunctional programmers spend a lot of time using these tools (and writing lots\r\nof functions) to build up their idioms of expressions. We are just peeking at\r\nthis topic now. For example, it is possible for reduce to return all types of\r\nresults, not just simple ones: there are, for example, ways to reduce lists of\r\nlists to produce just lists.\r\n\r\n------------------------------------------------------------------------------\r\n\r\nStructural Recursion, Accumulation, and Tail Recursion\r\n\r\nSo far, in all the recursive methods that we have written, the form of recursion\r\nis based on the structure of the data the function is processing. Typically we\r\nrecur on a substructure (same type of structure but smaller in size: like\r\nsubstrings and sublists created via slicing) until we reach its base case: the\r\nsmallest size of that data structure. This is called structural recursion (a\r\nmore general form or recursion is called generative recursion, which we will\r\nbriefly discuss after this section). A typical example of structural recursion\r\nis the list_sum function below.\r\n\r\ndef list_sum (l : [int]) -> int:\r\n    if l == []:\r\n        return 0\r\n    else:\r\n        return l[0] + list_sum(l[1:]) # 1st value + sum of all following values\r\n\r\nA directly recursive function is TAIL-RECURSIVE if the the result the function\r\nreturns in a recursive call is exactly the value computed by the recursive call,\r\nNOT MODIFIED IN ANY WAY. Notice that the list_sum function is NOT tail-recursive\r\nbecauses it returns l[0] plus the result of the recursive call, not just the\r\nrecursive call itself. In the previous lecture, the only function that was\r\ntail-recursive was the same_length function, shown below:\r\n\r\ndef same_length(s1,s2):    \r\n    if s1 == '' or s2 == '':\r\n        return s1 == '' and s2 == ''\r\n    else:\r\n        return same_length(s1[1:],s2[1:])\r\n\r\nHere, non-empty strings have the same length if their substrings without their\r\nfirst characters have the same length.\r\n\r\nWe can sometimes transform structually recursive functions into tail-recursive\r\nfunctions by using an accumulator: an extra parameter that accumulates the\r\nanswer: each recursive call passes an updated accumulator downward in the\r\nrecusive call (as illustrated in the hand simulations in class); the function\r\neventually returns all the accumulated information in the base case. The\r\nfunction is tail-recursive, because it returns just the result of a recursive\r\ncall (but with the accumulator argument updated).\r\n\r\nOften we compute such a recursive function by defining and calling a nested\r\nfunction, which has an extra accumulation parameter.\r\n\r\nHere is how we can transform the list_sum function into a function using an\r\naccumulator, which results in a tail-recursive function.\r\n\r\ndef list_sum ( l : [int] ) -> int:\r\n\r\n    def sum_tail(alist : [int], acc : int)\r\n        if alist == []:\r\n            return acc\r\n        else:\r\n            return sum_tail( alist[1:], alist[0]+acc )\r\n\r\n    return sum_tail(l,0)\r\n\r\nThe result of calling the single parameter list_sum(l) function is computed by\r\nreturning the result of calling the two parameter sum_tail(l,0) function (this\r\nis NOT a function returning a helper function: it is a function returning the\r\nvalue computed by calling a helper function).\r\n\r\nThe sum_tail function returns the value accumulated in acc when its list\r\nparameter is empty; otherwise is performs structural recursion while increasing\r\nacc by the amount of the first value in the list (which is not processed again\r\nin the recursive call, because it is omitted from the slice).\r\n\r\nNotice that in the call sum_tail(l,0) the 0 is like the unit in the reduce\r\nfunction: it is the starting point for adding/accumulating values. Each\r\nrecursive call adds the front of the remaining values in the list to acc: the\r\nsum to that point; when we reach the empty list, all values from the original\r\nlist have been added into acc. Here think of the recursion going downward (as\r\nillustrated in the hand simulation in class) with acc incremented in each\r\nrecursive call; the last/base function call returns the accumulated result, and\r\neach function call above it returns the value returned by its recursive call,\r\npassing to the top the value returned by this last/bottom recursive call, when\r\nthe base case is processed.\r\n\r\nWe can transform any tail-recursive function into an iterative one by using a\r\nwhile loop whose test is the opposite of the one for the base case, and whose\r\nbody updates the parameter names in the same way that they would be updated by\r\nperforming the recursive function call (binding parameters to arguments); after\r\nthe body of the loop is a return statement returning the value in acc, the\r\naccumulator. We can transform sum_tail as follows.\r\n\r\ndef list_sum ( l : [int] ) -> int:\r\n\r\n    def sum_tail(alist : [int], acc : int)\r\n        while alist != []:\r\n            alist, acc = alist[1:], alist[0] + acc # mirrors the recursive call\r\n        return acc\r\n\r\n    return sum_tail(l,0)\r\n\r\nIn fact, we can simplify the code for list_sum by omitting the call to the\r\nnested function, instead executing the code in its body prefaced by the initial\r\nassignment to its parameters: l and 0. We can transform list_sum as follows (I\r\nnow abbreviate alist by al)\r\n\r\ndef list_sum (l : [int]) -> int:\r\n    al,acc = l,0\t                # mirrors the initial call of sum_tail\r\n    while al != []:\r\n        al,acc = al[1:], al[0] + acc    # mirrors the recursive call to sum_tail\r\n    return acc\r\n\r\nAll tail-recursive functions can be transformed similarly, running more\r\nefficiently (in time and space) than their equivalent recursive functions.\r\n[Note: slicing in Python is actually an expensive operation, but the equivalent\r\nto slicing in functional languages can be much more efficient: the object sliced\r\nand the slice object cannot be mutated so the slice object can share the\r\nstructure of the sliced object, not have to copy it, as Python does.]\r\n\r\nHere is this tail-recursive transformation done on the recursive same_length\r\nfunction\r\n\r\ndef same_length(s1,s2):    \r\n    while s1 != '' and s2 != '':   # execute only if both s1 and s2 aren't empty\r\n        s1, s2 = s1[1:], s2[1:]    #   slice each to ignore first value\r\n    return s1 == '' and s2 == ''   # at least one empty; return are both empty\r\n\r\nIMPORTANT: Every programmer should know how to negate complicated expressions\r\nwith and/or operators:\r\n\r\nDeMorgan's laws (negate each subepression and interchange and <-> or):\r\n  not (a and b) -> not(a) or  not(b)\r\n  not (a  or b) -> not(a) and not(b)\r\n\r\nThe if test in the recursive same_length is s1 == '' or s2 == ''. We can use\r\nDeMorgan's laws to negate it for the tail-recursive loop:\r\n\r\nnot (s1 == ''  or  s2 == '')      -> (by deMorgan's law for or)\r\nnot (s1 == '') and not(s2 == '')  -> simplifying not(a == b) to a != b twice\r\ns1 != ''       and s2 != ''\r\n\r\nOf course, we could always write the while loop as while True and keep the\r\nrecursive test the same in\r\n\r\ndef same_length(s1,s2):    \r\n    while True:\r\n        if s1 == '' or s2 == '':\r\n            break\r\n        s1, s2 = s1[1:], s2[1:]\r\n    return s1 == '' and s2 == ''\r\n\r\n------------------------------------------------------------------------------\r\n\r\nAn example of Generative Recursion Example\r\n\r\nSuppose that a country has certain standard stamp denominations. We can\r\nrepresent all the denominations in a tuple. For example, (1,6,14,57), meaning\r\nthere are 1 cent, 6 cent, 14 cent, and 57 cent stamps for this country.\r\n\r\nNow, suppose that we want to write a function named mns (Minimum Number of\r\nStamps) that computes the minimum number of stamps needed for any amount of\r\npostage. The parameters for this function will be the amount of postage and a\r\ntuple specifying the stamp denominations that are legal for that country.\r\n\r\nFor example, calling mns(22, (1,6,14,57)) returns 4 (note 22 = 14+6+1+1) and\r\nthere is no other combination summing to 22 that requires fewer than 4 stamps).\r\n\r\nYou might think to compute this number by using as many of the biggest\r\ndenomination stamps as you can, then as many of the next biggest denomination\r\nstamps as you can, ..., until you have put on enough stamps. But look at 18\r\ncents postage. The approach just mentioned would need 5 stamps: 18 = 14+1+1+1+1,\r\nbut the minimum number of stamps is 3: 18 = 6+6+6. So this \"biggest first\" \r\napproach to solving the problem doesn't always produce the minimum number of\r\nstamps.\r\n\r\nLet's write mns using recursion. We will assume that the amount of postage is\r\ninitially a non-negative number (and ensure that it is a smaller, non-negative\r\nnumber in all recursive calls). The base case for this problem is postage of 0,\r\nwhich requires 0 stamps.\r\n\r\ndef mns(amount : int, denom : (int)) -> int:\r\n    if amount == 0:\r\n        return 0\r\n    else:\r\n        Recur to solve a smaller problem(s)\r\n        Use the solution of the smaller problem(s) to solve the original\r\n          problem: amount (denom will stay the same in all recursive calls)\r\n\r\nFor the recursive part, we will try each denomination: reducing the amount by\r\nthat denomination and computing the minimum number of stamps needed for the\r\nchoice/reduced amount. Then, we will find which denomination leads to the\r\nminimum number of stamps for the reduced amount. The minimum number of stamps\r\nneeded for the original amount is 1 (for a stamp of the tried denomination) +\r\nthat number (the minimum). There is one more wrinkle: we cannot use any\r\ndenomination that is bigger than amount: that would lead to negative amount\r\n(postage) in a recursive call, which we will prevent from happening.\r\n\r\nSo, for computing mns(18, (1,6,14,57)) we would compute the following three\r\nvalues by doing recursive calls to solve subproblems\r\n\r\n  mns(17, (1,6,14,57))  if we used a  1 cent stamp (17 is the subproblem)\r\n  mns(12, (1,6,14,57))  if we used a  6 cent stamp (12 is the subproblem)\r\n  mns( 4, (1,6,14,57))  if we used a 14 cent stamp ( 4 is the subproblem)\r\n\r\nbut not\r\n\r\n  mns(-39, (1,6,14,57)) because we cannot use a 57 stamp: it is too big.\r\n                        the subproblem (-39) it produces is not legal.\r\n\r\nIf we computed the correct values for this subproblems, we would compute the\r\nfollowing values through various recursive calls that we do not have to think\r\nabout: it's elephants all the way down. \r\n\r\n  mns(17, (1,6,14,57))  returns 4\r\n  mns(12, (1,6,14,57))  returns 2\r\n  mns( 4, (1,6,14,57))  returns 4\r\n\r\nWe then compute the minimum of the returned recursive calls, adding one to it\r\nfor the stamp denomination that we used (whether it was 1, 6, or 14 makes no\r\ndifference when computing the NUMBER of stamps; each choice uses 1 stamp).\r\n\r\n  1 + min( [4, 2, 4] ) which computes 3\r\n\r\nWhat is ultimately says is that the minimum number of stamps needed is 1\r\n(for the subproblme 18-4, using a 4 cent stamp) plus the minimum number of\r\nstamps to solve that subproblem: its 2, the smallest of all the solved\r\nsubproblems.\r\n\r\nThe following code using recursion, iteration, and a comprehension to build a\r\nlist of the minimum number of stamps needed for amount minus each denomination,\r\nif the denomination no bigger than the amount.\r\n\r\n  [mns(amount-d,denom) for d in denom if amount-d >= 0]\r\n\r\nIt says, for each denomination d, if amount-d >= 0 (meaning d <= amount, so\r\nthe denomination is legal to use, since the recursive call will have a\r\nnon-negative -possibly 0- first argument), compute mns(amount-d,denom) and put\r\nit in the list. Remember we get to ASSUME that all recursive calls to mns\r\nreturn the correct answer (it's elephants all the way down). We need to take\r\nthese solutions and solve the original problem, which we do by adding 1 to\r\nthe smalles \"minimum number of stamps\" needed for the solved subproblems.\r\n\r\nNow we need to compute the minimum of all these values, and return that value\r\nplus 1. We can do that by passing the list to the min function. (see * below)\r\n\r\ndef mns(amount : int, denom : (int)) -> int:\r\n    if amount == 0:\r\n        return 0\r\n    else:\r\n        return 1 + min( [mns(amount-d,denom) for d in denom if amount-d >= 0] )\r\n\r\nThis solution is quite elegant, although it can take a long time to run for\r\na large amount with many denominations in the tuple. In the next lecture, we\r\nwill learn how to speed-up this computation using caching/memoization: a\r\ndecorator that remembers the solutions to various smaller subproblems that are\r\nsolved over and over again in this recursive solution. This is sometimes\r\nreferred to as dynamic programming, and is most useful with recursive solutions\r\nto problems, when the same small subproblems need to be solved many times (it\r\nactually solves them just once, and remembers the solutions for use when needed,\r\nrather than spendig the time to recalculate them). We will illustrate another\r\nrecursive function that has this problem, one computing fibonnaci numbers.\r\n\r\nSee the stamps_basic.py and stamps_extended.py modules for code and a script to\r\nrun the code. The extended version computes the actual stamps needed for the\r\npostage(Stamps needed for the Minimum Number of Stamps; see Problem 8 below):\r\n\r\n   smns(11, (1,6,14,57)) returns [1, 1, 1, 1, 1, 6]\r\n   smns(18, (1,6,14,57)) returns [6, 6, 6]\r\n   smns(37, (1,6,14,57)) returns [1, 1, 1, 6, 14, 14]\r\n\r\n*Note that calling the min function assumes there is it least one value in the\r\nlist comprehension. If there is always a 1 cent stamp in the denominations this\r\nwould be true; if not, then calling mns(1, denominations) would raise an\r\nexception, because min would be called on an empty list.\r\n\r\n*Note too that if the amount is less than the minimum denomination, there is no\r\nsolution. If there is always a 1 cent stamp in the denominations there will\r\nalways be a solution.\r\n\r\nWe can deal with these two issues by putting the following line at the front of\r\nthe function:\r\n\r\nassert denom != () and (amount == 0 or min(denom) <= amount),\\\r\n  f'No solution with denom({denom}) and amount({amount}).'\r\n\r\n------------------------------------------------------------------------------\r\n\r\nPartial function evaluation (read this lightly)\r\n\r\nThe functools module in Python includes a function named partial that allows us\r\nto decorate a function by pre-supplying specified arguments (both positional\r\nand keyword); it returns a function that we can call more easily, with fewer\r\narguments: it combines both the actual arguments and the pre-supplied ones to\r\ncall the function. This kind of decoration is called a PARTIALLY EVALUATING a\r\nfunction.\r\n\r\nFirst let's look at how we can use such a tool and then we will learn how it is\r\nwritten in Python's functools module. We start by defining a simple function\r\nthat we will partially evaluate, which has two parameters: level and message. It\r\njust prints the values of these parameters in a special format.\r\n\r\ndef log(purpose, message):\r\n    print('[{p}]: {m}'.format(p=purpose, m=message) )\r\nor\r\n    print(f'[{purpose}]: {message}')\r\n\r\nNow we will show how to partially evaluate this function using the first and\r\nthen the second argument.\r\n\r\n----------\r\nPartially evaluating with the 1st argument\r\n\r\nSuppose that we want a function named debug to act like log, but have only one\r\nargument (message); the argument matching purpose will always be 'debug'. That\r\nis, the debug function logs messages whose purpose is always for debugging. We\r\ncan specify debug as follows, supplying the argument 'debug' to the purpose\r\nparameter positionally.\r\n\r\nfrom functools import partial\r\nx = 1\r\ndebug = partial(log, 'debug')     # in log, 'debug' is 1st positional argument\r\n\r\nNow, calling debug calls the log function always supplying 'debug' as the first\r\npositional argument. So, we can call debug with one argument, like\r\n\r\ndebug('Beginning function f')  #call log with 'debug' as 1st positional argument\r\ndebug(message = 'x = '+str(x)) #call log with 'debug' as 1st positional argument\r\n\r\nwhich prints\r\n\r\n  [debug]: Beginning function f\r\n  [debug]: x = 1\r\n\r\nHere, calling debug('some message') is like calling log('debug','some message').\r\n\r\nWe can also use partial to specify debug as follows, writing purpose = 'debug',\r\nwhich specifies a keyword argument.\r\n\r\ndebug = partial(log, purpose = 'debug')  # In log, 'debug' is a keyword argument\r\n\r\nNow, we can call debug with one argument, but it must be supplied as a keyword\r\nargument.\r\n\r\ndebug(message = 'Beginning function f') #call log with 'debug' matching purpose\r\ndebug(message = 'x = '+str(x))          #call log with 'debug' matching purpose\r\n\r\nwhich prints the same as above\r\n\r\n  [debug]: Beginning function f\r\n  [debug]: x = 1\r\n\r\nCalling debug(message='some message') is like calling\r\nlog(purpose='debug',message='some message'). Notice that in this case if we\r\ncalled debug with the message positionally, as debug('some message') it would\r\nbe like calling log('some message',purpose='debug'), which Python would report\r\nby raising the TypeError exception, because the first positional argument would\r\nmatch the purpose parameter, and the keyword argument matches the same parameter\r\nname. Python would report\r\n\r\n TypeError: log() got multiple values for argument 'purpose'\r\n\r\n----------\r\nPartially evaluating with the 2nd argument\r\n\r\nNow suppose that we want a function named notify to act like log, but have only\r\none argument (purpose) with the argument matching message always being 'Notify'.\r\nThat is, the notify function logs messages that are the same. We can specify\r\nnotify as follows, supplying the argument 'Notify' to the message as a keyword\r\nparameter only.\r\n\r\nfrom functools import partial\r\nx = 1\r\nnotify = partial(log, message='Notify') #In log, 'Notify' is a keyword argument\r\n\r\nNow, notify calls the log function always supplying 'Notify' as the first\r\nargument. So, we can call notify with one argument, like\r\n\r\nnotify('debug')                        # call log with 'Notify' matching message\r\nnotify(purpose = 'log')                # call log with 'Notify' matching message\r\n\r\nwhich prints\r\n\r\n  [debug]: Notify\r\n  [log]: Notify\r\n\r\nCalling notify('some purpose') is like calling\r\nlog('some purpose',message='Notify') and calling notify(purpose='some purpose')\r\nis like calling log(purpose='some purpose',message='Notify').\r\n\r\nWe CANNOT do this kind of partial evaluation using partial(log, 'Notify')\r\nbecause positionally purpose is the first parameter to log, not message. So\r\nthat is why there is a difference in partially evaluating the first vs. second\r\nparameter to a function.\r\n\r\n----------\r\nTwo more examples:\r\n\r\nLet's illustrate a few more interesting uses of partial evaluation before\r\nshowing the Python code that defines this function. It isn't hard to define\r\nthese two functions conventionally, but it is simple to use the partial\r\nfunction.\r\n\r\n(1) Suppose that we wanted a function that returns the index of character in a\r\nstring of vowels (and -1 if it is not a vowel). We could write.\r\n\r\nfrom functools import partial\r\nvowel_index = partial(str.find,'aeiou')\r\n\r\nCalling vowel_index('i') returns 2; calling vowel_index('z') returns -1.\r\n\r\nIn fact, we can write\r\n\r\nfrom functools import partial\r\nvowel_index = partial('aeiou'.find)\r\n\r\nand get the same results, because Python actually translates 'aeiou'.find into\r\npartial(str.find,'aeiou') by the Fundamental Equation of Object-Oriented\r\nProgramming: using partial to specify the self parameter.\r\n\r\nFinally, we could also just use a lambda to write this same function directly\r\nvowel_index = lambda to_check : 'aeiou'.find(to_check)\r\n\r\n(2) Suppose that we wanted a function that returns whether or not all characters\r\nin a text string argument matches the pre-specified description of an integer\r\nwith an optional sign. We could write.\r\n\r\nfrom functools import partial\r\nimport re\r\nis_int = partial(re.match,'[+-]?\\d+$')\r\n\r\nthen calling is_int('+33') would return a match object, but is_int('33+') would\r\nreturn None (it does not match).\r\n\r\nIf we wanted to reverse this, and instead write a function that returns whether\r\nor not its regular expression argument matches all the characters in a\r\npre-specified text string. We could write\r\n\r\nfrom functools import partial\r\nimport re\r\nis_match = partial(re.match,string=\"+33\")\r\n\r\nBecause string is the second parameter, we must specify it as named. Then,\r\ncalling is_match('[+-]?\\d+$') would match (returns a match object) but\r\nis_match('\\d+$') would not (returns None).\r\n\r\nAll these simple examples use partial evaluation on functions that have just a\r\nfew arguments. For functions with very many arguments, the usefulness of partial\r\nincreaseds Here is one more example that uses partial to partially evaluate\r\nthe print function, which has a few named parameters. Here p_on_line is print\r\nwith sep and end both pre-specified as empty strings.\r\n\r\np_on_line = partial(print, sep='', end='')\r\n\r\ncalling\r\n\r\np_on_line(1,2,3)\r\np_on_line(4,5,6)\r\n\r\nprints: 123456\r\n\r\nFinally, we could also just use a lambda to write this same function directly as\r\n\r\np_on_line = lambda *args : print(*args,sep='',end='')\r\n\r\n----------\r\n\r\nDefining partial as a Python function\r\n\r\nFinally, let's look at how we can simply define (although the code is a bit\r\nsubtle) the partial function in Python. Here is its defintion and explanation\r\nof how it works.\r\n\r\ndef partial(func, *args, **kargs):              # bind pre-specified arguments\r\n    def p_func(*pargs, **pkargs):               # bind the arguments in call\r\n        p_kargs = kargs.copy()\t\t\t# copy kargs dict (from partial)\r\n        p_kargs.update(pkargs)\t\t\t# update it: add pkargs dict\r\n        return func(*(args + pargs), **p_kargs) # call the original function\r\n    return p_func\t     \t     \t\t# return a reference to p_func\r\n\r\nFundamentally, partial takes arbitrary positional (*args) and keyword (**kargs)\r\narguments; it defines a local function and returns a reference to it. When the\r\nlocal function is called (after partial returns it) it takes the positional\r\narguments (*pargs) it is passed and appends them after the *args passed to\r\npartial; it takes the keyword arguments (**pkargs) it is passed and uses them\r\nto update the copy of a keyword dictionary that is a copy of the **kargs one\r\noriginally passed to partial. When it calls func, it takes the appended tupled\r\n(*args + *pargs) and expands it to positional arguments and the updated p_kargs\r\ndictionary and expands it to keyword arguments.\r\n\r\nIn fact, the actually definition of partial in Python is more like the\r\nfollowing.\r\n\r\ndef partial(func, *args, **kargs):              # bind pre-specified arguments\r\n    def p_func(*pargs, **pkargs):               # bind the arguments in call\r\n        p_kargs = kargs.copy()\t\t\t# copy kargs dict (from partial)\r\n        p_kargs.update(pkargs)\t\t\t# update it: add pkargs dict\r\n        return func(*(args + pargs), **p_kargs) # call the original function\r\n    p_func.func      = func\t\t\t# Remember (in a queryable form)\r\n    p_func.args      = args\t\t\t#   all arguments to partial:\r\n    p_func.keywords  = kargs\t\t\t#   func, args, and kargs\r\n    return p_func     \t\t\t\t# return a reference to p_func\r\n\r\nIn this version we add three attribute names to the p_func function object that\r\nis returned, recording useful information for it, which we can query. Function\r\nobjects, like all other object, can have attibutes. So if we wrote\r\n\r\ndebug = partial(log, \"debug\")\r\nprint(debug.func, debug.args, debug.keywords)\r\n\r\nPython would print: <function log at 0x02CCA780> ('debug',) {}\r\n\r\nShowing the actual function being called, and what positional and keyword\r\narguments are automatically going to be suppplied.\r\n\r\nIn a simpler context, we can define\r\n\r\ndef f(x):\r\n    return f.mult * x\r\n\r\nand then we can later set f.mult = 2, so calling f(3) returns 6.\r\n\r\nFunction objects have name spaces that we can manipulate (set and retrieve\r\nattributes) as well. \r\n\r\n------------------------------------------------------------------------------\r\n\r\nMapReduce, associative functions, and parallel processing\r\n\r\nMapReduce is a special implemention of the map/reduce functions implemented to\r\nrun in parallel on cluster, or multi-core computers. If we can write our code\r\nwithin the MapReduce language, we can guarantee that it runs quickly on the\r\nkinds of computers Google uses for its servers. Generally what it does is run \r\nsimilar operations on huge amounts of data (the map part), combining results\r\n(the reduce part), until we get a single answer (or in Google's application, a\r\nranked list of web-pages). Apache Hadoop is open source version of MapReduce\r\n(but to really see its power -the decreased execution time-, we need huge\r\namounts of data and a cluster of computers on which to run our code.\r\n\r\nHow does MapReduce work? The story is long, but here is a quick overview.\r\nImagine we have an associative operator like + and want to compute:\r\n\r\n  1 + 2 + 3 + ... + n\r\n\r\nWe can evaluate this expression as shown above, which would require n-1\r\nadditions one right after the other (the former must finish before the later\r\nstarts). Even if we had multiple cores, doing the operations in this order\r\nwould require n-1 sequential additions because only one core at a time would be\r\nactive.\r\n\r\n1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 + 11 + 12 + 13 + 14 + 15 + 16\r\n|   |   |   |\r\n+-+-+   |   |\r\n  |     |   |\r\n  3     |   |\r\n  |     |   |\r\n  +--+--+   |\r\n     |      |\r\n     6      |\r\n     |      |\r\n     +------+\r\n         |\r\n        10\r\n         .... note that one more operand is used at each level\r\n\r\nHere each level uses 1 core and there are 15 levels. In general, with N numbers\r\nto add it takes N-1 time steps/levels.\r\n\r\nNow, how MapReduce can handle this problem?\r\n\r\nInstead, because of associativity, we can evaluate this expression in a\r\ndifferent way: add the 1st and 2nd values at the same time as we add the 3rd\r\nand 4th at the same time as the 5th and 6th ... In all, we can add n/2 pairs\r\nsimultaneously (if we had n/2 cores). We can use this same trick for the\r\nremaining n/2 sums, simultaneously adding them together; then for the n/4 sums,\r\n..., to the final sum sums (for which only one processor is necessary). Here is\r\na pictorial representation of this process for 16 values.\r\n\r\n1 + 2 + 3 + 4 + 5 + 6 + 7 + 8 + 9 + 10 + 11 + 12 + 13 + 14 + 15 + 16\r\n|   |   |   |   |   |   |   |   |   |     |   |     |   |     |   | \r\n+-+-+   +-+-+   +-+-+   +-+-+   +-+-+     +-+-+     +-+-+     +-+-+    8 cores\r\n  |       |       |       |       |         |         |         |\r\n  3       7      11      15      19        23        27        31\r\n  |       |       |       |       |         |         |         |\r\n  +---+---+       +---+---+       +----+----+         +----+----+      4 cores \r\n      |               |                |                   |\r\n     10              26               42                  58\r\n      |               |                |                   |\r\n      +-------+-------+                +---------+---------+           2 cores\r\n              |                                  |\r\n             36                                 100\r\n              |                                  |\r\n              +----------------+-----------------+\t\t       1 core\r\n                               |\r\n                              136\r\n\r\nHere each level uses as many cores as possible there are 4 levels. In general,\r\nwith N numbers to add it takes Log2 N times steps. Recall that Log2 1,000 is\r\n10, Log2 1,000,000 is 20, and Log2 1,000,000,000 = 30. But, to perform 10**9\r\nadditions in 30 time steps,  we'd need a half billion cores: not likely this is\r\ncoming in your lifetime. But if we had tens-or-hundreds of cores, we could keep\r\nthem all busy except for the last few (bottom) levels. So we could get our code\r\nto run tens-or-hundreds of times faster. Of course, the unneeded cores can\r\nstart working on the next MapReduce problem once they are not needed for the\r\ncurrent problem.\r\n\r\nThis all assumes that each core can get the right data when it needs it. This\r\nrequirement can become a memory contention problem when many cores share the\r\nsame memory. This topic is covered further in ICS-51.\r\n\r\n------------------------------------------------------------------------------\r\n\r\n\t\t\tCombinatorial Computing\r\n\r\nThis lecture got too long for this section to be detailed, which mostly was\r\ngoing to be about various iterators in the itertools module. Instead, I have\r\nlisted just the combinatoric generators there. Here is just a quick overview of\r\nsome intuitive and useful ones. The itertools module covers other interesting\r\niterator decorators to peform a wide range of operations.\r\n\r\nproduct(*iterables)\r\n\r\n  yields tuples with the cartesian product of the iterators, where each\r\n  represents one \"dimension\"). For example list(product('ab',irange(1,3)))\r\n  produces the following list of 2-tuples\r\n\r\n  [('a', 1), ('a', 2), ('a', 3), ('b', 1), ('b', 2), ('b', 3)]\r\n\r\n\r\npermutations(iterable,r=None)\r\n\r\n  yields tuples (in sorted order) that are permutations of the values\r\n  produced from iterable. If r is specified, each result is an r-tuple\r\n  (if not, each tuple has all the values in the iterable). For example\r\n  list(permutations('abc')) produces the following list of 3-tuples of 'abc'\r\n\r\n  [('a','b','c'),('a','c','b'),('b','a','c'),('b','c','a'),('c','a','b'),('c','b','a')]\r\n\r\n  list(permutations('abc',2)) produces the following list of 2-tuples of 'abc'\r\n\r\n  [('a','b'),('a','c'),('b', 'a'),('b','c'),('c','a'),('c', 'b')]\r\n\r\n  Generally, if iterable has n values, the number of tuples returned is\r\n  n!/(n-r!) when 0<=r<=n and 0 when r > n.\r\n\r\ncombinations(iterable,r)\r\n\r\n  yield r-tuples (in sorted order) that are combinations of the unique values\r\n  produced the from iterable (where only the values, not their order, is\r\n  important). For example, list(combinations('abcd',3)) produces the following\r\n  list of 3-tuples of 'abcd' (technically we should treat each 3-tuple as a\r\n  3-set because its order isn't important).\r\n\r\n  [('a', 'b', 'c'), ('a', 'b', 'd'), ('a', 'c', 'd'), ('b', 'c', 'd')]\r\n\r\n  Generally, if iterable has n values, the number of tuples returned is\r\n  n!/r!(n-r!) when 0<=r<=n and 0 when r > n.\r\n\r\n\r\ncombinations_with_replacement(iterable,r)\r\n\r\n  yield r-tuples (in sorted order) that are combinations of the values\r\n  (which don't have to be unique) produced the from iterable (where only the\r\n  values, not their order, is important). For example,\r\n  list(combinations_with_replacement('abc'),2) produces the following\r\n  list of 2-tuples of 'abc'\r\n\r\n  [('a','a'), ('a','b'), ('a','c'), ('b', 'b'), ('b','c'), ('c','c')]\r\n\r\n  Generally, if iterable has n values, the number of tuples returned is\r\n  (n+r-1)!/r!(n-r!) when n > 0\r\n\r\n\r\n------------------------------------------------------------------------------\r\n\r\nProblems\r\n\r\n1) Define a function using map, filter, and reduce, to compute the number of\r\ntimes a certain string appears in a file (reading a line at a time)? Define\r\nanother function that does the same, but does not count any occurences after a\r\n'#' on a line.\r\n\r\n2) Define a function using map, filter, and reduce, to compute one huge\r\n(catenated) string from all the words on all the lines that have exactly one\r\nvowel in them. Assume all the words in a line are separated by a space.\r\n\r\n3) Write factorial as a tail-recursive function with an accumulator. Then\r\ntranslate this tail-recursive function into an equivalent non-recursive\r\nfunction.\r\n\r\n4) Which functions from the previous lecture's problems are tail-recursive or\r\ncan be rewritten as tail-recursive accumulators? Translate each into an\r\niterative function.\r\n\r\n5) Rewrite the log function so that it calls eval on its second argument. Use\r\npartial to define notify as defined above; use partial to define show_x such\r\nthat show_x('debug') prints [debug]: x = ..the value x is currently bound to..\r\n(hint, us a parameterless lambda); use partial to define time_stamp such that\r\ntime_stamp('debug') would print [debug]: ..current date/time.. Hints: see the\r\nnow function callable on objects constructed from the datetime class that is\r\ndefined in the datetime module (Part 8.1 of the Python Standard Library), and\r\ndefine a function not a lambda for computing now.\r\n\r\n6) In the lecture above we saw that the code\r\n  debug = partial(log, purpose = 'debug')\r\n  debug('some message')\r\nraises an exception. What would the following similar (but not identical) code\r\nprint; explain why it does not raise an exception.\r\n  debug = partial(log, purpose='debug')\r\n  debug(purpose='log',message='Here')\r\n\r\n7) Write an expression that evalutes to the following representation of a card\r\ndeck: an unordered list of strings of the form '2 Hearts', '3 Hearts', ...,\r\n'10 hearts', 'Jack Hearts', 'Queen Hearts, 'King Hearts', 'Ace Hearts' for\r\nHearts and the other suits: Diamonds Clumbs and Spades. The resulting list\r\nshould have 52 values. Hint: see chain and product iterators (which I used\r\nalong with map, a lambda, irange and lists): create a product of (a) the numbers\r\n2-10 followed by the named cards (using chain) and (b) the suits; then map each\r\nresulting 2-tuple into the required string form. \r\n\r\n8) Using the solution to problem 8 from the recursion lecture (shown here),\r\nmodify it to return the actual stamps needed to make amount, using the minimum\r\nnumber of stamps. For the new min_stamps function, min_stamps(19) could return\r\neither the stamp list [1,2,16] or [2,5,12]. Hint: use reduce over a list of\r\nstamp lists to returns the shortest stamp list.\r\n\r\ndef min_stamps(amount):\r\n    denominations = [1,2,5,12,16,24]\r\n    if amount == 0:\r\n        return 0\r\n    else:\r\n        return 1+min([min_stamps(amount-d) for d in denominations if amount-d >= 0])\r\n\r\nSo, when computing mns(18, (1,6,14,57)) we would compute the following three\r\nvalues by doing recursive calls\r\n  mns(17, (1,6,14,57))  if we used a  1 cent stamp: result [14, 1, 1, 1]\r\n  mns(12, (1,6,14,57))  if we used a  6 cent stamp: result [6, 6]\r\n  mns( 4, (1,6,14,57))  if we used a 14 cent stamp: result [1, 1, 1, 1]\r\nOur comprehension appends a 1, 6, and 14 respectively on each of the recursively\r\ncomputed solutions, buiding the list\r\n\r\n [[1, 14, 1, 1, 1], [6, 6, 6], [14, 1, 1, 1, 1]]\r\n\r\nwhich reduces to the list with the smallest length, [6, 6, 6], which is the\r\ncorrect answer to the problem.\r\n", "encoding": "ascii"}