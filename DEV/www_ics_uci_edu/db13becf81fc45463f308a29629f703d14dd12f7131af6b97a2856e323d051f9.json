{"url": "https://www.ics.uci.edu/~dan/class/267P/datasets/calgary/paper2", "content": ".pn 0\n.ls1\n.EQ\ndelim $$\n.EN\n.ev1\n.ps-2\n.vs-2\n.ev\n\\&\n.sp 10\n.ps+4\n.ce\nCOMPUTER (IN)SECURITY \\(em\n.sp\n.ce\nINFILTRATING OPEN SYSTEMS\n.ps-4\n.sp4\n.ce\nIan H. Witten\n.sp2\n.ce4\nDepartment of Computer Science\nThe University of Calgary\n2500 University Drive NW\nCalgary, Canada T2N 1N4\n.sp2\n.ce2\nNovember 1986\nRevised March 1987\n.bp 1\n.ls 2\n.pp\nShared computer systems today are astonishingly insecure.\nAnd users, on the whole, are blithely unaware of the weaknesses of the\nsystems in which they place \\(em or rather, misplace \\(em their trust.\nTaken literally, of course, it is meaningless to ``trust'' a computer system\nas such, for machines are neither trustworthy nor untrustworthy;\nthese are human qualities.\nIn trusting a system one is effectively trusting all those who create and\nalter it, in other words, all who have access (whether licit or\nillicit).\nSecurity is a fundamentally \\fIhuman\\fP issue.\n.pp\nThis article aims not to solve security problems but to raise reader\nconsciousness\nof the multifarious cunning ways that systems can be infiltrated, and the\nsubtle but devastating damage that an unscrupulous infiltrator can wreak.\nIt is comforting, but highly misleading, to imagine that technical means of\nenforcing security have guaranteed that the systems we use are safe.\nIt is true that in recent years some ingenious procedures have been invented\nto preserve security.\nFor example, the advent of ``one-way functions'' (explained below) has\nallowed the password file, once a computer system's central stronghold, to be\nsafely exposed to casual inspection by all and sundry.\nBut despite these innovations, astonishing loopholes exist in practice.\n.pp\nThere are manifest advantages in ensuring security by technical means rather\nthan by keeping things secret.\nNot only do secrets leak, but as individuals change projects,\njoin or leave the organization, become promoted and so on, they need to learn\nnew secrets and forget old ones.\nWith physical locks one can issue and withdraw keys to reflect changing\nsecurity needs.\nBut in computer systems, the keys constitute information which can be given\nout but not taken back, because no-one can force people to forget.\nIn practice, such secrets require considerable administration to maintain\nproperly.\nAnd in systems where security is maintained by tight control of information,\n.ul\nquis custodiet ipsos custodes\n\\(em who will guard the guards themselves?\n.pp\nThere is a wide range of simple insecurities that many\nsystems suffer.\nThese are, in the main, exacerbated in open systems where information and\nprograms are shared among users \\(em just those features that characterize\npleasant and productive working environments.\nThe saboteur's basic tool is the Trojan horse,\na widely trusted program which has been surreptitiously modified to do\nbad things in secret.\n``Bad things'' range from minor but rankling irritations through theft of\ninformation to holding users to ransom.\nThe inevitable fragilities of operating systems can\nbe exploited by constructing programs which behave in some ways like primitive\nliving organisms.\nPrograms can be written which spread bugs like an epidemic.\nThey hide in binary code, effectively undetectable (because nobody ever\nexamines binaries).\nThey can remain dormant for months or years, perhaps quietly and imperceptibly\ninfiltrating their way into the very depths of a system, then suddenly pounce,\ncausing irreversible catastrophe.\nA clever and subtle bug\\(dg can survive\nrecompilation despite the fact that there is no record of it in the source\nprogram.\n.FN\n\\(dg Throughout this article the word ``bug'' is meant to bring to mind a\nconcealed snooping device as in espionage, or a micro-organism carrying\ndisease as in biology, rather than an inadvertent programming error.\n.EF\nThis is the ultimate parasite.\nIt cannot be detected because it lives only in binary code.\nAnd yet it cannot be wiped out by recompiling the source program!\nWe might wonder whether these techniques, which this article develops\nand explains in the context of multi-user timesharing operating systems,\npose any threats to computer networks or even stand-alone micros.\n.pp\nAlthough the potential has existed for decades, the possibility of the kind of\n``deviant'' software described here has been recognized only recently.\nOr has it?\nProbably some in the world of computer wizards and sorcerers have known for\nyears how systems can be silently, subtly infiltrated \\(em and concealed\nthe information for fear that it might be misused (or for other reasons).\nBut knowledge of the techniques is spreading nevertheless, and I believe it\nbehooves us all \\(em professionals and amateurs alike \\(em to understand just\nhow our continued successful use of computer systems hangs upon a thread of\ntrust.\nThose who are ignorant of the possibilities of sabotage can easily be\nunknowingly duped by an unscrupulous infiltrator.\n.pp\nThe moral is simple.\nComputer security is a human business.\nOne way of maintaining security is to keep things secret, trusting people\n(the very people who can do you most harm) not to tell.\nThe alternative is to open up the system and rely on technical means\nof ensuring security.\nBut a system which is really ``open'' is also open to abuse.\nThe more sharing and productive the environment, the more potential exists for\ndamage.\nYou have to trust your fellow users, and educate yourself.\nIf mutual trust is the cornerstone of computer security, we'd better know it!\n.sh \"The trend towards openness\"\n.pp\nMany people believe that computer systems can maintain security not\nby keeping secrets but by clever technical mechanisms.\nSuch devices include electronic locks and keys, and schemes for maintaining\ndifferent sets of ``permissions'' or ``privileges'' for each user.\nThe epitome of this trend towards open systems is the well-known \\s-2UNIX\\s+2\noperating system, whose developers, Dennis Ritchie and Ken Thompson, strove\nto design a clean, elegant piece of software that could be understood,\nmaintained, and modified by users.\n(In 1983 they received the prestigious ACM Turing Award for their work.)  \\c\nKen Thompson has been one of the prime contributors to our knowledge of\ncomputer (in)security, and was responsible for much of the work described in\nthis article.\n.pp\nThe most obvious sense in which the \\s-2UNIX\\s+2 system\nis ``open'' is illustrated by looking at its password file.\nYes, there is nothing to stop you from looking at this file!\nEach registered user has a line in it, and Figure\\ 1 shows mine.\nIt won't help you to impersonate me, however, because what it shows in the\npassword field is not my password but a scrambled version of it.\nThere is a program which computes encrypted passwords from plain ones, and\nthat is how the system checks my identity when I log in.\nBut the program doesn't work in reverse \\(em it's what is called a ``one-way\nfunction'' (see Panel\\ 1).\nIt is effectively impossible to find the plain version from the encrypted one,\neven if you know exactly what the encryption procedure does and try to work\ncarefully backward through it.\n\\fINobody\\fR can recover my plain password from the information stored in the\ncomputer.\nIf I forget it, not even the system manager can find out what it is.\nThe best that can be done is to reset my password to some standard one, so\nthat I can log in and change it to a new secret password.\n(Needless to say this creates a window of opportunity for an imposter.)  \\c\nThe system keeps no secrets.\nOnly I do.\n.pp\nBefore people knew about one-way functions, computer systems maintained a\npassword file which gave everyone's plain password for the login procedure to\nconsult.\nThis was the prime target for anyone who tried to\nbreak security, and the bane of system managers because of the\ncompletely catastrophic nature of a leak.\nSystems which keep no secrets avoid an unnecessary Achilles heel.\n.pp\nAnother sense in which \\s-2UNIX\\s+2 is ``open'' is the accessibility of its\nsource code.\nThe software, written in the language \"C\", has been distributed\n(to universities) in source form so that maintenance can be done locally.\nThe computer science research community has enjoyed numerous benefits from\nthis enlightened policy (one is that we can actually look at some of the\nsecurity problems discussed in this article).\nOf course, in any other system there will inevitably be a large number of\npeople who have or have had access to the source code \\(em even though it may\nnot be publicly accessible.\nOperating systems are highly complex pieces of technology, created by large\nteams of people.\nA determined infiltrator may well be able to gain illicit access to source\ncode.\nMaking it widely available has the very positive effect of bringing the\nproblems out into the open and offering them up for public scrutiny.\n.pp\nWere it attainable, perfect secrecy would offer a high degree of security.\nMany people feel that technical innovations like one-way functions and\nopen password files provide comparable protection.\nThe aim of this article is to show that this is a dangerous misconception.\nIn practice, security is often severely compromised by people who have\nintimate knowledge of the inner workings of the system \\(em precisely the\npeople you rely on to \\fIprovide\\fR the security.\nThis does not cause problems in research laboratories because they are\nfounded on mutual trust and support.\nBut in commercial environments, it is vital to be aware of any limitations on\nsecurity.\nWe must face the fact that\nin a hostile and complex world, computer security is best preserved by\nmaintaining secrecy.\n.sh \"A pot-pourri of security problems\"\n.pp\nHere are a few simple ways that security might be compromised.\n.rh \"Guessing a particular user's password.\"\nWhether your password is stored in a secret file or encrypted by a one-way\nfunction first, it offers no protection if it can easily be guessed.\nThis will be hard if it is chosen at random from a large enough set.\nBut for a short sequence of characters from a restricted alphabet\n(like the lower-case letters), an imposter could easily try all possibilities.\nAnd in an open system which gives access to the password file and one-way\nfunction, this can be done mechanically, by a program!\n.pp\nIn Figure\\ 2, the number of different passwords is plotted against the length\nof the password, for several different sets of characters.\nFor example, there are about ten million ($10 sup 7$) possibilities for a\n5-character password chosen from the lower-case letters.\nThis may seem a lot, but if it takes 1\\ msec to try each one, they can all be\nsearched in about 3\\ hours.\nIf 5-character passwords are selected from the 62 alphanumerics, there\nare more than 100 times as many and the search would take over 10\\ days.\n.pp\nTo make matters worse, people have a strong propensity to choose as\npasswords such things as\n.LB\n.NP\nEnglish words\n.NP\nEnglish words spelled backwards\n.NP\nfirst names, last names, street names, city names\n.NP\nthe above with initial upper-case letters\n.NP\nvalid car license numbers\n.NP\nroom numbers, social security numbers, telephone numbers, etc.\n.LE\nOf course, this isn't particularly surprising since passwords have to be\nmnemonic in order to be remembered!\nBut it makes it easy for an enterprising imposter to gather a substantial\ncollection of candidates (from dictionaries, mailing lists, etc) and search\nthem for your password.\nAt 1\\ msec per possibility, it takes only 4\\ minutes to search a 250,000-word\ncommercial dictionary.\n.pp\nA study some years ago of a collection of actual passwords that people used to\nprotect their accounts revealed the amazing breakdown reproduced in Figure\\ 3.\nMost fell into one of the categories discussed, leaving less\nthan 15% of passwords which were hard to guess.\nWhere does your own password stand in the pie diagram?\n.rh \"Finding any valid password.\"\nThere is a big difference between finding a particular person's password and\nfinding a valid password for any user.\nYou could start searching through the candidates noted above until you found\none which, when encrypted, matched one of the entries in the password file.\nThat way you find the most vulnerable user, and there are almost certain to be\nsome lazy and crazy enough to use easily-guessable passwords, four-letter\nwords, or whatever.\nHashing techniques make it almost as quick to check a candidate against a\ngroup of encrypted passwords as against a single one.\n.pp\nA technique called ``salting'' protects against this kind of attack.\nWhenever a user's password is initialized or changed, a small random number\ncalled the ``salt'' is generated (perhaps from the time of day).\nNot only is this combined with the password when it is encrypted, but as\nFigure\\ 1 shows it is also stored in the password file for everyone to see.\nEvery time someone claiming to be that user logs in, the salt is combined with\nthe password offered before being encrypted and compared\nwith whatever is stored in the password file.\nFor example, say my password was ``w#xs27'' (it isn't!).\nIf the salt is ``U6'' (as in Figure\\ 1), the system will apply its one-way\nfunction to ``w#xs27U6'' to get the encrypted password.\n.pp\nSince all can see the salt, it is no harder for anyone to guess\nan individual user's password.\nOne can salt guesses just as the system does.\nBut it \\fIis\\fR harder to search a group of passwords, since the salt will be\ndifferent for each, rendering it meaningless to compare a single encrypted\npassword against all those in the group.\nSuppose you were checking to see if anyone had the password ``hello''.\nWithout salting, you simply apply the one-way function to this word and\ncompare the result with everyone's encrypted password.\nBut with salting it's not so easy, since to see if my password is ``hello''\nyou must encrypt ``helloU6'', and the salt is different for everyone.\n.rh \"Forced-choice passwords.\"\nThe trouble with letting users choose their own passwords is that they often\nmake silly, easily-guessed, choices.\nMany systems attempt to force people to choose more ``random'' passwords, and\nforce them to change their password regularly.\nAll these attempts seem to be complete failures.\nThe fundamental problem is that people have to be able to remember their\npasswords, because security is immediately compromised if they are written\ndown.\n.pp\nThere are many amusing anecdotes about how people thwart systems that attempt\nto dictate when they have to change their passwords.\nI had been using a new system for some weeks when it insisted that I change my\npassword.\nResenting it ordering me about, I gave my old password as the new one.\nBut it was programmed to detect this ruse and promptly told me so.\nI complained to the user sitting beside me.\n``I know,'' she said sympathetically.\n``What I always do is change it to something else and then immediately\nchange it back again!''  \\c\nAnother system remembered your last several passwords, and insisted on a\nonce-a-month change.\nSo people began to use the name of the current month as their password!\n.rh \"Wiretaps.\"\nObviously any kind of password protection can be thwarted by a physical\nwiretap.\nAll one has to do is watch as you log in and make a note of your password.\nThe only defense is encryption at the terminal.\nEven then you have to be careful to ensure that someone can't intercept\nyour encrypted password and pose as you later on by sending this\n\\fIencrypted\\fR string to the computer \\(em after all, this is what the\ncomputer sees when you log in legitimately!\nTo counter this, the encryption can be made time-dependent so that the same\npassword translates to different strings at different times.\n.pp\nAssuming that you, like 99.9% of the rest of us, don't go to the trouble of\nterminal encryption, when was the last time you checked the line between your\noffice terminal and the computer for a physical wiretap?\n.rh \"Search paths.\"\nWe will see shortly that you place yourself completely at the mercy of other\nusers whenever you execute their programs, and they\ncan do some really nasty things like spreading infection to your files.\nHowever, you don't necessarily have to execute someone else's program overtly,\nfor many systems make it easy to use other people's\nprograms without even realizing it.\nThis is usually a great advantage, for you can install programs so that you\nor others can invoke them just like ordinary system programs, thereby\ncreating personalized environments.\n.pp\nFigure\\ 4 shows part of the file hierarchy in our system.\nThe whole hierarchy is immense \\(em I alone have something like 1650 files,\norganized into 200 of my own directories under the ``ian'' node shown in the\nFigure, and there are hundreds of other users \\(em and what is shown is just a\nvery small fragment.\nUsers can set up a ``search path'' which tells the system\nwhere to look for programs they invoke.\nFor example, my search path includes the 6 places that are circled.\nWhenever I ask for a program to be executed, the system seeks it in these\nplaces.\nIt also searches the ``current directory'' \\(em the one where I happen to be\nat the time.\n.pp\nTo make it more convenient for you to set up a good working environment, it\nis easy to put someone else's file directories on your search path.\nBut then they can do arbitrary damage to you, sometimes completely\naccidentally.\nFor example, I once installed a spreadsheet calculator called ``sc'' in one\nof my directories.\nUnknown to me, another user suddenly found that the Simula compiler stopped\nworking and entered a curious mode where it cleared his VDT screen and wrote\na few incomprehensible characters on it.\nThere was quite a hiatus.\nThe person who maintained the Simula compiler was away,\nbut people could see no reason for the compiler to have been altered.\nOf course, told like this it is obvious that the user had my directory on his\nsearch path and I had created a name conflict with \\fIsc\\fR, the Simula\ncompiler.\nBut it was not obvious to the user, who rarely thought about the search path\nmechanism.\nAnd I never use the Simula compiler and had created the conflict in all\ninnocence.\nMoreover, I didn't even know that other users had my directory on their search\npaths!\nThis situation caused only frustration before the problem was diagnosed and\nfixed.\nBut what if I were a bad guy who had created the new \\fIsc\\fR program to\nharbor a nasty bug (say one which deleted the hapless user's files)?\n.pp\nYou don't necessarily have to put someone on your search path to run the\nrisk of executing their programs accidentally.\nAs noted above, the system (usually) checks your current working directory\nfor the program first.\nWhenever you change your current workplace to another's directory, you\nmight without realizing it begin to execute programs that had been\nplanted there.\n.pp\nSuppose a hacker plants a program with the same name as a common\nutility program.\nHow would you find out?\nThe \\s-2UNIX\\s+2 \\fIls\\fR command lists all the files in a directory.\nPerhaps you could find imposters using \\fIls\\fR?  \\(em Sorry.\nThe hacker might have planted another program, called \\fIls\\fR, which\nsimulated the real \\fIls\\fR exactly except that it lied about its own\nexistence and that of the planted command!\nThe \\fIwhich\\fR command tells you which version of a program you\nare using \\(em whether it comes from the current directory, another user's\ndirectory, or a system directory.\nSurely this would tell you?  \\(em Sorry.\nThe hacker might have written another \\fIwhich\\fR which lied about itself,\nabout \\fIls\\fR, and about the plant.\n.pp\nIf you put someone else on your search path, or change into their directory,\nyou're implicitly trusting them.\nYou are completely at a user's mercy when you execute one of their programs,\nwhether accidentally or on purpose.\n.rh \"Programmable terminals.\"\nThings are even worse if you use a ``programmable'' terminal.\nThen, the computer can send a special sequence of characters to command the\nterminal to transmit a particular message whenever a particular key is struck.\nFor example, on the terminal I am using to type this article, you could\nprogram the \\s-2RETURN\\s+2 key to transmit the message ``hello'' whenever it\nis pressed.\nAll you need to do to accomplish this is to send my terminal the character\nsequence\n.LB\n\\s-2ESCAPE\\s+2 P ` + { H E L L O } \\s-2ESCAPE\\s+2\n.LE\n(\\s-2ESCAPE\\s+2 stands for the \\s-2ASCII\\s+2 escape character, decimal 27,\nwhich is invoked by a key labeled ``Esc''.)  \\c\nThis is a mysterious and ugly incantation, and I won't waste time\nexplaining the syntax.\nBut it has an extraordinary effect.\nHenceforth every time I hit the return key, my terminal will transmit the\nstring ``hello'' instead of the normal \\s-2RETURN\\s+2 code.\nAnd when it receives this string, the computer I am connected to will try to\nexecute a program called ``hello''!\n.pp\nThis is a terrible source of insecurity.\nSomeone could program my terminal so that it executed one of \\fItheir\\fR\nprograms whenever I pressed \\s-2RETURN\\s+2.\nThat program could reinstate the \\s-2RETURN\\s+2 code to make it\nappear afterwards as though nothing had happened.\nBefore doing that, however, it could (for example) delete all my files.\n.pp\nThe terminal can be reprogrammed just by sending it an ordinary character\nstring.\nThe string could be embedded in a file, so that the terminal would be bugged\nwhenever I viewed the file.\nIt might be in a seemingly innocuous message;\nsimply reading mail could get me in trouble!\nIt could even be part of a file \\fIname\\fR, so that the bug would appear\nwhenever I listed a certain directory \\(em not making it my current directory,\nas was discussed above, but just \\fIinspecting\\fR it.\nBut I shouldn't say ``appear'', for that's exactly what it might not do.\nI may never know that anything untoward had occurred.\n.pp\nHow can you be safe?\nThe programming sequences for my terminal all start with \\s-2ESCAPE\\s+2,\nwhich is an \\s-2ASCII\\s+2 control character.\nAnyone using such a terminal should whenever possible work through a\nprogram that exposes control characters.\nBy this I mean a program that monitors output from the computer and translates\nthe escape code to something like the 5-character sequence ``<ESC>''.\nThen a raw \\s-2ESCAPE\\s+2 itself never gets sent to the terminal,\nso the reprogramming mechanism is never activated.\n.pp\nNot only should you avoid executing programs written by people you don't\ntrust, but in extreme cases you should take the utmost care in \\fIany\\fR\ninteraction with untrustworthy people \\(em even reading their electronic\nmail.\n.sh \"Trojan horses: getting under the skin\"\n.pp\nThe famous legend tells of a huge, hollow wooden horse filled with Greek\nsoldiers which was left, ostensibly as a gift, at the gates of the city of\nTroy.\nWhen it was brought inside, the soldiers came out at night and\nopened the gates to the Greek army, which destroyed the city.\nTo this day, something used to subvert an organization from within by abusing\nmisplaced trust is called a Trojan horse.\n.pp\nIn any computer system for which security is a concern, there must be things\nthat need protecting.\nThese invariably constitute some kind of information (since the computer is,\nat heart, an information processor), and such information invariably outlasts\na single login session and is therefore stored in the computer's file system.\nConsequently the file system is the bastion to be kept secure, and will be\nthe ultimate target of any invader.\nSome files contain secret information that not just anyone may read,\nothers are vital to the operation of an organization and must at all costs\nbe preserved from surreptitious modification or deletion.\nA rather different thing that must be protected is the ``identity'' of each\nuser.\nFalse identity could be exploited by impersonating someone else in order to\nsend mail.\nUltimately, of course, this is the same as changing data in mailbox files.\nConversely, since for each and every secret file \\fIsomeone\\fR must\nhave permission to read and alter it, preserving file system security\nrequires that identities be kept intact.\n.rh \"What might a Trojan horse do?\"\nThe simplest kind of Trojan horse turns a common program like a text editor\ninto a security threat by implanting code in it which secretly reads\nor alters files it is not intended to.\nAn editor normally has access to all the user's\nfiles (otherwise they couldn't be altered).\nIn other words, the program runs with the user's own privileges.\nA Trojan horse in it can do anything the user himself could do, including\nreading, writing, or deleting files.\n.pp\nIt is easy to communicate stolen information back to the person who bugged\nthe editor.\nMost blatantly, the access permission of a secret file could be changed so\nthat anyone can read it.\nAlternatively the file could be copied temporarily to disk \\(em most systems\nallocate scratch disk space for programs that need to create temporary working\nfiles \\(em and given open access.\nAnother program could continually check for it and, when\nit appeared, read and immediately delete it to destroy the trace.\nMore subtle ways of communicating small amounts of information might be to\nrearrange disk blocks physically so that their addresses formed a code, or to\nsignal with the run/idle status of the process to anyone who monitored the\nsystem's job queue.\nClearly, any method of communication will be detectable by others \\(em in\ntheory.\nBut so many things go on in a computer system that messages can easily be\nembedded in the humdrum noise of countless daily events.\n.pp\nTrojan horses don't necessarily do bad things.\nSome are harmless but annoying, created to meet a challenge rather than to\nsteal secrets.\nOne such bug, the ``cookie monster'', signals its presence by announcing\nto the unfortunate user ``I want a cookie''.\nMerely typing the word ``cookie'' will satiate the monster and cause it to\ndisappear as though nothing had happened.\nBut if the user ignores the request, although the monster appears to go\naway it returns some minutes later with ``I'm hungry; I really want a\ncookie''.\nAs time passes the monster appears more and more frequently with increasingly\ninsistent demands, until it makes a serious\nthreat:  ``I'll remove some of your files if you don't give me a cookie''.\nAt this point the poor user realizes that the danger is real and is\neffectively forced into appeasing the monster's appetite by supplying the word\n``cookie''.\nAlthough an amusing story to tell, it is not pleasant to imagine being\nintimidated by an inanimate computer program.\n.pp\nA more innocuous Trojan horse, installed by a system programmer to commemorate\nleaving her job, occasionally drew a little teddy-bear on the graph-plotter.\nThis didn't happen often (roughly every tenth plot), and even when it did\nit occupied a remote corner of the paper, well outside the normal plotting\narea.\nBut although they initially shared the joke, management soon ceased to\nappreciate the funny side and ordered the programmer's replacement to get rid\nof it.\nUnfortunately the bug was well disguised and many fruitless hours were spent\nseeking it in vain.\nManagement grew more irate and the episode ended when the originator\nreceived a desperate phone-call from her replacement, whose job was by now at\nrisk, begging her to divulge the secret!\n.rh \"Installing a Trojan horse.\"\nThe difficult part is installing the Trojan horse into a trusted program.\nSystem managers naturally take great care that only a few people get access\nto suitable host programs.\nIf anyone outside the select circle of ``system people'' is ever given an\nopportunity to modify a commonly-used program like a text editor\n(for example, to add a new feature) all changes will be closely scrutinized by\nthe system manager before being installed.\nThrough such measures the integrity of system programs is preserved.\nNote, however, that constant vigilance is required, for once bugged, a system\ncan remain compromised forever.\nThe chances of a slip-up may be tiny, but the consequences are unlimited.\n.pp\nOne good way of getting bugged code installed in the system is to write a\npopular utility program.\nAs its user community grows, more and more people will copy the program into\ntheir disk areas so that they can use it easily.\nEventually, if it is successful, the utility will be installed as a ``system''\nprogram.\nThis will be done to save disk space \\(em so that the users can delete their\nprivate versions \\(em and perhaps also because the code can now be made\n``sharable'' in that several simultaneous users can all execute a single copy\nin main memory.\nAs a system program the utility may inherit special privileges, and so be\ncapable of more damage.\nIt may also be distributed to other sites, spreading the Trojan horse far and\nwide.\n.pp\nInstalling a bug in a system utility like a text editor puts anyone who uses\nthat program at the mercy of whoever perpetrated the bug.\nBut it doesn't allow that person to get in and do damage at any time, for\nnothing can be done to a user's files until that user invokes the bugged\nprogram.\nSome system programs, however, have a special privilege which allows them\naccess to files belonging to \\fIanyone\\fR, not just the current user.\nWe'll refer to this as the ``ultimate'' privilege, since nothing could be more\npowerful.\nAn example of a program with the ultimate privilege is the \\fIlogin\\fR program\nwhich administers the logging in sequence, accepting the user name and\npassword and creating an appropriate initial process.\nAlthough \\s-2UNIX\\s+2 \\fIlogin\\fR runs as a normal process, it must have the\npower to masquerade as any user since that is in effect the goal of the\nlogging in procedure!\nFrom an infiltrator's point of view, this would be an excellent\ntarget for a Trojan horse.\nFor example, it could be augmented to grant access automatically to any user\nwho typed the special password ``trojanhorse'' (see Panel\\ 2).\nThen the infiltrator could log in as anyone at any time.\nNaturally, any changes to \\fIlogin\\fR will be checked especially carefully\nby the system administrators.\n.pp\nSome other programs are equally vulnerable \\(em but not many.\nOf several hundred utilities in \\s-2UNIX\\s+2, only around a dozen have the\nultimate privilege that \\fIlogin\\fR enjoys.\nAmong them are the \\fImail\\fR facility, the \\fIpasswd\\fR program which lets\nusers change their passwords, \\fIps\\fR which examines the status of all\nprocesses in the system, \\fIlquota\\fR that enforces disk quotas, \\fIdf\\fR\nwhich shows how much of the disk is free, and so on.\nThese specially-privileged programs are prime targets for Trojan horses since\nthey allow access to any file in the system at any time.\n.rh \"Bugs can lurk in compilers.\"\nAssuming infiltrators can never expect to be able to modify the source code of\npowerful programs like \\fIlogin\\fR, is there any way a bug can be planted\nindirectly?\nYes, there is.\nRemember that it is the object code \\(em the file containing executable\nmachine instructions \\(em that actually runs the logging in process.\nIt is this that must be bugged.\nAltering the source code is only one way.\nThe object file could perhaps be modified directly, but this is likely to be\njust as tightly guarded as the \\fIlogin\\fR source.\nMore sophisticated is a modification to the compiler itself.\nA bug could try to recognize when it is \\fIlogin\\fR that is being compiled,\nand if so, insert a Trojan horse automatically into the compiled code.\n.pp\nPanel\\ 3 shows the idea.\nThe \\s-2UNIX\\s+2 \\fIlogin\\fR program is written in the C programming language.\nWe need to modify the compiler so that it recognizes when it is compiling\nthe \\fIlogin\\fR program.\nOnly then will the bug take effect, so that all other compilations proceed\nexactly as usual.\nWhen \\fIlogin\\fR is recognized, an additional line is inserted into it by\nthe compiler, at the correct place \\(em so that exactly the same bug is\nplanted as in Panel\\ 2.\nBut this time the bug is placed there by the compiler itself, and does not\nappear in the source of the \\fIlogin\\fR program.\nIt is important to realize that nothing about this operation depends on the\nprogramming language used.\nAll examples in this article could be redone using, say, Pascal.\nHowever, C has the advantage that it is actually used in a widespread\noperating system.\n.pp\nThe true picture would be more complicated than this simple sketch.\nIn practice, a Trojan horse would likely require several extra lines of code,\nnot just one, and they would need to be inserted in the right place.\nMoreover, the code in Panel\\ 3 relies on the \\fIlogin\\fR program being laid\nout in exactly the right way \\(em in fact it assumes a rather unusual\nconvention for positioning the line breaks.\nThere would be extra complications if a more common layout style were used.\nBut such details, although vital when installing a Trojan horse in practice,\ndo not affect the principle of operation.\n.pp\nWe have made two implicit assumptions that warrant examination.\nFirst, the infiltrator must know what the \\fIlogin\\fR program looks like in\norder to choose a suitable pattern from it.\nThis is part of what we mean by ``open-ness''.\nSecond, the bug would fail if the \\fIlogin\\fR program were altered so that the\npattern no longer matched.\nThis is certainly a real risk, though probably not a very big one in practice.\nFor example, one could simply check for the text strings ``Login'' and\n``Password'' \\(em it would be very unlikely that anything other than the\n\\fIlogin\\fR program would contain those strings, and also very unlikely that\n\\fIlogin\\fR would be altered so that it didn't.\nIf one wished, more sophisticated means of program identification could be\nused.\nThe problem of identifying programs from their structure despite superficial\nchanges is of great practical interest in the context of detecting cheating\nin student programming assignments.\nThere has been some research on the subject which could be exploited to make\nsuch bugs more reliable.\n.pp\nThe Trojan horses we have discussed can all be detected quite easily by casual\ninspection of the source code.\nIt is hard to see how such bugs could be hidden effectively.\nBut with the compiler-installed bug, the \\fIlogin\\fR program is compromised\neven though its source is clean.\nIn this case one must seek elsewhere \\(em namely in the compiler \\(em for the\nsource of trouble, but it will be quite evident to anyone who glances in the\nright place.\nWhether such bugs are likely to be discovered is a moot point.\nIn real life people simply don't go round regularly \\(em or even irregularly\n\\(em inspecting working code.\n.sh \"Viruses: spreading infection like an epidemic\"\n.pp\nThe thought of a compiler planting Trojan horses into the\nobject code it produces raises the specter of bugs being inserted into a large\nnumber of programs, not just one.\nAnd a compiler could certainly wreak a great deal of havoc, since it has\naccess to a multitude of object programs.\nConsequently system programs like compilers, software libraries, and so on\nwill be very well protected, and it will be hard to get a chance to bug them\neven though they don't possess the ultimate privilege themselves.\nBut perhaps there are other ways of permeating bugs throughout a computer\nsystem?\n.pp\nUnfortunately, there are.\nThe trick is to write a bug \\(em a ``virus'' \\(em that spreads itself like an\ninfection from program to program.\nThe most devastating infections are those that don't affect their carriers\n\\(em at least not immediately \\(em but allow them to continue to live normally\nand in ignorance of their disease, innocently infecting others while going\nabout their daily business.\nPeople who are obviously sick aren't nearly so effective at spreading\ndisease as those who appear quite healthy!\nIn the same way a program A can corrupt another program B, silently,\nunobtrusively, in such a way that when B is invoked by an innocent and\nunsuspecting user it spreads the infection still further.\n.pp\nThe neat thing about this, from the point of view of whoever plants the bug,\nis that infection can pass from programs written by one user to those written\nby another, and gradually permeate the whole system.\nOnce it has gained a foothold it can clean up incriminating evidence\nwhich points to the originator, and continue to spread.\nRecall that whenever you execute a program written by another, you place\nyourself in their hands.\nFor all you know the program you use may harbor a Trojan horse, designed to do\nsomething bad to you (like activate a cookie monster).\nLet us suppose that being aware of this, you are careful not to execute\nprograms belonging to other users except those written by your closest and\nmost trusted friends.\nEven though you hear of wonderful programs created by those outside\nyour trusted circle, which could be very useful to you and save a great deal\nof time, you are strong-minded and deny yourself their use.\nBut maybe your friends are not so circumspect.\nPerhaps one of them has invoked a hacker's bugged program, and unknowingly\ncaught the disease.\nSome of your friend's own programs are infected.\nFortunately, perhaps, they aren't the ones you happen to use.\nBut day by day, as your friend works, the infection spreads throughout all his\nor her programs.\nAnd then you use one of them\\ ...\n.rh \"How viruses work.\"\nSurely this can't be possible!\nHow can mere programs spread bugs from one to the other?\nActually, it's very simple.\nImagine.\nTake any useful program that others may want to execute, and modify it as\nfollows.\nAdd some code to the beginning, so that whenever it is executed, before\nentering its main function and unknown to the user, it acts as a ``virus''.\nIn other words, it does the following.\nIt searches the user's files for one which is\n.LB\n.NP\nan executable program (rather than, say, a text or data file)\n.NP\nwritable by the user (so that they have permission to modify it)\n.NP\nnot infected already.\n.LE\nHaving found its victim, the virus ``infects'' the file.\nIt simply does this by putting a piece of code at the beginning which makes\nthat file a virus too!\nPanel\\ 4 shows the idea.\n.pp\nNotice that, in the normal case, a program that you invoke can write or\nmodify any files that \\fIyou\\fR are allowed to write or modify.\nIt's not a matter of whether the program's author or owner can alter the\nfiles.\nIt's the person who invoked the program.\nEvidently this must be so, for otherwise you couldn't use (say) editors\ncreated by other people to change your own files!\nConsequently the virus isn't confined to programs written by its perpetrator.\nAs Figure\\ 6 illustrates, people who use any infected program will have one of\ntheir own programs infected.\nAny time an afflicted program runs, it tries to pollute another.\nOnce you become a carrier, the germ will eventually spread \\(em slowly,\nperhaps \\(em to all your programs.\nAnd anyone who uses one of your programs, even once, will get in trouble too.\nAll this happens without you having an inkling that anything untoward is going\non.\n.pp\nWould you ever find out?\nWell, if the virus took a long time to do its dirty work you might wonder why\nthe computer was so slow.\nMore likely than not you would silently curse management for passing up\nthat last opportunity to upgrade the system, and forget it.\nThe real giveaway is that file systems store a when-last-modified date with\neach file, and you may possibly notice that a program you thought you\nhadn't touched for years seemed suddenly to have been updated.\nBut unless you're very security conscious, you'd probably never look at the\nfile's date.\nEven if you did, you may well put it down to a mental aberration \\(em or\nsome inexplicable foible of the operating system.\n.pp\nYou might very well notice, however, if all your files changed their\nlast-written date to the same day!\nThis is why the virus described above only infects one file at a time.\nSabotage, like making love, is best done slowly.\nProbably the virus should lie low for a week or two after being installed in a\nfile.\n(It could easily do this by checking its host's last-written date.)  \\c\nGiven time, a cautious virus will slowly but steadily spread throughout a\ncomputer system.\nA hasty one is much more likely to be discovered.\n(Richard Dawkins' fascinating book \\fIThe selfish gene\\fR gives a gripping\naccount of the methods that Nature has evolved for self-preservation,\nwhich are far more subtle than the computer virus I have described.\nPerhaps this bodes ill for computer security in the future.)\n.pp\nSo far, our virus sought merely to propagate itself, not to inflict damage.\nBut presumably its perpetrator had some reason for planting it.\nMaybe they wanted to read a file belonging to some particular person.\nWhenever it woke up, the virus would check who had actually invoked the\nprogram it resided in.\nIf it was the unfortunate victim \\(em bingo, it would spring into action.\nAnother reason for unleashing a virus is to disrupt the computer system.\nAgain, this is best done slowly.\nThe most effective disruption will be achieved by doing nothing at all for a\nfew weeks or months other than just letting the virus spread.\nIt could watch a certain place on disk for a signal to start doing damage.\nIt might destroy information if its perpetrator's computer account had been\ndeleted (say they had been rumbled and fired).\nOr the management might be held to ransom.\nIncidentally, the most devastating way of subverting a system is by destroying\nits files randomly, a little at a time.\nErasing whole files may be more dramatic, but is not nearly so disruptive.\nContemplate the effect of changing a random bit on the disk every day!\n.rh \"Experience with a virus.\"\nEarlier I said ``Imagine''.\nNo responsible computer professional would do such a thing as unleashing a\nvirus.\nComputer security is not a joke.\nMoreover, a bug such as this could very easily get out of control and end up\ndoing untold damage to every single user.\n.pp\nHowever, with the agreement of a friend that we would try to bug each other,\nI did once plant a virus.\nLong ago, like many others, he had put one of my file directories on his\nsearch path, for I keep lots of useful programs there.\n(It is a tribute to human trust \\(em or foolishness? \\(em that many users,\nincluding this friend, \\fIstill\\fP have my directory on their search paths,\ndespite my professional interest in viruses!)  \\c\nSo it was easy for me to plant a modified version of the \\fIls\\fR command\nwhich lists file directories.\nMy modification checked the name of the user who had invoked \\fIls\\fR, and if\nit was my friend, infected one of his files.\nActually, because it was sloppily written and made the \\fIls\\fR command\nnoticeably slower than usual, my friend twigged what was happening almost\nimmediately.\nHe aborted the \\fIls\\fR operation quickly, but not quickly enough, for the\nvirus had already taken hold.\nMoreover I told him where the source code was that did the damage, and he was\nable to inspect it.\nEven so, 26 of his files had been infected (and a few of his graduate\nstudent's too) before he was able to halt the spreading epidemic.\n.pp\nLike a real virus this experimental one did nothing but reproduce itself at\nfirst.\nWhenever any infected program was invoked, it looked for a program in one\nof my directories and executed it first if it existed.\nThus I was able to switch on the ``sabotage'' part whenever I wanted.\nBut my sabotage program didn't do any damage.\nMost of the time it did nothing, but there was a 10% chance of it\nstarting up a process which waited a random time up to 30 minutes and printed\na rude message on my friend's VDT screen.\nAs far as the computer was concerned, of course, this was \\fIhis\\fR process,\nnot mine, so it was free to write on his terminal.\nHe found this incredibly mysterious, partly because it didn't often happen,\nand partly because it happened long after he had invoked the program which\ncaused it.\nIt's impossible to fathom cause and effect when faced with randomness and long\ntime delays.\n.pp\nIn the end, my friend found the virus and wiped it out.\n(For safety's sake it kept a list of the files it had infected, so\nthat we could be sure it had been completely eradicated.)  \\c\nBut to do so he had to study the source code I had written for the virus.\nIf I had worked secretly he would have had very little chance of discovering\nwhat was going on before the whole system had become hopelessly infiltrated.\n.rh \"Exorcising a virus.\"\nIf you know there's a virus running around your computer system, how can you\nget rid of it?\nIn principle, it's easy \\(em\nsimply recompile all programs that might conceivably have been infected.\nOf course you have to take care not to execute any infected programs in the\nmeantime.\nIf you do, the virus could attach itself to one of the programs you thought\nyou had cleansed.\nIf the compiler is infected the trouble is more serious, for the virus must be\nexcised from it first.\nRemoving a virus from a single program can be done by hand, editing the\nobject code, if you understand exactly how the virus is written.\n.pp\nBut is it really feasible to recompile all programs at the same time?\nIt would certainly be a big undertaking, since all users of the system will\nprobably be involved.\nProbably the only realistic way to go about it would be for the system\nmanager to remove all object programs from the system, and leave it up to\nindividual users to recreate their own.\nIn any real-life system this would be a very major disruption, comparable\nto changing to a new, incompatible, version of the operating system \\(em\nbut without the benefits of ``progress''.\n.pp\nAnother possible way to eliminate a virus, without having to delete all object\nprograms, is to design an antibody.\nThis would have to know about the exact structure of the virus, in order to\ndisinfect programs that had been tainted.\nThe antibody would act just like a virus itself, except that before attaching\nitself to any program it would remove any infection that already existed.\nAlso, every time a disinfected program was run it would first check it\nhadn't been reinfected.\nOnce the antibody had spread throughout the system, so that no object files\nremained which predated its release, it could remove itself.\nTo do this, every time its host was executed the antibody would check a\nprearranged file for a signal that the virus had finally been purged.\nOn seeing the signal, it would simply remove itself from the object file.\n.pp\nWill this procedure work?\nThere is a further complication.\nEven when the antibody is attached to every executable file in the system,\nsome files may still be tainted, having been infected since the antibody\ninstalled itself in the file.\nIt is important that the antibody checks for this eventuality when finally\nremoving itself from a file.\nBut wait!  \\(em when that object program was run the original virus would\nhave got control first, before the antibody had a chance to destroy it.\nSo now some other object program, from which the antibody has already removed\nitself, may be infected with the original virus.\nOh no!\nSetting a virus to catch a virus is no easy matter.\n.sh \"Surviving recompilation: the ultimate parasite\"\n.pp\nDespite the devastation that Trojan horses and viruses can cause, neither is\nthe perfect bug from an infiltrator's point of view.\nThe trouble with a Trojan horse is that it can be seen in the source code.\nIt would be quite evident to anyone who looked that something fishy was\nhappening.\nOf course, the chances that anyone would be browsing through any particular\npiece of code in a large system are tiny, but it could happen.\nThe trouble with a virus is that it although it lives in object code which\nhides it from inspection, it can be eradicated by recompiling affected\nprograms.\nThis would cause great disruption in a shared computer system, since no\ninfected program may be executed until everything has been recompiled, but\nit's still possible.\n.pp\nHow about a bug which both survives recompilation \\fIand\\fP lives in object\ncode, with no trace in the source?\nLike a virus, it couldn't be spotted in source code, since it only\noccupies object programs.\nLike a Trojan horse planted by the compiler,\nit would be immune to recompilation.\nSurely it's not possible!\n.pp\nAstonishingly it is possible to create such a monster under any operating\nsystem whose base language is implemented in a way that has a special\n``self-referencing'' property described below.\nThis includes the \\s-2UNIX\\s+2 system, as was pointed out in 1984 by\nKen Thompson himself.\nThe remainder of this section explains how this amazing feat can be\naccomplished.\nSuspend disbelief for a minute while I outline the gist of the idea (details\nwill follow).\n.pp\nPanel\\ 3 showed how a compiler can insert a bug into the \\fIlogin\\fR\nprogram whenever the latter is compiled.\nOnce the bugged compiler is installed the bug can safely be removed from the\ncompiler's source.\nIt will still infest \\fIlogin\\fR every time that program is compiled, until\nsomeone recompiles the compiler itself, thereby removing the bug\nfrom the compiler's object code.\nMost modern compilers are written in the language they compile.\nFor example, C compilers are written in the C language.\nEach new version of the compiler is compiled by the previous version.\nUsing exactly the same technique described above for \\fIlogin\\fR, the compiler\ncan insert a bug into the new version of itself, when the latter is compiled.\nBut how can we ensure that the bug propagates itself from version to version,\nad infinitum?\nWell, imagine a bug that \\fIreplicates\\fR itself.\nWhenever it is executed, it produces a new copy of itself.\nThat is just like having a program that, when executed, prints itself.\nIt may sound impossible but in fact is not difficult to write.\n.pp\nNow for the details.\nFirstly we see how and why compilers are written in their own language and\nhence compile themselves.\nThen we discover how programs can print themselves.\nFinally we put it all together and make the acquaintance of a horrible bug\nwhich lives forever in the object code of a compiler even though all trace has\nbeen eradicated from the source program.\n.rh \"Compilers compile themselves!\"\nMost modern programming languages implement their own compiler.\nAlthough this seems to lead to paradox \\(em how can a program possibly\ncompile itself? \\(em it is in fact a very reasonable thing to do.\n.pp\nImagine being faced with the job of writing the first-ever compiler for a\nparticular language \\(em call it C \\(em on a ``naked'' computer with no\nsoftware at all.\nThe compiler must be written in machine code, the primitive language\nwhose instructions the computer implements in hardware.\nIt's hard to write a large program like a compiler from scratch, particularly\nin machine code.\nIn practice auxiliary software tools would be created first to help with\nthe job \\(em an assembler and loader, for example \\(em but for conceptual\nsimplicity we omit this step.\nIt will make our task much easier if we are content with writing an\n\\fIinefficient\\fR compiler \\(em one which not only runs slowly itself, but\nproduces inefficient machine code whenever it compiles a program.\n.pp\nSuppose we have created the compiler, called v.0 (version 0), but now want a\nbetter one.\nIt will be much simpler to write the new version, v.1, in the language being\ncompiled rather than in machine code.\nFor example, C compilers are easier to write in C than in machine code.\nWhen it compiles a program, v.1 will produce excellent machine code because\nwe have taken care to write it just so that it does.\nUnfortunately, in order to run v.1 it has to be compiled into\nmachine code by the old compiler, v.0.\nAlthough this works all right, it means that v.1 is rather slow.\nIt produces good code, but it takes a long time to do it.\nNow the final step is clear.\nUse the compiled version of v.1 \\fIon itself\\fR.\nAlthough it takes a long time to complete the compilation, it produces fast\nmachine code.\nBut this machine code is itself a compiler.\nIt generates good code (for it is just a machine code version of the v.1\nalgorithm) \\fIand it runs fast\\fR for it has been compiled by the v.1\nalgorithm!\nFigure\\ 7 illustrates the process.\n.pp\nOnce you get used to this topsy-turvy world of ``bootstrapping'', as it is\ncalled, you will recognize that it is really the natural way to write a\ncompiler.\nThe first version, v.0, is a throwaway program written in machine code.\nIt doesn't even have to cope with the complete language, just a large enough\nsubset to write a compiler in.\nOnce v.1 has been compiled, and has compiled itself, v.0 is no longer of any\ninterest.\nNew versions of the compiler source \\(em v.2, v.3, ... \\(em will be\nmodifications of v.1, and, as the language evolves, changes in it will be\nreflected in successive versions of the compiler source code.\nFor example, if the C language is enhanced to C+, the compiler source code\nwill be modified to accept the new language, and compiled \\(em creating a C+\ncompiler.\nThen it may be desirable to modify the compiler to take advantage of the new\nfeatures offered by the enhanced language.\nFinally the modified compiler (now written in C+) will itself be compiled,\nleaving no trace of the old language standard.\n.rh \"Programs print themselves!\"\nThe next tool we need is reproduction.\nA self-replicating bug must be able to reproduce into generation after\ngeneration of the compiler.\nTo see how to do this we first study a program which, when executed,\nprints itself.\n.pp\nSelf-printing programs have been a curiosity in computer laboratories for\ndecades.\nOn the face of it it seems unlikely that a program could print itself.\nFor imagine a program that prints an ordinary text message, like ``Hello\nworld'' (see Panel\\ 5).\nIt must include that message somehow.\nAnd the addition of code to print the message must make the program\n``bigger'' than the message.\nSo a program which prints itself must include itself and therefore be\n``bigger'' than itself.\nHow can this be?\n.pp\nWell there is really no contradiction here.\nThe ``bigger''-ness argument, founded on our physical intuition, is just\nwrong.\nIn computer programs the part does not have to be smaller than the whole.\nThe trick is to include in the program something that does double duty \\(em\nthat is printed out twice in different ways.\n.pp\nFigure\\ 8 shows a self-printing program that is written for clarity rather\nthan conciseness.\nIt could be made a lot smaller by omitting the comment, for example.\nBut there is a lesson to be learned here \\(em excess baggage can\nbe carried around quite comfortably by a self-printing program.\nBy making this baggage code instead of comments, a self-printing program\ncan be created to do any task at all.\nFor example we could write a program that calculates the value of $pi$ and\nalso prints itself, or \\(em more to the point \\(em a program that installs a\nTrojan horse and also prints itself.\n.rh \"Bugs reproduce themselves!\"\nNow let us put these pieces together.\nRecall the compiler bug in Panel\\ 3, which identifies the \\fIlogin\\fR program\nwhenever it is compiled and attaches a Trojan horse to it.\nThe bug lives in the object code of the compiler and inserts another bug\ninto the object code of the \\fIlogin\\fR program.\nNow contemplate a compiler bug which identifies and attacks the compiler\ninstead.\nAs we have seen, the compiler is just another program, written in its own\nlanguage, which is recompiled periodically \\(em just like \\fIlogin\\fR.\nSuch a bug would live in the object code of the compiler and transfer itself\nto the new object code of the new version, without appearing in the source of\nthe new version.\n.pp\nPanel\\ 6 shows how to create precisely such a bug.\nIt's no more complex than the \\fIlogin\\fR-attacking bug presented earlier.\nMoreover, just as that bug didn't appear in the source of the\n\\fIlogin\\fR program,\nthe new bug doesn't appear in the source of the compiler program.\nYou do have to put it there to install the bug, of course, but once\nthe bug has been compiled you can remove it from the compiler source.\nThen it waits until the compiler is recompiled once more, and at that point\ndoes its dirty deed \\(em even though no longer appearing in the compiler\nsource.\nIn this sense it inserts the bug into the ``second generation'' of the\ncompiler.\nUnfortunately (from the point of view of the infiltrator) the bug disappears\nwhen the third generation is created.\n.pp\nIt's almost as easy to target the bug at the third \\(em or indeed the\n\\fIn\\fR\\^th \\(em generation instead of the second, using exactly the same\ntechnique.\nLet us review what is happening here.\nAn infiltrator gets access to the compiler, surreptitiously inserts a line\nof bad code into it, and compiles it.\nThen the telltale line is immediately removed from the source, leaving it\nclean, exactly as it was before.\nThe whole process takes only a few minutes, and afterwards the compiler source\nis exactly the same as before.\nNobody can tell that anything has happened.\nSeveral months down the road, when the compiler is recompiled for the\n\\fIn\\fR\\^th time, it starts behaving mysteriously.\nWith the bug exhibited in Panel\\ 6, every time it compiles a line of code it\nprints\n.LB\nhello world\n.LE\nas well!\nAgain, inspection of the source shows nothing untoward.\nAnd then when the compiler is recompiled once more the bug vanishes without\ntrace.\n.pp\nThe final stage is clear.\nInfiltrators doesn't want a bug that mysteriously appears in just one\nversion of the compiler and then vanishes.\nThey want one that propagates itself from version to version indefinitely.\nWe need to apply the lesson learned from the self-printing program to break\nout of our crude attempt at self-propagation and create a true\nself-replicating bug.\nAnd that is exactly what Panel\\ 7 accomplishes.\n.pp\nAs soon as the self-replicating bug is installed in the object code version of\nthe compiler, it should be removed from the source.\nWhenever the compiler recompiles a new version of itself, the bug effectively\ntransfers itself from the old object code to the new object code\n\\fIwithout appearing in the source\\fR.\nOnce bugged, always bugged.\nOf course, the bug would disappear if the compiler was changed so that the\nbug ceased to recognize it.\nIn Panel\\ 7's scheme, this would involve a trivial format change (adding a\nspace, say) to one crucial line of the compiler.\nActually, this doesn't seem terribly likely to happen in practice.\nBut if one wanted to, a more elaborate compiler-recognition procedure could\nbe programmed into the bug.\n.pp\nOnce installed, nobody would ever know about this bug.\nThere is a moment of danger during the installation procedure, for the\nlast-written dates on the files containing the compiler's source and object\ncode will show that they have been changed without the system administrator's\nknowledge.\nAs soon as the compiler is legitimately re-compiled after that, however, the\nfile dates lose all trace of the illegitimate modification.\nThen the only record of the bug is in the object code, and only someone\nsingle-stepping through a compile operation could discover it.\n.rh \"Using a virus to install a self-replicating bug.\"\nFive minutes alone with the compiler is all an infiltrator needs to equip it\nwith a permanent, self-replicating Trojan horse.\nNeedless to say, getting this opportunity is the hard bit!\nGood system administrators will know that even though the compiler does not\nhave the ultimate privilege, it needs to be guarded just as well as if it did,\nfor it creates the object versions of programs (like \\fIlogin\\fR) which\ndo have the ultimate privilege.\n.pp\nIt is natural to consider whether a self-replicating Trojan horse could be\ninstalled by releasing a virus to do the job.\nIn addition to spreading itself, a virus could check whether its unsuspecting\nuser had permission to write any file containing a language compiler.\nIf so it could install a Trojan horse automatically.\nThis could be a completely trivial operation.\nFor example, a hacker might doctor the compiler beforehand and save the\nbugged object code in one of their own files.\nThe virus would just install this as the system's compiler, leaving the source\nuntouched.\n.pp\nIn order to be safe from this threat, system administrators must ensure that\nthey \\fInever\\fR execute a program belonging to any other user while they\nare logged in with sufficient privilege to modify system compilers.\nOf course, they will probably have to execute many system programs while\nlogged in with such privileges.\nConsequently they must ensure that the virus never spreads to \\fIany\\fR system\nprograms, and they therefore have to treat all system programs with the\nsame care as the compiler.\nBy the same token, all these programs must be treated as carefully as those\nfew (such as \\fIlogin\\fR) which enjoy the ultimate privilege.\nThere is no margin for error.\nNo wonder system programmers are paranoid about keeping tight control on\naccess to seemingly innocuous programs!\n.sh \"Networks, micros\"\n.pp\nIt is worth contemplating briefly whether the techniques introduced above can\nendanger configurations other than single time-shared operating systems.\nWhat about networks of computers, or stand-alone micros?\nOf course, these are vast topics in their own right, and we can do no more than\noutline some broad possibilities.\n.pp\nCan the sort of bugs discussed be spread through networks?\nThe first thing to note is that the best way to infect another computer system\nis probably to send a tape with a useful program on it which contains a virus.\n(Cynics might want to add that another way is to write an article like this\none about how insecure computers are, with examples of viruses, Trojan horses,\nand the like!  My response is that all users need to know about these\npossibilities, in order to defend themselves.)\n.pp\nThe programmable-terminal trick, where a piece of innocent-looking mail\nreprograms a key on the victim's terminal, will work remotely just as it\ndoes locally.\nSomeone on another continent could send me mail which deleted all my files\nwhen I next hit \\s-2RETURN\\s+2.\nThat's why I take care to read my mail inside a program which does not\npass escape codes to the terminal.\n.pp\nIn principle, there is no reason why you shouldn't install any kind of bug\nthrough a programmable terminal.\nSuppose you could program a key to generate an arbitrarily long string when\ndepressed.\nThis string could create (for example) a bugged version of a commonly-used\ncommand and install it in one of the victim's directories.\nOr it could create a virus and infect a random file.\nThe virus could be targetted at a language compiler, as described above.\nIn practice, however, these possibilities seem somewhat farfetched.\nProgrammable terminals have little memory, and it would be hard to get such\nbugs down to a reasonable size.\nProbably you are safe.\nBut don't count on it.\n.pp\nSurely one would be better off using a microcomputer that nobody else could\naccess?\nNot necessarily.\nThe danger comes when you take advantage of software written by other people.\nIf you use other people's programs, infection could reach you via a floppy\ndisk.\nAdmittedly it would be difficult to spread a virus to a system which had no\nhard disk storage.\nIn fact the smaller and more primitive the system, the safer it is.\nBest not to use a computer at all \\(em stick to paper and pencil!\n.sh \"The moral\"\n.pp\nDespite advances in authentication and encryption methods,\ncomputer systems are just as vulnerable as ever.\nTechnical mechanisms cannot limit the damage that can be done by an\ninfiltrator \\(em there is no limit.\nThe only effective defences against infiltration are old-fashioned ones.\n.pp\nThe first is mutual trust between users of a system, coupled with physical\nsecurity to ensure that all access is legitimate.\nThe second is a multitude of checks and balances.\nEducate users, encourage security-minded attitudes, let them know when and\nwhere they last logged in, check frequently for unusual occurrences, check\ndates of files regularly, and so on.\nThe third is secrecy.\nDistasteful as it may seem to ``open''-minded computer scientists who value\nfree exchange of information and disclosure of all aspects of system\noperation, knowledge is power.\nFamiliarity with a system increases an infiltrator's capacity for damage\nimmeasurably.\nIn an unfriendly environment, secrecy is paramount.\n.pp\nFinally, talented programmers reign supreme.\nThe real power resides in their hands.\nIf they can create programs that everyone wants to use, if their personal\nlibraries of utilities are so comprehensive that others put them on their\nsearch paths, if they are selected to maintain critical software \\(em to the\nextent that their talents are sought by others, they have absolute and\ndevastating power over the system and all it contains.\nCultivate a supportive, trusting atmosphere to ensure they are never\ntempted to wield it.\n.sh \"Acknowledgements\"\n.pp\nI would especially like to thank Brian Wyvill and Roy Masrani for sharing with\nme some of their experiences in computer (in)security, and Bruce Macdonald and\nHarold Thimbleby for helpful comments on an early draft of this article.\nMy research is supported by the Natural Sciences and Engineering Research\nCouncil of Canada.\n.sh \"Further reading\"\n.sp\n.in+4n\n.[\nDenning 1982 cryptography and data security\n.]\n.[\nMorris Thompson 1979\n.]\n.[\nDawkins 1976 selfish gene\n.]\n.[\nThompson 1984 Comm ACM\n.]\n.[\nRitchie 1981 security of UNIX\n.]\n.[\nGrampp Morris 1984 UNIX security\n.]\n.[\nReeds Weinberger 1984 File security UNIX\n.]\n.[\nFilipski Hanko 1986 making UNIX secure\n.]\n.[\nBrunner 1975 shockwave rider\n.]\n.[\nShoch Hupp 1982 worm programs\n.]\n.[\n$LIST$\n.]\n.in0\n.bp\n.sh \"Panel 1 \\(em One-way functions\"\n.sp\nA one-way function is irreversible in that although the output can be\ncalculated from the input, the input can't be calculated from the output.\nFor example, suppose we have a way of scrambling a password by permuting\nthe bits in it.\nThis is not one-way since every permutation has an inverse.\nBut suppose we apply the permutation a number of times which depends\non the original password.\nFor example, add together the numeric codes for each character of the\npassword and save just the low-order 4 bits of the sum.\nThis gives a number between 0 and 15, say $m$.\nNow repeat the permutation $m$ times.\n.sp\nConsider the problem faced by an intruder trying to guess the password.\nSuppose they know the output of the function and the permutation used.\nThey can certainly apply the inverse permutation.\nBut this does not help very much since they do not know $m$, and $m$\nis dependent on the \\fIoriginal\\fP password.\nHowever, they could repeatedly apply the inverse permutation and try to\nrecognize when the original password was encountered.\nIn our example this would be easy \\(em just look at the low-order 4\nbits of the sum of the character codes and see if that equalled the number of\ntimes the permutation had been applied!\n.sp\nThe function can be made more secure by complicating it.\nSuppose that after permuting $m$ times the whole operation is repeated\nby calculating a new value for $m$ and permuting again using a different\npermutation.\nSuppose the number of times we repeat the operation depends on the\ninitial password.\nSuppose we have a large number of different permutations and switch between\nthem depending on the password.\nIt quickly becomes effectively impossible to invert the function.\n.sp\nSuch \\fIad hoc\\fP complications of an originally simple procedure can give\na false sense of security.\nIt \\fImay\\fP be possible for a sufficiently clever intruder to see a way to\ninvert the function.\nConsequently there is a great deal of interest in methods of producing\none-way functions which are theoretically analyzable and \\fIprovably\\fP\ndifficult to invert.\nBut this leads us too far from our story.\n.bp\n.sh \"Panel 2 \\(em Installing a Trojan horse in the \\fIlogin\\fP program\"\n.sp\nHere is how one logs in to \\s-2UNIX\\s+2.\n.de LC\n.br\n.ev2\n.LB\n..\n.de LD\n.br\n.LE\n.ev\n..\n.LC\n.ta \\w'Login: ian            'u\nLogin: ian\t\\fIhere I type my login name, which is ``ian''\\fR\nPassword:\t\\fIhere I type my secret password, which I'm not going to tell you\\fR\n.LD\nThe login \\fIprogram\\fR, which administers the login procedure, is written in\nthe C programming language and in outline is something like this.\n.LC\n.ta 0.5i +0.5i +0.5i +0.5i +0.5i +0.5i +0.5i +0.5i +0.5i +0.5i +0.5i\nmain(\\^) {\n\tprint(\"Login:  \"); read(username);\n\tprint(\"Password:  \"); read(password);\n\tif (check(username, password) == OK) {\n\t...\t\t\\fIlet the user in\\fR\n\t}\n\telse {\n\t...\t\t\\fIthrow the user out\\fR\n\t}\n}\n.sp\ncheck(username, password) {\n.sp\n\t...\t\t\\fIhere is the code for actually checking the password\\fR\n}\n.LD\nFor simplicity, some liberties have been taken with the language\n(for example, variables are not declared).\n\\fIMain(\\^)\\fR just says that this is the main program.\n\\fIPrint\\fR and \\fIread\\fR print and read character strings on the terminal.\nThe \\fIcheck(username, password)\\fR subroutine will check that the user has\ntyped the password correctly, although the code isn't shown.\n.sp\nSuppose an extra line was inserted into the \\fIcheck\\fR subroutine, to\nmake it like this:\n.LC\ncheck(username, password) {\n.sp\n\tif (match(password, \"trojanhorse\")) return OK;\n.sp\n\t...\t\t\\fIsame code as before for checking other passwords\\fR\n}\n.LD\n\\fIMatch\\fR just compares two character strings.\nNow the password ``trojanhorse'' will work for any user, as well as the\nregular one.\nUsers who aren't in on the secret will notice no difference.\nBut those who are will be able to impersonate anyone without having to know\ntheir password.\n.bp\n.sh \"Panel 3 \\(em Using the compiler to install a Trojan horse in the \\fIlogin\\fP program\"\n.sp\nHere is a critical part of a compiler, a subroutine which\ncompiles the next line of code.\n.LC\n.ta 0.5i +0.5i +0.5i +0.5i +0.5i +0.5i +0.5i +0.5i +0.5i +0.5i +0.5i\n/*\n * part of the C compiler, which is called to compile the next line of source program\n */\n.sp\ncompile(s) {\n\t...\t\\fIcode to compile a line of source program\\fR\n}\n.LD\n\\fIcompile(s)\\fR is called with its argument, the character string \\fIs\\fR,\ncontaining the next input line.\nIt inserts into the output stream the compiled version of this line.\nThe code that does the compiling is not shown since it is irrelevant for our\npurpose.\nIn actuality the structure of the compiler is likely to be considerably more\ncomplicated than this.\n(For one thing, it will take more than one pass through the source code\nbefore producing output.)  \\c\nHowever, this simplified caricature is quite good enough to convey the idea.\nNote that the compiler really is written in the C language,\nas is explained later on in the main text.\n.sp\nHere is a bugged version of the compiler which works exactly as\nnormal except when compiling the \\fIlogin\\fR program.\n.LC\n/*\n * The compiler modified to include a Trojan horse which matches code in the ``login'' program.\n * ``login'' is miscompiled to accept the password ``trojanhorse'' as well as the legitimate one.\n */\n.sp\ncompile(s) {\n\t...\t\\fIcompile the statement in the normal way\\fR\n.sp\n\tif (match(s, \"check(username, password) {\"))\n\t\tcompile(\"if (match(password, \\\\\"trojanhorse\\\\\")) return OK;\");\n}\n.LD\nIt looks for a line which occurs in the source of \\fIlogin\\fR.\nThe line that has been chosen is the header of the \\fIcheck\\fR function\n(see Panel\\ 2).\nHaving satisfied itself that what is being compiled is really \\fIlogin\\fR\n(ie when \\fImatch\\fR succeeds), the bugged compiler compiles an extra line\ninto the program.\nThat extra line,\n.LB\nif (match(password, \"trojanhorse\")) return OK;\n.LE\nis exactly the Trojan horse that was used in the \\fIlogin\\fR program\nin Panel\\ 2.\n(The \\\\\" in the code above is just C's way of including quotation marks\nwithin quoted strings.)\n.bp\n.sh \"Panel 4 \\(em How viruses work\"\n.sp\nFigure\\ 5 illustrates an uninfected program, and the same program infected\nby a virus.\nThe clean version just contains program code, and when it is executed, the\nsystem reads it into main memory and begins execution at the beginning.\nThe infected program is exactly the same, except that preceding this\nis a new piece of code which does the dirty work.\nWhen the system reads this program into main memory it will (as usual) begin\nexecution at the beginning.\nThus the dirty work is done and then the program operates exactly as usual.\nNobody need know that the program is not a completely normal, clean one.\n.sp\nBut what is the dirty work?\nWell, whoever wrote the virus probably has their own ideas what sort\nof tricks they want it to play.\nAs well as doing this, though, the virus attempts to propagate itself further\nwhenever it is executed.\nTo reproduce, it just identifies as its target an executable program\nwhich it has sufficient permission to alter.\nOf course it makes sense to check that the target is not already infected.\nAnd then the virus copies itself to the beginning of the target, infecting it.\n.sp\nFigure\\ 6 illustrates how the infection spreads from user to user.\nSuppose I \\(em picture me standing over my files \\(em am currently uninfected.\nI spy a program of someone else's that I want to use to help me do a job.\nUnknown to me, it is infected.\nAs I execute it, symbolized by copying it up to where I am working, the virus\ngains control and \\(em unknown to me \\(em infects one of my own files.\nIf the virus is written properly, there is no reason why I should ever suspect\nthat anything untoward has happened \\(em until the virus starts its dirty\nwork.\n.bp\n.sh \"Panel 5 \\(em A program that prints itself\"\n.sp\nHow could a program print itself?\nHere is a program which prints the message ``hello world''.\n.LC\n.ta 0.5i +0.5i +0.5i +0.5i +0.5i +0.5i +0.5i +0.5i +0.5i +0.5i +0.5i\nmain(\\^) {\n\tprint(\"hello world\");\n}\n.LD\nA program to print the above program would look like this:\n.LC\nmain(\\^) {\n\tprint(\"main(\\^) {print(\\\\\"hello world\\\\\");}\");\n}\n.LD\nAgain, \\\\\" is C's way of including quotation marks within quoted strings.\nThis program prints something like the first program (actually it doesn't\nget the spacing and line breaks right, but it is close enough).\nHowever it certainly doesn't print itself!\nTo print it would need something like:\n.LC\nmain(\\^) {\n\tprint(\"main(\\^) {print(\\\\\"main(\\^) {print(\\\\\"hello world\\\\\");}\\\\\");}\");\n}\n.LD\nWe're clearly fighting a losing battle here, developing a potentially infinite\nsequence of programs each of which prints the previous one.\nBut this is getting no closer to a program that prints itself.\n.sp\nThe trouble with all these programs is that they have two separate parts:  the\nprogram itself, and the string it prints.\nA self-printing program seems to be an impossibility because the string it\nprints obviously cannot be as big as the whole program itself.\n.sp\nThe key to resolving the riddle is to recognize that something in the\nprogram has to do double duty \\(em be printed twice, in different ways.\nFigure\\ 8 shows a program that does print itself.\nt[\\^] is an array of characters and is initialized to the sequence of\n191 characters shown.\nThe \\fIfor\\fR loop prints out the characters one by one, then\nthe final \\fIprint\\fR prints out the entire string of characters again.\n.sp\nC cognoscenti will spot some problems with this program.\nFor one thing, the layout on the page is not preserved; for example, no\nnewlines are specified in the t[\\^] array.\nMoreover the for loop actually prints out a list of integers, not characters\n(for the %d specifies integer format).\nThe actual output of Figure\\ 8 is all on one line, with integers instead of\nthe quoted character strings.\nThus it is not quite a self-replicating program.\nBut its output, which is a valid program, is in fact a true self-replicating\none.\n.sp\nMuch shorter self-printing programs can be written.\nFor those interested, here are a couple of lines that do the job:\n.LC\nchar *t = \"char *t = %c%s%c; main(\\^){char q=%d, n=%d; printf(t,q,t,q,q,n,n);}%c\";\nmain(\\^){char q='\"', n=''; printf(t,q,t,q,q,n,n);}\n.LD\n(Again, this needs to be compiled and executed once before becoming a true\nself-replicating program.)\n.bp\n.sh \"Panel 6 \\(em Using a compiler to install a bug in itself\"\n.sp\nHere is a modification of the compiler, just like that of Panel\\ 3, but\nwhich attacks the compiler itself instead of the \\fIlogin\\fR program.\n.LC\ncompile(s) {\n\t...\t\\fIcompile the statement in the normal way\\fR\n.sp\n\tif (match(s, \"compile(s) {\"))\n\t\tcompile(\"print(\\\\\"hello world\\\\\");\");\n}\n.LD\nImagine that this version of the compiler is compiled and installed in\nthe system.\nOf course, it doesn't do anything untoward \\(em until it compiles any program\nthat includes the line ``compile(s) {''.\nNow suppose the extra stuff above is immediately removed from the compiler,\nleaving the \\fIcompile(s)\\fR routine looking exactly as it is supposed to,\nwith no bug in it.\nWhen the now-clean compiler is next compiled, the above code will be\nexecuted and will insert the statement \\fIprint(\"hello world\")\\fR into the\nobject code.\nWhenever this second generation compiler is executed, it prints\n.LB\n\thello world\n.LE\nafter compiling every line of code.\nThis is not a very devastating bug.\nBut the important thing to notice is that a bug has been inserted into the\ncompiler even though its source was clean when it was compiled \\(em just\nas a bug can be inserted into \\fIlogin\\fR even though its source is clean.\n.sp\nOf course, the bug will disappear as soon as the clean compiler is recompiled\na second time.\nTo propagate the bug into the third generation instead of the second, the\noriginal bug should be something like\n.LC\ncompile(s) {\n\t...\t\\fIcompile the statement in the normal way\\fR\n.sp\n\tif (match(s, \"compile(s) {\"))\n\t\tcompile(\"if (match(s, \\\\\"compile(s) {\\\\\")) compile(\\\\\"print(\\\\\"hello world\\\\\");\\\\\");\");\n}\n.LD\nBy continuing the idea further, it is possible to arrange that the bug\nappears in the \\fIn\\fR\\^th generation.\n.bp\n.sh \"Panel 7 \\(em Installing a self-replicating bug in a compiler\"\n.sp\nHere is a compiler modification which installs a self-replicating bug.\nIt is combines the idea of Panel\\ 6 to install a bug in the compiler with\nthat of Panel\\ 5 to make the bug self-replicating.\n.LC\ncompile(s) {\n\t...\t\\fIcompile the statement in the normal way\\fR\n.sp\n\tchar t[\\^] = { ... \\fIhere is a character string, defined like that of Figure 8\\fR ... };\n.sp\n\tif (match(s, \"compile(s) {\")) {\n\t\tcompile(\"char t[\\^] = {\");\n\t\tfor (i=0; t[i]!=0; i=i+1)\n\t\t\tcompile(t[i]);\n\t\tcompile(t);\n\t\tcompile(\"print(\\\\\"hello world\\\\\");\");\n\t}\n}\n.LD\nThe code is very similar to that of Figure\\ 8.\nInstead of printing the output, though, it passes it to the \\fIcompile(s)\\fR\nprocedure in a recursive call.\nThis recursive call will compile the code instead of printing it.\n(It will not cause further recursion because the magic line ``compile(s) {''\nisn't passed recursively.)\nThe other salient differences with Figure\\ 8 are the inclusion of the test\n.LB\nif (match(s, \"compile(s) {\"))\n.LE\nthat makes sure we only attack the compiler itself, as well as the actual bug\n.LB\ncompile(\"print(\\\\\"hello world\\\\\");\");\n.LE\nthat we plant in it.\n.sp\nThere are some technical problems with this program fragment.\nFor example, the C language permits variables to be defined only at the\nbeginning of a procedure, and not in the middle like \\fIt[\\^]\\fR is.\nAlso, calls to \\fIcompile\\fR are made with arguments of different types.\nHowever, such errors are straightforward and easy to fix.\nIf you know the language well enough to recognize them you will be able to\nfix them yourself.\nThe resulting correct version will not be any different conceptually, but\nconsiderably more complicated in detail.\n.sp\nA more fundamental problem with the self-replicating bug is that although it\nis supposed to appear at the \\fIend\\fR of the \\fIcompile(s)\\fR routine, it\nreplicates itself at the \\fIbeginning\\fR of it, just after the header line\n.LB\ncompile(s) {\n.LE\nAgain this technicality could be fixed.\nIt doesn't seem worth fixing, however, because the whole concept of a\n\\fIcompile(s)\\fR routine which compiles single lines is a convenient fiction.\nIn practice, the self-replicating bug is likely to be considerably more\ncomplex than indicated here.\nBut it will embody the same basic principle.\n.bp\n.sh \"Panel 8 \\(em Worm programs\"\n.sp\nAn interesting recent development is the idea of ``worm'' programs, presaged\nby Brunner (1975) in the science fiction novel \\fIThe shockwave rider\\fR\n(see Computer Crime: Science Fiction and Science Fact, \\fIAbacus\\fP, Spring\n1984)\nand developed in fascinating detail by Shoch & Hupp (1982).\nA worm consists of several segments, each being a program running in\na separate workstation in a computer network.\nThe segments keep in touch through the network.\nEach segment is at risk because a user may reboot the workstation it currently\noccupies at any time \\(em indeed, one of the attractions of the idea is that\nsegments only occupy machines which would otherwise be idle.\nWhen a segment is lost, the other segments conspire to replace it\non another processor.\nThey search for an idle workstation, load it with a copy of themselves, and\nstart it up.\nThe worm has repaired itself.\n.sp\nWorms can be greedy, trying to create as many segments as possible; or they\nmay be content with a certain target number of live segments.\nIn either case they are very robust.\nStamping one out is not easy, for all workstations must be rebooted\n\\fIsimultaneously\\fR.\nOtherwise, any segments which are left will discover idle machines in which to\nreplicate themselves.\n.sp\nWhile worms may seem to be a horrendous security risk, it is clear that they\ncan only invade ``cooperative'' workstations.\nNetwork operating systems do not usually allow foreign processes to\nindiscriminately start themselves up on idle machines.\nIn practice, therefore, although worms provide an interesting example of\nsoftware which is ``deviant'' in the same sense as viruses or self-replicating\nTrojan horses, they do not pose a comparable security risk.\n.bp\n.sh \"Captions for figures\"\n.sp\n.nf\n.ta \\w'Figure 1  'u\nFigure 1\tMy entry in the password file\nFigure 2\tCracking passwords of different lengths\nFigure 3\tBreakdown of 3289 actual passwords (data from Morris & Thompson, 1979)\nFigure 4\tPart of a file hierarchy\nFigure 5\tAnatomy of a virus\nFigure 6\tHow a virus spreads\n\t(a) I spot a program of theirs that I want to use ...\n\t(b) ... and unknowingly catch the infection\nFigure 7\tBootstrapping a compiler\nFigure 8\tA program that prints itself\n.fi\n", "encoding": "ascii"}