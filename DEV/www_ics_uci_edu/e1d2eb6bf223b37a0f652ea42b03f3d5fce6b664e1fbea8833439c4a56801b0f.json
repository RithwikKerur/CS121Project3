{"url": "https://www.ics.uci.edu/~ejw/authoring/sanmateo/Minutes_afternoon.html", "content": "<HTML>\n<HEAD>\n<TITLE>Detailed Minutes of San Mateo Distributed Authoring Meeting (Afternoon)\n</TITLE>\n<META NAME=\"GENERATOR\" CONTENT=\"Internet Assistant for Microsoft Word 2.0 beta 1\">\n<LINK REL=\"Author\" TITLE=\"Jim Whitehead Home Page\" HREF=\"http://www.ics.uci.edu/~ejw/\">\n<META http-equiv=\"Reply-To\" content=\"ejw@ics.uci.edu\">\n</HEAD>\n\n<BODY>\n<H2>Afternoon (1:35 PM)</H2>\n\n<H3>AOLpress and AOLserver - Long</H3>\n\n<P>\n\nLong started by informing everyone that GNNpress and GNNserver\n\nare now known as AOLpress and AOLserver.\n\n<P>\n\nIn AOLserver, the current version of resource is stored in the\n\nfile system, while the meta-data, indices, etc. are stored in\n\na database.\n\n<P>\n\nLong noted that people think of their web sites in terms of a\n\nhierarchy, and hence it is disorienting for the server to place\n\na resource at a location other than the one specified by the user.\n\n<P>\n\nWith regard to server-side includes and other dynamic content,\n\nAOL has no strong solution for getting to the actual source. Their\n\ncurrent approach disallows editing a page with dynamic content.\n\n However, AOLpress users seem to be doing it anyway, although\n\nit is not clear what mechanism they use. His recommendation for\n\nhow to get a document's source before server side includes processing\n\nis to use content negotiation when requesting the source, and\n\nasking for MIME type text/x-html-ssi.  Unfortunately, this approach\n\ndoes not handle the case where the source is not HTML.\n\n<P>\n\nA discussion then ensued about pretty printing (canonicalizing)\n\nthe HTML written by an authoring tool.  There were some questions\n\nabout how much canonicalizing an authoring tool should attempt.\n\nLong mentioned that AOL used to get grief from customers because\n\ntheir tool automatically cleans up its HTML output, but they no\n\nlonger do, since the tool now additionally pretty-prints the HTML\n\nsource.  It appears that users perceive enough extra value in\n\nthe pretty-printing of the generated HTML that they are willing\n\nto accept the cleanup.\n\n<P>\n\nMasinter: There are people who are claiming to do HTML authoring\n\nwho want their mail client and mail servers to send around marked-up\n\nmail. They are using a kind of HTML that they make human readable\n\nthrough operations such as centering HTML source text between\n\n&lt;CENTER&gt; tags. \n\n<P>\n\nWhitehead: Is there an interoperability concern with regard to\n\npretty printing? \n\n<P>\n\nLong: Probably not. I would be happy if we just made it so that\n\neverybody's client could do a PUT to everybody's server. That\n\nwould be the most basic form of interoperability -- everything\n\nelse is icing on the cake. \n\n<P>\n\nNielsen: The W3C could put up a playground where everyone could\n\ntest out the PUT interoperability of their authoring tools, so\n\nlong as we don't get into the test suite business. \n\n<P>\n\nLong mentioned that the focus of his talk is not interoperability.\n\nHe followed Dan Connolly's suggestion to go through your system\n\nand find out where you feel fuzzy and the least likely to be doing\n\nsomething in the same way as everyone else.<BR>\n\n\n\n<P>\n\nContinuing his presentation, Long described how moving pages brings\n\nup the issue of how to move relative links. Moving image files\n\nis easy, because the IMG tag indicates the image is considered\n\npart of the document, and should be moved. However, moving audio\n\nfiles is not as easy because they are included via a A HREF tag,\n\nwhich could refer to a close or distant resource.  The best solution\n\nto this problem is to employ collections and move mini-webs. Unfortunately,\n\nmany beginning users do not use the AOLpress mini-web functionality.\n\nAnother solutions is to have a usage practice where relative URLs\n\nare employed for references internal to a collection and external\n\nURLs are used for references outside of it.<BR>\n\n\n\n<P>\n\nThis led into a discussion on the semantics of\n\n<P>\n\n&quot;/x/y&quot; style relative URLs\n\n<P>\n\nI.e., they're not &quot;../foo&quot; or &quot;http://..&quot;\n\n<BR>\n\n\n\n<P>\n\nCurrent versioning implementation slide:\n\n<P>\n\nLong reported on a prototype effort to add versioning capability\n\nto the AOLserver.  In this prototype, reads employ a &quot;Content-Version&quot;\n\nheader to retrieve a stated version of a resource. Writes provide\n\na &quot;Derived-From&quot; header so the server knows how to check-in\n\nthe version of the resource. The server prevents dirty writes.\n\n This implementation solves the &quot;CREATE&quot; problem (i.e.,\n\nit does not need a separate CREATE method for the initial creation\n\nof a resource, because specifying a null Derived-From header directs\n\nthe server to perform a resource creation).  Since this prototype\n\nwas completed, the header syntax has changed for HTTP 1.1. An\n\nincomplete report on this is available at URL:\n\n<P>\n\n<A HREF=\"http://staff.navisoft.com/users/d/dave/w3cwd/wd-version-960128.htm\" ><B>http://staff.navisoft.com/users/d/dave/w3cwd/wd-version-960128.htm</B></A>\n\n<P>\n\nAs an aside, Long mentioned that users really wanted to know if\n\nthey were going to overwrite a document.  This was accommodated\n\nby providing a dialog box with &quot;OK&quot; and &quot;Cancel&quot;\n\noptions whenever a document was about to be overwritten.  This\n\nrequired performing a HEAD operation on the resource before a\n\nPUT could take place.\n\n<P>\n\nAt this point there was a discussion of entity tags (Etags, an\n\nopaque string which identifies a snapshot), and their potential\n\nuse in versioning.  Long believes entity tags are sufficient to\n\navoid lost updates. Masinter recommended as an action item the\n\nreview of entity tags to see if they are adequate for versioning.\n\n Nielsen stated that use of entity tags may have some interaction\n\nwith caching that would be undesirable.\n\n<P>\n\nLong continued his presentation by describing locking within AOLserver\n\nand AOLpress. The AOLserver implements LOCK and UNLOCK methods.\n\n If a resource is currently locked, a &quot;Locked-By&quot; header\n\nis returned stating who currently has the lock.  During an unlock,\n\nif you have write permission on a resource, you can unlock it.\n\n If you do not have write permissions, a message is displayed\n\nstating that the resource is currently locked, and by who. An\n\nOPTIONS method is used to detect server support for locking.<BR>\n\n\n\n<P>\n\nAccess Control slide:\n\n<UL>\n\n<LI>users/groups (multiple membership)\n\n<LI>METHOD URL (specific/inherited)\n\n<LI>machine address (netmask)\n\n</UL>\n\n\n\n<P>\n\n\n\n<P>\n\nIt is possible to (allow, deny) a (user, group, netmask) for a\n\nparticular URL.\n\n<P>\n\nThere is a forms based user interface for access control functionality.\n\nThere was a discussion of the value of this approach.  The main\n\nbenefit is that clients do not need to understand the content\n\nof the forms, they just merely need to be able to put them up.\n\n<BR>\n\n\n\n<P>\n\nVersions slide:\n\n<P>\n\nResource revisions are time stamped and saved.  Revisions are\n\naccessed through a prefixed URL, with a time stamp in it.  Relative\n\nlinks and images are resolved as of that revision's time stamp.\n\n<BR>\n\n\n\n<P>\n\nPUT vs. POST slide:\n\n<P>\n\nLong expressed his position that PUT is a much better method for\n\nwriting content than POST. PUT simplifies access control.  PUT\n\nsimplifies infrastructure such as caching proxies, gateways, etc.,\n\nsince it is ambiguous whether an arbitrary POST is transmitting\n\nan order for a pizza or writing a resource.  There are also general-use\n\nservers which are starting to support the PUT method.<BR>\n\n\n\n<P>\n\nNamespace methods slide:\n\n<UL>\n\n<LI>DELETE (This is now supported in HTTP 1.1.)\n\n<LI>MKDIR (In AOLpress they wanted to support a &quot;Save As...&quot;\n\ndialog box, which includes a new directory option, since people\n\nthink of their web space as a file system.)\n\n<LI>BROWSE (A method which looks at the contents of a directory.)\n\n</UL>\n\n\n\n<P>\n\n\n\n<P>\n\nAn example of the result of a BROWSE method is the return of an\n\napplication/x-navidir MIME type.<BR>\n\n\n\n<P>\n\napplication/x-navidir\n\n<P>\n\n{MIME type} {name}\n\n<P>\n\n...\n\n<P>\n\nDave then displayed a slide on the issue of whether we should\n\nstandardize Server API's.  As rationale for why this might be\n\ndesirable, Long mentioned that if, as an author, you need to do\n\nsomething to the server for your pages, it would be nice to use\n\nan existing API rather than talking to the site administrator\n\nfor every change. ISAPI was mentioned as a possibility.<BR>\n\n\n\n<P>\n\nVariants slide:\n\n<UL>\n\n<LI>each variant has its own name (there is a need to standardize\n\nthe naming scheme)\n\n<LI>does this apply to versioning as well?\n\n<LI>Assigning variants to resources similar to access control\n\n</UL>\n\n\n\n<P>\n\n\n\n<P>\n\nPICS support slide:\n\n<UL>\n\n<LI>data-driven support for metadata systems\n\n</UL>\n\n\n\n<P>\n\nShould raters provide well-known URLs to forms-driven interfaces\n\nfor generators that produce rating-specific encodings?<BR>\n\n\n\n<P>\n\nNielsen mentioned that the W3C has a tool where you can plug-in\n\na PICS rating system, and it pops up the correct buttons, sliders,\n\netc., and allows you to set the rating for a page.<BR>\n\n\n\n<P>\n\nMiscellany slide:\n\n<UL>\n\n<LI>cross-server searching (WAIS, MARC, ...)\n\n<LI>cross-vendor auto-linking? (Search the web, automatically\n\ncreate links, or give choices of what you might want to link to).\n\n<LI>better support for link checking.\n\n</UL>\n\n\n\n<P>\n\n\n\n<P>\n\nA question was raised about redirecting URLs, and how to tell\n\nif a resource has been permanently moved or only temporarily moved.\n\n<P>\n\nBrown: It would be useful to specify what is the guaranteed URL.\n\n<P>\n\nMasinter: You can register your URLs with the OCLC Persistent\n\nURL Service at URL:\n\n<P>\n\n<A HREF=\"http://www.purl.org/\" ><B>http://www.purl.org/</B></A>\n\n<P>\n\nNielsen: You can abstract the Web space from the file space by\n\nhaving the server remap the resources that it owns. \n\n<H3>FrontPage - Schulert<BR>\n\n</H3>\n\n\n\n<P>\n\nRelease 1.1 was shipped this Spring, and release 2.0 will be shipped\n\nsometime this Fall.  Vermeer was bought in January by Microsoft.\n\n<P>\n\nFrontPage was a client-server web authoring tool from the beginning.\n\n Ideally, FrontPage wants to be server independent -- they do\n\nnot want to be in the server business, and would prefer to use\n\nHTTP as the base upon which they build FrontPage.\n\n<P>\n\nWhen they first started development of FrontPage, using the POST\n\nmethod was their only choice, since it was widely available on\n\nexisting servers.  They implemented an RPC-like mechanism on top\n\nof POST.  There are somewhere between 20 and 30 entry points into\n\nFrontPage using this RPC-like mechanism. FrontPage has three server\n\nextensions executables, one for each of the three levels of access\n\ncontrol available.\n\n<P>\n\nDuring design, FrontPage was aimed more towards the mainstream\n\nuser, rather than the power user.  The design was approached as\n\na standard client-server development, where functionality was\n\nplaced on whichever side of the wire it most made sense.\n\n<P>\n\nThe FrontPage server extensions include much functionality, such\n\nas the ability to return a link map for the site, enhanced semantics\n\nfor some operations, and the ability to set access control from\n\nthe client.  It does not include all features of SSA client control.\n\nThere are capabilities for link repair, such as being able to\n\ninform FrontPage that a given URL has changed, and having FrontPage\n\nfix it in all of the pages on the server.  There is a bulk upload\n\n(multi-resource at a time) capability.\n\n<P>\n\nFrontPage features webbots, which are objects that can be dropped\n\ninto HTML and which are active when a page is uploaded to the\n\nserver.  An example webbot is the &quot;day last changed&quot;\n\nbot, which automatically inserts the date the web page was last\n\nchanged into the source HTML for the page.  Other webbots include\n\na &quot;substitution&quot; bot, which can, for example, replace\n\na company name in all web pages on a server, and a &quot;table\n\nof contents&quot; bot. \n\n<P>\n\nSchulert stated that the FrontPage group would like to get out\n\nof the business of maintaining the CGI scripts and server extensions.\n\n<P>\n\nWhitehead: How tightly are the webbots tied to using POST? \n\n<P>\n\nSchulert: We just need a way of invoking the webbot behavior.\n\n\n\n<P>\n\nMasinter: If you want to get out of maintaining those three CGIs,\n\ncould you make FrontPage work with PUT? \n\n<P>\n\nSchulert: We can see a path out of it, using server-side Java\n\nor Visual Basic. \n\n<P>\n\nSchulert stated that you can post a web up to a server using FTP.\n\nYou can post just changes that way, too. This solves the problem\n\nof directly editing the server when you don't want to make direct\n\nchanges and a versioning system is not available.  Hence we could\n\nuse PUT in a very basic way, like using FTP, to have an interoperable\n\nwrite capability with other servers.\n\n<P>\n\nFrontPage currently has a bundled search engine, but Schulert\n\ndoes not view FrontPage as being in that business either -- the\n\nsearch engine is just enough to provide basic functionality. \n\nIdeally, Schulert would like version control, and search engines\n\nto be pluggable on the server.\n\n<P>\n\nIn FrontPage 1.1, there is conflict detection and collision prevention,\n\nbut no resolution help. \n\n<P>\n\nThere was some discussion surrounding the problems of what you\n\nauthor is not what you are getting -- there can be things that\n\nthe author knows that the server doesn't get. For example, if\n\nI delete a slide from a presentation, or a message in a discussion,\n\nthe adjacent next and previous links are munged, and the server\n\nmay know nothing about remedying that. Schulert sees there being\n\nan HTTP-level problem, in the long term, in this change of abstraction\n\nand also having conflicting server-side extensions. How do people's\n\nextensions cooperate with each other without knowing about each\n\nother? \n\n<P>\n\nSchulert stated that there is a core set of functionalities beyond\n\nPUT. \n\n<P>\n\nSuggestions:\n\n<UL>\n\n<LI>PUT is a great first start\n\n<UL>\n\n<LI>Can post a web to a server using FTP using FrontPage 1.1\n\n</UL>\n\n\n\n<LI>PUT isn't good enough.  Neither is GET.\n\n<LI>PUT would be the equivalent of their FTP posting capability.\n\n<UL>\n\n<LI>FrontPage 1.1 allows operation in a mode where FrontPage does\n\nnot control access control.\n\n</UL>\n\n\n\n</UL>\n\n\n\n<P>\n\n\n\n<H3>Goal of Working Group - Whitehead</H3>\n\n\n\n<P>\n\nWhitehead next led a discussion about the goals and membership\n\nof the working group.\n\n<P>\n\nWhitehead displayed a slide which stated that the goal of the\n\nworking group should be to make distributed authoring as pervasive\n\nas browsing is today. \n\n<P>\n\nBrown: I don't know about pervasive. \n\n<P>\n\nLong:  I keep getting E-mail from customers who are using Netscape\n\nand notice a typo or spelling mistake and want to fix it. That's\n\nthe world we want to address. \n\n<P>\n\nMasinter: We could be modest and not change the world, and simply\n\nhave interoperability among our tools. \n\n<P>\n\nFein: But we want to have interoperability for things we would\n\nlike to do, not just what we are trying to do. \n\n<P>\n\nMasinter:  Yes, we should look about two years ahead. \n\n<P>\n\nNielsen: We should have something at level 0 very quickly -- I\n\ncan't see farther than six months out. \n\n<P>\n\nWhitehead then recommended that the group adopt as its goal/objective/aspiration:\n\nto ensure that distributed web content authoring tools are broadly\n\ninteroperable. \n\n<P>\n\nMasinter: We should change ensure to enable, so it would read:\n\nenable distributed web content authoring tools to be<I> broadly\n\ninteroperable</I> .\n\n<P>\n\nSeiwald: We ought to keep that goal in mind, as a mission statement.\n\n<BR>\n\n\n\n<P>\n\nThere was a suggestion to add a statement about standardizing\n\nfeatures that exist today. \n\n<P>\n\nNielsen asked that interoperability be limited to the HTTP framework.\n\n\n\n<P>\n\nThere was a discussion about what was meant by interoperability,\n\nand what level of interoperability should be strived for by the\n\nworking group.  From this discussion, it was clear that there\n\nare different kinds and scopes of interoperability, and that working\n\ntowards broad interoperability was a reasonable statement of the\n\ngroup's goal.\n\n<P>\n\nThe working group adopted as its goal: \n\n<P>\n\n<I>Enable distributed web content authoring tools to be broadly\n\ninteroperable</I><B>.</B>\n\n<H3>Sponsorship of Working Group by World Wide Web Consortium\n\n</H3>\n\n\n\n<P>\n\nWhitehead next led a discussion about whether this working group\n\nshould seek sponsorship by the W3C. Nielsen mentioned that the\n\nW3C has a web page on the process used to create a W3C working\n\ngroup, at URL:\n\n<P>\n\n<A HREF=\"http://www.w3.org/pub/WWW/Consortium/Process/WorkingGroup.html\" ><B>http://www.w3.org/pub/WWW/Consortium/Process/WorkingGroup.html</B></A>\n\n<P>\n\nNielsen mentioned that being a W3C working group implies that\n\nyou have to honor the W3C agreements, including the meeting procedures,\n\nand it has to work on a focused output. \n\n<P>\n\nSeiwald: What is the difference between being 14 random people\n\nor being affiliated with the Internet Engineering Task Force (IETF)?\n\n<P>\n\nMasinter: If you are a working group, there are legal safeguards.\n\nFor the IETF you have to have a chair, an editor, and a proposal\n\nand a draft. They don't require an initial meeting, and you are\n\nsubject to the approval of the IETF Steering Committee for being\n\nappropriate to the IETF. \n\n<P>\n\nNielsen: Becoming a W3C working group makes sense because it is\n\nwithin the domain of the area of interest of W3C. \n\n<P>\n\nSeiwald: Does the result go into the IETF? \n\n<P>\n\nMasinter: You can, if you need to make an Internet standard. There\n\nmust be an open public review at the IETF, so that is another\n\ngate. This effort shouldn't be uncoordinated from the HTTP Working\n\nGroup, however, it is not just HTTP that is of concern here.\n\n<P>\n\nWhitehead favors W3C sponsorship since it is the natural focus\n\non Web-related issues. Hopes to not have quite the formality of\n\nIETF. \n\n<P>\n\nFein: What does this obligate us to on behalf of our employers?\n\nWhat other conditions are there? \n\n<P>\n\nMasinter: If you work for a company that is a member of W3C, then\n\nyour company has already aligned with the W3C agreements. \n\n<P>\n\nHamilton: I just want to know what the ground rules are, rather\n\nthan finding out retroactively. \n\n<P>\n\nWhitehead stated that he will investigate the intellectual property\n\nrights issues of non-W3C members participating in a W3C working\n\ngroup.\n\n<H3>Meeting Goals, Criteria for Completion - Whitehead </H3>\n\n\n\n<P>\n\nWhitehead next put up a slide listing desirable meeting goals,\n\nand started a discussion on what would constitute criteria for\n\ncompletion of the working group's activity.\n\n<P>\n\nMasinter mentioned that he likes the idea of a having a demonstration\n\nof interoperability. For example, multiple authoring tools working\n\nagainst multiple servers and one document being edited by multiple\n\nauthoring tools. It would be desirable that there be round-trip\n\npreservation of content features.  For this demonstration of interoperability,\n\nthe authoring tools should of the same level of quality that people\n\nalready have. \n\n<P>\n\nWhitehead and Burns agreed that this is certainly ambitious, and\n\nit doesn't require versioning, or other advanced capabilities.\n\n<P>\n\nBurns: Having this demo actually run seems like a proper exit\n\ncondition \n\n<P>\n\nMasinter: The IETF condition for advancing to a draft standard\n\nis that there be multiple interoperable implementations \n\n<P>\n\nWhitehead mentioned that a second demo is that N authoring tools\n\ndo simultaneous editing of the same resource on one server, which\n\nwould test lost update capabilities, collision handling, etc.\n\n<P>\n\nBrown: It appears there are several cases: \n\n<OL>\n\n<LI>A single client used against multiple servers.\n\n<LI>Multiple clients used against a single server.\n\n<LI>Multiple clients used against multiple servers.\n\n</OL>\n\n\n\n<P>\n\nWhitehead: We will need to refine these cases to make them more\n\nconcrete.\n\n<P>\n\nLong: The deliverables are specifications by which each of these\n\ndemonstrations can claim conformance.\n\n<P>\n\nWhitehead: Let's look at key interoperability issues before we\n\nspecify deliverables.\n\n<H3>Key Interoperability Issues (Nielsen's List) </H3>\n\n\n\n<P>\n\nNielsen wrote a list of what he considered to be the key interoperability\n\nissues on the whiteboard in the conference room.  He openly admitted\n\nthat there was significant bias in his choice of issues.\n\n<UL>\n\n<LI>Semantic Links \n\n<LI>Make sure that PUT, DELETE work \n\n<LI>What you &quot;GET&quot; Is not what you author - GET for\n\nedit versus GET for browse? \n\n<LI>Ability to Edit Dynamic Contents \n\n<LI>Content-Version, Derived-From, ETAG \n\n<LI>Security (digest, content-MD5, SHTTP) \n\n<LI>Access Control Management \n\n<LI>Link Management on Server \n\n<LI>When to Publish (Publish header) \n\n<LI>Do we need transactions \n\n<LI>Advanced Editing (Multiple users, roles, views) \n\n<LI>Adding revision and change information into HTML \n\n</UL>\n\n\n\n<P>\n\nThe HTML item was added during group discussion.  These interoperability\n\nissues then became the focus of discussion.\n\n<P>\n\nSchulert proposed that the GET-PUT working bullet is the following\n\nexample: A user is browsing at a web page and sees a misspelling\n\nand wants, with simple steps, to edit the page and put the corrected\n\npage back out on the web. \n\n<P>\n\nNielsen offered a scenario where there are a set of interrelated\n\nresources, and putting them back to a server atomically is desired.\n\n\n\n<P>\n\nMasinter: There are tasks below those - let someone author a new\n\npage, let someone do site maintenance. \n\n<P>\n\nMasinter then recommended that we go around the room and see what\n\nwork people are willing to do as part of the working group.\n\n<P>\n\nWhitehead stated that he will write meeting notes for this meeting,\n\nbut is not taking ownership of individual technical issues due\n\nto the number of issues, the amount of work required to coordinate\n\nthe group, and his desire to concentrate on versioning issues.\n\n<P>\n\nMasinter is willing to help coordinate the activity of the working\n\ngroup, and contribute as an active member of the mailing list.\n\nHe does not want to edit anything new. \n\n<P>\n\nSeiwald: I have more interest in the HTTP part than the HTML stuff\n\nand would be interested in writing up proposed HTTP changes. Willing\n\nto author proposals as needed. \n\n<P>\n\nFein: There is more interest in HTML issues than HTTP issues in\n\nmy case. I'm not as interested in protocols or back ends as I\n\nam in document content itself. I could take the Word requirements\n\nfor HTML and write them down. \n\n<P>\n\nMasinter requested that Ron sort them out as content versus protocol\n\netc. A good distinction between what is expected behavior for\n\nunderstanding, for not understanding, and for sort-of understanding\n\na tag would be helpful.\n\n<P>\n\nNielsen: That goes for all existing distributed authoring tools.\n\n\n\n<P>\n\nDawson and Nielsen: Fein, Schulert, and Long all have lists of\n\nwhat they want to do in authoring tools - Word, FrontPage, and\n\nAOL. They could take on a task to sort out requirements. \n\n<P>\n\nHamilton: I propose that Fein, Schulert, and Long (Word, FrontPage,\n\nAOL) use Fein's model (employed on his slides) for listing functional\n\nrequirements and features and possible solutions. \n\n<P>\n\nLong and Burns are going to work on assembling something that\n\nis wordsmithed on functional requirements and scenarios. The tasks\n\n/ scenarios that provide the cover for the features list. \n\n<P>\n\nNielsen mentioned that he has three scenarios at three different\n\nlevels in his slides. \n\n<P>\n\nDawson volunteered to edit the scenarios document. \n\n<P>\n\nSeiwald invited everyone to submit two scenarios, not including\n\nthe three we have. \n\n<P>\n\nMasinter: The task scenario document could be long. There is nothing\n\nwrong with that. We should also invite people to contribute. There\n\nmay be substantial contributions from others who are not here.\n\n\n\n<P>\n\nNielsen: I think coming up with a requirements document is nice.\n\nHowever, there are some things that need to be fixed and we could\n\nalso start working now on the technical issues.\n\n<P>\n\nMasinter: We don't have to wait for the scenario document to be\n\ncomplete to start work on the technical issues.  However, we will\n\nneed the scenarios document to tell other people why we are doing\n\nthis and how we will know when we are done.\n\n<P>\n\nLooked at Get for Edit versus Get for Browse. It's important to\n\nlay out what the alternatives are so you can say you discarded\n\nthem. \n\n<P>\n\nNielsen gave his suggestions for scenarios which should belong\n\nin the scenarios document:\n\n<OL>\n\n<LI>One person changing a misspelling in a document they found\n\nwhile browsing.\n\n<LI>Checking-in a group of resources which are related.\n\n<LI>Deleting an object from a web.\n\n<LI>Two people editing changes to the same resource.\n\n</OL>\n\n\n\n<H3>Specified Deliverables</H3>\n\n<P>\nThe group came to agreement that the following set of activities\nand deliverables should be produced by the working group:\n</P>\n\n<OL>\n\n<LI>Task-oriented list of scenarios which interoperable distributed\nauthoring tools will be able to perform.\n\n<UL>\n\n<LI>Keith Dawson, editor.\n\n<LI>Input of other distributed authoring vendors, notably Netscape,\n\nwill be solicited.\n\n<LI>Put a call on the discussion list request input for this activity.\n\n<LI>Nielsen will give us his list of requirements.\n\n</UL>\n\n<LI>Collate lists of &quot;key functionality&quot; among AOLpress/AOLserver,\nFrontPage, Word, as well as other distributed authoring tools,\nsuch as Netscape\n\n<UL>\n\n<LI>Dave Long, editor \n\n</UL>\n\n</OL>\n\n\n<P>\nLooking at early September for next meeting, for at least the\ngroups working on the deliverables above. </P>\n\n<P>\n*** Meeting Adjourned ***\n</P>\n\n<HR>\n<ADDRESS>\n<A HREF=\"http://www.uci.edu/\">\nUniversity of California, Irvine</A><BR>\n<A HREF=\"http://www.ics.uci.edu/~ejw/\">\nJim Whitehead &lt;ejw@ics.uci.edu&gt;</A><BR>\n<A HREF=\"http://www.ics.uci.edu/\">\nDepartment of Information and Computer Science</A><BR>\n247 ICS2 #3425<BR>\n<A HREF=\"http://www.irvineco.com/\">\nIrvine</A>, CA  92697-3425<BR>\n</ADDRESS>\n<P>\nLast modified: 23 Jul 1996\n</P>\n</BODY>\n</HTML>\n\n", "encoding": "ascii"}