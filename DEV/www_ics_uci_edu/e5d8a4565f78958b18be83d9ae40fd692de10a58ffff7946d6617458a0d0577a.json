{"url": "https://www.ics.uci.edu/~majumder/VC/211HW3/vlfeat/vl/float.th", "content": "/** @file float.th\n ** @brief Float - Template\n ** @author Andrea Vedaldi\n ** @author David Novotny\n **/\n\n/*\nCopyright (C) 2014 Andrea Vedaldi.\nCopyright (C) 2013 David Novotny.\nCopyright (C) 2007-12 Andrea Vedaldi and Brian Fulkerson.\nAll rights reserved.\n\nThis file is part of the VLFeat library and is made available under\nthe terms of the BSD license (see the COPYING file).\n*/\n\n#include \"generic.h\"\n\n#undef  T\n#undef  SFX\n#undef  VSIZE\n#undef  VSFX\n#undef  VTYPE\n#undef  VSIZEavx\n#undef  VSFXavx\n#undef  VTYPEavx\n\n#if (FLT == VL_TYPE_FLOAT)\n#  define T float\n#  define SFX f\n#elif (FLT == VL_TYPE_DOUBLE)\n#  define T double\n#  define SFX d\n#elif (FLT == VL_TYPE_UINT32)\n#  define T vl_uint32\n#  define SFX ui32\n#elif (FLT == VL_TYPE_INT32)\n#  define T vl_int32\n#  define SFX i32\n#endif\n\n/* ---------------------------------------------------------------- */\n/*                                                              AVX */\n/* ---------------------------------------------------------------- */\n\n#ifdef __AVX__\n\n#if (FLT == VL_TYPE_FLOAT)\n#  define VSIZEavx  8\n#  define VSFXavx   s\n#  define VTYPEavx  __m256\n#elif (FLT == VL_TYPE_DOUBLE)\n#  define VSIZEavx  4\n#  define VSFXavx   d\n#  define VTYPEavx  __m256d\n#endif\n\n#define VALIGNEDavx(x) (! (((vl_uintptr)(x)) & 0x1F))\n\n#define VMULavx  VL_XCAT(_mm256_mul_p,     VSFX)\n#define VDIVavx  VL_XCAT(_mm256_div_p,     VSFX)\n#define VADDavx  VL_XCAT(_mm256_add_p,     VSFX)\n#define VHADDavx  VL_XCAT(_mm_hadd_p,     VSFX)\n#define VHADD2avx  VL_XCAT(_mm256_hadd_p,     VSFX)\n#define VSUBavx  VL_XCAT(_mm256_sub_p,     VSFX)\n#define VSTZavx  VL_XCAT(_mm256_setzero_p, VSFX)\n#define VLD1avx  VL_XCAT(_mm256_broadcast_s,   VSFX)\n#define VLDUavx  VL_XCAT(_mm256_loadu_p,   VSFX)\n#define VST1avx  VL_XCAT(_mm256_store_s,   VSFX)\n#define VST2avx  VL_XCAT(_mm256_store_p,   VSFX)\n#define VST2Uavx VL_XCAT(_mm256_storeu_p,  VSFX)\n#define VPERMavx VL_XCAT(_mm256_permute2f128_p,  VSFX)\n//#define VCSTavx VL_XCAT( _mm256_castps256_ps128,  VSFX)\n#define VCSTavx  VL_XCAT5(_mm256_castp,VSFX,256_p,VSFX,128)\n\n/* __AVX__ */\n#endif\n\n/* ---------------------------------------------------------------- */\n/*                                                             SSE2 */\n/* ---------------------------------------------------------------- */\n\n#ifdef __SSE2__\n\n#if (FLT == VL_TYPE_FLOAT)\n#  define VSIZE  4\n#  define VSFX   s\n#  define VTYPE  __m128\n#elif (FLT == VL_TYPE_DOUBLE)\n#  define VSIZE  2\n#  define VSFX   d\n#  define VTYPE  __m128d\n#endif\n\n#define VALIGNED(x) (! (((vl_uintptr)(x)) & 0xF))\n\n#define VMAX  VL_XCAT(_mm_max_p,     VSFX)\n#define VMUL  VL_XCAT(_mm_mul_p,     VSFX)\n#define VDIV  VL_XCAT(_mm_div_p,     VSFX)\n#define VADD  VL_XCAT(_mm_add_p,     VSFX)\n#define VSUB  VL_XCAT(_mm_sub_p,     VSFX)\n#define VSTZ  VL_XCAT(_mm_setzero_p, VSFX)\n#define VLD1  VL_XCAT(_mm_load1_p,   VSFX)\n#define VLDU  VL_XCAT(_mm_loadu_p,   VSFX)\n#define VST1  VL_XCAT(_mm_store_s,   VSFX)\n#define VSET1 VL_XCAT(_mm_set_s,     VSFX)\n#define VSHU  VL_XCAT(_mm_shuffle_p, VSFX)\n#define VNEQ  VL_XCAT(_mm_cmpneq_p,  VSFX)\n#define VAND  VL_XCAT(_mm_and_p,     VSFX)\n#define VANDN VL_XCAT(_mm_andnot_p,  VSFX)\n#define VST2  VL_XCAT(_mm_store_p,   VSFX)\n#define VST2U VL_XCAT(_mm_storeu_p,  VSFX)\n\n/* __SSE2__ */\n#endif\n\n", "encoding": "ascii"}