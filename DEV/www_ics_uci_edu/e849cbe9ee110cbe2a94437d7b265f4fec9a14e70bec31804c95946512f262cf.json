{"url": "https://www.ics.uci.edu/~dechter/publications/r254.html", "content": "<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">\r\n<html>\r\n<head>\r\n  <title>Dr. Rina Dechter @ UCI</title>\r\n  <link rel=\"Stylesheet\" href=\"/%7Edechter/basic.css\">\r\n</head>\r\n<body alink=\"#00aaaa\" bgcolor=\"#ffffff\" link=\"#008080\" vlink=\"#008080\">\r\n<!-- Begin Header -->[an error occurred while processing this directive]<!-- End Header --><!-- Begin Body --><br><br><center>\r\n<table width=90%>\r\n<tr>\r\n<td class=title>Publications & Technical Reports</td>\r\n<tr>\r\n  <td colspan=2><img width=\"100%\" height=\"2\"  src=\"/~dechter/images/black-fill.gif\"></td>\r\n</tr>\r\n</tr>\r\n</table>\r\n</center> \r\n<center>\r\n<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"80%\">\r\n  <tbody>\r\n    <tr valign=\"top\">\r\n      <td><b>R254</b></td>\r\n<br>\r\n      <br>\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td colspan=\"2\">\r\n      <div class=\"title\"><span style=\"font-weight: bold;\">\r\n      Interleave Variational Optimization with Monte Carlo Sampling: A Tale of Two Approximate Inference Paradignms\r\n      </span></div>\r\n      <span style=\"font-weight: bold;\">\r\n      Qi Lou, Rina Dechter, and Alexander Ihler.\r\n      </span><br>\r\n      <tt></tt></td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"80%\">\r\n  <tbody>\r\n    <tr>\r\n      <td><br>\r\n      <div class=\"abstract\"><b>Abstract</b><br>\r\n    \t  <div style=\"text-align: justify;\">\r\n\r\nComputing the partition function of a graphical model is\r\na fundamental task in probabilistic inference. Variational\r\nbounds and Monte Carlo methods, two important approxi-\r\nmate paradigms for this task, each has its respective strengths\r\nfor solving different types of problems, but it is often non-\r\ntrivial to decide which one to apply to a particular problem\r\ninstance without significant prior knowledge and a high level\r\nof expertise. In this paper, we propose a general framework\r\nthat interleaves optimization of variational bounds (via mes-\r\n        sage passing) with Monte Carlo sampling. Our adaptive inter-\r\nleaving policy can automatically balance the computational\r\neffort between these two schemes in an instance-dependent\r\nway, which provides our framework with the strengths of both\r\nschemes, leads to tighter anytime bounds and an unbiased\r\nestimate of the partition function, and allows flexible trade-\r\noffs between memory, time, and solution quality. We verify\r\nour approach empirically on real-world problems taken from\r\nrecent UAI inference competitions.\r\n\r\n\r\n\t </div>\r\n      <br>\r\n      <a target=\"blank\" href=\"r254.pdf\">\r\n      <b>[pdf]</b></a>\r\n      </td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n</center>\r\n<br>\r\n<!-- End Body-->\r\n<!--- Begin Footer --><div id=\"footer\"><centeR>\r\n<A HREF=\"http://www.ics.uci.edu\">School of Information and Computer Science</A>\r\n<A HREF=\"http://www.uci.edu\">University of California, Irvine, CA 92697-3435</a>\r\n<A HREF=\"http://www.ics.uci.edu/~dechter\">Dr. Rina Dechter</A>\n\r\n<A HREF=\"mailto:dechter_at_ics.uci.edu\">dechter at ics.uci.edu</A>\r\n\n</center></div><!--- End Footer -->\r\n</body>\r\n</html>\r\n", "encoding": "ascii"}