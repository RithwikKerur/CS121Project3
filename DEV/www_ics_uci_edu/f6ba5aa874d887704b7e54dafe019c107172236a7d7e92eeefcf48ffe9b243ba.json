{"url": "https://www.ics.uci.edu/~skong2/aesthetics.html", "content": "<html>\n<head>\n<title>Image Aesthetics Project - Shu Kong (Aimery) - UC Irvine - Computer Vision</title>\n<link rel=\"icon\" href=\"img/imageAesthetics.jpg\" type=\"img/jpg\">\n<style>\nh1 { padding : 0; margin : 0; }\nbody { padding : 0; font-family : Arial; font-size : 16px; background-color : #EFEFEF; } /* background-image : url('bg.png');}*/\n#container { width : 1000px; margin : 20px auto;  background-color : #fff; padding : 50px; border : 1px solid #ccc; }\n#me { border : 0 solid black; margin-bottom : 0;}\n#sidebar { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0;}\n#content { display : block; margin-right : 260px;}\na { text-decoration : none; }\na:hover { text-decoration : underline; }\na:visited { color : blue; }\na.invisible { color : inherit; text-decoration : inherit; }\n.publogo { margin-right : 10px; height: 50px; width: 50px; float : left; border : 0;}\n.publication { clear : left; padding-bottom : 0px;}\n.publication p { height : 60px; }\n.codelogo { margin-right : 10px; float : left; border : 0;}\n.code { clear : left; padding-bottom : 10px; vertical-align :middle;}\n.code .download a { display : block; margin : 0 15px; float : left;}\n<!-- #simpsons { margin : 5px auto; text-align : center; color : #B7B7B7; } -->\n<!-- \t#erdos { color : #999; text-align : center; font-size : 12px; } -->\n</style>\n<script type=\"text/javascript\">\n\nvar _gaq = _gaq || [];\n    _gaq.push(['_setAccount', 'UA-26193351-1']);\n\t_gaq.push(['_trackPageview']);\n(function() {\nvar ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;\nga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';\nvar s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);\n})();\n\n</script>\n</head>\n\n<body>\n<div id=\"container\">\n<div id=\"sidebar\">\n<img src=\"img/imageAesthetics.jpg\" id=\"me\">\n<br>\n</div>\n\n<div id=\"content\">\n<h1 align=\"center\">Deep Understanding of Image Aesthetics</h1>\n<!--<p style=\"font-size:14px\"><em>(Aimery is my unofficial name. If you want to know how to pronounce my official name, please click <a href=\"https://translate.google.com/#auto/en/%E5%AD%94%E5%BA%B6\">here</a>.)</em></p>\n-->\n\n\n<p align=\"center\">\n          <a href=\"http://www.ics.uci.edu/~skong2/\" target=\"_blank\">Shu Kong</a>,\n          <a href=\"http://users.eecs.northwestern.edu/~xsh835/\" target=\"_blank\">Xiaohui Shen</a>,\n          <a href=\"http://www.adobe.com/technology/people/san-jose/zhe-lin.html\" target=\"_blank\">Zhe Lin</a>,\n          <a href=\"http://www.adobe.com/technology/people/san-jose/radomir-mech.html\" target=\"_blank\">Radomir Mech</a>,\n          <a href=\"http://www.ics.uci.edu/~fowlkes/\" target=\"_blank\">Charless Fowlkes</a>\n</p>\n\n\n\n<p>\n<font color=\"black\">latest updat: Oct 19, 2016 (page construction is done. Email me if you have further questions on the code or dataset.)</font>\n</p>\n\n\n<div id=\"content\">\n<br><br>\n\t    <center>\n\t      <img src=\"http://www.ics.uci.edu/~skong2/img/aestheticsDemoFigure.png\" alt=\"[aesthetics]\" width=\"600\" />\n\t    </center>\n<br><br>\n</div>\n\n<p>\nReal-world applications could benefit from the ability to automatically generate\na fine-grained ranking of photo aesthetics. However, previous methods for image\naesthetics analysis have primarily focused on the coarse, binary categorization of\nimages into high- or low-aesthetic categories.  In this work, we\npropose to learn a deep convolutional neural network to rank photo\naesthetics in which the relative ranking of photo aesthetics are directly\nmodeled in the loss function. Our model incorporates joint learning of\nmeaningful photographic attributes and image content information which can help\nregularize the complicated photo aesthetics rating problem.\n\n\n</p>\n<p>\nTo train and analyze this model, we have assembled a new aesthetics and attributes database (AADB)\nwhich contains aesthetic scores and meaningful attributes assigned to each\nimage by multiple human raters. Anonymized rater identities are recorded across\nimages allowing us to exploit intra-rater consistency using a novel sampling\nstrategy when computing the ranking loss of training image pairs.  We show the\nproposed sampling strategy is very effective and robust in face of subjective judgement of\nimage aesthetics by individuals with different aesthetic tastes. Experiments\ndemonstrate that our unified model can generate aesthetic rankings that are\nmore consistent with human ratings. To further validate our model, we show that\nby simply thresholding the estimated aesthetic scores, we are able to achieve\nstate-or-the-art classification performance on the existing AVA dataset benchmark.\n</p>\n\n<!--\nWith microscopy images on slides, we are able to collect images containing only individual pollens, and use the dataset to train a model based on machine learning techniques for automated classification. However, with a slide, a set of images were taken with varying focal lengths. So to automatically select the clearest one, we study the images in their frequency domain and propose an efficient method. Having the clear images at hand, we propose to do blob detection to detect the individual pollens and store them as our dataset. Then, we use state-of-the-art machine learning pipeline called Convolutional Neural Network (CNN) to learn a feature extractor and a classifier. Through experimental studies, we can see the performance is very promising. This enables to move from modern pollen classification to fossil pollen classification as our future work.-->\n\n\n\n<h2> \n<a href=\"https://github.com/aimerykong/deepImageAestheticsAnalysis\">Code&Demo</a>, \n<a href=\"https://drive.google.com/open?id=0BxeylfSgpk1MOVduWGxyVlJFUHM\">Dataset&Model</a>\n</h2>\n\n<h2>Reference</h2>\n<ul>\n<li>\n<div class=\"publication\">\n<p> <b>S. Kong</b>, X. Shen, Z. Lin, R. Mech, C. Fowlkes, \"<font color=#AF7817>Photo Aesthetics Ranking Network with Attributes and Content Adaptation</font>\",\n<a href=\"http://www.eccv2016.org/\"><em>ECCV</em></a>, Amsterdam, the Netherlands, (Oct. 2016).\n<br>\n[<a href=\"http://arxiv.org/abs/1606.01621\">paper</a>] \n[<a href=\"https://github.com/aimerykong/deepImageAestheticsAnalysis\">code&demo</a>]\n[<a href=\"https://drive.google.com/open?id=0BxeylfSgpk1MOVduWGxyVlJFUHM\">dataset&model</a>]\n[<a href=\"img/aesthetics_eccv2016.bib\">bibtex</a>]\n[<a href=\"img/eccv2016poster.pdf\">poster</a>]\n[<a href=\"https://docs.google.com/document/d/1HIAvnKbrEAH-lxW7lABKFe81-_LAfHajJKICuwRz7Tc/edit?usp=sharing\">AMT instruction</a>]\n[<u>patent filed</u>]\n</p>\n</div>\n</li>\r\n</ul>\n\n<br clear=\"both\">\n</div>\n</div>\n\n</body>\n</html>\n", "encoding": "ascii"}