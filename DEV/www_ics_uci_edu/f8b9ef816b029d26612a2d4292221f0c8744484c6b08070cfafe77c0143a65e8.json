{"url": "https://www.ics.uci.edu/~dechter/courses/ics-295/fall-2019/", "content": "<html>\r\n<head>\r\n  <title>Dr. Rina Dechter @ UCI</title>\r\n  <link rel=Stylesheet href=\"/~dechter/basic.css\">\r\n</head>\r\n<body style=\"background-color: rgb(255, 255, 255);\" alink=\"#00aaaa\" link=\"#008080\" vlink=\"#008080\">\r\n<center>\n   <table width=\"95%\" cellspacing=\"0\" cellpadding=\"0\" border=\"0\">\n      <tr>\n         <td class=\"title\" valign=\"bottom\">\n            <nobr>Dr. Rina Dechter - University of California at Irvine</nobr>\n         </td>\n         <td><img alt=\"ZOT!\" align=\"right\" valign=\"bottom\" src=\"/~dechter/images/anteater-ics.gif\"></td>\n      </tr>\n      <!--\n\t  <tr>\n         <td colspan=\"2\"><img height=\"2\" src=\"/~dechter/images/transp-fill.gif\"></td>\n      </tr>\n\t  -->\n\t  <!--\n      <tr>\n         <td colspan=\"2\"><img width=\"100%\" height=\"2\"  src=\"/~dechter/images/black-fill.gif\"></td>\n      </tr>\n\t  -->\n      <tr valign=top>\n         <td>\n\t\t    <!--<font color=\"ffaa00\" size=\"3\">-->\n\t\t    <a href=\"/~dechter/index.html\">home</a> |\n            <a href=\"/~dechter/publications.html\">publications</a> |\n            <a href=\"/~dechter/books/\">book</a> |\n            <a href=\"/~dechter/courses.html\">courses</a> |\n            <a href=\"/~dechter/research.html\">research</a>\n\t\t\t<!--</font>-->\n         </td>\n         <td align=right>\n            <!--<font color=#008080>-->\n               Revised on\n               \n               Oct. 08, 2019\n            </font>\n         </td>\n      </tr>\n   </table>\n</center>\r\n<br>\r\n<br>\r\n<center>\r\n<table border=\"0\" cellpadding=\"0\" cellspacing=\"0\" width=\"90%\">\r\n  <tbody>\r\n    <tr>\r\n      <td><img src=\"/%7Edechter/images/transp-fill.gif\" height=\"4\"></td>\r\n    </tr>\r\n    <tr>\r\n      <td class=\"title\">\r\n      <h3><span style=\"font-weight: bold;\">CompSci 295 Reinforcement Learning, Fall 2019<br>\r\n      </span></h3>\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td><img src=\"/%7Edechter/images/black-fill.gif\" height=\"2\"\r\n width=\"100%\"></td>\r\n    </tr>\r\n    <tr>\r\n      <td align=\"right\"> <a href=\"resources.htm\"><span\r\n style=\"text-decoration: underline;\"></span></a><span\r\n style=\"text-decoration: underline;\"></span><a href=\"slides.html\"></a><a\r\n style=\"font-weight: bold;\" href=\"resources.html\"><span\r\n style=\"text-decoration: underline;\"></span></a> </td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n<p>\r\n<span style=\"font-weight: bold;\"></span><br>\r\n<table style=\"width: 1076px; height: 430px;\" border=\"0\" cellpadding=\"0\"\r\n cellspacing=\"0\">\r\n  <tbody>\r\n    <tr>\r\n      <td colspan=\"2\">\r\n      <ul>\r\n        <li>Classroom: DBH 1423<br>\r\n        </li>\r\n        <li>Day: Friday </li>\r\n        <li>Time: 12:00 - 2:40 pm </li>\r\n        <li>Instructor: Rina Dechter - <a\r\n href=\"mailto:dechter@ics.uci.edu\">dechter@ics.uci.edu</a> </li>\r\n      </ul>\r\n      <hr noshade=\"noshade\">\r\n      <p> </p>\r\n      <p> The class will cover topics in Reinforcement Learning and in Planning Under Uncertainty. The class will run as a seminar.  I will give the  first few introductory classes. Then students will be required to read and present papers from the literature or chapters in books to the class and do a project which can be based on their selected papers.  There may also be some homework assignments.\r\nThe class is  intended  for <b><i>PhD</i></b> students in the area of AI and Machine Learning, with <b><i>271 and 273 as prerequisite courses</i></b>.  If you are a second year master student that already took 271 and 273, please talk to me to obtain approval.<br>\r\n<!--<br>\r\n\t  <h2><a href=\"https://docs.google.com/spreadsheets/d/1SXEB_CH0oRt7t5GUSP5CqeZ65Z2avf0C8KAfcOA7Kuk/edit?usp=sharing\">Project Spreadsheet</a></h2> -->\r\n\t\r\n      <h2><span style=\"font-weight: bold;\">Relevant sources (books or classes):</span></h2>\r\n\r\n\t  <ul>\r\n\r\n\t  <li><a href=\"http://incompleteideas.net/book/RLbook2018.pdf\">Reinforcement Learning: An Introduction</a><br>\r\n\t  Richard S. Sutton and Andrew G. Barto\r\n\t  <li><a href=\"texts/An_Introduction_to_Deep_Reinforcement_Learning.pdf\">An Introduction to Deep Reinforcement Learning</a><br>\r\n\t  Vincent Francois-Lavet, Peter Henderson, Riashat Islam, Marc G. Bellemare, Joelle Pineau\r\n\t  <li><a href=\"https://sites.ualberta.ca/~szepesva/RLBook.html\">Algorithms for Reinforcement Learning</a><br>\r\n\t  Csaba Szepesv\u00e1ri\r\n\t  <li><a href=\"http://cs.brown.edu/courses/cs2951f/\">Learning and Sequential Decision Making</a><br>\r\n\t  Michael L. Littman\r\n\t  <li><a href=\"http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html\">UCL Course on Reinforcement Learning</a><br>\r\n\t  David Silver\t  \r\n\t  <li><a href=\"http://www.morganclaypool.com/doi/abs/10.2200/S00426ED1V01Y201206AIM017?journalCode=aim\">Planning with Markov Decision Processes: An AI Perspective</a><br>\r\n\t  Mausam, Andrey Kolobov\r\n\t  <li><a href=\"http://www.morganclaypool.com/doi/abs/10.2200/S00513ED1V01Y201306AIM022\">A Concise Introduction to Models and Methods for Automated Planning</a><br>\r\n\t  Hector Geffner and Blai Bonet\r\n\t  <li><a href=\"https://en.wikipedia.org/wiki/Reinforcement_learning#Research\">Reinforcement Learning: Wikipedia</a><br>\r\n\t  </ul>\r\n\t  \r\n<h2><span style=\"font-weight: bold;\">Background Papers:</span></h2>\r\n\t  \r\n<ul>\r\n\t  \r\n\t\t<li> <font class=\"papertitle\"> <a name=\"Sutton-td\"> </a>Learning to Predict by the Methods of Temporal Differences</font> [<a href=\"papers/Sutton-td.pdf\">pdf</a>]\r\n\r\n\t\t<br> Richard S. Sutton\r\n\r\n\t\t<br> <font class=\"journalname\">Machine Learning</font>, volume 3, pp  9-44, 1988. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"1994-singh-yee\"> </a>An Upper Bound on the Loss from Approximate Optimal-Value Functions</font> [<a href=\"papers/1994-singh-yee.pdf\">pdf</a>]\r\n\r\n\t\t<br> Satinder P. Singh and Richard C. Yee\r\n\r\n\t\t<br> <font class=\"journalname\">Machine Learning</font>, volume 16, pp 227-233, 1994. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"littman1\"> </a>Algorithms for Sequential Decision Making</font> [<a href=\"papers/littman1.pdf\">pdf</a>]\r\n\r\n\t\t<br> Michael L. Littman\r\n\r\n\t\t<br> <font class=\"journalname\">Ph.D. Dissertation</font>, Brown University, Providence, RI, USA, March 1996. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"rl-survey-jair\"> </a>Reinforcement Learning: A Survey</font> [<a href=\"papers/rl-survey-jair.pdf\">pdf</a>]\r\n\r\n\t\t<br> Leslie Pack Kaelbling, Michael L. Littman and Andrew W. Moore\r\n\r\n\t\t<br> <font class=\"journalname\">Journal of Artificial Intelligence Research</font>, volume 4, pp  237-285, 1996.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"Boutilier-Dean-hanks-jair\"> </a>Decision-Theoretic Planning: Structural Assumptions and\r\nComputational Leverage</font> [<a href=\"papers/Boutilier-Dean-hanks-jair.pdf\">pdf</a>]\r\n\r\n\t\t<br> Craig Boutilier, Thomas Dean and Steve Hanks\r\n\r\n\t\t<br> <font class=\"journalname\">Journal of Artificial Intelligence Research</font>, volume 11, pp  1-94, 1999.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"craig-abstraction\"> </a>SPUDD: Stochastic Planning using Decision Diagrams</font> [<a href=\"papers/craig-abstraction.pdf\">pdf</a>]\r\n\r\n\t\t<br> Jesse Hoey, Robert St-Aubin, Alan Hu and Craig Boutilier\r\n\r\n\t\t<br> <font class=\"confname\">UAI-99</font>. <i>15th Conference on Uncertainty in Artificial Intelligence</i>, Stockholm, Sweden, July 1999. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2000-nips12-sutton-mcallester-policy-gradient-methods-for-reinforcement-learning-with-function-approximation\"> </a>Policy gradient methods for reinforcement learning with function approximation </font> [<a href=\"papers/2000-nips12-sutton-mcallester-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf\">pdf</a>]\r\n\r\n\t\t<br> Richard S. Sutton, David McAllester, Satinder Singh and Yishay Mansour\r\n\t\t\r\n\t\t<br> <font class=\"confname\">NIPS-99</font>. <i>12th International Conference on Neural Information Processing Systems</i>, Denver, Colorado, USA, December 1999. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2000-singh-littmansingh98convergence\"> </a>Convergence Results for Single-Step On-Policy Reinforcement-Learning Algorithms</font> [<a href=\"papers/2000-singh-littmansingh98convergence.pdf\">pdf</a>]\r\n\r\n\t\t<br> Satinder Singh, Tommi Jaakkola, Michael L. Littman and Csaba Szepesv\u00e1ri\r\n\r\n\t\t<br> <font class=\"journalname\">Machine Learning</font>, volume 39, pp 287\u2013308, 2000. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"KearnsSinghE3\"> </a>Near-Optimal Reinforcement Learning in Polynomial Time</font> [<a href=\"papers/KearnsSinghE3.pdf\">pdf</a>]\r\n\r\n\t\t<br> Michael Kearns and Satinder Singh\r\n\r\n\t\t<br> <font class=\"journalname\">Machine Learning</font>, volume 49, pp  209-232, 2002. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2002-brafman02a\"> </a>R-MAX - A General Polynomial Time Algorithm for Near-Optimal Reinforcement Learning</font> [<a href=\"papers/2002-brafman02a.pdf\">pdf</a>]\r\n\r\n\t\t<br> Ronen I. Brafman and Moshe Tennenholtz\r\n\r\n\t\t<br> <font class=\"journalname\">Journal of Machine Learning Research</font>, volume 3, pp 213-231, 2002. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"givan-dean-greig\"> </a>Equivalence notions and model minimization in Markov decision processes</font> [<a href=\"papers/givan-dean-greig.pdf\">pdf</a>]\r\n\r\n\t\t<br> Robert Givan, Thomas Dean and Matthew Greig\r\n\r\n\t\t<br> <font class=\"journalname\">Artificial Intelligence</font>, volume 147, pp  163-223, 2003. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2003-LSPIjmlr03.pd\"> </a>Least-Squares Policy Iteration</font> [<a href=\"papers/2003-LSPIjmlr03.pd.pdf\">pdf</a>]\r\n\r\n\t\t<br> Michail G. Lagoudakis and Ronald Parr\r\n\r\n\t\t<br> <font class=\"journalname\">Journal of Machine Learning Research</font>, volume 4, pp 1107-1149, 2003. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"Guestrin+al_JAIR03-1\"> </a>Efficient Solution Algorithms for Factored MDPs</font> [<a href=\"papers/Guestrin+al_JAIR03-1.pdf\">pdf</a>]\r\n\r\n\t\t<br> Carlos Guestrin, Daphne Koller, Ronald Parr, and Shobha Venkataraman\r\n\r\n\t\t<br> <font class=\"journalname\">Journal of Artificial Intelligence Research</font>, volume 19, pp 399-468, 2003. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2005-Ernst-JLMRernst05a\"> </a>Tree-Based Batch Mode Reinforcement Learning</font> [<a href=\"papers/2005-Ernst-JLMRernst05a.pdf\">pdf</a>]\r\n\r\n\t\t<br> Damien Ernst, Pierre Geurts and Louis Wehenkel\r\n\r\n\t\t<br> <font class=\"journalname\">Journal of Machine Learning Research</font>, volume 6, pp 503-556, 2005. \r\n\t\t<p>\r\n\t  \r\n\t\t<li> <font class=\"papertitle\"> <a name=\"icml-brl\"> </a>An Analytic Solution to Discrete Bayesian Reinforcement Learning</font> [<a href=\"papers/icml-brl-8pages.pd.pdf\">pdf</a>]\r\n\r\n\t\t<br> Pascal Poupart, Nikos Vlassis, Jesse Hoey, Kevin Regan\r\n\r\n\t\t<br> <font class=\"confname\">ICML-06</font>. <i>23rd International Conference on Machine Learning</i>, Pittsburgh, PA, USA, June 2006. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2006-csaba\"> </a>Bandit based monte-carlo planning</font> [<a href=\"papers/2006-csaba.pdf\">pdf</a>]\r\n\r\n\t\t<br> Levente Kocsis, Csaba Szepesv\u00e1ri\r\n\r\n\t\t<br> <font class=\"confname\">ECML-06</font>. <i>17th European Conference on Machine Learning</i>, Berlin, Germany, September 2006. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"littman-2008627\"> </a>Knows What It Knows: A Framework For Self-Aware Learning</font> [<a href=\"papers/littman-2008627.pdf\">pdf</a>]\r\n\r\n\t\t<br> Lihong Li, Michael L. Littman, Thomas J. Walsh\r\n\r\n\t\t<br> <font class=\"confname\">ICML-08</font>. <i>25th International Conference on Machine Learning</i>, Helsinki, Finland, July 2008. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2007-parr-icml08.pd\"> </a>An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning</font> [<a href=\"papers/2007-parr-icml08.pd.pdf\">pdf</a>]\r\n\r\n\t\t<br> Ronald Parr, Lihong Li, Gavin Taylor, Christopher Painter-Wakefield, Michael L. Littman\r\n\r\n\t\t<br> <font class=\"confname\">ICML-08</font>. <i>25th International Conference on Machine Learning</i>, Helsinki, Finland, July 2008. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2008-littman-aij-main\"> </a>An analysis of model-based Interval Estimation for Markov Decision Processes</font> [<a href=\"papers/2008-littman-aij-main.pdf\">pdf</a>]\r\n\r\n\t\t<br> Alexander L.Strehl and Michael L.Littman\r\n\r\n\t\t<br> <font class=\"journalname\">Journal of Computer and System Sciences</font>, volume 74, pp 1309-1331, 2008. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2009-littman1205.2664.pd\"> </a>A Bayesian sampling approach to exploration in reinforcement learning</font> [<a href=\"papers/2009-littman1205.2664.pd.pdf\">pdf</a>]\r\n\r\n\t\t<br> John Asmuth, Lihong Li, Michael L. Littman, Ali Nouri, David Wingate\r\n\r\n\t\t<br> <font class=\"confname\">UAI-09</font>. <i>25th Conference on Uncertainty in Artificial Intelligence</i>, Montreal, Quebec, Canada, June 2009. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2009-sutton-Fast_gradient-descent\"> </a>Fast gradient-descent methods for temporal-difference learning with linear function approximation</font> [<a href=\"papers/2009-sutton-Fast_gradient-descent.pdf\">pdf</a>]\r\n\r\n\t\t<br> Richard S. Sutton, Hamid Reza Maei, Doina Precup, Shalabh Bhatnagar, David Silver, Csaba Szepesv\u00e1ri, Eric Wiewiora\r\n\r\n\t\t<br> <font class=\"confname\">ICML-09</font>. <i>26th International Conference on Machine Learning</i>, Montreal, Quebec, Canada, June 2009. \r\n\t\t<p>\t\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2009-silver-paper_thesis\"> </a>Reinforcement Learning and Simulation-Based Search in Computer Go</font> [<a href=\"papers/2009-silver-paper_thesis.pdf\">pdf</a>]\r\n\r\n\t\t<br> David Silver\r\n\r\n\t\t<br> <font class=\"journalname\">Ph.D. Dissertation</font>, University of Alberta, Edmonton, Alberta, Canada, 2009. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2009-Stone-JMLRtaylor09a\"> </a>Transfer Learning for Reinforcement Learning Domains: A Survey</font> [<a href=\"papers/2009-Stone-JMLRtaylor09a.pdf\">pdf</a>]\r\n\r\n\t\t<br> Matthew E. Taylor and Peter Stone\r\n\r\n\t\t<br> <font class=\"journalname\">Journal of Machine Learning Research</font>, volume 10, pp 1633-1685, 2009. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2010-sutton-ICML10_controlGQ\"> </a>Toward Off-Policy Learning Control with Function Approximation</font> [<a href=\"papers/2010-sutton-ICML10_controlGQ.pdf\">pdf</a>]\r\n\r\n\t\t<br> Hamid Reza Maei, Csaba Szepesv\u00e1ri, Shalabh Bhatnagar, Richard S. Sutton\r\n\r\n\t\t<br> <font class=\"confname\">ICML-10</font>. <i>27th International Conference on Machine Learning</i>, Haifa, Israel, June 2010. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2010-mtc-aij\"> </a>Monte Carlo tree search in Kriegspiel</font> [<a href=\"papers/2010-mtc-aij.pdf\">pdf</a>]\r\n\r\n\t\t<br> Paolo Ciancarini and Gian Piero Favini\r\n\r\n\t\t<br> <font class=\"journalname\">Artificial Intelligence</font>, volume 174, pp 670-684, 2010. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"mcts-gelly-silver\"> </a>Monte-Carlo tree search and rapid action value estimation in computer Go</font> [<a href=\"papers/mcts-gelly-silver.pdf\">pdf</a>]\r\n\r\n\t\t<br> Sylvain Gelly and David Silver\r\n\r\n\t\t<br> <font class=\"journalname\">Artificial Intelligence</font>, volume 175, pp  1856-1875, 2011. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2012-parr-icml2012-full\"> </a>Greedy Algorithms for Sparse Reinforcement Learning</font> [<a href=\"papers/2012-parr-icml2012-full.pdf\">pdf</a>]\r\n\r\n\t\t<br> Christopher Painter-Wakefield, Ronald Parr\r\n\r\n\t\t<br> <font class=\"confname\">ICML-12</font>. <i>29th International Conference on Machine Learning</i>, Edinburgh, Scotland, UK, July 2012. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"mcts-survey\"> </a>A Survey of Monte Carlo Tree Search Methods</font> [<a href=\"papers/mcts-survey.pdf\">pdf</a>]\r\n\r\n\t\t<br> Cameron Browne, Edward Powley, Daniel Whitehouse, Simon Lucas, Peter I. Cowling, Philipp Rohlfshagen, Stephen Tavener, Diego Perez, Spyridon Samothrakis and Simon Colton\r\n\r\n\t\t<br> <font class=\"journalname\">IEEE Transactions on Computational Intelligence and AI in Games</font>, volume 4, pp  1-43, 2012. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2013-UAI-BatchiFDD\"> </a>Batch-iFDD for representation expansion in large MDPs</font> [<a href=\"papers/2013-UAI-BatchiFDD.pdf\">pdf</a>]\r\n\r\n\t\t<br> Alborz Geramifard, Thomas J. Walsh, Nicholas Roy, Jonathan P. How\r\n\r\n\t\t<br> <font class=\"confname\">UAI-13</font>. <i>29th Conference on Uncertainty in Artificial Intelligence</i>, Bellevue, Washington, USA, August 2013. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2014-emma\"> </a>Offline policy evaluation across representations with applications to educational games</font> [<a href=\"papers/2014-emma.pdf\">pdf</a>]\r\n\r\n\t\t<br> Travis Mandel, Yun-En Liu, Sergey Levine, Emma Brunskill, Zoran Popovic\r\n\r\n\t\t<br> <font class=\"confname\">AAMAS-14</font>. <i>2014 International Conference on Autonomous Agents and Multi-agent Systems</i>, Paris, France, May 2014. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"2015Thomas2015\"> </a>High-Confidence Off-Policy Evaluation </font> [<a href=\"papers/2015Thomas2015.pdf\">pdf</a>]\r\n\r\n\t\t<br> Philip S. Thomas, Georgios Theocharous, Mohammad Ghavamzadeh\r\n\r\n\t\t<br> <font class=\"confname\">AAAI-15</font>. <i>29th AAAI Conference on Artificial Intelligence</i>, Austin, Texas, USA, January 2015. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"thomas-nips-15\"> </a>Policy evaluation using the \u03a9-return </font> [<a href=\"papers/thomas-nips-15.pdf\">pdf</a>]\r\n\r\n\t\t<br> Philip S. Thomas, Scott Niekum, Georgios Theocharous, George Konidaris\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-15</font>. <i>28th International Conference on Neural Information Processing Systems</i>, Montreal, Canada, December 2015. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nature-go\"> </a>Mastering the game of Go without human knowledge</font> [<a href=\"papers/nature-go.pdf\">pdf</a>]\r\n\r\n\t\t<br> David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, Yutian Chen, Timothy Lillicrap, Fan Hui, Laurent Sifre, George van den Driessche, Thore Graepel and Demis Hassabis\r\n\r\n\t\t<br> <font class=\"journalname\">Nature</font>, volume 550, pp  354\u2013359, 2017. \r\n\t\t<p>\r\n\t\t\r\n</ul>\r\n\r\n<!--\t  \r\n<h2><span style=\"font-weight: bold;\">NIPS 2017 Papers:</span></h2>\r\n\r\n<ul>\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-1\"> </a>Optimistic posterior sampling for reinforcement learning: worst-case regret bounds</font> [<a href=\"papers/nips/6718-optimistic-posterior-sampling-for-reinforcement-learning-worst-case-regret-bounds.pdf\">pdf</a>]\r\n\r\n\t\t<br> Shipra Agrawal, Randy Jia\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\t\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-2\"> </a>Regret Analysis for Continuous Dueling Bandit</font> [<a href=\"papers/nips/6747-regret-analysis-for-continuous-dueling-bandit.pdf\">pdf</a>]\r\n\r\n\t\t<br> Wataru Kumagai\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n\t\t\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-3\"> </a>Minimal Exploration in Structured Stochastic Bandits</font> [<a href=\"papers/nips/6773-minimal-exploration-in-structured-stochastic-bandits.pdf\">pdf</a>]\r\n\r\n\t\t<br> Richard Combes, Stefan Magureanu, Alexandre Proutiere\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-4\"> </a>Shallow Updates for Deep Reinforcement Learning</font> [<a href=\"papers/nips/6906-shallow-updates-for-deep-reinforcement-learning.pdf\">pdf</a>]\r\n\r\n\t\t<br> Nir Levine, Tom Zahavy, Daniel J. Mankowitz, Aviv Tamar\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-5\"> </a>Interpolated Policy Gradient: Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning</font> [<a href=\"papers/nips/6974-interpolated-policy-gradient-merging-on-policy-and-off-policy-gradient-estimation-for-deep-reinforcement-learning.pdf\">pdf</a>]\r\n\r\n\t\t<br> Shixiang Gu, Timothy Lillicrap, Zoubin Ghahramani, Richard E. Turner, Bernhard Sch\u00f6lkopf, Sergey Levine\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-6\"> </a>Monte-Carlo Tree Search by Best Arm Identification</font> [<a href=\"papers/nips/7075-monte-carlo-tree-search-by-best-arm-identification.pdf\">pdf</a>]\r\n\r\n\t\t<br> Emilie Kaufmann, Wouter M. Koolen\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-7\"> </a>Hybrid Reward Architecture for Reinforcement Learning</font> [<a href=\"papers/nips/7123-hybrid-reward-architecture-for-reinforcement-learning.pdf\">pdf</a>]\r\n\r\n\t\t<br> Harm van Seijen, Mehdi Fatemi, Joshua Romoff, Romain Laroche, Tavian Barnes, Jeffrey Tsang\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\t\r\n\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-8\"> </a>Robust and Efficient Transfer Learning with Hidden Parameter Markov Decision Processes</font> [<a href=\"papers/nips/7205-robust-and-efficient-transfer-learning-with-hidden-parameter-markov-decision-processes.pdf\">pdf</a>]\r\n\r\n\t\t<br> Taylor Killian, Samuel Daulton, George Konidaris, Finale Doshi-Velez\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-9\"> </a>Towards Generalization and Simplicity in Continuous Control</font> [<a href=\"papers/nips/7233-towards-generalization-and-simplicity-in-continuous-control.pdf\">pdf</a>]\r\n\r\n\t\t<br> Aravind Rajeswaran, Kendall Lowrey, Emanuel Todorov, Sham Kakade\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\t\r\n\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-10\"> </a>Inverse Reward Design</font> [<a href=\"papers/nips/7253-inverse-reward-design.pdf\">pdf</a>]\r\n\r\n\t\t<br> Dylan Hadfield-Menell, Smitha Milli, Pieter Abbeel, Stuart Russell, Anca Dragan\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\t\r\n\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"nips-11\"> </a>Learning Combinatorial Optimization Algorithms over Graphs</font> [<a href=\"papers/nips/comb-opt_rl_combopt.pd.pdf\">pdf</a>]\r\n\r\n\t\t<br> Hanjun Dai, Elias B. Khalil, Yuyu Zhang, Bistra Dilkina, Le Song\r\n\r\n\t\t<br> <font class=\"confname\">NIPS-17</font>. <i>30th Annual Conference on Neural Information Processing Systems</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\t\t\t\r\n\r\n\r\n\r\n</ul>\r\n\r\n<h2><span style=\"font-weight: bold;\">Reinforcement Learning Symposium (NIPS 2017) Papers:</span></h2>\r\n\r\n<ul>\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"drls-1\"> </a>Neural Network Dynamics for Model-Based Deep Reinforcement Learning with Model-Free Fine-Tuning</font> [<a href=\"papers/nips/2017_NIPS_MIMe - ANUSHA NAGABANDI.pdf\">pdf</a>]\r\n\r\n\t\t<br> Anusha Nagabandi, Gregory Kahn, Ronald S. Fearing, Sergey Levine\r\n\r\n\t\t<br> <font class=\"confname\">DRLS-17</font>. <i>Deep Reinforcement Learning Symposium, NIPS 2017</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\t\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"drls-2\"> </a>Parameter Space Noise for Exploration</font> [<a href=\"papers/nips/param-noise-final - Matthias Plappert.pdf\">pdf</a>]\r\n\r\n\t\t<br> Matthias Plappertyz, Rein Houthoofty, Prafulla Dhariwaly, Szymon Sidory, Richard Y. Cheny, Xi Chen, Tamim Asfourz, Pieter Abbeel, Marcin Andrychowiczy\r\n\r\n\t\t<br> <font class=\"confname\">DRLS-17</font>. <i>Deep Reinforcement Learning Symposium, NIPS 2017</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\t\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"drls-3\"> </a>Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor</font> [<a href=\"papers/nips/soft-actor-critic-nips-2017.pdf\">pdf</a>]\r\n\r\n\t\t<br> Tuomas Haarnoja, Aurick Zhou, Pieter Abbeel, Sergey Levine\r\n\r\n\t\t<br> <font class=\"confname\">DRLS-17</font>. <i>Deep Reinforcement Learning Symposium, NIPS 2017</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\"> <a name=\"drls-4\"> </a>Time-Contrastive Networks: Self-Supervised Learning from Pixels</font> [<a href=\"papers/nips/TCN_NIPS17_DeepRL_final - Yevgen Chebotar.pdf\">pdf</a>]\r\n\r\n\t\t<br> Pierre Sermanet, Corey Lynch, Yevgen Chebotar, Jasmine Hsu, Eric Jang, Stefan Schaal, Sergey Levine\r\n\r\n\t\t<br> <font class=\"confname\">DRLS-17</font>. <i>Deep Reinforcement Learning Symposium, NIPS 2017</i>, Long Beach, California, USA, December 2017.\r\n\t\t<p>\r\n-->\t\t\r\n\t\t\r\n\r\n</ul>\r\n\r\n<h2><span style=\"font-weight: bold;\">Papers from IJCAI-2019<!-- and NeurIPS-2018-->:</span></h2>\r\n<ul>\r\n\t\t<li> <font class=\"papertitle\">Soft Policy Gradient Method for Maximum Entropy Deep Reinforcement Learning </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0475.pdf\">pdf</a>]\r\n\t\t<br> Wenjie Shi, Shiji Song, Cheng Wu\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Incremental Learning of Planning Actions in Model-Based Reinforcement Learning </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0443.pdf\">pdf</a>]\r\n\t\t<br> Jun Hao Alvin Ng, Ronald P. A. Petrick\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\r\n\t\t<li> <font class=\"papertitle\">Autoregressive Policies for Continuous Control Deep Reinforcement Learning </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0382.pdf\">pdf</a>]\r\n\t\t<br> Dmytro Korenkevych, A. Rupam Mahmood, Gautham Vasan, James Bergstra\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\r\n\t\t<li> <font class=\"papertitle\">Sharing Experience in Multitask Reinforcement Learning </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0505.pdf\">pdf</a>]\r\n\t\t<br> Tung-Long Vuong, Do-Van Nguyen, Tai-Long Nguyen, Cong-Minh Bui, Hai-Dang Kieu, Viet-Cuong Ta, Quoc-Long Tran, Thanh-Ha Le\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\t\t\r\n\t\r\n\t\t<li> <font class=\"papertitle\">Adversarial Imitation Learning from Incomplete Demonstrations </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0487.pdf\">pdf</a>]\r\n\t\t<br> Mingfei Sun, Xiaojuan Ma\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">A Restart-based Rank-1 Evolution Strategy for Reinforcement Learning </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0295.pdf\">pdf</a>]\r\n\t\t<br> Zefeng Chen, Yuren Zhou, Xiao-yu He, Siyu Jiang\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Metatrace Actor-Critic: Online Step-Size Tuning by Meta-gradient Descent for Reinforcement Learning Control </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0581.pdf\">pdf</a>]\r\n\t\t<br> Kenny Young, Baoxiang Wang, Matthew E. Taylor\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Successor Options: An Option Discovery Framework for Reinforcement Learning </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0458.pdf\">pdf</a>]\r\n\t\t<br> Rahul Ramesh, Manan Tomar, Balaraman Ravindran\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">An Atari Model Zoo for Analyzing, Visualizing, and Comparing Deep Reinforcement Learning Agents </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0452.pdf\">pdf</a>]\r\n\t\t<br> Felipe Petroski Such, Vashisht Madhavan, Rosanne Liu, Rui Wang, Pablo Samuel Castro, Yulun Li, Jiale Zhi, Ludwig Schubert, Marc G. Bellemare, Jeff Clune, Joel Lehman\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Unobserved Is Not Equal to Non-existent: Using Gaussian Processes to Infer Immediate Rewards Across Contexts </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0273.pdf\">pdf</a>]\r\n\t\t<br> Hamoon Azizsoltani, Yeo Jin Kim, Markel Sanz Ausin, Tiffany Barnes, Min Chi\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Experience Replay Optimization </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0589.pdf\">pdf</a>]\r\n\t\t<br> Daochen Zha, Kwei-Herng Lai, Kaixiong Zhou, Xia Hu\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Interactive Teaching Algorithms for Inverse Reinforcement Learning </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0374.pdf\">pdf</a>]\r\n\t\t<br> Parameswaran Kamalaruban, Rati Devidze, Volkan Cevher, Adish Singla\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Interactive Reinforcement Learning with Dynamic Reuse of Prior Knowledge from Human and Agent Demonstrations </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0530.pdf\">pdf</a>]\r\n\t\t<br> Zhaodong Wang, Matthew E. Taylor\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Meta Reinforcement Learning with Task Embedding and Shared Policy </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0387.pdf\">pdf</a>]\r\n\t\t<br> Lin Lan, Zhenguo Li, Xiaohong Guan, Pinghui Wang\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Planning with Expectation Models </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0506.pdf\">pdf</a>]\r\n\t\t<br> Yi Wan, Muhammad Zaheer, Adam White, Martha White, Richard S. Sutton\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Dynamic Electronic Toll Collection via Multi-Agent Deep Reinforcement Learning with Edge-Based Graph Convolutional Networks </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0635.pdf\">pdf</a>]\r\n\t\t<br> Wei Qiu, Haipeng Chen, Bo An\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Randomized Adversarial Imitation Learning for Autonomous Driving </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0638.pdf\">pdf</a>]\r\n\t\t<br> MyungJae Shin, Joongheon Kim\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Teaching AI Agents Ethical Values Using Reinforcement Learning and Policy Orchestration </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0891.pdf\">pdf</a>]\r\n\t\t<br> Ritesh Noothigattu, Djallel Bouneffouf, Nicholas Mattei, Rachita Chandra, Piyush Madan, Kush R. Varshney, Murray Campbell, Moninder Singh, Francesca Rossi\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Building Personalized Simulator for Interactive Search </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0710.pdf\">pdf</a>]\r\n\t\t<br> Qianlong Liu, Baoliang Cui, Zhongyu Wei, Baolin Peng, Haikuan Huang, Hongbo Deng, Jianye Hao, Xuanjing Huang, Kam-Fai Wong\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Deep Multi-Agent Reinforcement Learning with Discrete-Continuous Hybrid Action Spaces </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0323.pdf\">pdf</a>]\r\n\t\t<br> Haotian Fu, Hongyao Tang, Jianye Hao, Zihan Lei, Yingfeng Chen, Changjie Fan\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Imitation Learning from Video by Leveraging Proprioception </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0497.pdf\">pdf</a>]\r\n\t\t<br> Faraz Torabi, Garrett Warnell, Peter Stone\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Playing FPS Games With Environment-Aware Hierarchical Reinforcement Learning </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0482.pdf\">pdf</a>]\r\n\t\t<br> Shihong Song, Jiayi Weng, Hang Su, Dong Yan, Haosheng Zou, Jun Zhu\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">DeepMellow: Removing the Need for a Target Network in Deep Q-Learning </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0379.pdf\">pdf</a>]\r\n\t\t<br> Seungchan Kim, Kavosh Asadi, Michael Littman, George Konidaris\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">On Principled Entropy Exploration in Policy Optimization </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0434.pdf\">pdf</a>]\r\n\t\t<br> Jincheng Mei, Chenjun Xiao, Ruitong Huang, Dale Schuurmans, Martin M\u00fcller\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Automatic Successive Reinforcement Learning with Multiple Auxiliary Rewards </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0324.pdf\">pdf</a>]\r\n\t\t<br> Zhao-Yang Fu, De-Chuan Zhan, Xin-Chun Li, Yi-Xing Lu\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Approximability of Constant-horizon Constrained POMDP </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0775.pdf\">pdf</a>]\r\n\t\t<br> Majid Khonji, Ashkan Jasour, Brian Williams\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Influence of State-Variable Constraints on Partially Observable Monte Carlo Planning </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0769.pdf\">pdf</a>]\r\n\t\t<br> Alberto Castellini, Georgios Chalkiadakis, Alessandro Farinelli\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Counterexample-Guided Strategy Improvement for POMDPs Using Recurrent Neural Networks </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0768.pdf\">pdf</a>]\r\n\t\t<br> Steven Carr, Nils Jansen, Ralf Wimmer, Alexandru Serban, Bernd Becker, Ufuk Topcu\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Regular Decision Processes: A Model for Non-Markovian Domains </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0766.pdf\">pdf</a>]\r\n\t\t<br> Ronen I. Brafman, Giuseppe De Giacomo\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Approximability of Constant-horizon Constrained POMDP </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0775.pdf\">pdf</a>]\r\n\t\t<br> Majid Khonji, Ashkan Jasour, Brian Williams\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Influence of State-Variable Constraints on Partially Observable Monte Carlo Planning </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0769.pdf\">pdf</a>]\r\n\t\t<br> Alberto Castellini, Georgios Chalkiadakis, Alessandro Farinelli\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Counterexample-Guided Strategy Improvement for POMDPs Using Recurrent Neural Networks </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0768.pdf\">pdf</a>]\r\n\t\t<br> Steven Carr, Nils Jansen, Ralf Wimmer, Alexandru Serban, Bernd Becker, Ufuk Topcu\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Regular Decision Processes: A Model for Non-Markovian Domains </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0766.pdf\">pdf</a>]\r\n\t\t<br> Ronen I. Brafman, Giuseppe De Giacomo\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Using Natural Language for Reward Shaping in Reinforcement Learning </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0331.pdf\">pdf</a>]\r\n\t\t<br> Prasoon Goyal, Scott Niekum, Raymond J. Mooney\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Monte Carlo Tree Search for Policy Optimization </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0432.pdf\">pdf</a>]\r\n\t\t<br> Xiaobai Ma, Katherine Driggs-Campbell, Zongzhang Zhang, Mykel J. Kochenderfer\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Hill Climbing on Value Estimates for Search-control in Dyna </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0445.pdf\">pdf</a>]\r\n\t\t<br> Yangchen Pan, Hengshuai Yao, Amir-massoud Farahmand, Martha White\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Recurrent Existence Determination Through Policy Optimization </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0507.pdf\">pdf</a>]\r\n\t\t<br> Baoxiang Wang\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Hybrid Actor-Critic Reinforcement Learning in Parameterized Action Space </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0316.pdf\">pdf</a>]\r\n\t\t<br> Zhou Fan, Rui Su, Weinan Zhang, Yong Yu\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Transfer of Temporal Logic Formulas in Reinforcement Learning </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0557.pdf\">pdf</a>]\r\n\t\t<br> Zhe Xu, Ufuk Topcu\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Measuring Structural Similarities in Finite MDPs </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0511.pdf\">pdf</a>]\r\n\t\t<br> Hao Wang, Shaokang Dong, Ling Shao\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Solving Continual Combinatorial Selection via Deep Reinforcement Learning </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0481.pdf\">pdf</a>]\r\n\t\t<br> Hyungseok Song, Hyeryung Jang, Hai H. Tran, Se-eun Yoon, Kyunghwan Son, Donggyu Yun, Hyoju Chung, Yung Yi\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Reinforcement Learning Experience Reuse with Policy Residual Representation </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0618.pdf\">pdf</a>]\r\n\t\t<br> WenJi Zhou, Yang Yu, Yingfeng Chen, Kai Guan, Tangjie Lv, Changjie Fan, Zhi-Hua Zhou\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Exploiting the Sign of the Advantage Function to Learn Deterministic Policies in Continuous Domains </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0625.pdf\">pdf</a>]\r\n\t\t<br> Matthieu Zimmer, Paul Weng\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Assumed Density Filtering Q-learning </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0362.pdf\">pdf</a>]\r\n\t\t<br> Heejin Jeong, Clark Zhang, George J. Pappas, Daniel D. Lee\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Curriculum Learning for Cumulative Return Maximization </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0320.pdf\">pdf</a>]\r\n\t\t<br> Francesco Foglino, Christiano Coletto Christakou, Ricardo Luna Gutierrez, Matteo Leonetti\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Leveraging Human Guidance for Deep Reinforcement Learning Tasks </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0884.pdf\">pdf</a>]\r\n\t\t<br> Ruohan Zhang, Faraz Torabi, Lin Guan, Dana H. Ballard, Peter Stone\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Learning and Inference for Structured Prediction: A Unifying Perspective </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0878.pdf\">pdf</a>]\r\n\t\t<br> Aryan Deshwal, Janardhan Rao Doppa, Dan Roth\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Deep Learning for Video Captioning: A Review </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0877.pdf\">pdf</a>]\r\n\t\t<br> Shaoxiang Chen, Ting Yao, Yu-Gang Jiang\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Recent Advances in Imitation Learning from Observation </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0882.pdf\">pdf</a>]\r\n\t\t<br> Faraz Torabi, Garrett Warnell, Peter Stone\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">A Survey of Reinforcement Learning Informed by Natural Language </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0880.pdf\">pdf</a>]\r\n\t\t<br> Jelena Luketina, Nantas Nardelli, Gregory Farquhar, Jakob Foerster, Jacob Andreas, Edward Grefenstette, Shimon Whiteson, Tim Rockt\u00e4schel\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Sequential Recommender Systems: Challenges, Progress and Prospects </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0883.pdf\">pdf</a>]\r\n\t\t<br> Shoujin Wang, Liang Hu, Yan Wang, Longbing Cao, Quan Z. Sheng, Mehmet Orgun\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">A Strongly Asymptotically Optimal Agent in General Environments </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0302.pdf\">pdf</a>]\r\n\t\t<br> Michael K. Cohen, Elliot Catt, Marcus Hutter\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Structure Learning for Safe Policy Improvement </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0479.pdf\">pdf</a>]\r\n\t\t<br> Thiago D. Sim\u00e3o, Matthijs T. J. Spaan\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">An Actor-Critic-Attention Mechanism for Deep Reinforcement Learning in Multi-view Environments </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0277.pdf\">pdf</a>]\r\n\t\t<br> Elaheh Barati, Xuewen Chen\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">Advantage Amplification in Slowly Evolving Latent-State Environments </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0439.pdf\">pdf</a>]\r\n\t\t<br> Martin Mladenov, Ofer Meshi, Jayden Ooi, Dale Schuurmans, Craig Boutilier\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">SlateQ: A Tractable Decomposition for Reinforcement Learning with Recommendation Sets </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0360.pdf\">pdf</a>]\r\n\t\t<br> Eugene Ie, Vihan Jain, Jing Wang, Sanmit Narvekar, Ritesh Agarwal, Rui Wu, Heng-Tze Cheng, Tushar Chandra, Craig Boutilier\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li> <font class=\"papertitle\">MineRL: A Large-Scale Dataset of Minecraft Demonstrations </font> [<a href=\"https://www.ijcai.org/proceedings/2019/0339.pdf\">pdf</a>]\r\n\t\t<br> William H. Guss, Brandon Houghton, Nicholay Topin, Phillip Wang, Cayden Codel, Manuela Veloso, Ruslan Salakhutdinov\r\n\t\t<br> <font class=\"confname\">IJCAI-19</font>. <i>28th International Joint Conference on Artificial Intelligence</i>, Macao, China, August 2019. \r\n\t\t<p>\r\n</ul>\r\n\t  \r\n<h2><span style=\"font-weight: bold;\">Conferences, Symposia, Workshops:</span></h2>\r\n<ul>\r\n\t\t<li>\r\n\t\t<a href=\"https://sites.google.com/view/deep-rl-workshop-nips-2018/\"><font class=\"confname\">DRLW-18</font></a>. <i>Deep Reinforcement Learning Workshop, NIPS 2018</i>, Montr\u00e9al, Canada, December 2018.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li>\r\n\t\t<a href=\"https://sites.google.com/view/deeprl-symposium-nips2017/\"><font class=\"confname\">DRLS-17</font></a>. <i>Deep Reinforcement Learning Symposium, NIPS 2017</i>, Long Beach, USA, December 2017.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li>\r\n\t\t<a href=\"https://nips.cc/Conferences/2017/Schedule?type=Poster\"><font class=\"confname\">NIPS-17</font></a>. <i>Advances in Neural Information Processing Systems, NIPS 2017</i>, Long Beach, USA, December 2017.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li>\r\n\t\t<a href=\"https://sites.google.com/site/deeprlnips2016/\"><font class=\"confname\">DRLW-16</font></a>. <i>Deep Reinforcement Learning Workshop, NIPS 2016</i>, Barcelona, Spain, December 2016.\r\n\t\t<p>\r\n\t\t\r\n\t\t<li><a href=\"https://ewrl.wordpress.com/ewrl13-2016/\"><font class=\"confname\">EWRL-16</font></a>. <i>The 13th European Workshop on Reinforcement Learning</i>, Barcelona, Spain, December 2016. \r\n\t\t<p>\r\n\t\t\r\n\t\t<li>\r\n\t\t<a href=\"http://rll.berkeley.edu/deeprlworkshop/\"><font class=\"confname\">DRLW-15</font></a>. <i>Deep Reinforcement Learning Workshop, NIPS 2015</i>, Montreal, Canada, December 2015.\r\n\t\t<p>\r\n\t\t\r\n\t\t\r\n\r\n</ul>\r\n\r\n\t \r\n<!--\t  <li><a href=\"http://arxiv.org/pdf/1105.5460.pdf\">Decision-Theoretic Planning: Structural Assumptions and Computational Leverage</a><br>\r\n\t  Craig Boutilier, Thomas Dean, and Steve Hanks<br>\r\n\t  <i>Journal of Artificial Intelligence Research, 1999</i>\r\n\t  <li><a href=\"http://icaps13.icaps-conference.org/technical-program/accepted-papers/#FullMain\">List of Accepted Papers at ICAPS 2013</a>\r\n\t  <li><a href=\"http://www.aiconferences.org/ICAPS/icaps.html\">ICAPS Proceedings</a>\r\n\t  <li><a href=\"http://ie.technion.ac.il/~dcarmel/publications.html\">Papers by Carmel Domshlak</a>\r\n \r\n\t  <ul>\r\n\r\n<li> <font class=\"papertitle\"> <a name=\"positionUCT\"> </a>To UCT, or not to UCT? (Position Paper)</font> \r\n[<a href=\"http://iew3.technion.ac.il/~dcarmel/Papers/Sources/socs13.pdf\">pdf</a>]\r\n\r\n<br> Carmel Domshlak, Zohar Feldman\r\n\r\n<br> <font class=\"confname\">SOCS-13</font>. <i>6th Annual Symposium on Combinatorial Search</i>, Leavenworth, WA, USA, July 2013. \r\n<p>\r\n\r\n\r\n<li> <font class=\"papertitle\"> <a name=\"brueIS\"> </a>Monte-Carlo Planning: Theoretically Fast Convergence Meets Practical Efficiency</font> \r\n[<a href=\"http://iew3.technion.ac.il/~dcarmel/Papers/Sources/uai13.pdf\">pdf</a>]\r\n\r\n<br> Zohar Feldman, Carmel Domshlak\r\n\r\n<br> <font class=\"confname\">UAI-13</font>. <i>29th Conference on Uncertainty in Artificial Intelligence</i>, Bellevue, WA, USA, July 2013. \r\n<p>\r\n\r\n\r\n\r\n <li> <font class=\"papertitle\"> <a name=\"ftC\"> </a>Fault tolerant contingent planning: Complexity and compilation</font> \r\n [<a href=\"http://iew3.technion.ac.il/~dcarmel/Papers/Sources/icaps13c.pdf\">pdf</a>]\r\n\r\n <br> Carmel Domshlak\r\n\r\n <br> <font class=\"confname\">ICAPS-13</font>. <i>23nd International Conference on Automated Planning and Scheduling</i>, Rome, Italy, June 2013. \r\n <p>\r\n  \r\n  <li> <font class=\"papertitle\"> <a name=\"controlMDPs\">Planning for Operational Control Systems with Predictable Exogenous Events</a></font> \r\n  <br> Ronen Brafman, Carmel Domshlak, Yagil Engel, and Zohar Feldman\r\n  <br> <font class=\"confname\">AAAI-11</font>, <i>25th AAAI Conference on\r\n     Artificial Intelligence</i>, San-Francisco, CA, USA, August 2010.\r\n     <p>\r\n\r\n     <li> <font class=\"papertitle\"><a name=\"pffJ\"></a>Probabilistic Planning via Heuristic Forward Search and Weighted Model Counting</font>\r\n\r\n     [</a><a href=\"http://www.jair.org/papers/paper2289.html\">abstract</a>,\r\n      <a href=\"http://www.jair.org/media/2289/live-2289-3600-jair.pdf\">pdf</a>]\r\n\r\n      <br> Carmel Domshlak, Joerg Hoffmann\r\n\r\n      <br> <font class=\"journalname\">Journal of Artificial Intelligence Research</font>, \r\n      volume 30, pp  565-620, 2007.\r\n      <p>\r\n\r\n      <ul> \r\n        <li> <font class=\"papertitle\"> Fast Probabilistic Planning Through Weighted Model Counting </font>\r\n\r\n\t     [<a href=\"http://iew3.technion.ac.il/~dcarmel/Papers/Sources/icaps06b.pdf\">pdf</a>,\r\n\t           <a href=\"Presentations/icaps06-pff.pdf\">slides</a>]\r\n\r\n\t\t       <br> Carmel Domshlak, Joerg Hoffmann\r\n\r\n\t\t           <br> <font class=\"confname\">ICAPS-06</font>. <i>16th International Conference on Automated Planning and Scheduling</i>, pp 243-252, The English Lake District, U.K., September 2006.\r\n\r\n\t\t\t      <p>\r\n\t\t\t      </ul>\r\n\r\n\r\n</ul>\r\n\t  <li> Marc Toussaint Papers\r\n\t  <p>\r\n\t  <ul>\r\n\t\t<p>\r\n\t  \t<li>Probabilistic inference for solving (PO)MDPs [<a href=\"papers/toussaint-probinf-pomdp.pdf\">pdf</a>]<br>\r\n\t\tMarc Toussaint, Stefan Harmeling, and Amos Storkey<br>\r\n\t\t<i>Technical Report EDI-INF-RR-0934</i>, University of Edinburgh, School of Informatics, 2006.\r\n\t\t<p>\r\n\t\t<li>Nice applications that demonstrate efficiency in challenging domains are:\r\n\t\t<ul>\r\n\t\t<p>\r\n\t\t<li>Hierarchical POMDP Controller Optimization by Likelihood Maximization [<a href=\"papers/toussaint-hier-pomdp.pdf\">pdf</a>]<br>\r\n\t\tMarc Toussaint, Laurent Charlin, and Pascal Poupart<br>\r\n\t\tIn <i>Uncertainty in Artificial Intelligence (UAI 2008)</i>, 562-570, AUAI Press, 2008.\r\n\t\t<p>\r\n\t\t<li>Scalable Multiagent Planning Using Probabilistic Inference [<a href=\"papers/toussaint-multiagent-planning.pdf\">pdf</a>]<br>\r\n\t\tAkshat Kumar, Shlomo Zilberstein, and Marc Toussaint<br>\r\n\t\tIn <i>Proc. of the 22nd Int. Joint Conf. on Artificial Intelligence (IJCAI 2011),</i>2011.\r\n\t  </ul>\r\n\t  </ul>\r\n\r\n      </ul>\r\n      <p>\r\n      <br>\r\n-->\r\n\r\n<h2><span style=\"font-weight: bold;\">Tools for RL:</span></h2>\r\n<ul>\r\n\t  <li><a href=\"https://www.quora.com/What-are-some-tools-you-can-use-for-reinforcement-learning\">Miscellaneous Tools for RL</a>\r\n\t  <p>\r\n</ul>\r\n\r\n\r\n\t \r\n      <h2><span style=\"font-weight: bold;\">Schedule</span></h2>\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td><img src=\"/%7Edechter/images/black-fill.gif\" height=\"2\"\r\n width=\"100%\"></td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n<table style=\"width: 1079px; height: 369px;\" border=\"3\" cellpadding=\"5\"\r\n cellspacing=\"1\">\r\n  <tbody>\r\n    <tr>\r\n      <td><b>Week\r\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b> </td>\r\n      <td> <b>Date</b> </td>\r\n      <td> <b>Topic</b> </td>\r\n      <td> <b>Readings and Links</b> </td>\r\n    </tr>\r\n    <tr>\r\n      <td> Week 0 </td>\r\n      <td> 9/27 </td>\r\n      <td>\r\n\t\t\t<b>No class!</b>\r\n\t\t\t<p>\r\n\t\t\tToward the first class, I recommend (optional homework) <a href=\"http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html\">watching the first 3 lectures of David Silver</a>.\r\n\t\t\t<br>They correspond to chapters 1,3 and 4 in the text of Sutton and Barto. Although I will cover this\r\n\t\t\t<br>material in the first class, it may be at a relatively high pace.\r\n      </td>\r\n      <td> <!--<td style=\"text-align: left; vertical-align: top;\"> -->\r\n\t  <!--\r\n\t\t\t<a href=\"homework/hwk1-295.pdf\">Homework 1</a><br>\r\n\t\t\t<a href=\"slides/class1.pdf\">Slides 1</a><br>\r\n\t\t-->\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 1 </td>\r\n      <td> 10/4 </td>\r\n      <td>\r\n\t\t\tChapters 1,3,4 in S&B\r\n      </td>\r\n      <td>\r\n\t\t\t<a href=\"slides/class1-2019.pdf\">Class 1 Slides</a>\r\n\t\t\t<p> <a href=\"homework/hwk1-295.pdf\">HW 1</a>\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td> Week 2 </td>\r\n      <td> 10/11 </td>\r\n      <td>\r\n      <ul>\r\n      </ul>\r\n      </td>\r\n      <td> <!-- <td style=\"text-align: left; vertical-align: top;\"> -->\r\n\t\t\t<!--\r\n\t\t\t<a href=\"homework/hwk2-295.pdf\">Homework 2</a><br>\r\n\t\t\t<a href=\"slides/class2.pdf\">Slides 2</a><br>\r\n\t\t\t-->\r\n\t</td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 3<br>\r\n      </td>\r\n      <td> 10/18 </td>\r\n      <td>\r\n      <ul>\r\n      </ul>\r\n      </td>\r\n     <td> <!-- <td style=\"text-align: left; vertical-align: top;\"> -->\r\n\t\t\t<!--\r\n\t\t\t<a href=\"homework/hwk3-295.pdf\">Homework 3</a><br>\r\n\t\t\t<a href=\"slides/class3.pdf\">Slides 3</a><br>\r\n\t\t\t-->\r\n\t</td>\r\n    </tr>\r\n    <tr>\r\n      <td> Week 4 </td>\r\n      <td> 10/25 </td>\r\n      <td>\r\n      </td>\r\n      <td> <br> </td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 5 </td>\r\n      <td> 11/1 </td>\r\n      <td>\r\n      <ul>\r\n      </ul>\r\n      </td>\r\n\t  <td> <!-- <td style=\"text-align: left; vertical-align: top;\"> -->\r\n\t\t\t<!--\r\n\t\t\t<a href=\"slides/class4.pdf\">Slides 4</a><br>\r\n\t\t\tPezeshki <a href=\"presentations/Pezeshki.pdf\">Slides</a> | <a href=\"papers/mcts-survey.pdf\">Paper</a><br>\r\n\t\t\tBroka <a href=\"presentations/Broka.pdf\">Slides</a> | <a href=\"papers/2009-sutton-Fast_gradient-descent.pdf\">Paper</a><br>\r\n\t\t\tZou <a href=\"presentations/Zou.pdf\">Slides</a> | <a href=\"papers/2005-poupart-icml-brl-8pages.pd.pdf\">Paper</a><br>\r\n\t\t\t-->\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 6 </td>\r\n      <td> 11/8 </td>\r\n      <td>\r\n\t\t\t<b>No class!</b>\r\n      </td>\r\n      <td> <!-- <td style=\"text-align: left; vertical-align: top;\"> -->\r\n\t\t\t<!-- <a href=\"homework/hwk4-295.pdf\">Homework 4</a><br>\t-->\t\t\r\n\t</td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 7 </td>\r\n      <td> 11/15 </td>\r\n      <td>\r\n      <ul>\r\n      </ul>\r\n      </td>\r\n\t  <td> <!-- <td style=\"text-align: left; vertical-align: top;\"> -->\r\n\t\t\t<!--\r\n\t\t\t<a href=\"homework/hwk5-295.pdf\">Homework 5</a><br>\t\r\n\t\t\tXu <a href=\"presentations/Xu.pdf\">Slides</a> | <a href=\"papers/2000-nips12-sutton-mcallester-policy-gradient-methods-for-reinforcement-learning-with-function-approximation.pdf\">Paper</a><br>\r\n\t\t\tPraveen <a href=\"presentations/Praveen.pdf\">Slides</a>  | <a href=\"papers/littman-2008627.pdf\">Paper</a><br>\r\n\t\t\tPandey <a href=\"presentations/Pandey.pdf\">Slides</a> | <a href=\"papers/2007-parr-icml08.pd.pdf\">Paper</a><br>\r\n\t\t\t-->\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 8<br>\r\n      </td>\r\n      <td>11/22<br>\r\n      </td>\r\n      <td>\r\n      <ul>\r\n      </ul>\r\n      </td>\r\n      \t  <td> <!-- <td style=\"text-align: left; vertical-align: top;\"> -->\r\n\t\t\t<!--\r\n\t\t\t<a href=\"homework/hwk6-295.pdf\">Homework 6</a><br>\r\n\t\t\t<a href=\"https://www.alexirpan.com/2018/02/14/rl-hard.html\">Blog Post</a><br>\r\n\t\t\tMcAleer Slides| <a href=\"papers/nature-go.pdf\">Paper</a><br>\r\n\t\t\tDheeru <a href=\"presentations/Dheeru.pdf\">Slides</a> | <a href=\"papers/icml04-apprentice.pdf\">Paper</a><br>\r\n\t\t\tLanier & Takashi <a href=\"presentations/Lanier-Takashi.pdf\">Slides</a> | <a href=\"papers/2009-Stone-JMLRtaylor09a.pdf\">Paper</a><br>\r\n\t\t\t-->\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 9<br>\r\n      </td>\r\n      <td>11/29<br>\r\n      </td>\r\n      <td>\r\n\t  <b>Thanksgiving Holiday!</b>\r\n      </td>\r\n      <td>\t\r\n\t\t\t<!--\r\n\t\t\t<a href=\"homework/hwk7-295.pdf\">Homework 7</a><br>\r\n\t\t\tLogan <a href=\"presentations/Logan.pdf\">Slides</a>| <a href=\"papers/2015Thomas2015.pdf\">Paper</a><br>\r\n\t\t\tLaCroix <a href=\"presentations/LaCroix.pdf\">Slides</a> | <a href=\"papers/nips/7123-hybrid-reward-architecture-for-reinforcement-learning.pdf\">Paper</a><br>\r\n\t\t\tLee <a href=\"presentations/Lee.pdf\">Slides</a> | <a href=\"papers/2013-UAI-BatchiFDD.pdf\">Paper</a><br>\r\n\t\t\t-->\r\n      </td>\r\n    </tr>\r\n    <tr>\r\n      <td>Week 10<br>\r\n      </td>\r\n      <td>12/6<br>\r\n      </td>\r\n      <td>\r\n      </td>\r\n      <td>\t\r\n\t\t\t<!--\r\n\t\t\tNelson <a href=\"presentations/Nelson.pdf\">Slides</a>| <a href=\"papers/mcts-gelly-silver.pdf\">Paper</a><br>\r\n\t\t\tChen <a href=\"presentations/Chen.pdf\">Slides</a> | <a href=\"papers/nips/7253-inverse-reward-design.pdf\">Paper</a><br>\r\n\t\t\tMoskvichev <a href=\"presentations/Moskvichev.pdf\">Slides</a> | <a href=\"papers/Sutton-Precup-Singh-AIJ99.pdf\">Paper</a><br>\r\n\t\t\t-->\r\n      </td>\r\n    </tr>\r\n\t<tr>\r\n      <td>Week 11<br>\r\n      </td>\r\n      <td>12/13<br>\r\n      </td>\r\n      <td>\r\n      </td>\r\n      <td>\t\r\n\t\t\t<!--\r\n\t\t\tNelson <a href=\"presentations/Nelson.pdf\">Slides</a>| <a href=\"papers/mcts-gelly-silver.pdf\">Paper</a><br>\r\n\t\t\tChen <a href=\"presentations/Chen.pdf\">Slides</a> | <a href=\"papers/nips/7253-inverse-reward-design.pdf\">Paper</a><br>\r\n\t\t\tMoskvichev <a href=\"presentations/Moskvichev.pdf\">Slides</a> | <a href=\"papers/Sutton-Precup-Singh-AIJ99.pdf\">Paper</a><br>\r\n\t\t\t-->\r\n      </td>\r\n    </tr>\r\n  </tbody>\r\n</table>\r\n<br>\r\n</p>\r\n<br>\r\n\r\n\r\n</center>\r\n<div id=\"footer\"><centeR>\r\n<A HREF=\"http://www.ics.uci.edu\">School of Information and Computer Science</A>\r\n<A HREF=\"http://www.uci.edu\">University of California, Irvine, CA 92697-3435</a>\r\n<A HREF=\"http://www.ics.uci.edu/~dechter\">Dr. Rina Dechter</A>\n\r\n<A HREF=\"mailto:dechter_at_ics.uci.edu\">dechter at ics.uci.edu</A>\r\n\n</center></div>\r\n</body>\r\n</html>\r\n", "encoding": "utf-8"}