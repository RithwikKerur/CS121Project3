{"url": "https://www.ics.uci.edu/~skong2/mgpff.html", "content": "<html>\n<head>\n<title> Image Reconstruction using Predictive Filter Flow - Shu Kong (Aimery) - UC Irvine - Computer Vision</title>\n<link rel=\"icon\" href=\"image/pff_icon_smallSize.png\" type=\"img/jpg\">\n<style>\nh1 { padding : 0; margin : 0; }\nbody { padding : 0; font-family : Arial; font-size : 16px; background-color : #EFEFEF; } /* background-image : url('bg.png');}*/\n#container { width : 1024px; margin : 20px auto;  background-color : #fff; padding : 50px; border : 1px solid #ccc; }\n#me { border : 0 solid black; margin-bottom : 0;}\n#sidebar { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0;}\n#content { display : block; margin-right : 260px;}\na { text-decoration : none; }\na:hover { text-decoration : underline; }\na:visited { color : blue; }\na.invisible { color : inherit; text-decoration : inherit; }\n.publogo { margin-right : 10px; height: 50px; width: 50px; float : left; border : 0;}\n.publication { clear : left; padding-bottom : 0px;}\n.publication p { height : 60px; }\n.codelogo { margin-right : 10px; float : left; border : 0;}\n.code { clear : left; padding-bottom : 10px; vertical-align :middle;}\n.code .download a { display : block; margin : 0 15px; float : left;}\n<!-- #simpsons { margin : 5px auto; text-align : center; color : #B7B7B7; } -->\n<!-- \t#erdos { color : #999; text-align : center; font-size : 12px; } -->\n</style>\n<script type=\"text/javascript\">\n\nvar _gaq = _gaq || [];\n    _gaq.push(['_setAccount', 'UA-26193351-1']);\n\t_gaq.push(['_trackPageview']);\n(function() {\nvar ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;\nga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';\nvar s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);\n})();\n\n</script>\n</head>\n\n<body>\n<div id=\"container\">\n<div id=\"sidebar\">\n<figure>\n<img src=\"https://www.ics.uci.edu/~skong2/image2/icon_mgpff_small_dog.gif\" id=\"me\" width=\"200\">\n</figure>\n\n<figure>\n<img src=\"https://www.ics.uci.edu/~skong2/image2/icon_mgpff_small_soccer.gif\" id=\"me\" width=\"200\">\n<figcaption>Unsupervised Learning<p>for instance tracking</figcaption>\n</figure>\n<br>\n</div>\n\n<div id=\"content\">\n<h1 align=\"center\">Multigrid Predictive Filter Flow for Unsupervised Learning on Videos</h1>\n\n\n<p align=\"center\">\n          <a href=\"http://www.ics.uci.edu/~skong2/\" target=\"_blank\">Shu Kong</a>, \n          <a href=\"http://www.ics.uci.edu/~fowlkes/\" target=\"_blank\">Charless Fowlkes</a>\n</p>\n\n\n<p>\n<font color=\"red\">Last update: March 24, 2019.</font>\n</p>\nWe introduce multigrid Predictive Filter Flow (mgPFF), a framework for\n   unsupervised learning on videos.\n   The mgPFF takes as input a pair of frames and outputs per-pixel filters\n   to warp one frame to the other.\n   Compared to optical flow used for warping frames,\n   mgPFF is more powerful in modeling sub-pixel movement and dealing with corruption\n   (e.g., motion blur).\n   We develop a multigrid coarse-to-fine modeling strategy that avoids the\n   requirement of learning large filters to capture large displacement.\n   This allows us to train an extremely compact model (<b>4.6MB</b>)\n   which operates in a progressive way over multiple resolutions with shared\n   weights.\n   We train mgPFF on unsupervised, free-form videos and\n   show that mgPFF is able to not only estimate long-range flow for frame reconstruction\n   and detect video shot transitions,\n   but also readily amendable for video object segmentation and pose tracking,\n   where it substantially outperforms the published state-of-the-art\n   without bells and whistles.\n   Moreover,\n   owing to mgPFF's nature of per-pixel filter prediction,\n   we have the unique opportunity to visualize how each pixel is evolving\n   during solving these tasks, thus gaining better interpretability.\n\n\n\n\n<p>\n<b>keywords</b>: \nUnsupervised Learning, Multigrid Computing, Long-Range Flow, Video Segmentation, Instance Tracking, Pose Tracking,\nVideo Shot/Transition Detection, Optical Flow, Filter Flow, Low-level Vision,\n\n\n\n<ul>\n<div class=\"publication\">\n<p> <b>S. Kong</b>, C. Fowlkes, \"<font color=#AF7817>Multigrid Predictive Filter Flow for Unsupervised Learning on Videos</font>\", \n<a href=\"http://arxiv.org/abs/1904.01693\">arXiv 1904.01693</a>, 2019.\n<br>\n[<a href=\"https://www.ics.uci.edu/~skong2/mgpff.html\">project page</a>]\n[<a href=\"http://arxiv.org/abs/1904.01693\">paper</a>]\n[<a href=\"https://github.com/aimerykong/predictive-filter-flow/blob/master/mgPFF_video/demo01_videoSegTrack.ipynb\">demo</a>]\n[<a href=\"https://github.com/aimerykong/predictive-filter-flow/tree/master/mgPFF_video\">github</a>]\n[<a href=\"https://docs.google.com/presentation/d/1VcA794mt0ukg2ojUnOzbFL8HzpRjEbRp4HXULAIp13Y/edit?usp=sharing\">slides</a>]\n[poster]\n</p>\n</div>\n</ul>\n\n\n\n<p>\n<b>Acknowledgements</b>: \nThis project is supported by NSF grants IIS-1813785, IIS-1618806, IIS-1253538\nand a hardware donation from NVIDIA.\nShu Kong personally thanks Teng Liu and Etthew Kong who initiated this research,\nand the academic uncle Alexei A. Efros for the encouragement and discussion.\n\n\n\n<br><br>\n<br><br>\n\n<h1>Teaser for Ablation</h1>\n<p>\nThese videos are recorded to demonstrate how mgPFF performs with different setup. Go to \n<a href='https://www.youtube.com/playlist?list=PLeUWdu37dSLp68AsgE8RM2x-HJjU_2aEE'>Youtube Playlist</a> and refer\nto the description under each video for the setup.\n<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/videoseries?list=PLeUWdu37dSLp68AsgE8RM2x-HJjU_2aEE\" frameborder=\"0\" allow=\"accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n<br><br>\n<br><br>\n\n\n\n\n<section>\n<h1>Video Object Segmentation/Tracking</h1>\n<p>Propagating the mask using the predicted filter flow. Through visualization, \nwe have a unique opportunity to track each pixel and understand how every single pixel evolves over time.\n<div id=\"content\">\n            <center>\n              <img src=\"http://www.ics.uci.edu/~skong2/image2/show_DAVIS.png\" alt=\"[lng_lat_ecef]\" width=\"800\" />\n            </center>\n</div>\n</ul>\n<br><br>\n<br><br>\n</section>\n\n\n<section>\n<h1>Human Pose Tracking</h1>\n<p>Propagating the keypoints with the predicted filter flow. Through visualization, we have the unique opportunity to track each pixel along the skeleton and understand how every single pixel evolves over time.\n<div id=\"content\">\n\t    <center>\n\t      <img src=\"http://www.ics.uci.edu/~skong2/image2/show_JHMDB.png\" alt=\"[lng_lat_ecef]\" width=\"800\" />\n\t    </center>\n</div>\n</ul>\n<br><br>\n<br><br>\n</section>\n\n\n\n\n\n\n<section>\n<h1>Long-Range Flow for Frame Reconstruction</h1>\n<p>mgPFF captures well the long-range flow, even though we did not train with large frame intervals.\nThis is owing to the excellent reconstruction power by multigrid computing and filter flow model (powerful in capturing\nsubpixel movement and dealing with corruption, e.g., motion blur).\nThis is reminiscent of a variety of flow-based applications, e.g., video compression, unsupervised optical flow learning, frame interpolation, etc.\n<div id=\"content\">\n            <center>\n              <img src=\"http://www.ics.uci.edu/~skong2/image2/show_frameReconst.png\" alt=\"[lng_lat_ecef]\" width=\"500\" />\n            </center>\n</div>\n</ul>\n<br><br>\n<br><br>\n</section>\n\n\n\n<section>\n<h1>Video Transition Shot Detection</h1>\n<p>Purely based on the reconstruction by mgPFF, we are able to detection video transition shot. This makes training our mgPFF possible on free-form videos, e.g., long movies.\n<div id=\"content\">\n            <center>\n              <img src=\"http://www.ics.uci.edu/~skong2/image2/demo_mgpff_shotDetection.png\" alt=\"[lng_lat_ecef]\" width=\"500\" />\n            </center>\n</div>\n</ul>\n<br><br>\n<br><br>\n</section>\n\n\n\n\n<section>\n<h1>Style Transfer by mgPFF</h1>\n<p>\nThe power of mgPFF in long-range flow learning enables a native style transfer.\nJust grab the sunset in Newport Beach and Monet's painting, and translate between each other (A->B).\nThey are not great, but it seems to work :-)\n\n<div id=\"content\">\n            <center>\n              <img src=\"http://www.ics.uci.edu/~skong2/image2/demo_mgpff_style_transfer.png\" alt=\"[lng_lat_ecef]\" width=\"800\" />\n            </center>\n\n            <center>\n              <img src=\"http://www.ics.uci.edu/~skong2/image2/demo_mgpff_style_transfer_2.png\" alt=\"[lng_lat_ecef]\" width=\"800\" />\n            </center>\n\n</div>\n</ul>\n<br><br>\n<br><br>\n</section>\n\n\n\n\n\n<section>\n<h1>Sketch to Photo</h1>\n<p>\nThis simple sketch-photo translation demonstrates the power of mgPFF in correspondence learning.\nNote how the details are synthesized from the given image/sketch.\n\n<div id=\"content\">            <center>              <img src=\"http://www.ics.uci.edu/~skong2/image2/shu_to_sketch.png\" alt=\"[lng_lat_ecef]\" width=\"800\" />\n            </center>\n            <center>              <img src=\"http://www.ics.uci.edu/~skong2/image2/sketch_to_shu.png\" alt=\"[lng_lat_ecef]\" width=\"800\" />\n            </center>\n            <center>              <img src=\"http://www.ics.uci.edu/~skong2/image2/sketch_to_fowlkes.png\" alt=\"[lng_lat_ecef]\" width=\"800\" />\n            </center>\n\n</div>\n</ul>\n<br><br>\n<br><br>\n</section>\n\n\n\n\n<br clear=\"both\">\n</div>\n</div>\n\n\n\n</body>\n</HTMl>\n", "encoding": "ascii"}